{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dataset\n",
    "raw_data = pd.read_csv(\"./TrafficTwoMonth.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data[['Time', 'Day of the week', 'CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total', 'Traffic Situation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12:00:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12:15:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12:30:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12:45:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:00:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>10:45:00 PM</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>11:00:00 PM</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>11:15:00 PM</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>11:30:00 PM</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>11:45:00 PM</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time Day of the week  CarCount  BikeCount  BusCount  TruckCount  \\\n",
       "0     12:00:00 AM         Tuesday        13          2         2          24   \n",
       "1     12:15:00 AM         Tuesday        14          1         1          36   \n",
       "2     12:30:00 AM         Tuesday        10          2         2          32   \n",
       "3     12:45:00 AM         Tuesday        10          2         2          36   \n",
       "4      1:00:00 AM         Tuesday        11          2         1          34   \n",
       "...           ...             ...       ...        ...       ...         ...   \n",
       "5947  10:45:00 PM        Thursday        16          3         1          36   \n",
       "5948  11:00:00 PM        Thursday        11          0         1          30   \n",
       "5949  11:15:00 PM        Thursday        15          4         1          25   \n",
       "5950  11:30:00 PM        Thursday        16          5         0          27   \n",
       "5951  11:45:00 PM        Thursday        14          3         1          15   \n",
       "\n",
       "      Total Traffic Situation  \n",
       "0        41            normal  \n",
       "1        52            normal  \n",
       "2        46            normal  \n",
       "3        50            normal  \n",
       "4        48            normal  \n",
       "...     ...               ...  \n",
       "5947     56            normal  \n",
       "5948     42            normal  \n",
       "5949     45            normal  \n",
       "5950     48            normal  \n",
       "5951     33               low  \n",
       "\n",
       "[5952 rows x 8 columns]"
      ]
     },
     "execution_count": 1577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time                 0\n",
       "Day of the week      0\n",
       "CarCount             0\n",
       "BikeCount            0\n",
       "BusCount             0\n",
       "TruckCount           0\n",
       "Total                0\n",
       "Traffic Situation    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_6724\\3206695382.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Time'] = pd.to_datetime(df['Time']).dt.hour\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuesday      960\n",
       "Wednesday    960\n",
       "Thursday     960\n",
       "Friday       768\n",
       "Saturday     768\n",
       "Sunday       768\n",
       "Monday       768\n",
       "Name: Day of the week, dtype: int64"
      ]
     },
     "execution_count": 1581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Day of the week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_6724\\3000454048.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Day of the week'] = df['Day of the week'].replace({\n"
     ]
    }
   ],
   "source": [
    "df['Day of the week'] = df['Day of the week'].replace({\n",
    "  'Monday':1,\n",
    "  'Tuesday':2,\n",
    "  'Wednesday':3,\n",
    "  'Thursday':4,\n",
    "  'Friday':5,\n",
    "  'Saturday':6,\n",
    "  'Sunday':7\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    3610\n",
       "heavy     1137\n",
       "low        834\n",
       "high       371\n",
       "Name: Traffic Situation, dtype: int64"
      ]
     },
     "execution_count": 1583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Traffic Situation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_6724\\3943949687.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Traffic Situation'] = df['Traffic Situation'].replace({\n"
     ]
    }
   ],
   "source": [
    "df['Traffic Situation'] = df['Traffic Situation'].replace({\n",
    "  'low':0,\n",
    "  'normal':0,\n",
    "  'high':1,\n",
    "  'heavy':1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Time', 'Day of the week', 'CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total']]\n",
    "y = df[['Traffic Situation']].values.reshape(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Day of the week</th>\n",
       "      <th>CarCount</th>\n",
       "      <th>BikeCount</th>\n",
       "      <th>BusCount</th>\n",
       "      <th>TruckCount</th>\n",
       "      <th>Total</th>\n",
       "      <th>Traffic Situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time  Day of the week  CarCount  BikeCount  BusCount  TruckCount  Total  \\\n",
       "0        0                2        13          2         2          24     41   \n",
       "1        0                2        14          1         1          36     52   \n",
       "2        0                2        10          2         2          32     46   \n",
       "3        0                2        10          2         2          36     50   \n",
       "4        1                2        11          2         1          34     48   \n",
       "...    ...              ...       ...        ...       ...         ...    ...   \n",
       "5947    22                4        16          3         1          36     56   \n",
       "5948    23                4        11          0         1          30     42   \n",
       "5949    23                4        15          4         1          25     45   \n",
       "5950    23                4        16          5         0          27     48   \n",
       "5951    23                4        14          3         1          15     33   \n",
       "\n",
       "      Traffic Situation  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "5947                  0  \n",
       "5948                  0  \n",
       "5949                  0  \n",
       "5950                  0  \n",
       "5951                  0  \n",
       "\n",
       "[5952 rows x 8 columns]"
      ]
     },
     "execution_count": 1588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/100\n",
    "x_test = x_test/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement algorithm Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionAssignment:\n",
    "  def __init__(self, iteration=1000, learning_rete=0.01, c=0, penalty='l1'):\n",
    "    self.iteration = iteration\n",
    "    self.learning_rete = learning_rete\n",
    "    self.c = c\n",
    "    self.penalty=penalty.lower()\n",
    "    self.w = None\n",
    "    self.b = None\n",
    "    self.loss = []\n",
    "    self.accuracy = []\n",
    "\n",
    "  def regularization(self):\n",
    "    # L1 regularization \n",
    "    if self.penalty == 'l1':\n",
    "      return self.c*np.sign(self.w)\n",
    "    # L2 regularization \n",
    "    if self.penalty == 'l2':\n",
    "      return self.c*self.w\n",
    "    return np.zeros(self.x.shape[0])\n",
    "  \n",
    "  def sigmoid(self, z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "  def fit(self, x, y, batch_size=1, random_seed = 4):\n",
    "    np.random.seed(random_seed)\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    num_samples, num_features = x.shape\n",
    "    self.loss = []\n",
    "    self.accuracy = []\n",
    "\n",
    "    if (self.w is None and self.b is None):\n",
    "      self.w = np.random.rand(num_features)\n",
    "      self.b = 0\n",
    "\n",
    "    # Gredient descent\n",
    "    for i in range(self.iteration):\n",
    "      \n",
    "      # Calculate loss\n",
    "      loss = self.cross_entropy(x, y)\n",
    "      self.loss.append(loss)\n",
    "      accuracy = self.score(x, y)\n",
    "      self.accuracy.append(accuracy)\n",
    "      print('iterations {} accuray : {}  loss : {}'.format(i, accuracy, loss))\n",
    "\n",
    "      # Random training data\n",
    "      idx = np.random.choice(num_samples, int(batch_size*num_samples))\n",
    "      x_batch = x.iloc[idx]\n",
    "      y_batch = y[idx]\n",
    "\n",
    "      # Predict\n",
    "      z = np.dot(self.w, x_batch.T) + self.b\n",
    "      y_pred = self.sigmoid(z)\n",
    "\n",
    "      # Calculate gradient\n",
    "      gred_w = np.dot(x_batch.T, (y_pred - y_batch))/num_samples\n",
    "      gred_b = np.sum(y_pred - y_batch)/num_samples\n",
    "\n",
    "      # Regularization\n",
    "      gred_w = gred_w + self.regularization()\n",
    " \n",
    "      # Update parameter\n",
    "      self.w = self.w - (self.learning_rete*gred_w)\n",
    "      self.b = self.b - (self.learning_rete*gred_b)\n",
    "\n",
    "    return self\n",
    "\n",
    "  def predict(self, x):\n",
    "    z = np.dot(self.w, x.T) + self.b\n",
    "    probYgivenX = self.sigmoid(z)\n",
    "    return np.array([1 if p >= 0.5 else 0 for p in probYgivenX])\n",
    "\n",
    "  def score(self, x, y):\n",
    "    y_pred = self.predict(x)\n",
    "    return np.mean(y == y_pred)\n",
    "  \n",
    "  def regularization_cost(self):\n",
    "    # L1 regularization \n",
    "    if self.penalty == 'l1':\n",
    "      return self.c*np.sum(np.abs(self.w))/(2*self.x.shape[0]) \n",
    "    # L2 regularization \n",
    "    if self.penalty == 'l2':\n",
    "      return self.c*np.sum(np.square(self.w))/(2*self.x.shape[0]) \n",
    "    return 0\n",
    "  \n",
    "  def cross_entropy(self, x, y):\n",
    "    eps = 1e-15  # Small constant value to prevent division by zero\n",
    "    z = np.dot(self.w, x.T) + self.b\n",
    "    y_pred = self.sigmoid(z)\n",
    "    return -(np.dot(y.T,np.log(y_pred + eps)) + np.dot((1-y).T, np.log(1-y_pred + eps)))/x.shape[0] + self.regularization_cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations 0 accuray : 0.2495274102079395  loss : 1.3682376973352492\n",
      "iterations 1 accuray : 0.2495274102079395  loss : 1.3622653792675994\n",
      "iterations 2 accuray : 0.2495274102079395  loss : 1.3562506066087827\n",
      "iterations 3 accuray : 0.2495274102079395  loss : 1.3504332732016708\n",
      "iterations 4 accuray : 0.2495274102079395  loss : 1.3444792468801805\n",
      "iterations 5 accuray : 0.2495274102079395  loss : 1.3385782688184356\n",
      "iterations 6 accuray : 0.2495274102079395  loss : 1.3326075032258613\n",
      "iterations 7 accuray : 0.2495274102079395  loss : 1.3266399372434172\n",
      "iterations 8 accuray : 0.2495274102079395  loss : 1.3208215955727705\n",
      "iterations 9 accuray : 0.2495274102079395  loss : 1.3149680935962578\n",
      "iterations 10 accuray : 0.2495274102079395  loss : 1.3092786368848075\n",
      "iterations 11 accuray : 0.2495274102079395  loss : 1.3033628395545345\n",
      "iterations 12 accuray : 0.2495274102079395  loss : 1.2976411755209614\n",
      "iterations 13 accuray : 0.2495274102079395  loss : 1.2919061953317534\n",
      "iterations 14 accuray : 0.2495274102079395  loss : 1.2861938821315149\n",
      "iterations 15 accuray : 0.2495274102079395  loss : 1.280425715061247\n",
      "iterations 16 accuray : 0.2495274102079395  loss : 1.274728875393524\n",
      "iterations 17 accuray : 0.2495274102079395  loss : 1.269195454173487\n",
      "iterations 18 accuray : 0.2495274102079395  loss : 1.263690080683513\n",
      "iterations 19 accuray : 0.2495274102079395  loss : 1.2583015615430728\n",
      "iterations 20 accuray : 0.2495274102079395  loss : 1.2528423497141226\n",
      "iterations 21 accuray : 0.2495274102079395  loss : 1.2473110783568542\n",
      "iterations 22 accuray : 0.2495274102079395  loss : 1.2417087522996058\n",
      "iterations 23 accuray : 0.2495274102079395  loss : 1.2362133258620012\n",
      "iterations 24 accuray : 0.2495274102079395  loss : 1.2306976276147388\n",
      "iterations 25 accuray : 0.2495274102079395  loss : 1.2252034553649425\n",
      "iterations 26 accuray : 0.2495274102079395  loss : 1.2198911154113414\n",
      "iterations 27 accuray : 0.2495274102079395  loss : 1.2144552736311287\n",
      "iterations 28 accuray : 0.2495274102079395  loss : 1.2090884323067532\n",
      "iterations 29 accuray : 0.2495274102079395  loss : 1.2037120364895986\n",
      "iterations 30 accuray : 0.2495274102079395  loss : 1.1985036568419682\n",
      "iterations 31 accuray : 0.2495274102079395  loss : 1.1932673513261987\n",
      "iterations 32 accuray : 0.2495274102079395  loss : 1.1880584940861296\n",
      "iterations 33 accuray : 0.2495274102079395  loss : 1.1829180907688046\n",
      "iterations 34 accuray : 0.2495274102079395  loss : 1.1777065049479825\n",
      "iterations 35 accuray : 0.2495274102079395  loss : 1.1726041219279049\n",
      "iterations 36 accuray : 0.2495274102079395  loss : 1.1674387538434197\n",
      "iterations 37 accuray : 0.2495274102079395  loss : 1.1622875653850728\n",
      "iterations 38 accuray : 0.2495274102079395  loss : 1.1570763115786051\n",
      "iterations 39 accuray : 0.2495274102079395  loss : 1.1519853982644663\n",
      "iterations 40 accuray : 0.2495274102079395  loss : 1.146899420193735\n",
      "iterations 41 accuray : 0.2495274102079395  loss : 1.1417482137079165\n",
      "iterations 42 accuray : 0.2495274102079395  loss : 1.1367071874177468\n",
      "iterations 43 accuray : 0.2495274102079395  loss : 1.131574648836326\n",
      "iterations 44 accuray : 0.2495274102079395  loss : 1.1266770653311804\n",
      "iterations 45 accuray : 0.2495274102079395  loss : 1.1217437542703295\n",
      "iterations 46 accuray : 0.2495274102079395  loss : 1.116769112613742\n",
      "iterations 47 accuray : 0.2495274102079395  loss : 1.1119314129243978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations 48 accuray : 0.2495274102079395  loss : 1.1070966748419295\n",
      "iterations 49 accuray : 0.2495274102079395  loss : 1.1023400811054131\n",
      "iterations 50 accuray : 0.2495274102079395  loss : 1.0974635827343597\n",
      "iterations 51 accuray : 0.2495274102079395  loss : 1.0926190775542235\n",
      "iterations 52 accuray : 0.2495274102079395  loss : 1.087941286618923\n",
      "iterations 53 accuray : 0.2495274102079395  loss : 1.0831541734993264\n",
      "iterations 54 accuray : 0.2495274102079395  loss : 1.0783681680116746\n",
      "iterations 55 accuray : 0.2495274102079395  loss : 1.073724135445662\n",
      "iterations 56 accuray : 0.2495274102079395  loss : 1.0689256588353755\n",
      "iterations 57 accuray : 0.2495274102079395  loss : 1.0643083992428182\n",
      "iterations 58 accuray : 0.2495274102079395  loss : 1.0597541225196145\n",
      "iterations 59 accuray : 0.2495274102079395  loss : 1.0551932522746912\n",
      "iterations 60 accuray : 0.2495274102079395  loss : 1.0505688234196529\n",
      "iterations 61 accuray : 0.2495274102079395  loss : 1.0459613622010067\n",
      "iterations 62 accuray : 0.2495274102079395  loss : 1.0414432892674919\n",
      "iterations 63 accuray : 0.2495274102079395  loss : 1.0368793446096012\n",
      "iterations 64 accuray : 0.2495274102079395  loss : 1.032448906000772\n",
      "iterations 65 accuray : 0.24973745011552195  loss : 1.0280140992946514\n",
      "iterations 66 accuray : 0.2499474900231044  loss : 1.0236256718593804\n",
      "iterations 67 accuray : 0.25015752993068685  loss : 1.019301617156578\n",
      "iterations 68 accuray : 0.25015752993068685  loss : 1.0150276947697268\n",
      "iterations 69 accuray : 0.25036756983826924  loss : 1.0105999142059097\n",
      "iterations 70 accuray : 0.25036756983826924  loss : 1.0063817387796004\n",
      "iterations 71 accuray : 0.2509976895610166  loss : 1.00213300907341\n",
      "iterations 72 accuray : 0.25162780928376394  loss : 0.9978613738529067\n",
      "iterations 73 accuray : 0.2526780088216761  loss : 0.9936247268329925\n",
      "iterations 74 accuray : 0.2533081285444234  loss : 0.9894611225284323\n",
      "iterations 75 accuray : 0.2547784078975005  loss : 0.985200870217287\n",
      "iterations 76 accuray : 0.2551984877126654  loss : 0.9810305976767694\n",
      "iterations 77 accuray : 0.2560386473429952  loss : 0.9768811951475344\n",
      "iterations 78 accuray : 0.2579290065112371  loss : 0.9727125052913124\n",
      "iterations 79 accuray : 0.2598193656794791  loss : 0.9686571972793596\n",
      "iterations 80 accuray : 0.26149968494013864  loss : 0.9646099321960269\n",
      "iterations 81 accuray : 0.26423020373871037  loss : 0.960554128215824\n",
      "iterations 82 accuray : 0.2659105229993699  loss : 0.9565352235133417\n",
      "iterations 83 accuray : 0.2680109220751943  loss : 0.9524862896394265\n",
      "iterations 84 accuray : 0.2701113211510187  loss : 0.9486038172677008\n",
      "iterations 85 accuray : 0.27284183994959044  loss : 0.9446765449536417\n",
      "iterations 86 accuray : 0.27473219911783237  loss : 0.9408041151156797\n",
      "iterations 87 accuray : 0.2768325981936568  loss : 0.9369829013640875\n",
      "iterations 88 accuray : 0.2799831968073934  loss : 0.9330081695201046\n",
      "iterations 89 accuray : 0.28334383532871243  loss : 0.9290729852855506\n",
      "iterations 90 accuray : 0.28607435412728416  loss : 0.9253781074771851\n",
      "iterations 91 accuray : 0.28901491283343833  loss : 0.9215706512721299\n",
      "iterations 92 accuray : 0.2919554715395925  loss : 0.9177471323657455\n",
      "iterations 93 accuray : 0.29405587061541694  loss : 0.9141154536522949\n",
      "iterations 94 accuray : 0.2976265490443184  loss : 0.9104426609868919\n",
      "iterations 95 accuray : 0.3005671077504726  loss : 0.9068661714949422\n",
      "iterations 96 accuray : 0.30497794580970383  loss : 0.9031696832878544\n",
      "iterations 97 accuray : 0.3093887838689351  loss : 0.8995475688060389\n",
      "iterations 98 accuray : 0.313169502205419  loss : 0.8959362752181653\n",
      "iterations 99 accuray : 0.3177903801722327  loss : 0.8923950575091456\n",
      "iterations 100 accuray : 0.3219911783238815  loss : 0.8887992964819283\n",
      "iterations 101 accuray : 0.3268220961982777  loss : 0.8852315939206509\n",
      "iterations 102 accuray : 0.3306028145347616  loss : 0.8817749693331628\n",
      "iterations 103 accuray : 0.337954211300147  loss : 0.8782904176321478\n",
      "iterations 104 accuray : 0.34341524889729047  loss : 0.8748949219009113\n",
      "iterations 105 accuray : 0.3482461667716866  loss : 0.8714223106568063\n",
      "iterations 106 accuray : 0.35622768325981935  loss : 0.867957429680805\n",
      "iterations 107 accuray : 0.3621088006721277  loss : 0.8644532353126622\n",
      "iterations 108 accuray : 0.3663095988237765  loss : 0.8611026791309243\n",
      "iterations 109 accuray : 0.37156059651333756  loss : 0.8577462883477386\n",
      "iterations 110 accuray : 0.37639151438773366  loss : 0.854477126473338\n",
      "iterations 111 accuray : 0.38311279143037175  loss : 0.8511542353404693\n",
      "iterations 112 accuray : 0.3879437093047679  loss : 0.8478424080007437\n",
      "iterations 113 accuray : 0.3898340684730099  loss : 0.844612016415404\n",
      "iterations 114 accuray : 0.3936147868094938  loss : 0.8414054163831328\n",
      "iterations 115 accuray : 0.39760554505356016  loss : 0.838196198275181\n",
      "iterations 116 accuray : 0.40096618357487923  loss : 0.8350374324663182\n",
      "iterations 117 accuray : 0.4039067422810334  loss : 0.8318899163235867\n",
      "iterations 118 accuray : 0.40747742070993487  loss : 0.8288185474281732\n",
      "iterations 119 accuray : 0.40978785969334175  loss : 0.8257571847915348\n",
      "iterations 120 accuray : 0.4137786179374081  loss : 0.8227210448706438\n",
      "iterations 121 accuray : 0.419449695442134  loss : 0.8196739864727898\n",
      "iterations 122 accuray : 0.421340054610376  loss : 0.816637939696718\n",
      "iterations 123 accuray : 0.42386053350136527  loss : 0.8135562874448216\n",
      "iterations 124 accuray : 0.426591052299937  loss : 0.8105853363942415\n",
      "iterations 125 accuray : 0.4307918504515858  loss : 0.8075804897239269\n",
      "iterations 126 accuray : 0.4333123293425751  loss : 0.804642777383428\n",
      "iterations 127 accuray : 0.43583280823356435  loss : 0.8017254946729653\n",
      "iterations 128 accuray : 0.43772316740180633  loss : 0.7987930326799567\n",
      "iterations 129 accuray : 0.4410838059231254  loss : 0.7959238488372159\n",
      "iterations 130 accuray : 0.4444444444444444  loss : 0.7931382253649546\n",
      "iterations 131 accuray : 0.4473850031505986  loss : 0.7902481657819392\n",
      "iterations 132 accuray : 0.4505356017643352  loss : 0.7874319839602754\n",
      "iterations 133 accuray : 0.4543163201008192  loss : 0.7845685306815398\n",
      "iterations 134 accuray : 0.4562066792690611  loss : 0.7817625881036288\n",
      "iterations 135 accuray : 0.45830707834488554  loss : 0.7790231833923776\n",
      "iterations 136 accuray : 0.46166771686620456  loss : 0.7763141167841899\n",
      "iterations 137 accuray : 0.4660785549254358  loss : 0.7735567410541583\n",
      "iterations 138 accuray : 0.4679689140936778  loss : 0.7708875372046493\n",
      "iterations 139 accuray : 0.47132955261499687  loss : 0.7683005231382376\n",
      "iterations 140 accuray : 0.47385003150598615  loss : 0.7656096995018811\n",
      "iterations 141 accuray : 0.4778407897500525  loss : 0.7629856709365764\n",
      "iterations 142 accuray : 0.4816215080865364  loss : 0.760393092133751\n",
      "iterations 143 accuray : 0.4845620667926906  loss : 0.7578350773107491\n",
      "iterations 144 accuray : 0.48750262549884477  loss : 0.7552843706347223\n",
      "iterations 145 accuray : 0.4891829447595043  loss : 0.7528561915516515\n",
      "iterations 146 accuray : 0.491913463558076  loss : 0.7504112420902869\n",
      "iterations 147 accuray : 0.49401386263390046  loss : 0.7478776479995509\n",
      "iterations 148 accuray : 0.497164461247637  loss : 0.7453963163817019\n",
      "iterations 149 accuray : 0.49926486032346146  loss : 0.7429959059744864\n",
      "iterations 150 accuray : 0.5017853392144508  loss : 0.7405019691790128\n",
      "iterations 151 accuray : 0.502835538752363  loss : 0.7381182820741234\n",
      "iterations 152 accuray : 0.5053560176433523  loss : 0.7357231009335078\n",
      "iterations 153 accuray : 0.5070363369040117  loss : 0.7333777183752874\n",
      "iterations 154 accuray : 0.5093467758874186  loss : 0.7310457758955908\n",
      "iterations 155 accuray : 0.5106070153329133  loss : 0.7286860034174457\n",
      "iterations 156 accuray : 0.5127074144087377  loss : 0.7263887729905917\n",
      "iterations 157 accuray : 0.5137576139466499  loss : 0.7241117851657716\n",
      "iterations 158 accuray : 0.515227893299727  loss : 0.7218879927921733\n",
      "iterations 159 accuray : 0.5175383322831338  loss : 0.7196738837418445\n",
      "iterations 160 accuray : 0.5187985717286284  loss : 0.7174397639351076\n",
      "iterations 161 accuray : 0.5200588111741231  loss : 0.7152169730005999\n",
      "iterations 162 accuray : 0.5217391304347826  loss : 0.7131044676042778\n",
      "iterations 163 accuray : 0.5232094097878597  loss : 0.7109453801291291\n",
      "iterations 164 accuray : 0.5244696492333544  loss : 0.7088048857374128\n",
      "iterations 165 accuray : 0.5259399285864315  loss : 0.7067135087765138\n",
      "iterations 166 accuray : 0.5276202478470909  loss : 0.7046952395510554\n",
      "iterations 167 accuray : 0.5288804872925856  loss : 0.70260412671394\n",
      "iterations 168 accuray : 0.5297206469229153  loss : 0.7005353830807269\n",
      "iterations 169 accuray : 0.5307708464608275  loss : 0.6984702451540347\n",
      "iterations 170 accuray : 0.5320310859063222  loss : 0.6964123344417978\n",
      "iterations 171 accuray : 0.5335013652593993  loss : 0.6943647950867534\n",
      "iterations 172 accuray : 0.5353917244276413  loss : 0.6923495875127762\n",
      "iterations 173 accuray : 0.5372820835958833  loss : 0.6903570635643009\n",
      "iterations 174 accuray : 0.5398025624868725  loss : 0.6883292476567753\n",
      "iterations 175 accuray : 0.5398025624868725  loss : 0.6863955277868194\n",
      "iterations 176 accuray : 0.5423230413778618  loss : 0.6844850769199736\n",
      "iterations 177 accuray : 0.5429531611006091  loss : 0.6825305012679687\n",
      "iterations 178 accuray : 0.5440033606385213  loss : 0.6807153645771431\n",
      "iterations 179 accuray : 0.5463137996219282  loss : 0.6787452727226128\n",
      "iterations 180 accuray : 0.5488342785129174  loss : 0.6768940728918037\n",
      "iterations 181 accuray : 0.5503045578659945  loss : 0.6750808208417294\n",
      "iterations 182 accuray : 0.5509346775887418  loss : 0.6732989312743713\n",
      "iterations 183 accuray : 0.5521949170342365  loss : 0.6714884228203148\n",
      "iterations 184 accuray : 0.553875236294896  loss : 0.669748305211349\n",
      "iterations 185 accuray : 0.5561856752783029  loss : 0.6679487011032497\n",
      "iterations 186 accuray : 0.5580760344465449  loss : 0.6661217111719998\n",
      "iterations 187 accuray : 0.5595463137996219  loss : 0.664394779161565\n",
      "iterations 188 accuray : 0.5601764335223692  loss : 0.6627150543702529\n",
      "iterations 189 accuray : 0.5624868725057761  loss : 0.6609185515673393\n",
      "iterations 190 accuray : 0.564797311489183  loss : 0.6592824654072734\n",
      "iterations 191 accuray : 0.5666876706574249  loss : 0.6575901980642574\n",
      "iterations 192 accuray : 0.5683679899180845  loss : 0.6558665762772625\n",
      "iterations 193 accuray : 0.5702583490863264  loss : 0.6542429149105351\n",
      "iterations 194 accuray : 0.5725687880697332  loss : 0.652572693789639\n",
      "iterations 195 accuray : 0.5748792270531401  loss : 0.6509745308799229\n",
      "iterations 196 accuray : 0.5778197857592943  loss : 0.6493969581187412\n",
      "iterations 197 accuray : 0.5797101449275363  loss : 0.6477726650234031\n",
      "iterations 198 accuray : 0.5818105440033606  loss : 0.6462535377433439\n",
      "iterations 199 accuray : 0.5847511027095148  loss : 0.6447087055788263\n",
      "iterations 200 accuray : 0.5872715816005041  loss : 0.6431655389539397\n",
      "iterations 201 accuray : 0.5889519008611637  loss : 0.641655594741879\n",
      "iterations 202 accuray : 0.5916824196597353  loss : 0.6401812205474567\n",
      "iterations 203 accuray : 0.5942028985507246  loss : 0.6386737040591045\n",
      "iterations 204 accuray : 0.5977735769796261  loss : 0.6371772706928941\n",
      "iterations 205 accuray : 0.5996639361478681  loss : 0.6357049262987692\n",
      "iterations 206 accuray : 0.60155429531611  loss : 0.6342799542215617\n",
      "iterations 207 accuray : 0.6044948540222642  loss : 0.6328502996169246\n",
      "iterations 208 accuray : 0.6078554925435833  loss : 0.6314181130808982\n",
      "iterations 209 accuray : 0.6103759714345726  loss : 0.6299377129525086\n",
      "iterations 210 accuray : 0.6128964503255618  loss : 0.6285004232909885\n",
      "iterations 211 accuray : 0.6154169292165511  loss : 0.6270552683824283\n",
      "iterations 212 accuray : 0.6175173282923756  loss : 0.6256873034408087\n",
      "iterations 213 accuray : 0.6206679269061122  loss : 0.6243369965763382\n",
      "iterations 214 accuray : 0.6242386053350136  loss : 0.6229711791375707\n",
      "iterations 215 accuray : 0.626339004410838  loss : 0.6216731544695894\n",
      "iterations 216 accuray : 0.6286494433942449  loss : 0.6202969196290196\n",
      "iterations 217 accuray : 0.6313799621928167  loss : 0.6189406333897297\n",
      "iterations 218 accuray : 0.633480361268641  loss : 0.6175965790415205\n",
      "iterations 219 accuray : 0.6357908002520479  loss : 0.616306127747555\n",
      "iterations 220 accuray : 0.6395715185885318  loss : 0.6149874653941032\n",
      "iterations 221 accuray : 0.6429321571098509  loss : 0.6136896069240505\n",
      "iterations 222 accuray : 0.6448225162780928  loss : 0.6123788955123457\n",
      "iterations 223 accuray : 0.6490233144297417  loss : 0.6111522442615555\n",
      "iterations 224 accuray : 0.6521739130434783  loss : 0.6098983842223086\n",
      "iterations 225 accuray : 0.6546943919344675  loss : 0.6087109347615517\n",
      "iterations 226 accuray : 0.6588951900861164  loss : 0.607487618942508\n",
      "iterations 227 accuray : 0.6622558286074354  loss : 0.6063271768426391\n",
      "iterations 228 accuray : 0.665406427221172  loss : 0.6051373172188942\n",
      "iterations 229 accuray : 0.6679269061121613  loss : 0.6039747354949128\n",
      "iterations 230 accuray : 0.6698172652804033  loss : 0.602816179933691\n",
      "iterations 231 accuray : 0.6721277042638101  loss : 0.6016542093386713\n",
      "iterations 232 accuray : 0.674438143247217  loss : 0.6004909172792187\n",
      "iterations 233 accuray : 0.6794791010291955  loss : 0.5992989008522526\n",
      "iterations 234 accuray : 0.6817895400126024  loss : 0.5981808424376428\n",
      "iterations 235 accuray : 0.6851501785339215  loss : 0.597084259785258\n",
      "iterations 236 accuray : 0.688300777147658  loss : 0.5959861595277246\n",
      "iterations 237 accuray : 0.692081495484142  loss : 0.594898734930853\n",
      "iterations 238 accuray : 0.6935517748372191  loss : 0.5938654968515366\n",
      "iterations 239 accuray : 0.695862213820626  loss : 0.592856754931896\n",
      "iterations 240 accuray : 0.6990128124343625  loss : 0.5917751791847565\n",
      "iterations 241 accuray : 0.7009031716026045  loss : 0.5907497643928393\n",
      "iterations 242 accuray : 0.7032136105860114  loss : 0.5897346694131973\n",
      "iterations 243 accuray : 0.7051039697542533  loss : 0.5887566785939956\n",
      "iterations 244 accuray : 0.706364209199748  loss : 0.587725290755063\n",
      "iterations 245 accuray : 0.7101449275362319  loss : 0.5866922057745043\n",
      "iterations 246 accuray : 0.7114051669817265  loss : 0.5857338993308503\n",
      "iterations 247 accuray : 0.7139256458727158  loss : 0.5847432647582741\n",
      "iterations 248 accuray : 0.7166561646712876  loss : 0.5837409473118574\n",
      "iterations 249 accuray : 0.7195967233774417  loss : 0.5827749692425243\n",
      "iterations 250 accuray : 0.7227473219911783  loss : 0.5817996942790583\n",
      "iterations 251 accuray : 0.7252678008821676  loss : 0.5808774558756564\n",
      "iterations 252 accuray : 0.7273681999579921  loss : 0.5799090645880851\n",
      "iterations 253 accuray : 0.730728838479311  loss : 0.5789807210002693\n",
      "iterations 254 accuray : 0.7334593572778828  loss : 0.5780680472273071\n",
      "iterations 255 accuray : 0.7368199957992019  loss : 0.5771826537427136\n",
      "iterations 256 accuray : 0.7391304347826086  loss : 0.5763384170594237\n",
      "iterations 257 accuray : 0.7399705944129384  loss : 0.5753877025533627\n",
      "iterations 258 accuray : 0.7412308338584331  loss : 0.5744777644079436\n",
      "iterations 259 accuray : 0.7441713925645873  loss : 0.5736182485455376\n",
      "iterations 260 accuray : 0.7481621508086537  loss : 0.572798025722975\n",
      "iterations 261 accuray : 0.7494223902541483  loss : 0.5719389753006291\n",
      "iterations 262 accuray : 0.7525729888678849  loss : 0.5710816595150559\n",
      "iterations 263 accuray : 0.7550934677588742  loss : 0.5702451903536669\n",
      "iterations 264 accuray : 0.7574039067422811  loss : 0.5694773919809498\n",
      "iterations 265 accuray : 0.7605545053560177  loss : 0.5686516558938199\n",
      "iterations 266 accuray : 0.7632850241545893  loss : 0.5678630164135298\n",
      "iterations 267 accuray : 0.7676958622138206  loss : 0.5670550155508268\n",
      "iterations 268 accuray : 0.7697962612896451  loss : 0.5662787540517055\n",
      "iterations 269 accuray : 0.7704263810123924  loss : 0.5655040315318354\n",
      "iterations 270 accuray : 0.7723167401806343  loss : 0.5647688534959442\n",
      "iterations 271 accuray : 0.7748372190716236  loss : 0.5640089308818181\n",
      "iterations 272 accuray : 0.7773576979626129  loss : 0.5633103153267085\n",
      "iterations 273 accuray : 0.77882797731569  loss : 0.5625535483825842\n",
      "iterations 274 accuray : 0.7802982566687671  loss : 0.5618245025614079\n",
      "iterations 275 accuray : 0.7817685360218442  loss : 0.561077382482319\n",
      "iterations 276 accuray : 0.7838689350976685  loss : 0.5602841259921116\n",
      "iterations 277 accuray : 0.7853392144507456  loss : 0.5595494810456834\n",
      "iterations 278 accuray : 0.7878596933417349  loss : 0.5588824776727357\n",
      "iterations 279 accuray : 0.7889098928796471  loss : 0.5582070062391202\n",
      "iterations 280 accuray : 0.7905902121403067  loss : 0.5575352131650154\n",
      "iterations 281 accuray : 0.7939508506616257  loss : 0.5568387299005313\n",
      "iterations 282 accuray : 0.7956311699222852  loss : 0.5561470646019925\n",
      "iterations 283 accuray : 0.7977315689981096  loss : 0.5555030959644385\n",
      "iterations 284 accuray : 0.7985717286284394  loss : 0.5548385027852246\n",
      "iterations 285 accuray : 0.7996219281663516  loss : 0.5541692816650637\n",
      "iterations 286 accuray : 0.8008821676118463  loss : 0.553483544491604\n",
      "iterations 287 accuray : 0.8021424070573409  loss : 0.5528590517568762\n",
      "iterations 288 accuray : 0.8044528460407477  loss : 0.5522308809299881\n",
      "iterations 289 accuray : 0.8059231253938248  loss : 0.551595580886888\n",
      "iterations 290 accuray : 0.8065532451165721  loss : 0.5509408921762285\n",
      "iterations 291 accuray : 0.8090737240075614  loss : 0.5503074434417559\n",
      "iterations 292 accuray : 0.8105440033606385  loss : 0.5496669351747053\n",
      "iterations 293 accuray : 0.8132745221592103  loss : 0.5490850193907651\n",
      "iterations 294 accuray : 0.81411468178954  loss : 0.5484663685434478\n",
      "iterations 295 accuray : 0.8162150808653644  loss : 0.5478576965812788\n",
      "iterations 296 accuray : 0.817475320310859  loss : 0.5472689806915175\n",
      "iterations 297 accuray : 0.8191556395715186  loss : 0.5466086798884906\n",
      "iterations 298 accuray : 0.8204158790170132  loss : 0.5459948842273866\n",
      "iterations 299 accuray : 0.8216761184625079  loss : 0.5454037928864744\n",
      "iterations 300 accuray : 0.8233564377231674  loss : 0.5448313424454391\n",
      "iterations 301 accuray : 0.824616677168662  loss : 0.5442410747559676\n",
      "iterations 302 accuray : 0.8273471959672338  loss : 0.543702345975251\n",
      "iterations 303 accuray : 0.8279773156899811  loss : 0.5431374583957407\n",
      "iterations 304 accuray : 0.8292375551354757  loss : 0.5425426720545594\n",
      "iterations 305 accuray : 0.8298676748582231  loss : 0.5419918653799973\n",
      "iterations 306 accuray : 0.8307078344885528  loss : 0.5414504081406041\n",
      "iterations 307 accuray : 0.8325981936567948  loss : 0.5409309492285326\n",
      "iterations 308 accuray : 0.835118672547784  loss : 0.5403929472539412\n",
      "iterations 309 accuray : 0.8346985927326191  loss : 0.5398422034743323\n",
      "iterations 310 accuray : 0.8367989918084436  loss : 0.539309855041323\n",
      "iterations 311 accuray : 0.8380592312539382  loss : 0.53880852455859\n",
      "iterations 312 accuray : 0.8384793110691031  loss : 0.5383249898679977\n",
      "iterations 313 accuray : 0.8397395505145978  loss : 0.5378141163673\n",
      "iterations 314 accuray : 0.8412098298676749  loss : 0.5373047306250913\n",
      "iterations 315 accuray : 0.8420499894980046  loss : 0.5368002172988531\n",
      "iterations 316 accuray : 0.8428901491283344  loss : 0.5362961919017758\n",
      "iterations 317 accuray : 0.8428901491283344  loss : 0.5357996550882418\n",
      "iterations 318 accuray : 0.8435202688510817  loss : 0.535320440079766\n",
      "iterations 319 accuray : 0.8445704683889939  loss : 0.5348344956022107\n",
      "iterations 320 accuray : 0.8458307078344885  loss : 0.5343748918345756\n",
      "iterations 321 accuray : 0.8477210670027305  loss : 0.5338852323323541\n",
      "iterations 322 accuray : 0.8491913463558076  loss : 0.5334245016091734\n",
      "iterations 323 accuray : 0.8504515858013022  loss : 0.5329428782774058\n",
      "iterations 324 accuray : 0.8525519848771267  loss : 0.5324460819478258\n",
      "iterations 325 accuray : 0.8546523839529511  loss : 0.5319759778909494\n",
      "iterations 326 accuray : 0.8563327032136105  loss : 0.5314984764702252\n",
      "iterations 327 accuray : 0.8578029825666876  loss : 0.5310617220317795\n",
      "iterations 328 accuray : 0.8596933417349296  loss : 0.5306252134241218\n",
      "iterations 329 accuray : 0.8607435412728418  loss : 0.5301611199762194\n",
      "iterations 330 accuray : 0.8615837009031716  loss : 0.5297396306097616\n",
      "iterations 331 accuray : 0.8622138206259189  loss : 0.5292886952036889\n",
      "iterations 332 accuray : 0.8628439403486663  loss : 0.5288773975362298\n",
      "iterations 333 accuray : 0.8643142197017434  loss : 0.528419522833477\n",
      "iterations 334 accuray : 0.865574459147238  loss : 0.5280126449432403\n",
      "iterations 335 accuray : 0.867044738500315  loss : 0.5275810395856361\n",
      "iterations 336 accuray : 0.8685150178533921  loss : 0.5271870162650331\n",
      "iterations 337 accuray : 0.8693551774837219  loss : 0.5267718971273511\n",
      "iterations 338 accuray : 0.870825456836799  loss : 0.5263701498712624\n",
      "iterations 339 accuray : 0.8731358958202058  loss : 0.5259617423407094\n",
      "iterations 340 accuray : 0.8746061751732829  loss : 0.5255597432562815\n",
      "iterations 341 accuray : 0.8754463348036127  loss : 0.5251640232873396\n",
      "iterations 342 accuray : 0.8764965343415249  loss : 0.5247618141521486\n",
      "iterations 343 accuray : 0.8773366939718547  loss : 0.5243737919445137\n",
      "iterations 344 accuray : 0.8783868935097668  loss : 0.5240159106284383\n",
      "iterations 345 accuray : 0.8796471329552615  loss : 0.5236220935355971\n",
      "iterations 346 accuray : 0.8802772526780088  loss : 0.523251026972485\n",
      "iterations 347 accuray : 0.8825876916614157  loss : 0.5228774304853296\n",
      "iterations 348 accuray : 0.8830077714765806  loss : 0.522504468073433\n",
      "iterations 349 accuray : 0.8844780508296576  loss : 0.5221291795876948\n",
      "iterations 350 accuray : 0.8859483301827347  loss : 0.5217603973667743\n",
      "iterations 351 accuray : 0.8878386893509767  loss : 0.5213899612683754\n",
      "iterations 352 accuray : 0.8890989287964713  loss : 0.5210466974762296\n",
      "iterations 353 accuray : 0.8907792480571308  loss : 0.5206746678563063\n",
      "iterations 354 accuray : 0.8920394875026255  loss : 0.5203013777319585\n",
      "iterations 355 accuray : 0.8932997269481201  loss : 0.519972951463287\n",
      "iterations 356 accuray : 0.8935097668557026  loss : 0.5196317062906035\n",
      "iterations 357 accuray : 0.8941398865784499  loss : 0.5192847486994382\n",
      "iterations 358 accuray : 0.8951900861163621  loss : 0.518974822279144\n",
      "iterations 359 accuray : 0.8949800462087797  loss : 0.5186292116185086\n",
      "iterations 360 accuray : 0.8951900861163621  loss : 0.5183264224071096\n",
      "iterations 361 accuray : 0.8964503255618568  loss : 0.5179889355144516\n",
      "iterations 362 accuray : 0.8968704053770217  loss : 0.5176516463602909\n",
      "iterations 363 accuray : 0.897500525099769  loss : 0.5173225990660025\n",
      "iterations 364 accuray : 0.8985507246376812  loss : 0.5169618328530936\n",
      "iterations 365 accuray : 0.8998109640831758  loss : 0.5166487696985601\n",
      "iterations 366 accuray : 0.9012812434362529  loss : 0.516327759471049\n",
      "iterations 367 accuray : 0.9019113631590002  loss : 0.5160196373037698\n",
      "iterations 368 accuray : 0.9025414828817475  loss : 0.5156900087643845\n",
      "iterations 369 accuray : 0.9031716026044948  loss : 0.5153567561225846\n",
      "iterations 370 accuray : 0.9035916824196597  loss : 0.5150400207611434\n",
      "iterations 371 accuray : 0.9042218021424071  loss : 0.5147406144340785\n",
      "iterations 372 accuray : 0.9054820415879017  loss : 0.5144207468105096\n",
      "iterations 373 accuray : 0.9073724007561437  loss : 0.5141002079833794\n",
      "iterations 374 accuray : 0.908002520478891  loss : 0.5138254168441175\n",
      "iterations 375 accuray : 0.9088426801092208  loss : 0.5135274542176063\n",
      "iterations 376 accuray : 0.909472799831968  loss : 0.5132365636681178\n",
      "iterations 377 accuray : 0.9103129594622978  loss : 0.512938376826867\n",
      "iterations 378 accuray : 0.91136315900021  loss : 0.5126522675662486\n",
      "iterations 379 accuray : 0.91136315900021  loss : 0.5123597482065714\n",
      "iterations 380 accuray : 0.91136315900021  loss : 0.5120866509364584\n",
      "iterations 381 accuray : 0.9126233984457047  loss : 0.5117906494082587\n",
      "iterations 382 accuray : 0.9134635580760344  loss : 0.5114747038984191\n",
      "iterations 383 accuray : 0.9143037177063642  loss : 0.5112015942694945\n",
      "iterations 384 accuray : 0.9147237975215291  loss : 0.5109150725087733\n",
      "iterations 385 accuray : 0.915143877336694  loss : 0.5106302242635017\n",
      "iterations 386 accuray : 0.9164041167821886  loss : 0.5103395562625638\n",
      "iterations 387 accuray : 0.917034236504936  loss : 0.5100737832591145\n",
      "iterations 388 accuray : 0.917034236504936  loss : 0.5098093843131712\n",
      "iterations 389 accuray : 0.9174543163201008  loss : 0.5095678104359318\n",
      "iterations 390 accuray : 0.9182944759504306  loss : 0.5093002441942364\n",
      "iterations 391 accuray : 0.9195547153959253  loss : 0.5090238680114231\n",
      "iterations 392 accuray : 0.9193446754883428  loss : 0.5087521817117603\n",
      "iterations 393 accuray : 0.9199747952110902  loss : 0.5084895613921714\n",
      "iterations 394 accuray : 0.9203948750262549  loss : 0.5082296407891271\n",
      "iterations 395 accuray : 0.9210249947490023  loss : 0.5079730789975107\n",
      "iterations 396 accuray : 0.9212350346565847  loss : 0.5077257011431527\n",
      "iterations 397 accuray : 0.9229153539172443  loss : 0.5074603534398866\n",
      "iterations 398 accuray : 0.9227053140096618  loss : 0.5071999153042576\n",
      "iterations 399 accuray : 0.9241755933627389  loss : 0.506948854990694\n",
      "iterations 400 accuray : 0.9248057130854862  loss : 0.5066826339971169\n",
      "iterations 401 accuray : 0.9250157529930687  loss : 0.5064568475980514\n",
      "iterations 402 accuray : 0.9262759924385633  loss : 0.5062156417632022\n",
      "iterations 403 accuray : 0.9271161520688931  loss : 0.505977017875836\n",
      "iterations 404 accuray : 0.9279563116992229  loss : 0.5057221485146535\n",
      "iterations 405 accuray : 0.9285864314219702  loss : 0.505470052825586\n",
      "iterations 406 accuray : 0.9292165511447175  loss : 0.5052198300560086\n",
      "iterations 407 accuray : 0.9302667506826297  loss : 0.504985797753069\n",
      "iterations 408 accuray : 0.931316950220542  loss : 0.5047493818033838\n",
      "iterations 409 accuray : 0.931316950220542  loss : 0.5045263140475654\n",
      "iterations 410 accuray : 0.9317370300357067  loss : 0.5043114881208558\n",
      "iterations 411 accuray : 0.9311069103129594  loss : 0.5040933317219741\n",
      "iterations 412 accuray : 0.9304767905902122  loss : 0.5038830210645908\n",
      "iterations 413 accuray : 0.930896870405377  loss : 0.5036446689230245\n",
      "iterations 414 accuray : 0.9302667506826297  loss : 0.503398595676553\n",
      "iterations 415 accuray : 0.9300567107750473  loss : 0.5031970064570788\n",
      "iterations 416 accuray : 0.9302667506826297  loss : 0.5029683714151456\n",
      "iterations 417 accuray : 0.9300567107750473  loss : 0.5027428517210781\n",
      "iterations 418 accuray : 0.930896870405377  loss : 0.5025193496810182\n",
      "iterations 419 accuray : 0.9296366309598824  loss : 0.5022976766279984\n",
      "iterations 420 accuray : 0.9296366309598824  loss : 0.5020895942298683\n",
      "iterations 421 accuray : 0.9287964713295526  loss : 0.5018827682368787\n",
      "iterations 422 accuray : 0.9281663516068053  loss : 0.5016645733500262\n",
      "iterations 423 accuray : 0.9277462717916404  loss : 0.5014510418352842\n",
      "iterations 424 accuray : 0.9273261919764755  loss : 0.5012383398259574\n",
      "iterations 425 accuray : 0.9269061121613107  loss : 0.5010268624472208\n",
      "iterations 426 accuray : 0.9269061121613107  loss : 0.5008285507339595\n",
      "iterations 427 accuray : 0.925645872715816  loss : 0.5006097216996277\n",
      "iterations 428 accuray : 0.9243856332703214  loss : 0.5003739488780753\n",
      "iterations 429 accuray : 0.9239655534551565  loss : 0.500172010301657\n",
      "iterations 430 accuray : 0.9241755933627389  loss : 0.4999747473727411\n",
      "iterations 431 accuray : 0.9235454736399916  loss : 0.49977063007831607\n",
      "iterations 432 accuray : 0.9233354337324091  loss : 0.49957673064935293\n",
      "iterations 433 accuray : 0.9231253938248267  loss : 0.49937090765957204\n",
      "iterations 434 accuray : 0.9224952741020794  loss : 0.49917820117234996\n",
      "iterations 435 accuray : 0.9214450745641672  loss : 0.4990019604136639\n",
      "iterations 436 accuray : 0.9214450745641672  loss : 0.4988106850287781\n",
      "iterations 437 accuray : 0.9212350346565847  loss : 0.49862987124108693\n",
      "iterations 438 accuray : 0.9206049149338374  loss : 0.49843858699090926\n",
      "iterations 439 accuray : 0.9191346355807604  loss : 0.49822782028511675\n",
      "iterations 440 accuray : 0.9182944759504306  loss : 0.4980266677029763\n",
      "iterations 441 accuray : 0.9178743961352657  loss : 0.4978415244914579\n",
      "iterations 442 accuray : 0.917034236504936  loss : 0.49765801105347623\n",
      "iterations 443 accuray : 0.9159840369670237  loss : 0.4974664089172684\n",
      "iterations 444 accuray : 0.9157739970594413  loss : 0.4972755197388185\n",
      "iterations 445 accuray : 0.9157739970594413  loss : 0.497087897037218\n",
      "iterations 446 accuray : 0.9153539172442764  loss : 0.496913309185936\n",
      "iterations 447 accuray : 0.9145137576139466  loss : 0.4967148428765984\n",
      "iterations 448 accuray : 0.9138836378911993  loss : 0.496531417579127\n",
      "iterations 449 accuray : 0.9128334383532871  loss : 0.4963493260526184\n",
      "iterations 450 accuray : 0.9119932787229573  loss : 0.49619148748273434\n",
      "iterations 451 accuray : 0.9111531190926276  loss : 0.49601429308959555\n",
      "iterations 452 accuray : 0.9105229993698802  loss : 0.49583419612889473\n",
      "iterations 453 accuray : 0.9092627599243857  loss : 0.4956546307649043\n",
      "iterations 454 accuray : 0.9090527200168032  loss : 0.49547076371629584\n",
      "iterations 455 accuray : 0.9084226002940559  loss : 0.4952880598493501\n",
      "iterations 456 accuray : 0.908002520478891  loss : 0.4951058686746129\n",
      "iterations 457 accuray : 0.9075824406637261  loss : 0.49494219481880225\n",
      "iterations 458 accuray : 0.9069523209409788  loss : 0.49476755374926973\n",
      "iterations 459 accuray : 0.9054820415879017  loss : 0.4945897150744961\n",
      "iterations 460 accuray : 0.9046418819575719  loss : 0.4944164777459445\n",
      "iterations 461 accuray : 0.9038017223272422  loss : 0.494256947301191\n",
      "iterations 462 accuray : 0.9029615626969124  loss : 0.4940752203355256\n",
      "iterations 463 accuray : 0.9025414828817475  loss : 0.4938972647841826\n",
      "iterations 464 accuray : 0.9014912833438353  loss : 0.49372938356714957\n",
      "iterations 465 accuray : 0.9006511237135055  loss : 0.4935649164022349\n",
      "iterations 466 accuray : 0.9006511237135055  loss : 0.49339570717725534\n",
      "iterations 467 accuray : 0.9002310438983406  loss : 0.49321345547766593\n",
      "iterations 468 accuray : 0.8998109640831758  loss : 0.49303848539873063\n",
      "iterations 469 accuray : 0.8991808443604284  loss : 0.4928629944820899\n",
      "iterations 470 accuray : 0.8979206049149339  loss : 0.4927012581505331\n",
      "iterations 471 accuray : 0.8979206049149339  loss : 0.49253743272289746\n",
      "iterations 472 accuray : 0.8972904851921865  loss : 0.4923837611921657\n",
      "iterations 473 accuray : 0.8964503255618568  loss : 0.4922159956772744\n",
      "iterations 474 accuray : 0.8964503255618568  loss : 0.49206468223037686\n",
      "iterations 475 accuray : 0.8958202058391095  loss : 0.49189014874202414\n",
      "iterations 476 accuray : 0.8941398865784499  loss : 0.49172992839383306\n",
      "iterations 477 accuray : 0.8935097668557026  loss : 0.4915622652110111\n",
      "iterations 478 accuray : 0.8926696072253728  loss : 0.4914143084774367\n",
      "iterations 479 accuray : 0.8928796471329553  loss : 0.491262934394931\n",
      "iterations 480 accuray : 0.8922495274102079  loss : 0.49110582217503007\n",
      "iterations 481 accuray : 0.8911993278722957  loss : 0.4909486123886469\n",
      "iterations 482 accuray : 0.8905692081495484  loss : 0.4907895308816015\n",
      "iterations 483 accuray : 0.8899390884268011  loss : 0.4906246389893236\n",
      "iterations 484 accuray : 0.8893089687040537  loss : 0.4904735606533729\n",
      "iterations 485 accuray : 0.8880487292585592  loss : 0.490327055969776\n",
      "iterations 486 accuray : 0.8874186095358118  loss : 0.49018174923649205\n",
      "iterations 487 accuray : 0.8865784499054821  loss : 0.4900411439415493\n",
      "iterations 488 accuray : 0.8855282503675699  loss : 0.48988192096490296\n",
      "iterations 489 accuray : 0.8848981306448225  loss : 0.489732355637729\n",
      "iterations 490 accuray : 0.8842680109220752  loss : 0.4895844225914304\n",
      "iterations 491 accuray : 0.8838479311069103  loss : 0.48944600989189013\n",
      "iterations 492 accuray : 0.8838479311069103  loss : 0.48930141169269575\n",
      "iterations 493 accuray : 0.8836378911993279  loss : 0.48915692223979607\n",
      "iterations 494 accuray : 0.8830077714765806  loss : 0.4890120042521741\n",
      "iterations 495 accuray : 0.8825876916614157  loss : 0.48886711545130923\n",
      "iterations 496 accuray : 0.8819575719386683  loss : 0.4887269108937732\n",
      "iterations 497 accuray : 0.8809073724007561  loss : 0.4885711417019867\n",
      "iterations 498 accuray : 0.8806973324931737  loss : 0.48842574643720954\n",
      "iterations 499 accuray : 0.8804872925855912  loss : 0.48828414729456937\n",
      "iterations 500 accuray : 0.8798571728628439  loss : 0.48814558792513235\n",
      "iterations 501 accuray : 0.879437093047679  loss : 0.4879988922906421\n",
      "iterations 502 accuray : 0.8790170132325141  loss : 0.48786208301273865\n",
      "iterations 503 accuray : 0.8781768536021844  loss : 0.48771626586978917\n",
      "iterations 504 accuray : 0.8777567737870196  loss : 0.4875738201000628\n",
      "iterations 505 accuray : 0.8771266540642723  loss : 0.4874353526655443\n",
      "iterations 506 accuray : 0.8767065742491074  loss : 0.48729761075261485\n",
      "iterations 507 accuray : 0.8756563747111952  loss : 0.4871575063474253\n",
      "iterations 508 accuray : 0.8756563747111952  loss : 0.4870237927645021\n",
      "iterations 509 accuray : 0.8756563747111952  loss : 0.48688429185484516\n",
      "iterations 510 accuray : 0.8754463348036127  loss : 0.4867531743161882\n",
      "iterations 511 accuray : 0.8750262549884478  loss : 0.48660920561895826\n",
      "iterations 512 accuray : 0.8746061751732829  loss : 0.48646762279218486\n",
      "iterations 513 accuray : 0.8741860953581181  loss : 0.48633054190209285\n",
      "iterations 514 accuray : 0.8735559756353707  loss : 0.486193008949324\n",
      "iterations 515 accuray : 0.8725057760974585  loss : 0.4860522198265915\n",
      "iterations 516 accuray : 0.8722957361898761  loss : 0.4859186574920579\n",
      "iterations 517 accuray : 0.8712455366519639  loss : 0.4857762948919583\n",
      "iterations 518 accuray : 0.870825456836799  loss : 0.4856459456568904\n",
      "iterations 519 accuray : 0.8704053770216341  loss : 0.4855094693290191\n",
      "iterations 520 accuray : 0.8697752572988868  loss : 0.485372035299853\n",
      "iterations 521 accuray : 0.8685150178533921  loss : 0.48524336585072814\n",
      "iterations 522 accuray : 0.8676748582230623  loss : 0.4851055751018415\n",
      "iterations 523 accuray : 0.8659945389624029  loss : 0.48497383826462176\n",
      "iterations 524 accuray : 0.8653644192396556  loss : 0.4848433156824298\n",
      "iterations 525 accuray : 0.8651543793320731  loss : 0.4847184780412532\n",
      "iterations 526 accuray : 0.8638941398865785  loss : 0.4845841840191723\n",
      "iterations 527 accuray : 0.8634740600714136  loss : 0.4844615365491216\n",
      "iterations 528 accuray : 0.8626339004410838  loss : 0.4843303438008237\n",
      "iterations 529 accuray : 0.861793740810754  loss : 0.4841986472818951\n",
      "iterations 530 accuray : 0.8613736609955892  loss : 0.4840695656305264\n",
      "iterations 531 accuray : 0.8611636210880067  loss : 0.4839384153267426\n",
      "iterations 532 accuray : 0.8601134215500945  loss : 0.48381005916746145\n",
      "iterations 533 accuray : 0.8596933417349296  loss : 0.4836857340193473\n",
      "iterations 534 accuray : 0.8594833018273472  loss : 0.48356082505934445\n",
      "iterations 535 accuray : 0.8592732619197647  loss : 0.4834466362869354\n",
      "iterations 536 accuray : 0.858433102289435  loss : 0.48331583457395744\n",
      "iterations 537 accuray : 0.8582230623818525  loss : 0.4831983057966727\n",
      "iterations 538 accuray : 0.8575929426591052  loss : 0.483071196617359\n",
      "iterations 539 accuray : 0.8573829027515227  loss : 0.4829504537882915\n",
      "iterations 540 accuray : 0.8573829027515227  loss : 0.48283461636378994\n",
      "iterations 541 accuray : 0.8567527830287754  loss : 0.48271449216540496\n",
      "iterations 542 accuray : 0.8567527830287754  loss : 0.4826025364513431\n",
      "iterations 543 accuray : 0.856542743121193  loss : 0.4824852566288533\n",
      "iterations 544 accuray : 0.856542743121193  loss : 0.4823641506159058\n",
      "iterations 545 accuray : 0.8563327032136105  loss : 0.48224264270439976\n",
      "iterations 546 accuray : 0.8559126233984458  loss : 0.4821261030409713\n",
      "iterations 547 accuray : 0.8557025834908633  loss : 0.48200988259423017\n",
      "iterations 548 accuray : 0.8557025834908633  loss : 0.4818847817928113\n",
      "iterations 549 accuray : 0.8557025834908633  loss : 0.4817687091479507\n",
      "iterations 550 accuray : 0.8554925435832809  loss : 0.4816561613076232\n",
      "iterations 551 accuray : 0.855072463768116  loss : 0.48153496733345624\n",
      "iterations 552 accuray : 0.8542323041377862  loss : 0.48140928701766506\n",
      "iterations 553 accuray : 0.8536021844150389  loss : 0.4812885364571925\n",
      "iterations 554 accuray : 0.853182104599874  loss : 0.4811669084305703\n",
      "iterations 555 accuray : 0.8529720646922916  loss : 0.4810481820430522\n",
      "iterations 556 accuray : 0.8527620247847091  loss : 0.4809276900071338\n",
      "iterations 557 accuray : 0.8525519848771267  loss : 0.4808044468000131\n",
      "iterations 558 accuray : 0.8525519848771267  loss : 0.4806844727963741\n",
      "iterations 559 accuray : 0.8519218651543793  loss : 0.4805646201169739\n",
      "iterations 560 accuray : 0.8517118252467969  loss : 0.4804411369378211\n",
      "iterations 561 accuray : 0.8515017853392145  loss : 0.4803315189690831\n",
      "iterations 562 accuray : 0.8500315059861374  loss : 0.4802111344734551\n",
      "iterations 563 accuray : 0.8498214660785549  loss : 0.48009652722324064\n",
      "iterations 564 accuray : 0.8496114261709725  loss : 0.4799827120064449\n",
      "iterations 565 accuray : 0.8496114261709725  loss : 0.47987027507391794\n",
      "iterations 566 accuray : 0.84940138626339  loss : 0.47975398412445763\n",
      "iterations 567 accuray : 0.84940138626339  loss : 0.47963741515076186\n",
      "iterations 568 accuray : 0.8489813064482251  loss : 0.4795191001769948\n",
      "iterations 569 accuray : 0.8483511867254778  loss : 0.4794019271684723\n",
      "iterations 570 accuray : 0.8483511867254778  loss : 0.479287416645784\n",
      "iterations 571 accuray : 0.8483511867254778  loss : 0.47917498915998485\n",
      "iterations 572 accuray : 0.8479311069103129  loss : 0.4790574237036242\n",
      "iterations 573 accuray : 0.8470909472799832  loss : 0.4789456379627481\n",
      "iterations 574 accuray : 0.8462507876496534  loss : 0.47882936578122776\n",
      "iterations 575 accuray : 0.8462507876496534  loss : 0.4787187292211516\n",
      "iterations 576 accuray : 0.8460407477420709  loss : 0.4786049900367156\n",
      "iterations 577 accuray : 0.8460407477420709  loss : 0.4784930609194434\n",
      "iterations 578 accuray : 0.8458307078344885  loss : 0.47837485461357804\n",
      "iterations 579 accuray : 0.8454106280193237  loss : 0.47826249699500123\n",
      "iterations 580 accuray : 0.8452005881117413  loss : 0.47815531404333267\n",
      "iterations 581 accuray : 0.8452005881117413  loss : 0.4780435442749163\n",
      "iterations 582 accuray : 0.8449905482041588  loss : 0.4779302122706869\n",
      "iterations 583 accuray : 0.8449905482041588  loss : 0.4778305331206787\n",
      "iterations 584 accuray : 0.8447805082965764  loss : 0.4777142408840818\n",
      "iterations 585 accuray : 0.8441503885738291  loss : 0.47760301362132734\n",
      "iterations 586 accuray : 0.8441503885738291  loss : 0.4774950441425893\n",
      "iterations 587 accuray : 0.8437303087586642  loss : 0.4773840651056013\n",
      "iterations 588 accuray : 0.8435202688510817  loss : 0.4772757353006979\n",
      "iterations 589 accuray : 0.8435202688510817  loss : 0.47716668982067706\n",
      "iterations 590 accuray : 0.8433102289434993  loss : 0.4770584563442752\n",
      "iterations 591 accuray : 0.8431001890359168  loss : 0.4769464315799253\n",
      "iterations 592 accuray : 0.8431001890359168  loss : 0.47684354326983525\n",
      "iterations 593 accuray : 0.8428901491283344  loss : 0.4767332115530508\n",
      "iterations 594 accuray : 0.8422600294055871  loss : 0.47661669435563964\n",
      "iterations 595 accuray : 0.8416299096828398  loss : 0.4765019238397237\n",
      "iterations 596 accuray : 0.8416299096828398  loss : 0.47638926511756813\n",
      "iterations 597 accuray : 0.8414198697752573  loss : 0.4762839030997782\n",
      "iterations 598 accuray : 0.8412098298676749  loss : 0.4761785572986082\n",
      "iterations 599 accuray : 0.8412098298676749  loss : 0.4760766672529258\n",
      "iterations 600 accuray : 0.8412098298676749  loss : 0.4759712734615885\n",
      "iterations 601 accuray : 0.8403696702373451  loss : 0.47585652527950506\n",
      "iterations 602 accuray : 0.8397395505145978  loss : 0.47574252761939245\n",
      "iterations 603 accuray : 0.8395295106070153  loss : 0.4756388806573378\n",
      "iterations 604 accuray : 0.8393194706994329  loss : 0.47553429443636214\n",
      "iterations 605 accuray : 0.8393194706994329  loss : 0.47542643342625646\n",
      "iterations 606 accuray : 0.8393194706994329  loss : 0.47532124308415896\n",
      "iterations 607 accuray : 0.8391094307918504  loss : 0.47521398278416316\n",
      "iterations 608 accuray : 0.8391094307918504  loss : 0.4751141456274316\n",
      "iterations 609 accuray : 0.838899390884268  loss : 0.4750076363215544\n",
      "iterations 610 accuray : 0.8386893509766856  loss : 0.4749052518878863\n",
      "iterations 611 accuray : 0.8382692711615207  loss : 0.4747998578710865\n",
      "iterations 612 accuray : 0.8382692711615207  loss : 0.47469864615795926\n",
      "iterations 613 accuray : 0.8382692711615207  loss : 0.47459656416865253\n",
      "iterations 614 accuray : 0.8380592312539382  loss : 0.474495180535304\n",
      "iterations 615 accuray : 0.8380592312539382  loss : 0.47438840114860154\n",
      "iterations 616 accuray : 0.8380592312539382  loss : 0.47429073280513534\n",
      "iterations 617 accuray : 0.8378491913463558  loss : 0.47419022311726683\n",
      "iterations 618 accuray : 0.8376391514387733  loss : 0.4740878169444617\n",
      "iterations 619 accuray : 0.8376391514387733  loss : 0.4739854176698389\n",
      "iterations 620 accuray : 0.837009031716026  loss : 0.4738762957235623\n",
      "iterations 621 accuray : 0.837009031716026  loss : 0.47377144049064646\n",
      "iterations 622 accuray : 0.837009031716026  loss : 0.47367101637833164\n",
      "iterations 623 accuray : 0.8363789119932787  loss : 0.47356511454491196\n",
      "iterations 624 accuray : 0.8359588321781138  loss : 0.47346408711009386\n",
      "iterations 625 accuray : 0.8359588321781138  loss : 0.47336516636575776\n",
      "iterations 626 accuray : 0.8359588321781138  loss : 0.47326447512087116\n",
      "iterations 627 accuray : 0.8355387523629489  loss : 0.4731572625402569\n",
      "iterations 628 accuray : 0.8353287124553666  loss : 0.47305290132232874\n",
      "iterations 629 accuray : 0.835118672547784  loss : 0.47294715579596425\n",
      "iterations 630 accuray : 0.835118672547784  loss : 0.47284681375675985\n",
      "iterations 631 accuray : 0.835118672547784  loss : 0.4727458219876922\n",
      "iterations 632 accuray : 0.8346985927326191  loss : 0.47264258490898037\n",
      "iterations 633 accuray : 0.8346985927326191  loss : 0.47254166713584056\n",
      "iterations 634 accuray : 0.8344885528250368  loss : 0.47244188257309283\n",
      "iterations 635 accuray : 0.8342785129174544  loss : 0.47233902446763226\n",
      "iterations 636 accuray : 0.8342785129174544  loss : 0.47224294812253736\n",
      "iterations 637 accuray : 0.8338584331022895  loss : 0.4721406058756202\n",
      "iterations 638 accuray : 0.833648393194707  loss : 0.4720390065121079\n",
      "iterations 639 accuray : 0.8334383532871246  loss : 0.47194228633209023\n",
      "iterations 640 accuray : 0.8332283133795421  loss : 0.4718454416910264\n",
      "iterations 641 accuray : 0.8332283133795421  loss : 0.4717443862317153\n",
      "iterations 642 accuray : 0.8332283133795421  loss : 0.47164625984244485\n",
      "iterations 643 accuray : 0.8328082335643773  loss : 0.4715439249921047\n",
      "iterations 644 accuray : 0.8328082335643773  loss : 0.471438668416915\n",
      "iterations 645 accuray : 0.8328082335643773  loss : 0.47134510685967623\n",
      "iterations 646 accuray : 0.8323881537492124  loss : 0.4712463304077199\n",
      "iterations 647 accuray : 0.8323881537492124  loss : 0.471151047249711\n",
      "iterations 648 accuray : 0.8321781138416299  loss : 0.4710508541066858\n",
      "iterations 649 accuray : 0.831758034026465  loss : 0.47094916339422\n",
      "iterations 650 accuray : 0.8315479941188826  loss : 0.4708499514302316\n",
      "iterations 651 accuray : 0.8315479941188826  loss : 0.47074872631923276\n",
      "iterations 652 accuray : 0.8313379542113002  loss : 0.4706535888847012\n",
      "iterations 653 accuray : 0.8311279143037177  loss : 0.4705546679322062\n",
      "iterations 654 accuray : 0.8311279143037177  loss : 0.4704555090856913\n",
      "iterations 655 accuray : 0.8311279143037177  loss : 0.4703587053788354\n",
      "iterations 656 accuray : 0.8311279143037177  loss : 0.47026120563105156\n",
      "iterations 657 accuray : 0.8311279143037177  loss : 0.47016574076931167\n",
      "iterations 658 accuray : 0.8311279143037177  loss : 0.4700706672299329\n",
      "iterations 659 accuray : 0.8311279143037177  loss : 0.46997596750492726\n",
      "iterations 660 accuray : 0.8311279143037177  loss : 0.4698785137853983\n",
      "iterations 661 accuray : 0.8309178743961353  loss : 0.46978259215254276\n",
      "iterations 662 accuray : 0.8311279143037177  loss : 0.4696893907944679\n",
      "iterations 663 accuray : 0.8309178743961353  loss : 0.46959203581457387\n",
      "iterations 664 accuray : 0.8309178743961353  loss : 0.4694969083177616\n",
      "iterations 665 accuray : 0.8307078344885528  loss : 0.4694043166911656\n",
      "iterations 666 accuray : 0.8304977945809704  loss : 0.4693098062492537\n",
      "iterations 667 accuray : 0.8302877546733879  loss : 0.46921300598041416\n",
      "iterations 668 accuray : 0.8300777147658055  loss : 0.469117265559573\n",
      "iterations 669 accuray : 0.8298676748582231  loss : 0.46901963228893706\n",
      "iterations 670 accuray : 0.8298676748582231  loss : 0.46892461173282307\n",
      "iterations 671 accuray : 0.8298676748582231  loss : 0.4688316111051524\n",
      "iterations 672 accuray : 0.8298676748582231  loss : 0.4687403832480341\n",
      "iterations 673 accuray : 0.8294475950430582  loss : 0.46864205717298185\n",
      "iterations 674 accuray : 0.8290275152278933  loss : 0.46854587147391835\n",
      "iterations 675 accuray : 0.8290275152278933  loss : 0.46845358547815164\n",
      "iterations 676 accuray : 0.8292375551354757  loss : 0.46835937187118915\n",
      "iterations 677 accuray : 0.8292375551354757  loss : 0.468269058958886\n",
      "iterations 678 accuray : 0.8290275152278933  loss : 0.46817308763556126\n",
      "iterations 679 accuray : 0.8290275152278933  loss : 0.46807961854809227\n",
      "iterations 680 accuray : 0.8290275152278933  loss : 0.46798662977221306\n",
      "iterations 681 accuray : 0.8288174753203108  loss : 0.4678903516753334\n",
      "iterations 682 accuray : 0.8288174753203108  loss : 0.46779698852205936\n",
      "iterations 683 accuray : 0.8288174753203108  loss : 0.4677023730796961\n",
      "iterations 684 accuray : 0.8288174753203108  loss : 0.4676085496431618\n",
      "iterations 685 accuray : 0.8288174753203108  loss : 0.46751395644171606\n",
      "iterations 686 accuray : 0.828397395505146  loss : 0.46741659921353795\n",
      "iterations 687 accuray : 0.8281873555975635  loss : 0.4673236485054416\n",
      "iterations 688 accuray : 0.8281873555975635  loss : 0.4672317946675092\n",
      "iterations 689 accuray : 0.8279773156899811  loss : 0.46713703804361406\n",
      "iterations 690 accuray : 0.8275572358748162  loss : 0.4670395189079371\n",
      "iterations 691 accuray : 0.8275572358748162  loss : 0.4669465847739563\n",
      "iterations 692 accuray : 0.8275572358748162  loss : 0.46685491663307865\n",
      "iterations 693 accuray : 0.8275572358748162  loss : 0.4667619009805039\n",
      "iterations 694 accuray : 0.8275572358748162  loss : 0.46666763240407205\n",
      "iterations 695 accuray : 0.8275572358748162  loss : 0.46657698868950426\n",
      "iterations 696 accuray : 0.8275572358748162  loss : 0.46648614448944153\n",
      "iterations 697 accuray : 0.8275572358748162  loss : 0.4663950570333907\n",
      "iterations 698 accuray : 0.8275572358748162  loss : 0.466305987369447\n",
      "iterations 699 accuray : 0.8275572358748162  loss : 0.4662162830739425\n",
      "iterations 700 accuray : 0.8275572358748162  loss : 0.466122905292684\n",
      "iterations 701 accuray : 0.8275572358748162  loss : 0.4660307410740547\n",
      "iterations 702 accuray : 0.8273471959672338  loss : 0.4659375762558489\n",
      "iterations 703 accuray : 0.8275572358748162  loss : 0.46584742589617234\n",
      "iterations 704 accuray : 0.8275572358748162  loss : 0.4657574053530269\n",
      "iterations 705 accuray : 0.8275572358748162  loss : 0.4656662397833193\n",
      "iterations 706 accuray : 0.8275572358748162  loss : 0.4655770306908537\n",
      "iterations 707 accuray : 0.8273471959672338  loss : 0.46548576046727663\n",
      "iterations 708 accuray : 0.8275572358748162  loss : 0.4653993810638202\n",
      "iterations 709 accuray : 0.8273471959672338  loss : 0.46530422480160594\n",
      "iterations 710 accuray : 0.8273471959672338  loss : 0.4652134401312915\n",
      "iterations 711 accuray : 0.8273471959672338  loss : 0.46512480038472165\n",
      "iterations 712 accuray : 0.8273471959672338  loss : 0.46503463522421556\n",
      "iterations 713 accuray : 0.8273471959672338  loss : 0.46494112536800025\n",
      "iterations 714 accuray : 0.8271371560596513  loss : 0.4648488866526785\n",
      "iterations 715 accuray : 0.8267170762444864  loss : 0.46475900291628475\n",
      "iterations 716 accuray : 0.826507036336904  loss : 0.4646665310602428\n",
      "iterations 717 accuray : 0.826507036336904  loss : 0.46457740183115387\n",
      "iterations 718 accuray : 0.8267170762444864  loss : 0.46449047833428403\n",
      "iterations 719 accuray : 0.8267170762444864  loss : 0.4644012930381194\n",
      "iterations 720 accuray : 0.8267170762444864  loss : 0.46431550000984395\n",
      "iterations 721 accuray : 0.8267170762444864  loss : 0.46422283201523157\n",
      "iterations 722 accuray : 0.8267170762444864  loss : 0.46413373881961495\n",
      "iterations 723 accuray : 0.8267170762444864  loss : 0.4640452253932048\n",
      "iterations 724 accuray : 0.8267170762444864  loss : 0.4639584382837019\n",
      "iterations 725 accuray : 0.8267170762444864  loss : 0.46386897495539464\n",
      "iterations 726 accuray : 0.8267170762444864  loss : 0.46377735344184545\n",
      "iterations 727 accuray : 0.8267170762444864  loss : 0.46368731273320646\n",
      "iterations 728 accuray : 0.8267170762444864  loss : 0.46359774909805057\n",
      "iterations 729 accuray : 0.8267170762444864  loss : 0.4635109731072675\n",
      "iterations 730 accuray : 0.8267170762444864  loss : 0.4634223288786985\n",
      "iterations 731 accuray : 0.8267170762444864  loss : 0.46333383072044876\n",
      "iterations 732 accuray : 0.8267170762444864  loss : 0.46324582755033816\n",
      "iterations 733 accuray : 0.8267170762444864  loss : 0.4631564910291725\n",
      "iterations 734 accuray : 0.8267170762444864  loss : 0.4630687392438815\n",
      "iterations 735 accuray : 0.8267170762444864  loss : 0.46298089106508006\n",
      "iterations 736 accuray : 0.8267170762444864  loss : 0.4628902135417371\n",
      "iterations 737 accuray : 0.8267170762444864  loss : 0.4628001912405743\n",
      "iterations 738 accuray : 0.8267170762444864  loss : 0.46271086417693863\n",
      "iterations 739 accuray : 0.8267170762444864  loss : 0.4626250916592006\n",
      "iterations 740 accuray : 0.8267170762444864  loss : 0.4625366491562693\n",
      "iterations 741 accuray : 0.8267170762444864  loss : 0.46244755785740427\n",
      "iterations 742 accuray : 0.8267170762444864  loss : 0.4623586654088668\n",
      "iterations 743 accuray : 0.8267170762444864  loss : 0.46227233548658264\n",
      "iterations 744 accuray : 0.8267170762444864  loss : 0.4621856434280281\n",
      "iterations 745 accuray : 0.8267170762444864  loss : 0.46209788116519446\n",
      "iterations 746 accuray : 0.8267170762444864  loss : 0.46201120430679316\n",
      "iterations 747 accuray : 0.8267170762444864  loss : 0.46192269336703545\n",
      "iterations 748 accuray : 0.8267170762444864  loss : 0.46183454638144983\n",
      "iterations 749 accuray : 0.8267170762444864  loss : 0.46174633736678417\n",
      "iterations 750 accuray : 0.8267170762444864  loss : 0.4616590646937344\n",
      "iterations 751 accuray : 0.8267170762444864  loss : 0.46157175847628573\n",
      "iterations 752 accuray : 0.8267170762444864  loss : 0.46148312453405865\n",
      "iterations 753 accuray : 0.8267170762444864  loss : 0.46139654759602977\n",
      "iterations 754 accuray : 0.8267170762444864  loss : 0.4613084826092405\n",
      "iterations 755 accuray : 0.8267170762444864  loss : 0.46122129404158113\n",
      "iterations 756 accuray : 0.8267170762444864  loss : 0.4611347788202086\n",
      "iterations 757 accuray : 0.8267170762444864  loss : 0.4610475174861147\n",
      "iterations 758 accuray : 0.8267170762444864  loss : 0.4609619512244558\n",
      "iterations 759 accuray : 0.8267170762444864  loss : 0.46087622440365555\n",
      "iterations 760 accuray : 0.8267170762444864  loss : 0.4607928399494783\n",
      "iterations 761 accuray : 0.8269271161520689  loss : 0.4607088954082729\n",
      "iterations 762 accuray : 0.8269271161520689  loss : 0.46062480312633236\n",
      "iterations 763 accuray : 0.8269271161520689  loss : 0.4605405472229543\n",
      "iterations 764 accuray : 0.8269271161520689  loss : 0.46045365666184207\n",
      "iterations 765 accuray : 0.8269271161520689  loss : 0.46036738209749856\n",
      "iterations 766 accuray : 0.8269271161520689  loss : 0.4602817760372184\n",
      "iterations 767 accuray : 0.8269271161520689  loss : 0.46019548713443276\n",
      "iterations 768 accuray : 0.8269271161520689  loss : 0.4601095076802593\n",
      "iterations 769 accuray : 0.8269271161520689  loss : 0.4600251743499032\n",
      "iterations 770 accuray : 0.8269271161520689  loss : 0.4599378871133594\n",
      "iterations 771 accuray : 0.8269271161520689  loss : 0.45985232470228815\n",
      "iterations 772 accuray : 0.8269271161520689  loss : 0.45976656455711795\n",
      "iterations 773 accuray : 0.8271371560596513  loss : 0.4596802356274508\n",
      "iterations 774 accuray : 0.8269271161520689  loss : 0.45959397821307335\n",
      "iterations 775 accuray : 0.8269271161520689  loss : 0.4595066534446695\n",
      "iterations 776 accuray : 0.8269271161520689  loss : 0.45942132155512666\n",
      "iterations 777 accuray : 0.8271371560596513  loss : 0.45933657652829724\n",
      "iterations 778 accuray : 0.8271371560596513  loss : 0.45925178344809486\n",
      "iterations 779 accuray : 0.8271371560596513  loss : 0.45916572307277514\n",
      "iterations 780 accuray : 0.8271371560596513  loss : 0.45908106492766004\n",
      "iterations 781 accuray : 0.8271371560596513  loss : 0.4589975897306901\n",
      "iterations 782 accuray : 0.8271371560596513  loss : 0.4589136838677677\n",
      "iterations 783 accuray : 0.8271371560596513  loss : 0.45883016964079903\n",
      "iterations 784 accuray : 0.8271371560596513  loss : 0.4587461545505974\n",
      "iterations 785 accuray : 0.8271371560596513  loss : 0.4586613125275648\n",
      "iterations 786 accuray : 0.8271371560596513  loss : 0.4585758806771269\n",
      "iterations 787 accuray : 0.8271371560596513  loss : 0.4584910398936866\n",
      "iterations 788 accuray : 0.8271371560596513  loss : 0.458405551666595\n",
      "iterations 789 accuray : 0.8271371560596513  loss : 0.4583223530815465\n",
      "iterations 790 accuray : 0.8271371560596513  loss : 0.4582386097393125\n",
      "iterations 791 accuray : 0.8271371560596513  loss : 0.45815483376749905\n",
      "iterations 792 accuray : 0.8271371560596513  loss : 0.4580678403141913\n",
      "iterations 793 accuray : 0.8271371560596513  loss : 0.45798221884270046\n",
      "iterations 794 accuray : 0.8271371560596513  loss : 0.45790058644309756\n",
      "iterations 795 accuray : 0.8271371560596513  loss : 0.457815562844487\n",
      "iterations 796 accuray : 0.8271371560596513  loss : 0.4577334856971192\n",
      "iterations 797 accuray : 0.8271371560596513  loss : 0.4576485842268316\n",
      "iterations 798 accuray : 0.8271371560596513  loss : 0.45756623034531896\n",
      "iterations 799 accuray : 0.8271371560596513  loss : 0.45748430207310864\n",
      "iterations 800 accuray : 0.8271371560596513  loss : 0.45740103944222854\n",
      "iterations 801 accuray : 0.8273471959672338  loss : 0.4573176003163128\n",
      "iterations 802 accuray : 0.8273471959672338  loss : 0.45723386098761687\n",
      "iterations 803 accuray : 0.8273471959672338  loss : 0.45715140351439243\n",
      "iterations 804 accuray : 0.8273471959672338  loss : 0.4570670086880845\n",
      "iterations 805 accuray : 0.8273471959672338  loss : 0.4569832670838334\n",
      "iterations 806 accuray : 0.8273471959672338  loss : 0.4568992615014951\n",
      "iterations 807 accuray : 0.8273471959672338  loss : 0.4568138000671952\n",
      "iterations 808 accuray : 0.8271371560596513  loss : 0.45672668985799153\n",
      "iterations 809 accuray : 0.8271371560596513  loss : 0.4566430550768324\n",
      "iterations 810 accuray : 0.8271371560596513  loss : 0.4565587246442473\n",
      "iterations 811 accuray : 0.8271371560596513  loss : 0.45647600204698785\n",
      "iterations 812 accuray : 0.8271371560596513  loss : 0.45639266287412267\n",
      "iterations 813 accuray : 0.8271371560596513  loss : 0.4563074423510501\n",
      "iterations 814 accuray : 0.8271371560596513  loss : 0.4562241610354501\n",
      "iterations 815 accuray : 0.8271371560596513  loss : 0.4561416575024211\n",
      "iterations 816 accuray : 0.8271371560596513  loss : 0.456058217481175\n",
      "iterations 817 accuray : 0.8271371560596513  loss : 0.4559766841517858\n",
      "iterations 818 accuray : 0.8271371560596513  loss : 0.45589398166184136\n",
      "iterations 819 accuray : 0.8271371560596513  loss : 0.4558107660133844\n",
      "iterations 820 accuray : 0.8271371560596513  loss : 0.4557273448345198\n",
      "iterations 821 accuray : 0.8271371560596513  loss : 0.45564648705850175\n",
      "iterations 822 accuray : 0.8271371560596513  loss : 0.4555643611189948\n",
      "iterations 823 accuray : 0.8273471959672338  loss : 0.455481423062531\n",
      "iterations 824 accuray : 0.8273471959672338  loss : 0.4553993184921598\n",
      "iterations 825 accuray : 0.8273471959672338  loss : 0.45531677221498307\n",
      "iterations 826 accuray : 0.8277672757823986  loss : 0.45523518251124706\n",
      "iterations 827 accuray : 0.8279773156899811  loss : 0.4551531997857464\n",
      "iterations 828 accuray : 0.8279773156899811  loss : 0.4550719080343478\n",
      "iterations 829 accuray : 0.8286074354127284  loss : 0.4549903520112221\n",
      "iterations 830 accuray : 0.8286074354127284  loss : 0.45490755919125536\n",
      "iterations 831 accuray : 0.8286074354127284  loss : 0.454826711752957\n",
      "iterations 832 accuray : 0.8286074354127284  loss : 0.4547447612844052\n",
      "iterations 833 accuray : 0.8286074354127284  loss : 0.45466350406193046\n",
      "iterations 834 accuray : 0.8286074354127284  loss : 0.45457971748231785\n",
      "iterations 835 accuray : 0.8286074354127284  loss : 0.4544974590690293\n",
      "iterations 836 accuray : 0.8286074354127284  loss : 0.4544164434288522\n",
      "iterations 837 accuray : 0.8286074354127284  loss : 0.45433493991610757\n",
      "iterations 838 accuray : 0.8286074354127284  loss : 0.4542545498642144\n",
      "iterations 839 accuray : 0.8286074354127284  loss : 0.4541731431183075\n",
      "iterations 840 accuray : 0.8286074354127284  loss : 0.45409157245340526\n",
      "iterations 841 accuray : 0.8286074354127284  loss : 0.4540096148557589\n",
      "iterations 842 accuray : 0.8286074354127284  loss : 0.4539293730917961\n",
      "iterations 843 accuray : 0.8290275152278933  loss : 0.45384972431344056\n",
      "iterations 844 accuray : 0.8290275152278933  loss : 0.4537677179601541\n",
      "iterations 845 accuray : 0.8292375551354757  loss : 0.45368637719757554\n",
      "iterations 846 accuray : 0.8294475950430582  loss : 0.4536065086876844\n",
      "iterations 847 accuray : 0.8296576349506406  loss : 0.4535272404768629\n",
      "iterations 848 accuray : 0.8300777147658055  loss : 0.4534483269943707\n",
      "iterations 849 accuray : 0.8300777147658055  loss : 0.45336937725160553\n",
      "iterations 850 accuray : 0.8300777147658055  loss : 0.4532896272271636\n",
      "iterations 851 accuray : 0.8294475950430582  loss : 0.4532068428037785\n",
      "iterations 852 accuray : 0.8302877546733879  loss : 0.4531268626557309\n",
      "iterations 853 accuray : 0.8304977945809704  loss : 0.45304737730526795\n",
      "iterations 854 accuray : 0.8304977945809704  loss : 0.45296635871155305\n",
      "iterations 855 accuray : 0.8304977945809704  loss : 0.45288689045045327\n",
      "iterations 856 accuray : 0.8304977945809704  loss : 0.4528073089814554\n",
      "iterations 857 accuray : 0.8304977945809704  loss : 0.4527268863732373\n",
      "iterations 858 accuray : 0.8304977945809704  loss : 0.4526467390655063\n",
      "iterations 859 accuray : 0.8304977945809704  loss : 0.45256691329082416\n",
      "iterations 860 accuray : 0.8304977945809704  loss : 0.45248618810800373\n",
      "iterations 861 accuray : 0.8304977945809704  loss : 0.4524059396909277\n",
      "iterations 862 accuray : 0.8304977945809704  loss : 0.45232587284534853\n",
      "iterations 863 accuray : 0.8304977945809704  loss : 0.45224695628563577\n",
      "iterations 864 accuray : 0.8307078344885528  loss : 0.45216711800991405\n",
      "iterations 865 accuray : 0.8307078344885528  loss : 0.4520857728884757\n",
      "iterations 866 accuray : 0.8307078344885528  loss : 0.4520059977523775\n",
      "iterations 867 accuray : 0.8307078344885528  loss : 0.45192445931637354\n",
      "iterations 868 accuray : 0.8309178743961353  loss : 0.4518461572470452\n",
      "iterations 869 accuray : 0.8309178743961353  loss : 0.4517657742607189\n",
      "iterations 870 accuray : 0.8311279143037177  loss : 0.45168873757135364\n",
      "iterations 871 accuray : 0.8311279143037177  loss : 0.4516092296922285\n",
      "iterations 872 accuray : 0.8311279143037177  loss : 0.45152905008980365\n",
      "iterations 873 accuray : 0.8309178743961353  loss : 0.4514488496720723\n",
      "iterations 874 accuray : 0.8309178743961353  loss : 0.4513684045058616\n",
      "iterations 875 accuray : 0.8309178743961353  loss : 0.45128857165026154\n",
      "iterations 876 accuray : 0.8309178743961353  loss : 0.4512077496375908\n",
      "iterations 877 accuray : 0.8309178743961353  loss : 0.4511291005920457\n",
      "iterations 878 accuray : 0.8311279143037177  loss : 0.45104971276184913\n",
      "iterations 879 accuray : 0.8311279143037177  loss : 0.45097103167546115\n",
      "iterations 880 accuray : 0.8311279143037177  loss : 0.4508918209068511\n",
      "iterations 881 accuray : 0.8311279143037177  loss : 0.450814317566555\n",
      "iterations 882 accuray : 0.8311279143037177  loss : 0.4507370456935049\n",
      "iterations 883 accuray : 0.8311279143037177  loss : 0.45065946194596634\n",
      "iterations 884 accuray : 0.8315479941188826  loss : 0.4505809009913402\n",
      "iterations 885 accuray : 0.8315479941188826  loss : 0.4505034600171962\n",
      "iterations 886 accuray : 0.831758034026465  loss : 0.45042633831851137\n",
      "iterations 887 accuray : 0.831758034026465  loss : 0.45034838216329987\n",
      "iterations 888 accuray : 0.831758034026465  loss : 0.4502701884299915\n",
      "iterations 889 accuray : 0.8319680739340475  loss : 0.4501904212576396\n",
      "iterations 890 accuray : 0.8319680739340475  loss : 0.4501114207097278\n",
      "iterations 891 accuray : 0.8319680739340475  loss : 0.4500322090211733\n",
      "iterations 892 accuray : 0.8319680739340475  loss : 0.44995287021155234\n",
      "iterations 893 accuray : 0.8319680739340475  loss : 0.4498729030391452\n",
      "iterations 894 accuray : 0.8319680739340475  loss : 0.44979558779285256\n",
      "iterations 895 accuray : 0.8323881537492124  loss : 0.4497182989551235\n",
      "iterations 896 accuray : 0.8323881537492124  loss : 0.44963940686291715\n",
      "iterations 897 accuray : 0.8325981936567948  loss : 0.4495636671474547\n",
      "iterations 898 accuray : 0.8325981936567948  loss : 0.44948561366015344\n",
      "iterations 899 accuray : 0.8325981936567948  loss : 0.44940706563553573\n",
      "iterations 900 accuray : 0.8325981936567948  loss : 0.44932871664633867\n",
      "iterations 901 accuray : 0.8325981936567948  loss : 0.44925194977779137\n",
      "iterations 902 accuray : 0.8332283133795421  loss : 0.44917553467376825\n",
      "iterations 903 accuray : 0.8330182734719597  loss : 0.44909841541059875\n",
      "iterations 904 accuray : 0.8332283133795421  loss : 0.44902006925951204\n",
      "iterations 905 accuray : 0.8332283133795421  loss : 0.44894191128692407\n",
      "iterations 906 accuray : 0.8332283133795421  loss : 0.4488644153224697\n",
      "iterations 907 accuray : 0.8332283133795421  loss : 0.4487871922077637\n",
      "iterations 908 accuray : 0.833648393194707  loss : 0.4487099517228748\n",
      "iterations 909 accuray : 0.833648393194707  loss : 0.4486329939656187\n",
      "iterations 910 accuray : 0.833648393194707  loss : 0.44855628758783667\n",
      "iterations 911 accuray : 0.8338584331022895  loss : 0.44847778940224076\n",
      "iterations 912 accuray : 0.8338584331022895  loss : 0.44839915093676747\n",
      "iterations 913 accuray : 0.8338584331022895  loss : 0.4483229492625635\n",
      "iterations 914 accuray : 0.8340684730098719  loss : 0.4482470527059017\n",
      "iterations 915 accuray : 0.8340684730098719  loss : 0.4481708532036893\n",
      "iterations 916 accuray : 0.8340684730098719  loss : 0.44809253518812076\n",
      "iterations 917 accuray : 0.8342785129174544  loss : 0.4480148832020428\n",
      "iterations 918 accuray : 0.8344885528250368  loss : 0.447937922092306\n",
      "iterations 919 accuray : 0.8344885528250368  loss : 0.4478601113905438\n",
      "iterations 920 accuray : 0.8344885528250368  loss : 0.4477835296095753\n",
      "iterations 921 accuray : 0.8344885528250368  loss : 0.44770738388581716\n",
      "iterations 922 accuray : 0.8344885528250368  loss : 0.4476297384727394\n",
      "iterations 923 accuray : 0.8344885528250368  loss : 0.4475540684597448\n",
      "iterations 924 accuray : 0.8346985927326191  loss : 0.44747723471218687\n",
      "iterations 925 accuray : 0.8346985927326191  loss : 0.4474002683986149\n",
      "iterations 926 accuray : 0.835118672547784  loss : 0.44732502373262595\n",
      "iterations 927 accuray : 0.835118672547784  loss : 0.4472500405019895\n",
      "iterations 928 accuray : 0.835118672547784  loss : 0.44717419276010323\n",
      "iterations 929 accuray : 0.835118672547784  loss : 0.4470999027238617\n",
      "iterations 930 accuray : 0.835118672547784  loss : 0.44702300375367426\n",
      "iterations 931 accuray : 0.835118672547784  loss : 0.44694655873544814\n",
      "iterations 932 accuray : 0.835118672547784  loss : 0.4468691765889485\n",
      "iterations 933 accuray : 0.835118672547784  loss : 0.4467925211699851\n",
      "iterations 934 accuray : 0.835118672547784  loss : 0.44671486947837585\n",
      "iterations 935 accuray : 0.835118672547784  loss : 0.44663803590457724\n",
      "iterations 936 accuray : 0.835118672547784  loss : 0.44656061821678167\n",
      "iterations 937 accuray : 0.835118672547784  loss : 0.44648379511081987\n",
      "iterations 938 accuray : 0.835118672547784  loss : 0.4464082206049022\n",
      "iterations 939 accuray : 0.8355387523629489  loss : 0.44633092530709356\n",
      "iterations 940 accuray : 0.8353287124553666  loss : 0.4462543823512864\n",
      "iterations 941 accuray : 0.8355387523629489  loss : 0.4461780062322637\n",
      "iterations 942 accuray : 0.8353287124553666  loss : 0.44610305708699344\n",
      "iterations 943 accuray : 0.8353287124553666  loss : 0.44602791883975035\n",
      "iterations 944 accuray : 0.835118672547784  loss : 0.44595458650715347\n",
      "iterations 945 accuray : 0.8355387523629489  loss : 0.44587863433116276\n",
      "iterations 946 accuray : 0.8355387523629489  loss : 0.44580244046420303\n",
      "iterations 947 accuray : 0.8359588321781138  loss : 0.44572608488201476\n",
      "iterations 948 accuray : 0.8359588321781138  loss : 0.44565073895228546\n",
      "iterations 949 accuray : 0.8359588321781138  loss : 0.4455761036859673\n",
      "iterations 950 accuray : 0.8359588321781138  loss : 0.44549922856867447\n",
      "iterations 951 accuray : 0.8361688720856962  loss : 0.44542425385738726\n",
      "iterations 952 accuray : 0.8363789119932787  loss : 0.4453491586250094\n",
      "iterations 953 accuray : 0.8365889519008611  loss : 0.44527242986341153\n",
      "iterations 954 accuray : 0.8367989918084436  loss : 0.4451959805032136\n",
      "iterations 955 accuray : 0.8365889519008611  loss : 0.44512174181417996\n",
      "iterations 956 accuray : 0.8367989918084436  loss : 0.4450469863281083\n",
      "iterations 957 accuray : 0.837009031716026  loss : 0.4449722644526606\n",
      "iterations 958 accuray : 0.837009031716026  loss : 0.44489739931169187\n",
      "iterations 959 accuray : 0.837009031716026  loss : 0.4448233074632914\n",
      "iterations 960 accuray : 0.837009031716026  loss : 0.4447491582487827\n",
      "iterations 961 accuray : 0.837009031716026  loss : 0.4446762538328739\n",
      "iterations 962 accuray : 0.837009031716026  loss : 0.4446015066277066\n",
      "iterations 963 accuray : 0.837009031716026  loss : 0.44452737420068766\n",
      "iterations 964 accuray : 0.8372190716236085  loss : 0.4444537036482362\n",
      "iterations 965 accuray : 0.8372190716236085  loss : 0.44438032250925524\n",
      "iterations 966 accuray : 0.8374291115311909  loss : 0.4443037233962727\n",
      "iterations 967 accuray : 0.8374291115311909  loss : 0.4442287339847173\n",
      "iterations 968 accuray : 0.8378491913463558  loss : 0.44415343376490446\n",
      "iterations 969 accuray : 0.8378491913463558  loss : 0.44407857243627474\n",
      "iterations 970 accuray : 0.8380592312539382  loss : 0.44400457962804685\n",
      "iterations 971 accuray : 0.8382692711615207  loss : 0.44392998914919807\n",
      "iterations 972 accuray : 0.8384793110691031  loss : 0.44385536965290295\n",
      "iterations 973 accuray : 0.838899390884268  loss : 0.4437809897066859\n",
      "iterations 974 accuray : 0.8391094307918504  loss : 0.44370702565814507\n",
      "iterations 975 accuray : 0.838899390884268  loss : 0.4436331878211315\n",
      "iterations 976 accuray : 0.8393194706994329  loss : 0.44355855912630243\n",
      "iterations 977 accuray : 0.8393194706994329  loss : 0.44348422480604766\n",
      "iterations 978 accuray : 0.8393194706994329  loss : 0.4434087362821156\n",
      "iterations 979 accuray : 0.8393194706994329  loss : 0.443334631127384\n",
      "iterations 980 accuray : 0.8393194706994329  loss : 0.4432600488327611\n",
      "iterations 981 accuray : 0.8393194706994329  loss : 0.44318706901353205\n",
      "iterations 982 accuray : 0.8393194706994329  loss : 0.44311330681273176\n",
      "iterations 983 accuray : 0.8393194706994329  loss : 0.44303876599982617\n",
      "iterations 984 accuray : 0.8393194706994329  loss : 0.4429655279329786\n",
      "iterations 985 accuray : 0.8393194706994329  loss : 0.4428908984121449\n",
      "iterations 986 accuray : 0.8395295106070153  loss : 0.4428162152548462\n",
      "iterations 987 accuray : 0.8397395505145978  loss : 0.4427430552870126\n",
      "iterations 988 accuray : 0.8393194706994329  loss : 0.4426697324290295\n",
      "iterations 989 accuray : 0.8393194706994329  loss : 0.4425969529186482\n",
      "iterations 990 accuray : 0.8393194706994329  loss : 0.44252397937773424\n",
      "iterations 991 accuray : 0.8397395505145978  loss : 0.442449862054147\n",
      "iterations 992 accuray : 0.8397395505145978  loss : 0.4423766412474627\n",
      "iterations 993 accuray : 0.8397395505145978  loss : 0.4423052291620461\n",
      "iterations 994 accuray : 0.8397395505145978  loss : 0.44223143138525534\n",
      "iterations 995 accuray : 0.8397395505145978  loss : 0.44215729033300155\n",
      "iterations 996 accuray : 0.8401596303297627  loss : 0.442082200820096\n",
      "iterations 997 accuray : 0.8403696702373451  loss : 0.44200881553538146\n",
      "iterations 998 accuray : 0.8403696702373451  loss : 0.44193423649753705\n",
      "iterations 999 accuray : 0.8405797101449275  loss : 0.4418628385373585\n",
      "iterations 1000 accuray : 0.8405797101449275  loss : 0.4417891964134185\n",
      "iterations 1001 accuray : 0.8405797101449275  loss : 0.44171644585473213\n",
      "iterations 1002 accuray : 0.8405797101449275  loss : 0.4416437248443054\n",
      "iterations 1003 accuray : 0.84078975005251  loss : 0.4415712046978132\n",
      "iterations 1004 accuray : 0.84078975005251  loss : 0.4414988042701949\n",
      "iterations 1005 accuray : 0.8409997899600924  loss : 0.44142523630156844\n",
      "iterations 1006 accuray : 0.8409997899600924  loss : 0.441352170834019\n",
      "iterations 1007 accuray : 0.8409997899600924  loss : 0.4412806925096517\n",
      "iterations 1008 accuray : 0.8409997899600924  loss : 0.44120821471406\n",
      "iterations 1009 accuray : 0.8409997899600924  loss : 0.4411365287843732\n",
      "iterations 1010 accuray : 0.8409997899600924  loss : 0.44106356793466867\n",
      "iterations 1011 accuray : 0.8409997899600924  loss : 0.44099024059858255\n",
      "iterations 1012 accuray : 0.8409997899600924  loss : 0.44091663187234986\n",
      "iterations 1013 accuray : 0.8409997899600924  loss : 0.4408432947668653\n",
      "iterations 1014 accuray : 0.8409997899600924  loss : 0.4407721257877696\n",
      "iterations 1015 accuray : 0.8409997899600924  loss : 0.44070089776182314\n",
      "iterations 1016 accuray : 0.8409997899600924  loss : 0.4406275609694741\n",
      "iterations 1017 accuray : 0.8409997899600924  loss : 0.44055654463412663\n",
      "iterations 1018 accuray : 0.8409997899600924  loss : 0.4404851779040842\n",
      "iterations 1019 accuray : 0.8412098298676749  loss : 0.44041281190585485\n",
      "iterations 1020 accuray : 0.8412098298676749  loss : 0.4403396672951402\n",
      "iterations 1021 accuray : 0.8412098298676749  loss : 0.44026699596209845\n",
      "iterations 1022 accuray : 0.8412098298676749  loss : 0.44019526488648963\n",
      "iterations 1023 accuray : 0.8412098298676749  loss : 0.4401222874643984\n",
      "iterations 1024 accuray : 0.8412098298676749  loss : 0.44004956228744385\n",
      "iterations 1025 accuray : 0.8412098298676749  loss : 0.43997841197301346\n",
      "iterations 1026 accuray : 0.8412098298676749  loss : 0.4399060901251235\n",
      "iterations 1027 accuray : 0.8412098298676749  loss : 0.4398332861236894\n",
      "iterations 1028 accuray : 0.8412098298676749  loss : 0.4397614739710492\n",
      "iterations 1029 accuray : 0.8412098298676749  loss : 0.43969114371362794\n",
      "iterations 1030 accuray : 0.8412098298676749  loss : 0.43961953079071425\n",
      "iterations 1031 accuray : 0.8412098298676749  loss : 0.4395482617362884\n",
      "iterations 1032 accuray : 0.8412098298676749  loss : 0.4394746648778817\n",
      "iterations 1033 accuray : 0.8412098298676749  loss : 0.4394041951308069\n",
      "iterations 1034 accuray : 0.8412098298676749  loss : 0.4393332256160295\n",
      "iterations 1035 accuray : 0.8412098298676749  loss : 0.4392608503870462\n",
      "iterations 1036 accuray : 0.8414198697752573  loss : 0.4391872706884611\n",
      "iterations 1037 accuray : 0.8414198697752573  loss : 0.4391160384160545\n",
      "iterations 1038 accuray : 0.8414198697752573  loss : 0.43904381001998416\n",
      "iterations 1039 accuray : 0.8414198697752573  loss : 0.4389715003620746\n",
      "iterations 1040 accuray : 0.8414198697752573  loss : 0.4389006493035268\n",
      "iterations 1041 accuray : 0.8416299096828398  loss : 0.4388294244549897\n",
      "iterations 1042 accuray : 0.8416299096828398  loss : 0.4387597776183661\n",
      "iterations 1043 accuray : 0.8416299096828398  loss : 0.4386883708447874\n",
      "iterations 1044 accuray : 0.8416299096828398  loss : 0.4386157352777752\n",
      "iterations 1045 accuray : 0.8416299096828398  loss : 0.4385451739579322\n",
      "iterations 1046 accuray : 0.8420499894980046  loss : 0.4384727353907292\n",
      "iterations 1047 accuray : 0.8420499894980046  loss : 0.43840116348474195\n",
      "iterations 1048 accuray : 0.8420499894980046  loss : 0.4383314318913564\n",
      "iterations 1049 accuray : 0.8420499894980046  loss : 0.4382603174776885\n",
      "iterations 1050 accuray : 0.8422600294055871  loss : 0.4381902839457312\n",
      "iterations 1051 accuray : 0.8422600294055871  loss : 0.43811629674022456\n",
      "iterations 1052 accuray : 0.8422600294055871  loss : 0.4380454358763828\n",
      "iterations 1053 accuray : 0.8422600294055871  loss : 0.43797583013661856\n",
      "iterations 1054 accuray : 0.8424700693131695  loss : 0.43790568299112775\n",
      "iterations 1055 accuray : 0.842680109220752  loss : 0.43783447703253975\n",
      "iterations 1056 accuray : 0.842680109220752  loss : 0.4377631198614669\n",
      "iterations 1057 accuray : 0.8428901491283344  loss : 0.43769170510523586\n",
      "iterations 1058 accuray : 0.8428901491283344  loss : 0.4376199818844936\n",
      "iterations 1059 accuray : 0.8428901491283344  loss : 0.43754912172727833\n",
      "iterations 1060 accuray : 0.8428901491283344  loss : 0.4374785461830186\n",
      "iterations 1061 accuray : 0.8428901491283344  loss : 0.43740793955822976\n",
      "iterations 1062 accuray : 0.8431001890359168  loss : 0.4373370198226625\n",
      "iterations 1063 accuray : 0.8431001890359168  loss : 0.4372673861913726\n",
      "iterations 1064 accuray : 0.8428901491283344  loss : 0.43719838691818536\n",
      "iterations 1065 accuray : 0.8431001890359168  loss : 0.43712866148692797\n",
      "iterations 1066 accuray : 0.8431001890359168  loss : 0.43705887475114974\n",
      "iterations 1067 accuray : 0.8431001890359168  loss : 0.4369882356989107\n",
      "iterations 1068 accuray : 0.8431001890359168  loss : 0.43691895084943416\n",
      "iterations 1069 accuray : 0.8431001890359168  loss : 0.4368490297136984\n",
      "iterations 1070 accuray : 0.8433102289434993  loss : 0.4367781503790025\n",
      "iterations 1071 accuray : 0.8431001890359168  loss : 0.43670871854472004\n",
      "iterations 1072 accuray : 0.8433102289434993  loss : 0.43663734522893094\n",
      "iterations 1073 accuray : 0.8435202688510817  loss : 0.43656826833643836\n",
      "iterations 1074 accuray : 0.8437303087586642  loss : 0.43649731554594606\n",
      "iterations 1075 accuray : 0.8439403486662466  loss : 0.43642750519691886\n",
      "iterations 1076 accuray : 0.8439403486662466  loss : 0.4363570696890273\n",
      "iterations 1077 accuray : 0.8439403486662466  loss : 0.43628474770278214\n",
      "iterations 1078 accuray : 0.8445704683889939  loss : 0.4362157774245065\n",
      "iterations 1079 accuray : 0.8445704683889939  loss : 0.4361454892046141\n",
      "iterations 1080 accuray : 0.8445704683889939  loss : 0.4360768304149673\n",
      "iterations 1081 accuray : 0.8445704683889939  loss : 0.4360077861758673\n",
      "iterations 1082 accuray : 0.8445704683889939  loss : 0.43593708032206985\n",
      "iterations 1083 accuray : 0.8445704683889939  loss : 0.43586581661651685\n",
      "iterations 1084 accuray : 0.8445704683889939  loss : 0.4357959076181725\n",
      "iterations 1085 accuray : 0.8447805082965764  loss : 0.43572675227280466\n",
      "iterations 1086 accuray : 0.8447805082965764  loss : 0.43565700052773443\n",
      "iterations 1087 accuray : 0.8447805082965764  loss : 0.4355898248650729\n",
      "iterations 1088 accuray : 0.8447805082965764  loss : 0.4355197684878735\n",
      "iterations 1089 accuray : 0.8447805082965764  loss : 0.4354488146157344\n",
      "iterations 1090 accuray : 0.8447805082965764  loss : 0.435378358806531\n",
      "iterations 1091 accuray : 0.8447805082965764  loss : 0.43530921008369095\n",
      "iterations 1092 accuray : 0.8447805082965764  loss : 0.4352411600109429\n",
      "iterations 1093 accuray : 0.8447805082965764  loss : 0.4351719430848241\n",
      "iterations 1094 accuray : 0.8452005881117413  loss : 0.4351016812936674\n",
      "iterations 1095 accuray : 0.8449905482041588  loss : 0.4350331135567806\n",
      "iterations 1096 accuray : 0.8456206679269062  loss : 0.43496197769737344\n",
      "iterations 1097 accuray : 0.8456206679269062  loss : 0.43489454374002834\n",
      "iterations 1098 accuray : 0.8460407477420709  loss : 0.43482439308772225\n",
      "iterations 1099 accuray : 0.8460407477420709  loss : 0.4347545195236423\n",
      "iterations 1100 accuray : 0.8460407477420709  loss : 0.4346861008825613\n",
      "iterations 1101 accuray : 0.8460407477420709  loss : 0.43461688744439175\n",
      "iterations 1102 accuray : 0.8460407477420709  loss : 0.4345486516121578\n",
      "iterations 1103 accuray : 0.8460407477420709  loss : 0.4344805975834984\n",
      "iterations 1104 accuray : 0.8462507876496534  loss : 0.4344114568142619\n",
      "iterations 1105 accuray : 0.8464608275572358  loss : 0.43434287110699166\n",
      "iterations 1106 accuray : 0.8468809073724007  loss : 0.434274167051707\n",
      "iterations 1107 accuray : 0.8468809073724007  loss : 0.4342054391791301\n",
      "iterations 1108 accuray : 0.8470909472799832  loss : 0.4341365091849874\n",
      "iterations 1109 accuray : 0.847511027095148  loss : 0.43406797959434396\n",
      "iterations 1110 accuray : 0.847511027095148  loss : 0.433998732332914\n",
      "iterations 1111 accuray : 0.847511027095148  loss : 0.43393059560156183\n",
      "iterations 1112 accuray : 0.8479311069103129  loss : 0.433859776933683\n",
      "iterations 1113 accuray : 0.8481411468178954  loss : 0.4337919567686317\n",
      "iterations 1114 accuray : 0.8481411468178954  loss : 0.4337228976071651\n",
      "iterations 1115 accuray : 0.8483511867254778  loss : 0.433654595080437\n",
      "iterations 1116 accuray : 0.8483511867254778  loss : 0.43358604908613646\n",
      "iterations 1117 accuray : 0.8485612266330603  loss : 0.43351777675330394\n",
      "iterations 1118 accuray : 0.8485612266330603  loss : 0.43345079878212517\n",
      "iterations 1119 accuray : 0.8487712665406427  loss : 0.4333822768459012\n",
      "iterations 1120 accuray : 0.8487712665406427  loss : 0.43331484824356664\n",
      "iterations 1121 accuray : 0.8487712665406427  loss : 0.43324780676443614\n",
      "iterations 1122 accuray : 0.8487712665406427  loss : 0.4331806992701772\n",
      "iterations 1123 accuray : 0.8487712665406427  loss : 0.43311311399585084\n",
      "iterations 1124 accuray : 0.84940138626339  loss : 0.43304357714337566\n",
      "iterations 1125 accuray : 0.8498214660785549  loss : 0.4329747351511265\n",
      "iterations 1126 accuray : 0.8500315059861374  loss : 0.4329063507271225\n",
      "iterations 1127 accuray : 0.8502415458937198  loss : 0.4328383539874095\n",
      "iterations 1128 accuray : 0.8502415458937198  loss : 0.4327703450828746\n",
      "iterations 1129 accuray : 0.8502415458937198  loss : 0.432702187282569\n",
      "iterations 1130 accuray : 0.8502415458937198  loss : 0.4326355740051887\n",
      "iterations 1131 accuray : 0.8502415458937198  loss : 0.4325667253077875\n",
      "iterations 1132 accuray : 0.8502415458937198  loss : 0.43249999827055186\n",
      "iterations 1133 accuray : 0.8502415458937198  loss : 0.432433057710991\n",
      "iterations 1134 accuray : 0.8502415458937198  loss : 0.4323658244541869\n",
      "iterations 1135 accuray : 0.8502415458937198  loss : 0.4322979677250183\n",
      "iterations 1136 accuray : 0.8502415458937198  loss : 0.4322311376037484\n",
      "iterations 1137 accuray : 0.8506616257088847  loss : 0.4321625713634656\n",
      "iterations 1138 accuray : 0.8506616257088847  loss : 0.43209483974429275\n",
      "iterations 1139 accuray : 0.8506616257088847  loss : 0.4320281603707219\n",
      "iterations 1140 accuray : 0.8506616257088847  loss : 0.43196042830769693\n",
      "iterations 1141 accuray : 0.8506616257088847  loss : 0.431894096031842\n",
      "iterations 1142 accuray : 0.8506616257088847  loss : 0.43182785076180463\n",
      "iterations 1143 accuray : 0.851291745431632  loss : 0.43175987312082686\n",
      "iterations 1144 accuray : 0.8515017853392145  loss : 0.4316931027188792\n",
      "iterations 1145 accuray : 0.8519218651543793  loss : 0.43162651578733147\n",
      "iterations 1146 accuray : 0.8519218651543793  loss : 0.4315603087873517\n",
      "iterations 1147 accuray : 0.8521319050619618  loss : 0.4314945109157106\n",
      "iterations 1148 accuray : 0.8523419449695442  loss : 0.4314279590605595\n",
      "iterations 1149 accuray : 0.8523419449695442  loss : 0.4313591855810345\n",
      "iterations 1150 accuray : 0.8523419449695442  loss : 0.43129267162569473\n",
      "iterations 1151 accuray : 0.8523419449695442  loss : 0.4312270827477939\n",
      "iterations 1152 accuray : 0.8523419449695442  loss : 0.43116056037837025\n",
      "iterations 1153 accuray : 0.8525519848771267  loss : 0.4310934163570558\n",
      "iterations 1154 accuray : 0.8523419449695442  loss : 0.4310290040793756\n",
      "iterations 1155 accuray : 0.8527620247847091  loss : 0.43096438863871384\n",
      "iterations 1156 accuray : 0.8529720646922916  loss : 0.43089600510238774\n",
      "iterations 1157 accuray : 0.8529720646922916  loss : 0.43082908224410255\n",
      "iterations 1158 accuray : 0.8529720646922916  loss : 0.43076245080799846\n",
      "iterations 1159 accuray : 0.8529720646922916  loss : 0.43069698693282843\n",
      "iterations 1160 accuray : 0.8529720646922916  loss : 0.43063018128372743\n",
      "iterations 1161 accuray : 0.8529720646922916  loss : 0.4305622242368695\n",
      "iterations 1162 accuray : 0.8529720646922916  loss : 0.4304960748248958\n",
      "iterations 1163 accuray : 0.8529720646922916  loss : 0.4304308439352177\n",
      "iterations 1164 accuray : 0.8529720646922916  loss : 0.4303647784142977\n",
      "iterations 1165 accuray : 0.8529720646922916  loss : 0.43029796362135186\n",
      "iterations 1166 accuray : 0.8529720646922916  loss : 0.4302319449873285\n",
      "iterations 1167 accuray : 0.8529720646922916  loss : 0.43016498464295927\n",
      "iterations 1168 accuray : 0.853182104599874  loss : 0.43009802596011526\n",
      "iterations 1169 accuray : 0.853182104599874  loss : 0.4300324860336063\n",
      "iterations 1170 accuray : 0.8533921445074564  loss : 0.4299654613685187\n",
      "iterations 1171 accuray : 0.8533921445074564  loss : 0.42990077820017825\n",
      "iterations 1172 accuray : 0.8536021844150389  loss : 0.4298351418425161\n",
      "iterations 1173 accuray : 0.8536021844150389  loss : 0.4297696850841925\n",
      "iterations 1174 accuray : 0.8536021844150389  loss : 0.4297036160430903\n",
      "iterations 1175 accuray : 0.8536021844150389  loss : 0.4296382472835655\n",
      "iterations 1176 accuray : 0.8536021844150389  loss : 0.4295730156427285\n",
      "iterations 1177 accuray : 0.8538122243226213  loss : 0.42950774802632347\n",
      "iterations 1178 accuray : 0.8538122243226213  loss : 0.4294424370729672\n",
      "iterations 1179 accuray : 0.8538122243226213  loss : 0.4293769180201337\n",
      "iterations 1180 accuray : 0.8538122243226213  loss : 0.429311156331392\n",
      "iterations 1181 accuray : 0.8540222642302038  loss : 0.42924544807782217\n",
      "iterations 1182 accuray : 0.8542323041377862  loss : 0.42917897154657186\n",
      "iterations 1183 accuray : 0.8542323041377862  loss : 0.42911406725143886\n",
      "iterations 1184 accuray : 0.8546523839529511  loss : 0.4290469582398418\n",
      "iterations 1185 accuray : 0.855072463768116  loss : 0.4289803955833044\n",
      "iterations 1186 accuray : 0.855072463768116  loss : 0.4289147714890625\n",
      "iterations 1187 accuray : 0.8552825036756984  loss : 0.42884887288598306\n",
      "iterations 1188 accuray : 0.8554925435832809  loss : 0.4287821628730079\n",
      "iterations 1189 accuray : 0.8554925435832809  loss : 0.4287165639344567\n",
      "iterations 1190 accuray : 0.8554925435832809  loss : 0.42865138218490084\n",
      "iterations 1191 accuray : 0.8554925435832809  loss : 0.4285842569805732\n",
      "iterations 1192 accuray : 0.8557025834908633  loss : 0.4285188097428845\n",
      "iterations 1193 accuray : 0.8557025834908633  loss : 0.4284546835129375\n",
      "iterations 1194 accuray : 0.8559126233984458  loss : 0.4283891000156913\n",
      "iterations 1195 accuray : 0.8559126233984458  loss : 0.4283237114457974\n",
      "iterations 1196 accuray : 0.8561226633060282  loss : 0.4282582373199605\n",
      "iterations 1197 accuray : 0.856542743121193  loss : 0.4281910278740073\n",
      "iterations 1198 accuray : 0.8567527830287754  loss : 0.428124632123572\n",
      "iterations 1199 accuray : 0.856962822936358  loss : 0.42805971825538097\n",
      "iterations 1200 accuray : 0.856962822936358  loss : 0.42799443459726255\n",
      "iterations 1201 accuray : 0.856962822936358  loss : 0.42792944720059056\n",
      "iterations 1202 accuray : 0.856962822936358  loss : 0.42786478592325633\n",
      "iterations 1203 accuray : 0.856962822936358  loss : 0.42779983876307537\n",
      "iterations 1204 accuray : 0.856962822936358  loss : 0.42773603036029445\n",
      "iterations 1205 accuray : 0.856962822936358  loss : 0.42767124644096866\n",
      "iterations 1206 accuray : 0.8571728628439403  loss : 0.4276067437559652\n",
      "iterations 1207 accuray : 0.8578029825666876  loss : 0.42754176031484803\n",
      "iterations 1208 accuray : 0.8580130224742701  loss : 0.4274769210888715\n",
      "iterations 1209 accuray : 0.858433102289435  loss : 0.42741086243791193\n",
      "iterations 1210 accuray : 0.858433102289435  loss : 0.4273477993515725\n",
      "iterations 1211 accuray : 0.8586431421970174  loss : 0.4272826945004889\n",
      "iterations 1212 accuray : 0.8586431421970174  loss : 0.42721746105444414\n",
      "iterations 1213 accuray : 0.8590632220121823  loss : 0.42715358712823376\n",
      "iterations 1214 accuray : 0.8594833018273472  loss : 0.4270889775592518\n",
      "iterations 1215 accuray : 0.8596933417349296  loss : 0.42702490395161513\n",
      "iterations 1216 accuray : 0.8596933417349296  loss : 0.42696026588361624\n",
      "iterations 1217 accuray : 0.8596933417349296  loss : 0.42689394605764536\n",
      "iterations 1218 accuray : 0.8596933417349296  loss : 0.42683024888566873\n",
      "iterations 1219 accuray : 0.8596933417349296  loss : 0.426765054323824\n",
      "iterations 1220 accuray : 0.8596933417349296  loss : 0.4267000738557973\n",
      "iterations 1221 accuray : 0.8596933417349296  loss : 0.4266356299909257\n",
      "iterations 1222 accuray : 0.8599033816425121  loss : 0.4265713380558197\n",
      "iterations 1223 accuray : 0.8599033816425121  loss : 0.426507653106647\n",
      "iterations 1224 accuray : 0.8601134215500945  loss : 0.4264417600424256\n",
      "iterations 1225 accuray : 0.8601134215500945  loss : 0.4263789627546706\n",
      "iterations 1226 accuray : 0.8601134215500945  loss : 0.42631618557547957\n",
      "iterations 1227 accuray : 0.8601134215500945  loss : 0.426251877989027\n",
      "iterations 1228 accuray : 0.8603234614576769  loss : 0.4261876329104693\n",
      "iterations 1229 accuray : 0.8601134215500945  loss : 0.42612376999894697\n",
      "iterations 1230 accuray : 0.8601134215500945  loss : 0.4260602606273447\n",
      "iterations 1231 accuray : 0.8603234614576769  loss : 0.42599584880446084\n",
      "iterations 1232 accuray : 0.8603234614576769  loss : 0.4259321165260991\n",
      "iterations 1233 accuray : 0.8605335013652594  loss : 0.425867524812503\n",
      "iterations 1234 accuray : 0.8607435412728418  loss : 0.42580222772190085\n",
      "iterations 1235 accuray : 0.8607435412728418  loss : 0.4257372360738884\n",
      "iterations 1236 accuray : 0.8613736609955892  loss : 0.4256737064722265\n",
      "iterations 1237 accuray : 0.8613736609955892  loss : 0.4256100188104457\n",
      "iterations 1238 accuray : 0.8613736609955892  loss : 0.42554657943392804\n",
      "iterations 1239 accuray : 0.8615837009031716  loss : 0.42548328148764664\n",
      "iterations 1240 accuray : 0.861793740810754  loss : 0.425417345118771\n",
      "iterations 1241 accuray : 0.8620037807183365  loss : 0.4253525134854011\n",
      "iterations 1242 accuray : 0.8620037807183365  loss : 0.42528949897049734\n",
      "iterations 1243 accuray : 0.8620037807183365  loss : 0.4252271208302571\n",
      "iterations 1244 accuray : 0.8620037807183365  loss : 0.4251643780784862\n",
      "iterations 1245 accuray : 0.8620037807183365  loss : 0.4251008202174592\n",
      "iterations 1246 accuray : 0.8620037807183365  loss : 0.4250387470101352\n",
      "iterations 1247 accuray : 0.8620037807183365  loss : 0.4249744603763819\n",
      "iterations 1248 accuray : 0.8620037807183365  loss : 0.42491003607600564\n",
      "iterations 1249 accuray : 0.8622138206259189  loss : 0.4248460773074062\n",
      "iterations 1250 accuray : 0.8622138206259189  loss : 0.4247823824202678\n",
      "iterations 1251 accuray : 0.8622138206259189  loss : 0.42471942200394597\n",
      "iterations 1252 accuray : 0.8626339004410838  loss : 0.42465423693745974\n",
      "iterations 1253 accuray : 0.8626339004410838  loss : 0.42459059612833383\n",
      "iterations 1254 accuray : 0.8628439403486663  loss : 0.42452631661730866\n",
      "iterations 1255 accuray : 0.8626339004410838  loss : 0.4244630286946373\n",
      "iterations 1256 accuray : 0.8626339004410838  loss : 0.42440015301414774\n",
      "iterations 1257 accuray : 0.8628439403486663  loss : 0.4243377891653561\n",
      "iterations 1258 accuray : 0.8628439403486663  loss : 0.42427386691574026\n",
      "iterations 1259 accuray : 0.8628439403486663  loss : 0.4242111526610147\n",
      "iterations 1260 accuray : 0.8628439403486663  loss : 0.4241480123598078\n",
      "iterations 1261 accuray : 0.8628439403486663  loss : 0.42408528098874015\n",
      "iterations 1262 accuray : 0.8628439403486663  loss : 0.4240247313278598\n",
      "iterations 1263 accuray : 0.8630539802562487  loss : 0.4239617116420693\n",
      "iterations 1264 accuray : 0.8630539802562487  loss : 0.4238987566625355\n",
      "iterations 1265 accuray : 0.8630539802562487  loss : 0.4238358035790838\n",
      "iterations 1266 accuray : 0.8632640201638311  loss : 0.42377363400701046\n",
      "iterations 1267 accuray : 0.8632640201638311  loss : 0.4237104459860661\n",
      "iterations 1268 accuray : 0.8634740600714136  loss : 0.42364711667595467\n",
      "iterations 1269 accuray : 0.8634740600714136  loss : 0.42358525575976574\n",
      "iterations 1270 accuray : 0.863684099978996  loss : 0.4235226890418263\n",
      "iterations 1271 accuray : 0.863684099978996  loss : 0.42346100086871824\n",
      "iterations 1272 accuray : 0.8638941398865785  loss : 0.42339872060117684\n",
      "iterations 1273 accuray : 0.8638941398865785  loss : 0.4233339164010872\n",
      "iterations 1274 accuray : 0.8638941398865785  loss : 0.4232724412889118\n",
      "iterations 1275 accuray : 0.8638941398865785  loss : 0.423210158258\n",
      "iterations 1276 accuray : 0.8638941398865785  loss : 0.42314785408781663\n",
      "iterations 1277 accuray : 0.8643142197017434  loss : 0.4230856848363222\n",
      "iterations 1278 accuray : 0.8645242596093258  loss : 0.4230227606683774\n",
      "iterations 1279 accuray : 0.8643142197017434  loss : 0.4229616415946684\n",
      "iterations 1280 accuray : 0.8645242596093258  loss : 0.422897917516028\n",
      "iterations 1281 accuray : 0.8645242596093258  loss : 0.42283470971275433\n",
      "iterations 1282 accuray : 0.8645242596093258  loss : 0.422770884551942\n",
      "iterations 1283 accuray : 0.8645242596093258  loss : 0.42270834317231876\n",
      "iterations 1284 accuray : 0.8645242596093258  loss : 0.4226460378901301\n",
      "iterations 1285 accuray : 0.8647342995169082  loss : 0.42258482329649144\n",
      "iterations 1286 accuray : 0.8649443394244907  loss : 0.42252356199312285\n",
      "iterations 1287 accuray : 0.8649443394244907  loss : 0.42246123607831815\n",
      "iterations 1288 accuray : 0.8649443394244907  loss : 0.42239926188117777\n",
      "iterations 1289 accuray : 0.8651543793320731  loss : 0.422336428049871\n",
      "iterations 1290 accuray : 0.8651543793320731  loss : 0.42227207411479256\n",
      "iterations 1291 accuray : 0.865574459147238  loss : 0.4222119600894076\n",
      "iterations 1292 accuray : 0.865574459147238  loss : 0.42214917068536834\n",
      "iterations 1293 accuray : 0.8657844990548205  loss : 0.4220876601557284\n",
      "iterations 1294 accuray : 0.8659945389624029  loss : 0.42202496168518383\n",
      "iterations 1295 accuray : 0.8662045788699853  loss : 0.4219627641737006\n",
      "iterations 1296 accuray : 0.8664146187775678  loss : 0.4219011876275031\n",
      "iterations 1297 accuray : 0.8666246586851502  loss : 0.4218381124079021\n",
      "iterations 1298 accuray : 0.8666246586851502  loss : 0.4217758037283072\n",
      "iterations 1299 accuray : 0.8666246586851502  loss : 0.4217140866152054\n",
      "iterations 1300 accuray : 0.8668346985927327  loss : 0.42165263288949034\n",
      "iterations 1301 accuray : 0.867044738500315  loss : 0.42159174451511794\n",
      "iterations 1302 accuray : 0.867044738500315  loss : 0.4215306782419731\n",
      "iterations 1303 accuray : 0.867044738500315  loss : 0.4214696743320505\n",
      "iterations 1304 accuray : 0.86746481831548  loss : 0.4214080766058852\n",
      "iterations 1305 accuray : 0.8678848981306448  loss : 0.42134742055529467\n",
      "iterations 1306 accuray : 0.8678848981306448  loss : 0.4212852689397342\n",
      "iterations 1307 accuray : 0.8678848981306448  loss : 0.42122490081249564\n",
      "iterations 1308 accuray : 0.8678848981306448  loss : 0.4211639153797578\n",
      "iterations 1309 accuray : 0.8678848981306448  loss : 0.4211023015052\n",
      "iterations 1310 accuray : 0.8678848981306448  loss : 0.42104233058778584\n",
      "iterations 1311 accuray : 0.8678848981306448  loss : 0.4209801370297447\n",
      "iterations 1312 accuray : 0.8678848981306448  loss : 0.42091987383409984\n",
      "iterations 1313 accuray : 0.8678848981306448  loss : 0.4208587239118161\n",
      "iterations 1314 accuray : 0.8678848981306448  loss : 0.4207974459383056\n",
      "iterations 1315 accuray : 0.8678848981306448  loss : 0.42073462533232026\n",
      "iterations 1316 accuray : 0.8678848981306448  loss : 0.4206739098739654\n",
      "iterations 1317 accuray : 0.8680949380382272  loss : 0.4206116493368959\n",
      "iterations 1318 accuray : 0.8680949380382272  loss : 0.42055076676722153\n",
      "iterations 1319 accuray : 0.8685150178533921  loss : 0.4204896236951344\n",
      "iterations 1320 accuray : 0.8687250577609746  loss : 0.4204292873369605\n",
      "iterations 1321 accuray : 0.8687250577609746  loss : 0.4203673306398164\n",
      "iterations 1322 accuray : 0.868935097668557  loss : 0.4203053681514014\n",
      "iterations 1323 accuray : 0.868935097668557  loss : 0.42024582469309746\n",
      "iterations 1324 accuray : 0.868935097668557  loss : 0.4201848477656184\n",
      "iterations 1325 accuray : 0.868935097668557  loss : 0.4201242995098207\n",
      "iterations 1326 accuray : 0.8691451375761394  loss : 0.42006356143556567\n",
      "iterations 1327 accuray : 0.8691451375761394  loss : 0.4200030744741031\n",
      "iterations 1328 accuray : 0.8691451375761394  loss : 0.41994301889635227\n",
      "iterations 1329 accuray : 0.8693551774837219  loss : 0.41988209010366573\n",
      "iterations 1330 accuray : 0.8693551774837219  loss : 0.41982288224756065\n",
      "iterations 1331 accuray : 0.8695652173913043  loss : 0.41976265133010937\n",
      "iterations 1332 accuray : 0.8695652173913043  loss : 0.41970330828050895\n",
      "iterations 1333 accuray : 0.8695652173913043  loss : 0.419643117001035\n",
      "iterations 1334 accuray : 0.8697752572988868  loss : 0.4195817330287573\n",
      "iterations 1335 accuray : 0.8697752572988868  loss : 0.4195214549853742\n",
      "iterations 1336 accuray : 0.8697752572988868  loss : 0.4194602798062511\n",
      "iterations 1337 accuray : 0.8697752572988868  loss : 0.41939958241851266\n",
      "iterations 1338 accuray : 0.8699852972064692  loss : 0.41933648564090664\n",
      "iterations 1339 accuray : 0.8701953371140516  loss : 0.41927663294992606\n",
      "iterations 1340 accuray : 0.8704053770216341  loss : 0.419216895262562\n",
      "iterations 1341 accuray : 0.8706154169292165  loss : 0.4191560162584711\n",
      "iterations 1342 accuray : 0.8706154169292165  loss : 0.4190962810693289\n",
      "iterations 1343 accuray : 0.870825456836799  loss : 0.4190347813275867\n",
      "iterations 1344 accuray : 0.8712455366519639  loss : 0.41897367231615784\n",
      "iterations 1345 accuray : 0.8712455366519639  loss : 0.41891341403402205\n",
      "iterations 1346 accuray : 0.8714555765595463  loss : 0.41885381551041007\n",
      "iterations 1347 accuray : 0.8714555765595463  loss : 0.4187935818886144\n",
      "iterations 1348 accuray : 0.8716656164671287  loss : 0.4187337369803\n",
      "iterations 1349 accuray : 0.8716656164671287  loss : 0.4186740893668049\n",
      "iterations 1350 accuray : 0.8716656164671287  loss : 0.41861447071411834\n",
      "iterations 1351 accuray : 0.8716656164671287  loss : 0.4185550745409407\n",
      "iterations 1352 accuray : 0.8716656164671287  loss : 0.41849514653863845\n",
      "iterations 1353 accuray : 0.8718756563747112  loss : 0.41843323467385934\n",
      "iterations 1354 accuray : 0.8718756563747112  loss : 0.41837455726809264\n",
      "iterations 1355 accuray : 0.8718756563747112  loss : 0.41831559415386577\n",
      "iterations 1356 accuray : 0.8718756563747112  loss : 0.4182555999198978\n",
      "iterations 1357 accuray : 0.8718756563747112  loss : 0.41819494517446787\n",
      "iterations 1358 accuray : 0.8718756563747112  loss : 0.41813626217081773\n",
      "iterations 1359 accuray : 0.8718756563747112  loss : 0.41807755489483167\n",
      "iterations 1360 accuray : 0.8718756563747112  loss : 0.4180174916198091\n",
      "iterations 1361 accuray : 0.8718756563747112  loss : 0.41795721100448474\n",
      "iterations 1362 accuray : 0.8718756563747112  loss : 0.41789739777332463\n",
      "iterations 1363 accuray : 0.8722957361898761  loss : 0.4178381404760338\n",
      "iterations 1364 accuray : 0.8725057760974585  loss : 0.41777753303732995\n",
      "iterations 1365 accuray : 0.8725057760974585  loss : 0.4177176411968475\n",
      "iterations 1366 accuray : 0.872715816005041  loss : 0.4176564280265929\n",
      "iterations 1367 accuray : 0.8725057760974585  loss : 0.4175981345730194\n",
      "iterations 1368 accuray : 0.8725057760974585  loss : 0.4175399678441141\n",
      "iterations 1369 accuray : 0.8725057760974585  loss : 0.4174795710490219\n",
      "iterations 1370 accuray : 0.872715816005041  loss : 0.41742009081936177\n",
      "iterations 1371 accuray : 0.872715816005041  loss : 0.41736083639985455\n",
      "iterations 1372 accuray : 0.8731358958202058  loss : 0.41730182162675045\n",
      "iterations 1373 accuray : 0.8731358958202058  loss : 0.41724184169891504\n",
      "iterations 1374 accuray : 0.8731358958202058  loss : 0.4171819236611266\n",
      "iterations 1375 accuray : 0.8731358958202058  loss : 0.41712240541155843\n",
      "iterations 1376 accuray : 0.8731358958202058  loss : 0.41706417632357995\n",
      "iterations 1377 accuray : 0.8731358958202058  loss : 0.41700619550110707\n",
      "iterations 1378 accuray : 0.8733459357277883  loss : 0.41694610079357514\n",
      "iterations 1379 accuray : 0.8735559756353707  loss : 0.41688698078259867\n",
      "iterations 1380 accuray : 0.8735559756353707  loss : 0.41682894002218385\n",
      "iterations 1381 accuray : 0.8737660155429532  loss : 0.4167702769103257\n",
      "iterations 1382 accuray : 0.8737660155429532  loss : 0.41671013149521324\n",
      "iterations 1383 accuray : 0.8737660155429532  loss : 0.4166512959938389\n",
      "iterations 1384 accuray : 0.8737660155429532  loss : 0.4165921718582574\n",
      "iterations 1385 accuray : 0.8737660155429532  loss : 0.4165325334157299\n",
      "iterations 1386 accuray : 0.8737660155429532  loss : 0.41647380235408404\n",
      "iterations 1387 accuray : 0.8737660155429532  loss : 0.4164144558359961\n",
      "iterations 1388 accuray : 0.8737660155429532  loss : 0.4163562431626348\n",
      "iterations 1389 accuray : 0.8737660155429532  loss : 0.4162982950171441\n",
      "iterations 1390 accuray : 0.8737660155429532  loss : 0.4162382043098228\n",
      "iterations 1391 accuray : 0.8743961352657005  loss : 0.41617989543664385\n",
      "iterations 1392 accuray : 0.8743961352657005  loss : 0.41612139885656024\n",
      "iterations 1393 accuray : 0.8746061751732829  loss : 0.41606208493298114\n",
      "iterations 1394 accuray : 0.8746061751732829  loss : 0.41600422877365834\n",
      "iterations 1395 accuray : 0.8746061751732829  loss : 0.4159449213669383\n",
      "iterations 1396 accuray : 0.8748162150808654  loss : 0.4158865442122591\n",
      "iterations 1397 accuray : 0.8750262549884478  loss : 0.41582759659796537\n",
      "iterations 1398 accuray : 0.8750262549884478  loss : 0.41576916449270657\n",
      "iterations 1399 accuray : 0.8750262549884478  loss : 0.4157102432449477\n",
      "iterations 1400 accuray : 0.8750262549884478  loss : 0.41565097985153626\n",
      "iterations 1401 accuray : 0.8750262549884478  loss : 0.41559307816641805\n",
      "iterations 1402 accuray : 0.8752362948960303  loss : 0.41553421919109645\n",
      "iterations 1403 accuray : 0.8752362948960303  loss : 0.41547705100172544\n",
      "iterations 1404 accuray : 0.8754463348036127  loss : 0.4154187863661486\n",
      "iterations 1405 accuray : 0.8752362948960303  loss : 0.4153613433629893\n",
      "iterations 1406 accuray : 0.8756563747111952  loss : 0.41530272948352526\n",
      "iterations 1407 accuray : 0.8756563747111952  loss : 0.4152448033856671\n",
      "iterations 1408 accuray : 0.8756563747111952  loss : 0.4151852304022704\n",
      "iterations 1409 accuray : 0.8756563747111952  loss : 0.4151273245516709\n",
      "iterations 1410 accuray : 0.8756563747111952  loss : 0.41507019674512025\n",
      "iterations 1411 accuray : 0.8756563747111952  loss : 0.41501284458500665\n",
      "iterations 1412 accuray : 0.8758664146187776  loss : 0.414954558481819\n",
      "iterations 1413 accuray : 0.8756563747111952  loss : 0.41489632502075985\n",
      "iterations 1414 accuray : 0.87607645452636  loss : 0.41483622561785094\n",
      "iterations 1415 accuray : 0.87607645452636  loss : 0.41477936005215144\n",
      "iterations 1416 accuray : 0.87607645452636  loss : 0.4147211922695035\n",
      "iterations 1417 accuray : 0.87607645452636  loss : 0.4146623201029516\n",
      "iterations 1418 accuray : 0.87607645452636  loss : 0.4146039145884324\n",
      "iterations 1419 accuray : 0.87607645452636  loss : 0.4145467699242843\n",
      "iterations 1420 accuray : 0.8762864944339425  loss : 0.4144885843903613\n",
      "iterations 1421 accuray : 0.8767065742491074  loss : 0.41442946843568784\n",
      "iterations 1422 accuray : 0.8767065742491074  loss : 0.41437042960479537\n",
      "iterations 1423 accuray : 0.8767065742491074  loss : 0.414314032400335\n",
      "iterations 1424 accuray : 0.8767065742491074  loss : 0.41425583028530266\n",
      "iterations 1425 accuray : 0.8769166141566898  loss : 0.4141969364570732\n",
      "iterations 1426 accuray : 0.8771266540642723  loss : 0.4141397606313141\n",
      "iterations 1427 accuray : 0.8773366939718547  loss : 0.4140825372238887\n",
      "iterations 1428 accuray : 0.8773366939718547  loss : 0.4140253578577758\n",
      "iterations 1429 accuray : 0.8773366939718547  loss : 0.4139698357576137\n",
      "iterations 1430 accuray : 0.8773366939718547  loss : 0.41391205428045624\n",
      "iterations 1431 accuray : 0.877546733879437  loss : 0.413854810754478\n",
      "iterations 1432 accuray : 0.8781768536021844  loss : 0.41379713163739346\n",
      "iterations 1433 accuray : 0.8783868935097668  loss : 0.4137398146282028\n",
      "iterations 1434 accuray : 0.8785969334173493  loss : 0.41368264954521944\n",
      "iterations 1435 accuray : 0.8790170132325141  loss : 0.41362531974775146\n",
      "iterations 1436 accuray : 0.879437093047679  loss : 0.41356695476268207\n",
      "iterations 1437 accuray : 0.879437093047679  loss : 0.4135110987614938\n",
      "iterations 1438 accuray : 0.879437093047679  loss : 0.41345521303664157\n",
      "iterations 1439 accuray : 0.879437093047679  loss : 0.41339777199287436\n",
      "iterations 1440 accuray : 0.879437093047679  loss : 0.41334099193815127\n",
      "iterations 1441 accuray : 0.8796471329552615  loss : 0.41328448283690794\n",
      "iterations 1442 accuray : 0.8796471329552615  loss : 0.41322660146043544\n",
      "iterations 1443 accuray : 0.8798571728628439  loss : 0.41316876018475196\n",
      "iterations 1444 accuray : 0.8798571728628439  loss : 0.41311280762386765\n",
      "iterations 1445 accuray : 0.8798571728628439  loss : 0.4130553061565856\n",
      "iterations 1446 accuray : 0.8800672127704264  loss : 0.4129969830474483\n",
      "iterations 1447 accuray : 0.8800672127704264  loss : 0.41293952200034706\n",
      "iterations 1448 accuray : 0.8802772526780088  loss : 0.41288191988819245\n",
      "iterations 1449 accuray : 0.8800672127704264  loss : 0.41282418275733435\n",
      "iterations 1450 accuray : 0.8802772526780088  loss : 0.41276695230347415\n",
      "iterations 1451 accuray : 0.8802772526780088  loss : 0.4127112672105377\n",
      "iterations 1452 accuray : 0.8804872925855912  loss : 0.4126542124789658\n",
      "iterations 1453 accuray : 0.8811174123083386  loss : 0.41259668562653223\n",
      "iterations 1454 accuray : 0.8811174123083386  loss : 0.41254083125755786\n",
      "iterations 1455 accuray : 0.881327452215921  loss : 0.412484097375869\n",
      "iterations 1456 accuray : 0.881327452215921  loss : 0.41242652738886176\n",
      "iterations 1457 accuray : 0.881327452215921  loss : 0.4123689688607303\n",
      "iterations 1458 accuray : 0.881327452215921  loss : 0.4123126378938588\n",
      "iterations 1459 accuray : 0.881327452215921  loss : 0.412254332676232\n",
      "iterations 1460 accuray : 0.881327452215921  loss : 0.41219697069222183\n",
      "iterations 1461 accuray : 0.881327452215921  loss : 0.4121405117094935\n",
      "iterations 1462 accuray : 0.881327452215921  loss : 0.4120855083008382\n",
      "iterations 1463 accuray : 0.8815374921235035  loss : 0.41202952621316763\n",
      "iterations 1464 accuray : 0.8817475320310859  loss : 0.41197298001465127\n",
      "iterations 1465 accuray : 0.8817475320310859  loss : 0.41191733836142974\n",
      "iterations 1466 accuray : 0.8817475320310859  loss : 0.41186048349051135\n",
      "iterations 1467 accuray : 0.8817475320310859  loss : 0.41180395768529304\n",
      "iterations 1468 accuray : 0.8817475320310859  loss : 0.41174929203771565\n",
      "iterations 1469 accuray : 0.8819575719386683  loss : 0.411691286254365\n",
      "iterations 1470 accuray : 0.8819575719386683  loss : 0.41163480832952354\n",
      "iterations 1471 accuray : 0.8821676118462508  loss : 0.41157896855465\n",
      "iterations 1472 accuray : 0.8823776517538332  loss : 0.41152374073889725\n",
      "iterations 1473 accuray : 0.8823776517538332  loss : 0.4114690608892586\n",
      "iterations 1474 accuray : 0.8823776517538332  loss : 0.4114119079358228\n",
      "iterations 1475 accuray : 0.8823776517538332  loss : 0.4113565129181401\n",
      "iterations 1476 accuray : 0.8823776517538332  loss : 0.41130151735269604\n",
      "iterations 1477 accuray : 0.8823776517538332  loss : 0.4112442854452819\n",
      "iterations 1478 accuray : 0.8823776517538332  loss : 0.4111884499113485\n",
      "iterations 1479 accuray : 0.8823776517538332  loss : 0.41113258939452246\n",
      "iterations 1480 accuray : 0.8823776517538332  loss : 0.41107577503878195\n",
      "iterations 1481 accuray : 0.8823776517538332  loss : 0.41101935855925587\n",
      "iterations 1482 accuray : 0.8823776517538332  loss : 0.41096363629118193\n",
      "iterations 1483 accuray : 0.8823776517538332  loss : 0.4109068722043724\n",
      "iterations 1484 accuray : 0.8823776517538332  loss : 0.4108502470558276\n",
      "iterations 1485 accuray : 0.8823776517538332  loss : 0.4107946166683123\n",
      "iterations 1486 accuray : 0.8823776517538332  loss : 0.41073873376737907\n",
      "iterations 1487 accuray : 0.8823776517538332  loss : 0.4106825397657714\n",
      "iterations 1488 accuray : 0.8825876916614157  loss : 0.4106265608677633\n",
      "iterations 1489 accuray : 0.8825876916614157  loss : 0.4105710152197923\n",
      "iterations 1490 accuray : 0.8825876916614157  loss : 0.4105166367641287\n",
      "iterations 1491 accuray : 0.8827977315689981  loss : 0.4104610337312364\n",
      "iterations 1492 accuray : 0.8825876916614157  loss : 0.41040540079126625\n",
      "iterations 1493 accuray : 0.8823776517538332  loss : 0.41035107627182427\n",
      "iterations 1494 accuray : 0.8827977315689981  loss : 0.41029408968764225\n",
      "iterations 1495 accuray : 0.8830077714765806  loss : 0.4102381415919116\n",
      "iterations 1496 accuray : 0.883217811384163  loss : 0.410183511602533\n",
      "iterations 1497 accuray : 0.8830077714765806  loss : 0.41012912698299825\n",
      "iterations 1498 accuray : 0.883217811384163  loss : 0.41007459254630246\n",
      "iterations 1499 accuray : 0.8830077714765806  loss : 0.41001961163401823\n",
      "iterations 1500 accuray : 0.8830077714765806  loss : 0.40996315745545703\n",
      "iterations 1501 accuray : 0.883217811384163  loss : 0.4099069529872567\n",
      "iterations 1502 accuray : 0.883217811384163  loss : 0.4098516438646022\n",
      "iterations 1503 accuray : 0.883217811384163  loss : 0.4097962546631848\n",
      "iterations 1504 accuray : 0.883217811384163  loss : 0.40974135408358814\n",
      "iterations 1505 accuray : 0.883217811384163  loss : 0.4096849892664719\n",
      "iterations 1506 accuray : 0.883217811384163  loss : 0.409629425787114\n",
      "iterations 1507 accuray : 0.8834278512917454  loss : 0.40957320882083187\n",
      "iterations 1508 accuray : 0.8836378911993279  loss : 0.4095180478543788\n",
      "iterations 1509 accuray : 0.8836378911993279  loss : 0.40946341426426375\n",
      "iterations 1510 accuray : 0.8836378911993279  loss : 0.4094093063205148\n",
      "iterations 1511 accuray : 0.8836378911993279  loss : 0.40935347565499586\n",
      "iterations 1512 accuray : 0.8836378911993279  loss : 0.40929747116411336\n",
      "iterations 1513 accuray : 0.8836378911993279  loss : 0.40924196852799744\n",
      "iterations 1514 accuray : 0.8836378911993279  loss : 0.4091879342662103\n",
      "iterations 1515 accuray : 0.8838479311069103  loss : 0.4091318451004656\n",
      "iterations 1516 accuray : 0.8838479311069103  loss : 0.4090780994898591\n",
      "iterations 1517 accuray : 0.8840579710144928  loss : 0.40902351151363614\n",
      "iterations 1518 accuray : 0.8840579710144928  loss : 0.4089688237330314\n",
      "iterations 1519 accuray : 0.8840579710144928  loss : 0.40891346641549386\n",
      "iterations 1520 accuray : 0.8840579710144928  loss : 0.40885966553020087\n",
      "iterations 1521 accuray : 0.8840579710144928  loss : 0.40880590378630016\n",
      "iterations 1522 accuray : 0.8840579710144928  loss : 0.4087512561963153\n",
      "iterations 1523 accuray : 0.8840579710144928  loss : 0.4086957859485192\n",
      "iterations 1524 accuray : 0.8840579710144928  loss : 0.4086404894573404\n",
      "iterations 1525 accuray : 0.8840579710144928  loss : 0.4085858041953856\n",
      "iterations 1526 accuray : 0.8840579710144928  loss : 0.4085309074138889\n",
      "iterations 1527 accuray : 0.8840579710144928  loss : 0.40847666321297915\n",
      "iterations 1528 accuray : 0.8840579710144928  loss : 0.40842197920278\n",
      "iterations 1529 accuray : 0.8840579710144928  loss : 0.408366457412523\n",
      "iterations 1530 accuray : 0.8842680109220752  loss : 0.4083121446677319\n",
      "iterations 1531 accuray : 0.8842680109220752  loss : 0.40825643725697386\n",
      "iterations 1532 accuray : 0.8842680109220752  loss : 0.4082020180597563\n",
      "iterations 1533 accuray : 0.8842680109220752  loss : 0.4081465729838437\n",
      "iterations 1534 accuray : 0.8842680109220752  loss : 0.40809208729102747\n",
      "iterations 1535 accuray : 0.8842680109220752  loss : 0.4080380775609558\n",
      "iterations 1536 accuray : 0.8844780508296576  loss : 0.407983271858258\n",
      "iterations 1537 accuray : 0.8844780508296576  loss : 0.40792920132246724\n",
      "iterations 1538 accuray : 0.8846880907372401  loss : 0.40787422602934653\n",
      "iterations 1539 accuray : 0.8846880907372401  loss : 0.40782030674815767\n",
      "iterations 1540 accuray : 0.8846880907372401  loss : 0.4077664858593987\n",
      "iterations 1541 accuray : 0.8846880907372401  loss : 0.4077129025871978\n",
      "iterations 1542 accuray : 0.8853182104599874  loss : 0.40765761380704046\n",
      "iterations 1543 accuray : 0.8853182104599874  loss : 0.40760411283641185\n",
      "iterations 1544 accuray : 0.8853182104599874  loss : 0.4075509182352033\n",
      "iterations 1545 accuray : 0.8853182104599874  loss : 0.40749547248503426\n",
      "iterations 1546 accuray : 0.8853182104599874  loss : 0.40744008292728673\n",
      "iterations 1547 accuray : 0.8853182104599874  loss : 0.40738632926685525\n",
      "iterations 1548 accuray : 0.8853182104599874  loss : 0.4073322065696429\n",
      "iterations 1549 accuray : 0.8853182104599874  loss : 0.4072777523058073\n",
      "iterations 1550 accuray : 0.8855282503675699  loss : 0.4072233449105256\n",
      "iterations 1551 accuray : 0.8855282503675699  loss : 0.4071692154686135\n",
      "iterations 1552 accuray : 0.8855282503675699  loss : 0.4071165501540272\n",
      "iterations 1553 accuray : 0.8855282503675699  loss : 0.40706228815643725\n",
      "iterations 1554 accuray : 0.8855282503675699  loss : 0.4070079667910314\n",
      "iterations 1555 accuray : 0.8855282503675699  loss : 0.40695374814800034\n",
      "iterations 1556 accuray : 0.8855282503675699  loss : 0.40689996790396143\n",
      "iterations 1557 accuray : 0.8855282503675699  loss : 0.40684628193781003\n",
      "iterations 1558 accuray : 0.8855282503675699  loss : 0.4067934557281114\n",
      "iterations 1559 accuray : 0.8855282503675699  loss : 0.40673898052235885\n",
      "iterations 1560 accuray : 0.8855282503675699  loss : 0.4066860051649857\n",
      "iterations 1561 accuray : 0.8855282503675699  loss : 0.40663309503236683\n",
      "iterations 1562 accuray : 0.8855282503675699  loss : 0.40657914792853933\n",
      "iterations 1563 accuray : 0.8855282503675699  loss : 0.40652660635562915\n",
      "iterations 1564 accuray : 0.8855282503675699  loss : 0.4064724827250233\n",
      "iterations 1565 accuray : 0.8855282503675699  loss : 0.4064186701073846\n",
      "iterations 1566 accuray : 0.8857382902751523  loss : 0.4063644999298508\n",
      "iterations 1567 accuray : 0.8857382902751523  loss : 0.4063113215229803\n",
      "iterations 1568 accuray : 0.8857382902751523  loss : 0.4062588995053667\n",
      "iterations 1569 accuray : 0.8861583700903172  loss : 0.406203222483087\n",
      "iterations 1570 accuray : 0.8861583700903172  loss : 0.4061503631777759\n",
      "iterations 1571 accuray : 0.8857382902751523  loss : 0.4060986778420155\n",
      "iterations 1572 accuray : 0.8861583700903172  loss : 0.40604521475928473\n",
      "iterations 1573 accuray : 0.8861583700903172  loss : 0.4059909042402161\n",
      "iterations 1574 accuray : 0.8861583700903172  loss : 0.405938072519873\n",
      "iterations 1575 accuray : 0.8863684099978996  loss : 0.4058848224361701\n",
      "iterations 1576 accuray : 0.8863684099978996  loss : 0.4058323604750698\n",
      "iterations 1577 accuray : 0.8863684099978996  loss : 0.40577840774304785\n",
      "iterations 1578 accuray : 0.886998529720647  loss : 0.40572509450036776\n",
      "iterations 1579 accuray : 0.886998529720647  loss : 0.4056735608807257\n",
      "iterations 1580 accuray : 0.886998529720647  loss : 0.40561906210259013\n",
      "iterations 1581 accuray : 0.886998529720647  loss : 0.4055663513115115\n",
      "iterations 1582 accuray : 0.886998529720647  loss : 0.4055120191444842\n",
      "iterations 1583 accuray : 0.8872085696282294  loss : 0.40545816890534847\n",
      "iterations 1584 accuray : 0.8872085696282294  loss : 0.40540495485823064\n",
      "iterations 1585 accuray : 0.8872085696282294  loss : 0.4053522108188001\n",
      "iterations 1586 accuray : 0.8874186095358118  loss : 0.4052975938672352\n",
      "iterations 1587 accuray : 0.8876286494433943  loss : 0.4052443452059092\n",
      "iterations 1588 accuray : 0.8876286494433943  loss : 0.40519161358644257\n",
      "iterations 1589 accuray : 0.8876286494433943  loss : 0.4051384239751567\n",
      "iterations 1590 accuray : 0.8878386893509767  loss : 0.40508553228880684\n",
      "iterations 1591 accuray : 0.8878386893509767  loss : 0.40503171431906915\n",
      "iterations 1592 accuray : 0.8878386893509767  loss : 0.4049789230141314\n",
      "iterations 1593 accuray : 0.8880487292585592  loss : 0.40492576892387533\n",
      "iterations 1594 accuray : 0.8880487292585592  loss : 0.40487397628389493\n",
      "iterations 1595 accuray : 0.8880487292585592  loss : 0.4048224277906517\n",
      "iterations 1596 accuray : 0.8880487292585592  loss : 0.40476769717115957\n",
      "iterations 1597 accuray : 0.8880487292585592  loss : 0.4047149971927197\n",
      "iterations 1598 accuray : 0.8880487292585592  loss : 0.4046630709190672\n",
      "iterations 1599 accuray : 0.8880487292585592  loss : 0.4046095204283734\n",
      "iterations 1600 accuray : 0.8882587691661415  loss : 0.40455544572898977\n",
      "iterations 1601 accuray : 0.8882587691661415  loss : 0.4045027022179406\n",
      "iterations 1602 accuray : 0.888468809073724  loss : 0.4044505041660117\n",
      "iterations 1603 accuray : 0.8886788489813064  loss : 0.4043957177305602\n",
      "iterations 1604 accuray : 0.8890989287964713  loss : 0.4043438529301066\n",
      "iterations 1605 accuray : 0.8888888888888888  loss : 0.4042912232254095\n",
      "iterations 1606 accuray : 0.8890989287964713  loss : 0.40423763399266077\n",
      "iterations 1607 accuray : 0.8895190086116362  loss : 0.40418558375223435\n",
      "iterations 1608 accuray : 0.8890989287964713  loss : 0.40413439100393184\n",
      "iterations 1609 accuray : 0.8890989287964713  loss : 0.404082749636796\n",
      "iterations 1610 accuray : 0.8890989287964713  loss : 0.40403080664769075\n",
      "iterations 1611 accuray : 0.8895190086116362  loss : 0.4039774033280543\n",
      "iterations 1612 accuray : 0.8893089687040537  loss : 0.40392580752130125\n",
      "iterations 1613 accuray : 0.8897290485192186  loss : 0.40387239985548096\n",
      "iterations 1614 accuray : 0.8890989287964713  loss : 0.4038201672299441\n",
      "iterations 1615 accuray : 0.8899390884268011  loss : 0.40376668881126204\n",
      "iterations 1616 accuray : 0.8901491283343835  loss : 0.4037139922273278\n",
      "iterations 1617 accuray : 0.8901491283343835  loss : 0.40366234248166855\n",
      "iterations 1618 accuray : 0.8905692081495484  loss : 0.4036098732470381\n",
      "iterations 1619 accuray : 0.8905692081495484  loss : 0.40355702844633806\n",
      "iterations 1620 accuray : 0.8905692081495484  loss : 0.40350500364051556\n",
      "iterations 1621 accuray : 0.8905692081495484  loss : 0.4034543809378059\n",
      "iterations 1622 accuray : 0.8905692081495484  loss : 0.4034022225774287\n",
      "iterations 1623 accuray : 0.8905692081495484  loss : 0.4033494411132974\n",
      "iterations 1624 accuray : 0.8905692081495484  loss : 0.40329584936525903\n",
      "iterations 1625 accuray : 0.8905692081495484  loss : 0.4032431690216772\n",
      "iterations 1626 accuray : 0.8907792480571308  loss : 0.4031911012659145\n",
      "iterations 1627 accuray : 0.8907792480571308  loss : 0.40314030237671733\n",
      "iterations 1628 accuray : 0.8907792480571308  loss : 0.40308866571820284\n",
      "iterations 1629 accuray : 0.8909892879647133  loss : 0.4030357050326777\n",
      "iterations 1630 accuray : 0.8907792480571308  loss : 0.4029855267955686\n",
      "iterations 1631 accuray : 0.8909892879647133  loss : 0.40293341789680415\n",
      "iterations 1632 accuray : 0.8907792480571308  loss : 0.4028830071674777\n",
      "iterations 1633 accuray : 0.8909892879647133  loss : 0.4028291071516929\n",
      "iterations 1634 accuray : 0.8909892879647133  loss : 0.40277788806670695\n",
      "iterations 1635 accuray : 0.8909892879647133  loss : 0.4027256346888195\n",
      "iterations 1636 accuray : 0.8909892879647133  loss : 0.40267341223361686\n",
      "iterations 1637 accuray : 0.8914093677798782  loss : 0.40262061453695364\n",
      "iterations 1638 accuray : 0.8914093677798782  loss : 0.4025691507933146\n",
      "iterations 1639 accuray : 0.8914093677798782  loss : 0.40251922661624445\n",
      "iterations 1640 accuray : 0.8914093677798782  loss : 0.40246650936401424\n",
      "iterations 1641 accuray : 0.8914093677798782  loss : 0.4024148906478978\n",
      "iterations 1642 accuray : 0.891829447595043  loss : 0.4023627918749397\n",
      "iterations 1643 accuray : 0.891829447595043  loss : 0.40231037588205304\n",
      "iterations 1644 accuray : 0.891829447595043  loss : 0.402257904354718\n",
      "iterations 1645 accuray : 0.891829447595043  loss : 0.4022051032205876\n",
      "iterations 1646 accuray : 0.8920394875026255  loss : 0.4021530687118984\n",
      "iterations 1647 accuray : 0.8920394875026255  loss : 0.40210235385986076\n",
      "iterations 1648 accuray : 0.891829447595043  loss : 0.40205196561064743\n",
      "iterations 1649 accuray : 0.8922495274102079  loss : 0.40199950414369356\n",
      "iterations 1650 accuray : 0.8922495274102079  loss : 0.40194911920548176\n",
      "iterations 1651 accuray : 0.8922495274102079  loss : 0.4018980125975148\n",
      "iterations 1652 accuray : 0.8922495274102079  loss : 0.40184656132977264\n",
      "iterations 1653 accuray : 0.8922495274102079  loss : 0.4017945742700035\n",
      "iterations 1654 accuray : 0.8922495274102079  loss : 0.40174433764691403\n",
      "iterations 1655 accuray : 0.8922495274102079  loss : 0.4016930078366574\n",
      "iterations 1656 accuray : 0.8922495274102079  loss : 0.40164252862066074\n",
      "iterations 1657 accuray : 0.8922495274102079  loss : 0.40159055228521573\n",
      "iterations 1658 accuray : 0.8924595673177904  loss : 0.40153853435605147\n",
      "iterations 1659 accuray : 0.8924595673177904  loss : 0.401488103403676\n",
      "iterations 1660 accuray : 0.8924595673177904  loss : 0.40143739530080386\n",
      "iterations 1661 accuray : 0.8924595673177904  loss : 0.4013856152668619\n",
      "iterations 1662 accuray : 0.8926696072253728  loss : 0.40133381659409306\n",
      "iterations 1663 accuray : 0.8926696072253728  loss : 0.4012839554626154\n",
      "iterations 1664 accuray : 0.8926696072253728  loss : 0.40123165543432326\n",
      "iterations 1665 accuray : 0.8926696072253728  loss : 0.4011803848860491\n",
      "iterations 1666 accuray : 0.8928796471329553  loss : 0.4011288917000108\n",
      "iterations 1667 accuray : 0.8928796471329553  loss : 0.4010776353436782\n",
      "iterations 1668 accuray : 0.8930896870405377  loss : 0.40102755447058525\n",
      "iterations 1669 accuray : 0.8930896870405377  loss : 0.4009767210320495\n",
      "iterations 1670 accuray : 0.8932997269481201  loss : 0.4009251748852931\n",
      "iterations 1671 accuray : 0.8932997269481201  loss : 0.40087297489226886\n",
      "iterations 1672 accuray : 0.8932997269481201  loss : 0.40082182114206333\n",
      "iterations 1673 accuray : 0.8932997269481201  loss : 0.40077084999337703\n",
      "iterations 1674 accuray : 0.8935097668557026  loss : 0.40071942410867295\n",
      "iterations 1675 accuray : 0.8935097668557026  loss : 0.4006686430500379\n",
      "iterations 1676 accuray : 0.8935097668557026  loss : 0.40061716949211895\n",
      "iterations 1677 accuray : 0.8935097668557026  loss : 0.4005660909399823\n",
      "iterations 1678 accuray : 0.8935097668557026  loss : 0.4005141563960276\n",
      "iterations 1679 accuray : 0.8935097668557026  loss : 0.4004647939034941\n",
      "iterations 1680 accuray : 0.8935097668557026  loss : 0.4004144850741061\n",
      "iterations 1681 accuray : 0.8935097668557026  loss : 0.40036494642507037\n",
      "iterations 1682 accuray : 0.8935097668557026  loss : 0.40031497226334584\n",
      "iterations 1683 accuray : 0.8935097668557026  loss : 0.4002631524373406\n",
      "iterations 1684 accuray : 0.8935097668557026  loss : 0.40021356684092757\n",
      "iterations 1685 accuray : 0.8935097668557026  loss : 0.4001625066311147\n",
      "iterations 1686 accuray : 0.8935097668557026  loss : 0.40011183911657067\n",
      "iterations 1687 accuray : 0.8935097668557026  loss : 0.40006188219063415\n",
      "iterations 1688 accuray : 0.8935097668557026  loss : 0.4000126797183457\n",
      "iterations 1689 accuray : 0.8935097668557026  loss : 0.3999627262490809\n",
      "iterations 1690 accuray : 0.8935097668557026  loss : 0.39991147550408235\n",
      "iterations 1691 accuray : 0.8935097668557026  loss : 0.39986160107309554\n",
      "iterations 1692 accuray : 0.893719806763285  loss : 0.39981111805799374\n",
      "iterations 1693 accuray : 0.8941398865784499  loss : 0.3997609124476728\n",
      "iterations 1694 accuray : 0.8935097668557026  loss : 0.399711596628725\n",
      "iterations 1695 accuray : 0.8941398865784499  loss : 0.39966077846373343\n",
      "iterations 1696 accuray : 0.8941398865784499  loss : 0.3996119266396086\n",
      "iterations 1697 accuray : 0.8943499264860324  loss : 0.39956261795586684\n",
      "iterations 1698 accuray : 0.8941398865784499  loss : 0.39951518165468686\n",
      "iterations 1699 accuray : 0.8941398865784499  loss : 0.3994647395399533\n",
      "iterations 1700 accuray : 0.8947700063011972  loss : 0.39941592628473893\n",
      "iterations 1701 accuray : 0.8945599663936148  loss : 0.3993659683265757\n",
      "iterations 1702 accuray : 0.8947700063011972  loss : 0.399315063279104\n",
      "iterations 1703 accuray : 0.8947700063011972  loss : 0.3992653096149476\n",
      "iterations 1704 accuray : 0.8947700063011972  loss : 0.39921494564992777\n",
      "iterations 1705 accuray : 0.8947700063011972  loss : 0.3991648494871222\n",
      "iterations 1706 accuray : 0.8947700063011972  loss : 0.39911358234842004\n",
      "iterations 1707 accuray : 0.8947700063011972  loss : 0.3990644514962746\n",
      "iterations 1708 accuray : 0.8947700063011972  loss : 0.39901490668550516\n",
      "iterations 1709 accuray : 0.8947700063011972  loss : 0.39896548610287813\n",
      "iterations 1710 accuray : 0.8947700063011972  loss : 0.39891541564532934\n",
      "iterations 1711 accuray : 0.8947700063011972  loss : 0.39886607059141893\n",
      "iterations 1712 accuray : 0.8947700063011972  loss : 0.39881527215344287\n",
      "iterations 1713 accuray : 0.8947700063011972  loss : 0.39876567312995925\n",
      "iterations 1714 accuray : 0.8947700063011972  loss : 0.3987171578450363\n",
      "iterations 1715 accuray : 0.8949800462087797  loss : 0.398666500943884\n",
      "iterations 1716 accuray : 0.8949800462087797  loss : 0.3986181682859477\n",
      "iterations 1717 accuray : 0.8947700063011972  loss : 0.3985700179167843\n",
      "iterations 1718 accuray : 0.8949800462087797  loss : 0.3985200050363334\n",
      "iterations 1719 accuray : 0.8947700063011972  loss : 0.3984710519642673\n",
      "iterations 1720 accuray : 0.8949800462087797  loss : 0.39842170792787873\n",
      "iterations 1721 accuray : 0.8949800462087797  loss : 0.398371328987883\n",
      "iterations 1722 accuray : 0.8947700063011972  loss : 0.3983222860808239\n",
      "iterations 1723 accuray : 0.8949800462087797  loss : 0.39827097025429414\n",
      "iterations 1724 accuray : 0.8949800462087797  loss : 0.3982219272732635\n",
      "iterations 1725 accuray : 0.8949800462087797  loss : 0.3981728004129176\n",
      "iterations 1726 accuray : 0.8949800462087797  loss : 0.39812375020326324\n",
      "iterations 1727 accuray : 0.8949800462087797  loss : 0.3980755686566787\n",
      "iterations 1728 accuray : 0.8951900861163621  loss : 0.39802629711214077\n",
      "iterations 1729 accuray : 0.8951900861163621  loss : 0.397977117221408\n",
      "iterations 1730 accuray : 0.8951900861163621  loss : 0.39792750393531306\n",
      "iterations 1731 accuray : 0.8951900861163621  loss : 0.3978789507422953\n",
      "iterations 1732 accuray : 0.8951900861163621  loss : 0.39782964214383654\n",
      "iterations 1733 accuray : 0.8951900861163621  loss : 0.3977806939165404\n",
      "iterations 1734 accuray : 0.8951900861163621  loss : 0.39773168005670245\n",
      "iterations 1735 accuray : 0.8951900861163621  loss : 0.397683152721489\n",
      "iterations 1736 accuray : 0.8951900861163621  loss : 0.39763409483219897\n",
      "iterations 1737 accuray : 0.8951900861163621  loss : 0.39758563106709166\n",
      "iterations 1738 accuray : 0.8954001260239446  loss : 0.3975369914252937\n",
      "iterations 1739 accuray : 0.8954001260239446  loss : 0.3974880032830524\n",
      "iterations 1740 accuray : 0.895610165931527  loss : 0.3974385153994479\n",
      "iterations 1741 accuray : 0.895610165931527  loss : 0.39738910338393535\n",
      "iterations 1742 accuray : 0.8958202058391095  loss : 0.39733951281378643\n",
      "iterations 1743 accuray : 0.8958202058391095  loss : 0.3972894007553681\n",
      "iterations 1744 accuray : 0.8958202058391095  loss : 0.39724105911219937\n",
      "iterations 1745 accuray : 0.8958202058391095  loss : 0.39719204104776035\n",
      "iterations 1746 accuray : 0.8958202058391095  loss : 0.39714486632226587\n",
      "iterations 1747 accuray : 0.8958202058391095  loss : 0.3970970814923082\n",
      "iterations 1748 accuray : 0.8960302457466919  loss : 0.3970501308023972\n",
      "iterations 1749 accuray : 0.8960302457466919  loss : 0.39700128848784055\n",
      "iterations 1750 accuray : 0.8960302457466919  loss : 0.39695324383762803\n",
      "iterations 1751 accuray : 0.8964503255618568  loss : 0.3969047200858256\n",
      "iterations 1752 accuray : 0.8964503255618568  loss : 0.3968556331365777\n",
      "iterations 1753 accuray : 0.8964503255618568  loss : 0.39680691653943\n",
      "iterations 1754 accuray : 0.8966603654694392  loss : 0.3967568630869759\n",
      "iterations 1755 accuray : 0.8966603654694392  loss : 0.39670906032814296\n",
      "iterations 1756 accuray : 0.8966603654694392  loss : 0.39666024665554594\n",
      "iterations 1757 accuray : 0.8966603654694392  loss : 0.39661189370932515\n",
      "iterations 1758 accuray : 0.8966603654694392  loss : 0.3965644742233388\n",
      "iterations 1759 accuray : 0.8966603654694392  loss : 0.39651542022924774\n",
      "iterations 1760 accuray : 0.8966603654694392  loss : 0.39646670753260893\n",
      "iterations 1761 accuray : 0.8966603654694392  loss : 0.396417567058766\n",
      "iterations 1762 accuray : 0.8968704053770217  loss : 0.3963680178319071\n",
      "iterations 1763 accuray : 0.8968704053770217  loss : 0.3963204038410097\n",
      "iterations 1764 accuray : 0.8968704053770217  loss : 0.39627321812620553\n",
      "iterations 1765 accuray : 0.8968704053770217  loss : 0.39622408422423855\n",
      "iterations 1766 accuray : 0.8968704053770217  loss : 0.3961760462915396\n",
      "iterations 1767 accuray : 0.8968704053770217  loss : 0.3961292615291137\n",
      "iterations 1768 accuray : 0.8968704053770217  loss : 0.396080833867075\n",
      "iterations 1769 accuray : 0.8970804452846041  loss : 0.3960314942602171\n",
      "iterations 1770 accuray : 0.897500525099769  loss : 0.3959826822406961\n",
      "iterations 1771 accuray : 0.897500525099769  loss : 0.3959343045467743\n",
      "iterations 1772 accuray : 0.897500525099769  loss : 0.395885933441491\n",
      "iterations 1773 accuray : 0.897500525099769  loss : 0.3958383251671679\n",
      "iterations 1774 accuray : 0.897500525099769  loss : 0.3957908590212286\n",
      "iterations 1775 accuray : 0.897500525099769  loss : 0.3957435283621287\n",
      "iterations 1776 accuray : 0.897500525099769  loss : 0.39569561497071576\n",
      "iterations 1777 accuray : 0.897500525099769  loss : 0.3956481914102234\n",
      "iterations 1778 accuray : 0.897500525099769  loss : 0.39559962678968547\n",
      "iterations 1779 accuray : 0.897500525099769  loss : 0.3955511342829666\n",
      "iterations 1780 accuray : 0.8977105650073514  loss : 0.3955032329398303\n",
      "iterations 1781 accuray : 0.8977105650073514  loss : 0.3954539169492384\n",
      "iterations 1782 accuray : 0.8977105650073514  loss : 0.39540586094694\n",
      "iterations 1783 accuray : 0.8977105650073514  loss : 0.39535844503728435\n",
      "iterations 1784 accuray : 0.8977105650073514  loss : 0.39531101326141194\n",
      "iterations 1785 accuray : 0.8977105650073514  loss : 0.3952620424016421\n",
      "iterations 1786 accuray : 0.8977105650073514  loss : 0.39521375730396685\n",
      "iterations 1787 accuray : 0.8977105650073514  loss : 0.39516614805874967\n",
      "iterations 1788 accuray : 0.8977105650073514  loss : 0.39511775112917313\n",
      "iterations 1789 accuray : 0.8977105650073514  loss : 0.3950679514911558\n",
      "iterations 1790 accuray : 0.8981306448225163  loss : 0.39502037190900424\n",
      "iterations 1791 accuray : 0.8983406847300988  loss : 0.39497167128034694\n",
      "iterations 1792 accuray : 0.8981306448225163  loss : 0.3949252507910637\n",
      "iterations 1793 accuray : 0.8983406847300988  loss : 0.39487751323250975\n",
      "iterations 1794 accuray : 0.8983406847300988  loss : 0.39483037760312817\n",
      "iterations 1795 accuray : 0.8983406847300988  loss : 0.39478300078849343\n",
      "iterations 1796 accuray : 0.8983406847300988  loss : 0.3947346308619211\n",
      "iterations 1797 accuray : 0.8985507246376812  loss : 0.39468739599992514\n",
      "iterations 1798 accuray : 0.8985507246376812  loss : 0.39463890894684744\n",
      "iterations 1799 accuray : 0.8985507246376812  loss : 0.39459162902510586\n",
      "iterations 1800 accuray : 0.8987607645452635  loss : 0.39454366141756186\n",
      "iterations 1801 accuray : 0.898970804452846  loss : 0.3944943971535734\n",
      "iterations 1802 accuray : 0.8987607645452635  loss : 0.39444840471339565\n",
      "iterations 1803 accuray : 0.8987607645452635  loss : 0.3944009459029952\n",
      "iterations 1804 accuray : 0.898970804452846  loss : 0.3943533146186995\n",
      "iterations 1805 accuray : 0.898970804452846  loss : 0.3943054889272999\n",
      "iterations 1806 accuray : 0.898970804452846  loss : 0.3942590032890009\n",
      "iterations 1807 accuray : 0.898970804452846  loss : 0.39421187712656497\n",
      "iterations 1808 accuray : 0.898970804452846  loss : 0.3941631373109859\n",
      "iterations 1809 accuray : 0.898970804452846  loss : 0.3941165128320219\n",
      "iterations 1810 accuray : 0.898970804452846  loss : 0.3940701342723442\n",
      "iterations 1811 accuray : 0.898970804452846  loss : 0.39402348862234\n",
      "iterations 1812 accuray : 0.898970804452846  loss : 0.393974806764759\n",
      "iterations 1813 accuray : 0.899390884268011  loss : 0.39392678653033825\n",
      "iterations 1814 accuray : 0.8996009241755933  loss : 0.3938786650499859\n",
      "iterations 1815 accuray : 0.8996009241755933  loss : 0.3938314670265489\n",
      "iterations 1816 accuray : 0.8996009241755933  loss : 0.39378459036384594\n",
      "iterations 1817 accuray : 0.8996009241755933  loss : 0.39373835227130677\n",
      "iterations 1818 accuray : 0.8996009241755933  loss : 0.39369122750757085\n",
      "iterations 1819 accuray : 0.8998109640831758  loss : 0.3936433087376496\n",
      "iterations 1820 accuray : 0.9000210039907582  loss : 0.3935958218534104\n",
      "iterations 1821 accuray : 0.9000210039907582  loss : 0.3935488230773968\n",
      "iterations 1822 accuray : 0.9000210039907582  loss : 0.39350071066296344\n",
      "iterations 1823 accuray : 0.9000210039907582  loss : 0.39345417099170604\n",
      "iterations 1824 accuray : 0.9000210039907582  loss : 0.39340799917936764\n",
      "iterations 1825 accuray : 0.9000210039907582  loss : 0.393361691502403\n",
      "iterations 1826 accuray : 0.9002310438983406  loss : 0.393314399520026\n",
      "iterations 1827 accuray : 0.9004410838059231  loss : 0.3932672306572246\n",
      "iterations 1828 accuray : 0.9006511237135055  loss : 0.393220037349711\n",
      "iterations 1829 accuray : 0.9006511237135055  loss : 0.39317273999770186\n",
      "iterations 1830 accuray : 0.9006511237135055  loss : 0.39312743776783854\n",
      "iterations 1831 accuray : 0.9006511237135055  loss : 0.39308051080837864\n",
      "iterations 1832 accuray : 0.9006511237135055  loss : 0.39303460957281955\n",
      "iterations 1833 accuray : 0.9006511237135055  loss : 0.39298683253978745\n",
      "iterations 1834 accuray : 0.9006511237135055  loss : 0.3929398362645343\n",
      "iterations 1835 accuray : 0.9006511237135055  loss : 0.3928928994394571\n",
      "iterations 1836 accuray : 0.9006511237135055  loss : 0.3928460042043201\n",
      "iterations 1837 accuray : 0.9006511237135055  loss : 0.3927993667216076\n",
      "iterations 1838 accuray : 0.9006511237135055  loss : 0.3927524193401012\n",
      "iterations 1839 accuray : 0.9006511237135055  loss : 0.39270480383240625\n",
      "iterations 1840 accuray : 0.9006511237135055  loss : 0.39265858873497483\n",
      "iterations 1841 accuray : 0.9006511237135055  loss : 0.3926119309660264\n",
      "iterations 1842 accuray : 0.9006511237135055  loss : 0.3925665170338769\n",
      "iterations 1843 accuray : 0.9006511237135055  loss : 0.3925195947372969\n",
      "iterations 1844 accuray : 0.9006511237135055  loss : 0.39247331263784696\n",
      "iterations 1845 accuray : 0.9006511237135055  loss : 0.3924245426664506\n",
      "iterations 1846 accuray : 0.9006511237135055  loss : 0.39237881227474897\n",
      "iterations 1847 accuray : 0.9006511237135055  loss : 0.3923322639018295\n",
      "iterations 1848 accuray : 0.900861163621088  loss : 0.39228550304476545\n",
      "iterations 1849 accuray : 0.900861163621088  loss : 0.39223904568553547\n",
      "iterations 1850 accuray : 0.900861163621088  loss : 0.39219194948141134\n",
      "iterations 1851 accuray : 0.900861163621088  loss : 0.39214578047234017\n",
      "iterations 1852 accuray : 0.900861163621088  loss : 0.39209986325351254\n",
      "iterations 1853 accuray : 0.900861163621088  loss : 0.3920527814106383\n",
      "iterations 1854 accuray : 0.900861163621088  loss : 0.39200635265009043\n",
      "iterations 1855 accuray : 0.900861163621088  loss : 0.39195997898846885\n",
      "iterations 1856 accuray : 0.9010712035286704  loss : 0.391912512675506\n",
      "iterations 1857 accuray : 0.9010712035286704  loss : 0.39186715170773234\n",
      "iterations 1858 accuray : 0.9014912833438353  loss : 0.39182089999595543\n",
      "iterations 1859 accuray : 0.9017013232514177  loss : 0.39177485768686676\n",
      "iterations 1860 accuray : 0.9017013232514177  loss : 0.3917293931611724\n",
      "iterations 1861 accuray : 0.9017013232514177  loss : 0.3916818764529451\n",
      "iterations 1862 accuray : 0.9019113631590002  loss : 0.3916357352576405\n",
      "iterations 1863 accuray : 0.9023314429741651  loss : 0.39158932255253553\n",
      "iterations 1864 accuray : 0.9023314429741651  loss : 0.39154339152870815\n",
      "iterations 1865 accuray : 0.9023314429741651  loss : 0.39149821719452543\n",
      "iterations 1866 accuray : 0.9023314429741651  loss : 0.39145301089014667\n",
      "iterations 1867 accuray : 0.9025414828817475  loss : 0.3914070661858239\n",
      "iterations 1868 accuray : 0.9025414828817475  loss : 0.391361197217535\n",
      "iterations 1869 accuray : 0.9025414828817475  loss : 0.39131493517026034\n",
      "iterations 1870 accuray : 0.90275152278933  loss : 0.3912688178785754\n",
      "iterations 1871 accuray : 0.9031716026044948  loss : 0.39122235324559584\n",
      "iterations 1872 accuray : 0.9031716026044948  loss : 0.39117663457357565\n",
      "iterations 1873 accuray : 0.9031716026044948  loss : 0.39113023928754603\n",
      "iterations 1874 accuray : 0.9033816425120773  loss : 0.3910831515248163\n",
      "iterations 1875 accuray : 0.9035916824196597  loss : 0.39103701565900373\n",
      "iterations 1876 accuray : 0.9033816425120773  loss : 0.3909928170135665\n",
      "iterations 1877 accuray : 0.9035916824196597  loss : 0.39094633444743976\n",
      "iterations 1878 accuray : 0.9035916824196597  loss : 0.3909004928514477\n",
      "iterations 1879 accuray : 0.9035916824196597  loss : 0.3908547026969335\n",
      "iterations 1880 accuray : 0.9035916824196597  loss : 0.3908079490134182\n",
      "iterations 1881 accuray : 0.9035916824196597  loss : 0.3907630485646918\n",
      "iterations 1882 accuray : 0.9035916824196597  loss : 0.390715472944664\n",
      "iterations 1883 accuray : 0.9035916824196597  loss : 0.39067094626953275\n",
      "iterations 1884 accuray : 0.9035916824196597  loss : 0.3906255834519885\n",
      "iterations 1885 accuray : 0.9035916824196597  loss : 0.39058018488284485\n",
      "iterations 1886 accuray : 0.9035916824196597  loss : 0.39053456231910955\n",
      "iterations 1887 accuray : 0.9035916824196597  loss : 0.3904884636493189\n",
      "iterations 1888 accuray : 0.9035916824196597  loss : 0.39044403328636407\n",
      "iterations 1889 accuray : 0.9035916824196597  loss : 0.39039721515878356\n",
      "iterations 1890 accuray : 0.9035916824196597  loss : 0.39035193890630737\n",
      "iterations 1891 accuray : 0.9035916824196597  loss : 0.39030711282256614\n",
      "iterations 1892 accuray : 0.9035916824196597  loss : 0.3902604099730966\n",
      "iterations 1893 accuray : 0.9035916824196597  loss : 0.3902147421714709\n",
      "iterations 1894 accuray : 0.9035916824196597  loss : 0.3901700109518166\n",
      "iterations 1895 accuray : 0.9035916824196597  loss : 0.3901253299550984\n",
      "iterations 1896 accuray : 0.9040117622348246  loss : 0.3900795397582495\n",
      "iterations 1897 accuray : 0.9040117622348246  loss : 0.3900336519515368\n",
      "iterations 1898 accuray : 0.9042218021424071  loss : 0.38998871652495887\n",
      "iterations 1899 accuray : 0.9042218021424071  loss : 0.3899427894159166\n",
      "iterations 1900 accuray : 0.9042218021424071  loss : 0.3898964208655898\n",
      "iterations 1901 accuray : 0.9044318420499895  loss : 0.3898505703375647\n",
      "iterations 1902 accuray : 0.9044318420499895  loss : 0.3898050016972951\n",
      "iterations 1903 accuray : 0.9044318420499895  loss : 0.3897603017651704\n",
      "iterations 1904 accuray : 0.9044318420499895  loss : 0.38971409626534753\n",
      "iterations 1905 accuray : 0.9044318420499895  loss : 0.3896686694307388\n",
      "iterations 1906 accuray : 0.9044318420499895  loss : 0.38962300002792494\n",
      "iterations 1907 accuray : 0.9044318420499895  loss : 0.38957902029638103\n",
      "iterations 1908 accuray : 0.9044318420499895  loss : 0.3895333966017251\n",
      "iterations 1909 accuray : 0.9046418819575719  loss : 0.3894868400151159\n",
      "iterations 1910 accuray : 0.9046418819575719  loss : 0.3894430182177852\n",
      "iterations 1911 accuray : 0.9046418819575719  loss : 0.38939728811134083\n",
      "iterations 1912 accuray : 0.9046418819575719  loss : 0.3893531835897126\n",
      "iterations 1913 accuray : 0.9048519218651544  loss : 0.3893081361163147\n",
      "iterations 1914 accuray : 0.9046418819575719  loss : 0.38926374090773375\n",
      "iterations 1915 accuray : 0.9048519218651544  loss : 0.3892191267559392\n",
      "iterations 1916 accuray : 0.9048519218651544  loss : 0.3891747082472281\n",
      "iterations 1917 accuray : 0.9050619617727368  loss : 0.3891296480307472\n",
      "iterations 1918 accuray : 0.9050619617727368  loss : 0.3890834512683955\n",
      "iterations 1919 accuray : 0.9050619617727368  loss : 0.3890393768258161\n",
      "iterations 1920 accuray : 0.9050619617727368  loss : 0.3889949448709247\n",
      "iterations 1921 accuray : 0.9052720016803193  loss : 0.38895054737635976\n",
      "iterations 1922 accuray : 0.9052720016803193  loss : 0.3889062792217039\n",
      "iterations 1923 accuray : 0.9052720016803193  loss : 0.3888604824680164\n",
      "iterations 1924 accuray : 0.9052720016803193  loss : 0.3888157796487202\n",
      "iterations 1925 accuray : 0.9056920814954842  loss : 0.3887720194071025\n",
      "iterations 1926 accuray : 0.9054820415879017  loss : 0.38872818866518255\n",
      "iterations 1927 accuray : 0.9056920814954842  loss : 0.3886826054207434\n",
      "iterations 1928 accuray : 0.9056920814954842  loss : 0.3886382857486429\n",
      "iterations 1929 accuray : 0.9059021214030666  loss : 0.3885931645995354\n",
      "iterations 1930 accuray : 0.906112161310649  loss : 0.3885478018608659\n",
      "iterations 1931 accuray : 0.906112161310649  loss : 0.3885031279106831\n",
      "iterations 1932 accuray : 0.906112161310649  loss : 0.38845984017934404\n",
      "iterations 1933 accuray : 0.906112161310649  loss : 0.38841442165715245\n",
      "iterations 1934 accuray : 0.906112161310649  loss : 0.3883706447945951\n",
      "iterations 1935 accuray : 0.906112161310649  loss : 0.3883246344634897\n",
      "iterations 1936 accuray : 0.906112161310649  loss : 0.3882804394406803\n",
      "iterations 1937 accuray : 0.906112161310649  loss : 0.38823544514844877\n",
      "iterations 1938 accuray : 0.906112161310649  loss : 0.3881913119510989\n",
      "iterations 1939 accuray : 0.906112161310649  loss : 0.3881464352441032\n",
      "iterations 1940 accuray : 0.906112161310649  loss : 0.3881013020897952\n",
      "iterations 1941 accuray : 0.906112161310649  loss : 0.3880574149450464\n",
      "iterations 1942 accuray : 0.906112161310649  loss : 0.388013167558265\n",
      "iterations 1943 accuray : 0.906112161310649  loss : 0.38796920098162235\n",
      "iterations 1944 accuray : 0.906112161310649  loss : 0.38792544828966674\n",
      "iterations 1945 accuray : 0.906112161310649  loss : 0.3878814982406505\n",
      "iterations 1946 accuray : 0.9063222012182315  loss : 0.387836855592376\n",
      "iterations 1947 accuray : 0.9063222012182315  loss : 0.38779198264696124\n",
      "iterations 1948 accuray : 0.9065322411258139  loss : 0.38774752914331073\n",
      "iterations 1949 accuray : 0.9065322411258139  loss : 0.38770401368194024\n",
      "iterations 1950 accuray : 0.9067422810333964  loss : 0.3876595912784104\n",
      "iterations 1951 accuray : 0.9067422810333964  loss : 0.38761476860810445\n",
      "iterations 1952 accuray : 0.9067422810333964  loss : 0.38757032225280363\n",
      "iterations 1953 accuray : 0.9069523209409788  loss : 0.3875268194685623\n",
      "iterations 1954 accuray : 0.9071623608485613  loss : 0.38748138162385254\n",
      "iterations 1955 accuray : 0.9071623608485613  loss : 0.3874371038431533\n",
      "iterations 1956 accuray : 0.9071623608485613  loss : 0.38739286332173506\n",
      "iterations 1957 accuray : 0.9071623608485613  loss : 0.3873492560248076\n",
      "iterations 1958 accuray : 0.9071623608485613  loss : 0.38730473169382146\n",
      "iterations 1959 accuray : 0.9071623608485613  loss : 0.38726122024705967\n",
      "iterations 1960 accuray : 0.9073724007561437  loss : 0.38721696057958405\n",
      "iterations 1961 accuray : 0.9073724007561437  loss : 0.38717364265186976\n",
      "iterations 1962 accuray : 0.9073724007561437  loss : 0.38713040402057586\n",
      "iterations 1963 accuray : 0.9073724007561437  loss : 0.38708657215262243\n",
      "iterations 1964 accuray : 0.9073724007561437  loss : 0.3870427711946842\n",
      "iterations 1965 accuray : 0.9073724007561437  loss : 0.38699833869078776\n",
      "iterations 1966 accuray : 0.908002520478891  loss : 0.38695320144545725\n",
      "iterations 1967 accuray : 0.908002520478891  loss : 0.38690925617080385\n",
      "iterations 1968 accuray : 0.908002520478891  loss : 0.38686474367884377\n",
      "iterations 1969 accuray : 0.908002520478891  loss : 0.3868210070073153\n",
      "iterations 1970 accuray : 0.908002520478891  loss : 0.3867777713349548\n",
      "iterations 1971 accuray : 0.908002520478891  loss : 0.3867337889207786\n",
      "iterations 1972 accuray : 0.908002520478891  loss : 0.3866915958819085\n",
      "iterations 1973 accuray : 0.908002520478891  loss : 0.38664786149430364\n",
      "iterations 1974 accuray : 0.9077924805713086  loss : 0.38660410976144927\n",
      "iterations 1975 accuray : 0.908002520478891  loss : 0.38655990259884426\n",
      "iterations 1976 accuray : 0.908002520478891  loss : 0.38651718131518403\n",
      "iterations 1977 accuray : 0.908002520478891  loss : 0.38647363956192277\n",
      "iterations 1978 accuray : 0.908002520478891  loss : 0.38643103522543787\n",
      "iterations 1979 accuray : 0.908002520478891  loss : 0.38638848438294904\n",
      "iterations 1980 accuray : 0.908002520478891  loss : 0.3863439582930054\n",
      "iterations 1981 accuray : 0.9082125603864735  loss : 0.38630025551952174\n",
      "iterations 1982 accuray : 0.908002520478891  loss : 0.3862575742483646\n",
      "iterations 1983 accuray : 0.908002520478891  loss : 0.38621516248985616\n",
      "iterations 1984 accuray : 0.908002520478891  loss : 0.3861729434279233\n",
      "iterations 1985 accuray : 0.9082125603864735  loss : 0.3861277397454793\n",
      "iterations 1986 accuray : 0.9082125603864735  loss : 0.38608416857437494\n",
      "iterations 1987 accuray : 0.9084226002940559  loss : 0.3860398834812776\n",
      "iterations 1988 accuray : 0.9084226002940559  loss : 0.38599732548693805\n",
      "iterations 1989 accuray : 0.9084226002940559  loss : 0.38595342676670064\n",
      "iterations 1990 accuray : 0.9084226002940559  loss : 0.385909732092805\n",
      "iterations 1991 accuray : 0.9084226002940559  loss : 0.38586535576018505\n",
      "iterations 1992 accuray : 0.9084226002940559  loss : 0.3858233001673567\n",
      "iterations 1993 accuray : 0.9084226002940559  loss : 0.385779703902389\n",
      "iterations 1994 accuray : 0.9084226002940559  loss : 0.3857363592058282\n",
      "iterations 1995 accuray : 0.9084226002940559  loss : 0.3856918251730607\n",
      "iterations 1996 accuray : 0.9084226002940559  loss : 0.3856495383858675\n",
      "iterations 1997 accuray : 0.9084226002940559  loss : 0.3856073036851283\n",
      "iterations 1998 accuray : 0.9084226002940559  loss : 0.3855635638198203\n",
      "iterations 1999 accuray : 0.9084226002940559  loss : 0.3855199171106162\n",
      "iterations 2000 accuray : 0.9086326402016384  loss : 0.38547685850332974\n",
      "iterations 2001 accuray : 0.9086326402016384  loss : 0.3854339209529711\n",
      "iterations 2002 accuray : 0.9086326402016384  loss : 0.3853909213069357\n",
      "iterations 2003 accuray : 0.9086326402016384  loss : 0.3853468647989872\n",
      "iterations 2004 accuray : 0.9086326402016384  loss : 0.38530407401554057\n",
      "iterations 2005 accuray : 0.9088426801092208  loss : 0.38526076559008365\n",
      "iterations 2006 accuray : 0.9088426801092208  loss : 0.385218642254975\n",
      "iterations 2007 accuray : 0.9088426801092208  loss : 0.3851743732268785\n",
      "iterations 2008 accuray : 0.9088426801092208  loss : 0.3851302898581686\n",
      "iterations 2009 accuray : 0.9088426801092208  loss : 0.38508827644678245\n",
      "iterations 2010 accuray : 0.9088426801092208  loss : 0.38504535693864533\n",
      "iterations 2011 accuray : 0.9088426801092208  loss : 0.38500276742657646\n",
      "iterations 2012 accuray : 0.9088426801092208  loss : 0.3849596127530823\n",
      "iterations 2013 accuray : 0.9088426801092208  loss : 0.3849152047944044\n",
      "iterations 2014 accuray : 0.9088426801092208  loss : 0.3848711491751834\n",
      "iterations 2015 accuray : 0.9088426801092208  loss : 0.38482861405529856\n",
      "iterations 2016 accuray : 0.9088426801092208  loss : 0.38478535650946555\n",
      "iterations 2017 accuray : 0.9088426801092208  loss : 0.3847418407129802\n",
      "iterations 2018 accuray : 0.9088426801092208  loss : 0.38469811342142657\n",
      "iterations 2019 accuray : 0.9090527200168032  loss : 0.384655983913746\n",
      "iterations 2020 accuray : 0.9092627599243857  loss : 0.3846126300676122\n",
      "iterations 2021 accuray : 0.9092627599243857  loss : 0.384569513235274\n",
      "iterations 2022 accuray : 0.9092627599243857  loss : 0.38452677762585935\n",
      "iterations 2023 accuray : 0.9092627599243857  loss : 0.3844837339053887\n",
      "iterations 2024 accuray : 0.9092627599243857  loss : 0.38444126340867035\n",
      "iterations 2025 accuray : 0.9092627599243857  loss : 0.3843983059070451\n",
      "iterations 2026 accuray : 0.9092627599243857  loss : 0.3843556687958396\n",
      "iterations 2027 accuray : 0.9092627599243857  loss : 0.38431312893877295\n",
      "iterations 2028 accuray : 0.9092627599243857  loss : 0.38427072275931357\n",
      "iterations 2029 accuray : 0.909472799831968  loss : 0.3842283130092288\n",
      "iterations 2030 accuray : 0.9092627599243857  loss : 0.3841859429172738\n",
      "iterations 2031 accuray : 0.9092627599243857  loss : 0.38414318313763673\n",
      "iterations 2032 accuray : 0.9092627599243857  loss : 0.3841018551725466\n",
      "iterations 2033 accuray : 0.9092627599243857  loss : 0.38405916182933225\n",
      "iterations 2034 accuray : 0.9092627599243857  loss : 0.38401694293228\n",
      "iterations 2035 accuray : 0.909892879647133  loss : 0.383973440451994\n",
      "iterations 2036 accuray : 0.909892879647133  loss : 0.38392984983897166\n",
      "iterations 2037 accuray : 0.9101029195547155  loss : 0.3838866929390536\n",
      "iterations 2038 accuray : 0.9103129594622978  loss : 0.38384381911282794\n",
      "iterations 2039 accuray : 0.9105229993698802  loss : 0.38380092306293523\n",
      "iterations 2040 accuray : 0.9105229993698802  loss : 0.38375840862498684\n",
      "iterations 2041 accuray : 0.9105229993698802  loss : 0.3837149772494935\n",
      "iterations 2042 accuray : 0.9105229993698802  loss : 0.38367242514661665\n",
      "iterations 2043 accuray : 0.9107330392774627  loss : 0.3836292124450537\n",
      "iterations 2044 accuray : 0.9105229993698802  loss : 0.38358681119657595\n",
      "iterations 2045 accuray : 0.9107330392774627  loss : 0.3835437019163417\n",
      "iterations 2046 accuray : 0.9109430791850451  loss : 0.383500273803332\n",
      "iterations 2047 accuray : 0.9109430791850451  loss : 0.3834578862107926\n",
      "iterations 2048 accuray : 0.9111531190926276  loss : 0.3834150303615083\n",
      "iterations 2049 accuray : 0.9111531190926276  loss : 0.38337278087794385\n",
      "iterations 2050 accuray : 0.9109430791850451  loss : 0.38333180800779243\n",
      "iterations 2051 accuray : 0.9111531190926276  loss : 0.3832883167896071\n",
      "iterations 2052 accuray : 0.9111531190926276  loss : 0.3832460862817987\n",
      "iterations 2053 accuray : 0.91136315900021  loss : 0.38320249945542306\n",
      "iterations 2054 accuray : 0.91136315900021  loss : 0.3831591620538882\n",
      "iterations 2055 accuray : 0.91136315900021  loss : 0.3831171913722501\n",
      "iterations 2056 accuray : 0.91136315900021  loss : 0.3830750445259228\n",
      "iterations 2057 accuray : 0.91136315900021  loss : 0.3830332359093543\n",
      "iterations 2058 accuray : 0.9115731989077924  loss : 0.38299087155821154\n",
      "iterations 2059 accuray : 0.9115731989077924  loss : 0.38294930854020764\n",
      "iterations 2060 accuray : 0.9115731989077924  loss : 0.38290832802800245\n",
      "iterations 2061 accuray : 0.9115731989077924  loss : 0.38286519750603965\n",
      "iterations 2062 accuray : 0.9115731989077924  loss : 0.38282408970631315\n",
      "iterations 2063 accuray : 0.9117832388153749  loss : 0.38278208279453196\n",
      "iterations 2064 accuray : 0.9117832388153749  loss : 0.3827407642460467\n",
      "iterations 2065 accuray : 0.9117832388153749  loss : 0.3826990921798681\n",
      "iterations 2066 accuray : 0.9117832388153749  loss : 0.38265732967514476\n",
      "iterations 2067 accuray : 0.9117832388153749  loss : 0.38261662053151785\n",
      "iterations 2068 accuray : 0.9117832388153749  loss : 0.38257486243027367\n",
      "iterations 2069 accuray : 0.9117832388153749  loss : 0.3825323577663233\n",
      "iterations 2070 accuray : 0.9117832388153749  loss : 0.38249077468372483\n",
      "iterations 2071 accuray : 0.9117832388153749  loss : 0.3824487292361242\n",
      "iterations 2072 accuray : 0.9117832388153749  loss : 0.38240771427170234\n",
      "iterations 2073 accuray : 0.9117832388153749  loss : 0.3823657368082809\n",
      "iterations 2074 accuray : 0.9117832388153749  loss : 0.38232479436493\n",
      "iterations 2075 accuray : 0.9119932787229573  loss : 0.3822832568257126\n",
      "iterations 2076 accuray : 0.9119932787229573  loss : 0.38224195417436513\n",
      "iterations 2077 accuray : 0.9119932787229573  loss : 0.3821998044184009\n",
      "iterations 2078 accuray : 0.9119932787229573  loss : 0.38215790798541277\n",
      "iterations 2079 accuray : 0.9119932787229573  loss : 0.3821155631672166\n",
      "iterations 2080 accuray : 0.9119932787229573  loss : 0.38207545280703487\n",
      "iterations 2081 accuray : 0.9119932787229573  loss : 0.38203383282499465\n",
      "iterations 2082 accuray : 0.9119932787229573  loss : 0.3819921741503263\n",
      "iterations 2083 accuray : 0.9119932787229573  loss : 0.3819510443032672\n",
      "iterations 2084 accuray : 0.9119932787229573  loss : 0.38190937550441245\n",
      "iterations 2085 accuray : 0.9119932787229573  loss : 0.38186675983982704\n",
      "iterations 2086 accuray : 0.9119932787229573  loss : 0.3818251414433102\n",
      "iterations 2087 accuray : 0.9119932787229573  loss : 0.38178475635577197\n",
      "iterations 2088 accuray : 0.9119932787229573  loss : 0.38174348549053516\n",
      "iterations 2089 accuray : 0.9119932787229573  loss : 0.38170178477765043\n",
      "iterations 2090 accuray : 0.9119932787229573  loss : 0.3816603938744172\n",
      "iterations 2091 accuray : 0.9119932787229573  loss : 0.3816175296948216\n",
      "iterations 2092 accuray : 0.9119932787229573  loss : 0.38157514617509175\n",
      "iterations 2093 accuray : 0.9119932787229573  loss : 0.38153440955797147\n",
      "iterations 2094 accuray : 0.9122033186305398  loss : 0.3814926248566052\n",
      "iterations 2095 accuray : 0.9122033186305398  loss : 0.38145256849079423\n",
      "iterations 2096 accuray : 0.9122033186305398  loss : 0.38141123223126927\n",
      "iterations 2097 accuray : 0.9119932787229573  loss : 0.38137016728123646\n",
      "iterations 2098 accuray : 0.9119932787229573  loss : 0.38132840246865213\n",
      "iterations 2099 accuray : 0.9119932787229573  loss : 0.3812880587033306\n",
      "iterations 2100 accuray : 0.9119932787229573  loss : 0.38124739124274215\n",
      "iterations 2101 accuray : 0.9119932787229573  loss : 0.38120514950352785\n",
      "iterations 2102 accuray : 0.9119932787229573  loss : 0.38116449457955043\n",
      "iterations 2103 accuray : 0.9119932787229573  loss : 0.3811232486386476\n",
      "iterations 2104 accuray : 0.9122033186305398  loss : 0.3810815632872048\n",
      "iterations 2105 accuray : 0.9119932787229573  loss : 0.38103985877812796\n",
      "iterations 2106 accuray : 0.9122033186305398  loss : 0.38099922908285094\n",
      "iterations 2107 accuray : 0.9119932787229573  loss : 0.3809578614283629\n",
      "iterations 2108 accuray : 0.9122033186305398  loss : 0.38091604579976834\n",
      "iterations 2109 accuray : 0.9126233984457047  loss : 0.3808754458673825\n",
      "iterations 2110 accuray : 0.9128334383532871  loss : 0.3808336247363857\n",
      "iterations 2111 accuray : 0.9130434782608695  loss : 0.38079194702709496\n",
      "iterations 2112 accuray : 0.9130434782608695  loss : 0.3807505249173965\n",
      "iterations 2113 accuray : 0.913253518168452  loss : 0.38070893340967926\n",
      "iterations 2114 accuray : 0.9130434782608695  loss : 0.38066856670990257\n",
      "iterations 2115 accuray : 0.9130434782608695  loss : 0.38062852489445076\n",
      "iterations 2116 accuray : 0.9130434782608695  loss : 0.38058775687865853\n",
      "iterations 2117 accuray : 0.9130434782608695  loss : 0.380545768685121\n",
      "iterations 2118 accuray : 0.913253518168452  loss : 0.38050579489120817\n",
      "iterations 2119 accuray : 0.913253518168452  loss : 0.38046540141815643\n",
      "iterations 2120 accuray : 0.913253518168452  loss : 0.3804248710975095\n",
      "iterations 2121 accuray : 0.9136735979836169  loss : 0.38038264352164614\n",
      "iterations 2122 accuray : 0.9138836378911993  loss : 0.3803422977711627\n",
      "iterations 2123 accuray : 0.9138836378911993  loss : 0.380301067705119\n",
      "iterations 2124 accuray : 0.9138836378911993  loss : 0.380258827733202\n",
      "iterations 2125 accuray : 0.9138836378911993  loss : 0.3802183410987099\n",
      "iterations 2126 accuray : 0.9138836378911993  loss : 0.38017765262341696\n",
      "iterations 2127 accuray : 0.9138836378911993  loss : 0.380136665045864\n",
      "iterations 2128 accuray : 0.9138836378911993  loss : 0.3800953173167314\n",
      "iterations 2129 accuray : 0.9138836378911993  loss : 0.38005352570249884\n",
      "iterations 2130 accuray : 0.9138836378911993  loss : 0.38001347457625934\n",
      "iterations 2131 accuray : 0.9138836378911993  loss : 0.3799729233378741\n",
      "iterations 2132 accuray : 0.9138836378911993  loss : 0.3799329793279679\n",
      "iterations 2133 accuray : 0.9138836378911993  loss : 0.3798930426671141\n",
      "iterations 2134 accuray : 0.9138836378911993  loss : 0.37985371791824313\n",
      "iterations 2135 accuray : 0.9138836378911993  loss : 0.3798126676249528\n",
      "iterations 2136 accuray : 0.9140936777987818  loss : 0.3797718576570639\n",
      "iterations 2137 accuray : 0.9138836378911993  loss : 0.3797315283139694\n",
      "iterations 2138 accuray : 0.9138836378911993  loss : 0.37969221006301856\n",
      "iterations 2139 accuray : 0.9138836378911993  loss : 0.37965222242704316\n",
      "iterations 2140 accuray : 0.9140936777987818  loss : 0.3796110974746795\n",
      "iterations 2141 accuray : 0.9143037177063642  loss : 0.37957007269214954\n",
      "iterations 2142 accuray : 0.9143037177063642  loss : 0.37952983273832164\n",
      "iterations 2143 accuray : 0.9143037177063642  loss : 0.37948980059912163\n",
      "iterations 2144 accuray : 0.9143037177063642  loss : 0.37944992073532263\n",
      "iterations 2145 accuray : 0.9143037177063642  loss : 0.3794099546343366\n",
      "iterations 2146 accuray : 0.9143037177063642  loss : 0.37936927626617856\n",
      "iterations 2147 accuray : 0.9143037177063642  loss : 0.3793284013417192\n",
      "iterations 2148 accuray : 0.9143037177063642  loss : 0.3792874159955052\n",
      "iterations 2149 accuray : 0.9143037177063642  loss : 0.37924589516728685\n",
      "iterations 2150 accuray : 0.9143037177063642  loss : 0.3792041187024667\n",
      "iterations 2151 accuray : 0.9143037177063642  loss : 0.3791642968888769\n",
      "iterations 2152 accuray : 0.9145137576139466  loss : 0.37912430669036795\n",
      "iterations 2153 accuray : 0.9143037177063642  loss : 0.3790847989606647\n",
      "iterations 2154 accuray : 0.9145137576139466  loss : 0.3790434650595768\n",
      "iterations 2155 accuray : 0.9149338374291115  loss : 0.3790027149265513\n",
      "iterations 2156 accuray : 0.9149338374291115  loss : 0.3789631566667224\n",
      "iterations 2157 accuray : 0.9149338374291115  loss : 0.37892298641961225\n",
      "iterations 2158 accuray : 0.9149338374291115  loss : 0.3788831050642265\n",
      "iterations 2159 accuray : 0.9149338374291115  loss : 0.37884358099065363\n",
      "iterations 2160 accuray : 0.9149338374291115  loss : 0.3788037324724306\n",
      "iterations 2161 accuray : 0.9149338374291115  loss : 0.3787638887093261\n",
      "iterations 2162 accuray : 0.9149338374291115  loss : 0.3787236400480055\n",
      "iterations 2163 accuray : 0.915143877336694  loss : 0.3786832131653952\n",
      "iterations 2164 accuray : 0.9153539172442764  loss : 0.378642528114062\n",
      "iterations 2165 accuray : 0.9153539172442764  loss : 0.3786020505746407\n",
      "iterations 2166 accuray : 0.9153539172442764  loss : 0.37856271109497613\n",
      "iterations 2167 accuray : 0.9153539172442764  loss : 0.37852291932872917\n",
      "iterations 2168 accuray : 0.9153539172442764  loss : 0.37848364223044006\n",
      "iterations 2169 accuray : 0.9153539172442764  loss : 0.3784428942129795\n",
      "iterations 2170 accuray : 0.9155639571518589  loss : 0.37840240369323447\n",
      "iterations 2171 accuray : 0.9155639571518589  loss : 0.3783633120912313\n",
      "iterations 2172 accuray : 0.9155639571518589  loss : 0.3783235101366662\n",
      "iterations 2173 accuray : 0.9155639571518589  loss : 0.3782831286572645\n",
      "iterations 2174 accuray : 0.9157739970594413  loss : 0.3782432939654162\n",
      "iterations 2175 accuray : 0.9157739970594413  loss : 0.3782037180519782\n",
      "iterations 2176 accuray : 0.9157739970594413  loss : 0.3781641764407109\n",
      "iterations 2177 accuray : 0.9157739970594413  loss : 0.3781246064451855\n",
      "iterations 2178 accuray : 0.9159840369670237  loss : 0.37808415692790526\n",
      "iterations 2179 accuray : 0.9159840369670237  loss : 0.37804445236539475\n",
      "iterations 2180 accuray : 0.9161940768746062  loss : 0.37800506088747354\n",
      "iterations 2181 accuray : 0.9159840369670237  loss : 0.377966952490302\n",
      "iterations 2182 accuray : 0.9161940768746062  loss : 0.3779279237497196\n",
      "iterations 2183 accuray : 0.9159840369670237  loss : 0.3778883844183264\n",
      "iterations 2184 accuray : 0.9161940768746062  loss : 0.3778479766404403\n",
      "iterations 2185 accuray : 0.9161940768746062  loss : 0.3778072901125594\n",
      "iterations 2186 accuray : 0.9161940768746062  loss : 0.37776804938377995\n",
      "iterations 2187 accuray : 0.9161940768746062  loss : 0.37772760256747356\n",
      "iterations 2188 accuray : 0.9161940768746062  loss : 0.37768824696884074\n",
      "iterations 2189 accuray : 0.9164041167821886  loss : 0.3776484759674635\n",
      "iterations 2190 accuray : 0.9164041167821886  loss : 0.3776089932422402\n",
      "iterations 2191 accuray : 0.9164041167821886  loss : 0.3775702365531146\n",
      "iterations 2192 accuray : 0.9164041167821886  loss : 0.3775304923530999\n",
      "iterations 2193 accuray : 0.9164041167821886  loss : 0.37749009501142894\n",
      "iterations 2194 accuray : 0.9164041167821886  loss : 0.37745021991793654\n",
      "iterations 2195 accuray : 0.9164041167821886  loss : 0.3774108077048886\n",
      "iterations 2196 accuray : 0.9164041167821886  loss : 0.37737207441357573\n",
      "iterations 2197 accuray : 0.9164041167821886  loss : 0.3773318319697089\n",
      "iterations 2198 accuray : 0.9164041167821886  loss : 0.3772922126607788\n",
      "iterations 2199 accuray : 0.9164041167821886  loss : 0.37725217505641345\n",
      "iterations 2200 accuray : 0.9164041167821886  loss : 0.37721346582587434\n",
      "iterations 2201 accuray : 0.9164041167821886  loss : 0.3771749337901551\n",
      "iterations 2202 accuray : 0.9164041167821886  loss : 0.3771355970093578\n",
      "iterations 2203 accuray : 0.9164041167821886  loss : 0.3770956934912663\n",
      "iterations 2204 accuray : 0.9164041167821886  loss : 0.3770556227402958\n",
      "iterations 2205 accuray : 0.9164041167821886  loss : 0.3770160434945998\n",
      "iterations 2206 accuray : 0.9164041167821886  loss : 0.376976917194723\n",
      "iterations 2207 accuray : 0.9164041167821886  loss : 0.3769371886597865\n",
      "iterations 2208 accuray : 0.9164041167821886  loss : 0.37689725819666836\n",
      "iterations 2209 accuray : 0.9164041167821886  loss : 0.37685825219631813\n",
      "iterations 2210 accuray : 0.9164041167821886  loss : 0.37681882310269005\n",
      "iterations 2211 accuray : 0.9161940768746062  loss : 0.37677983150907957\n",
      "iterations 2212 accuray : 0.9161940768746062  loss : 0.37674104882925086\n",
      "iterations 2213 accuray : 0.9161940768746062  loss : 0.37670153461110256\n",
      "iterations 2214 accuray : 0.9161940768746062  loss : 0.3766608047957507\n",
      "iterations 2215 accuray : 0.9161940768746062  loss : 0.37662306757379915\n",
      "iterations 2216 accuray : 0.9161940768746062  loss : 0.37658460784231196\n",
      "iterations 2217 accuray : 0.9161940768746062  loss : 0.3765453020432521\n",
      "iterations 2218 accuray : 0.9161940768746062  loss : 0.37650647842666773\n",
      "iterations 2219 accuray : 0.9161940768746062  loss : 0.3764664297605374\n",
      "iterations 2220 accuray : 0.9164041167821886  loss : 0.3764261700383918\n",
      "iterations 2221 accuray : 0.9164041167821886  loss : 0.37638752200972875\n",
      "iterations 2222 accuray : 0.9164041167821886  loss : 0.37634819662388547\n",
      "iterations 2223 accuray : 0.9164041167821886  loss : 0.37631011790931335\n",
      "iterations 2224 accuray : 0.9164041167821886  loss : 0.3762713423275339\n",
      "iterations 2225 accuray : 0.9164041167821886  loss : 0.37623266648570136\n",
      "iterations 2226 accuray : 0.9164041167821886  loss : 0.3761947801251724\n",
      "iterations 2227 accuray : 0.9164041167821886  loss : 0.37615603881059234\n",
      "iterations 2228 accuray : 0.9164041167821886  loss : 0.37611678477753724\n",
      "iterations 2229 accuray : 0.9164041167821886  loss : 0.37607822918641004\n",
      "iterations 2230 accuray : 0.9164041167821886  loss : 0.3760398670094276\n",
      "iterations 2231 accuray : 0.9164041167821886  loss : 0.3760009808778813\n",
      "iterations 2232 accuray : 0.9164041167821886  loss : 0.37596215837231334\n",
      "iterations 2233 accuray : 0.9164041167821886  loss : 0.37592396444323434\n",
      "iterations 2234 accuray : 0.9166141566897711  loss : 0.37588415227148747\n",
      "iterations 2235 accuray : 0.9166141566897711  loss : 0.3758458957140802\n",
      "iterations 2236 accuray : 0.9166141566897711  loss : 0.3758078553661167\n",
      "iterations 2237 accuray : 0.9164041167821886  loss : 0.37576852889421297\n",
      "iterations 2238 accuray : 0.9164041167821886  loss : 0.37573002911469044\n",
      "iterations 2239 accuray : 0.9164041167821886  loss : 0.3756906454537146\n",
      "iterations 2240 accuray : 0.9164041167821886  loss : 0.37565212744249876\n",
      "iterations 2241 accuray : 0.9161940768746062  loss : 0.3756132164947681\n",
      "iterations 2242 accuray : 0.9161940768746062  loss : 0.37557470092357875\n",
      "iterations 2243 accuray : 0.9161940768746062  loss : 0.37553590152460464\n",
      "iterations 2244 accuray : 0.9166141566897711  loss : 0.37549689800638136\n",
      "iterations 2245 accuray : 0.9166141566897711  loss : 0.375459426582138\n",
      "iterations 2246 accuray : 0.9166141566897711  loss : 0.37542055918849165\n",
      "iterations 2247 accuray : 0.9166141566897711  loss : 0.37538126043226944\n",
      "iterations 2248 accuray : 0.9166141566897711  loss : 0.37534205317829683\n",
      "iterations 2249 accuray : 0.9166141566897711  loss : 0.3753043032398931\n",
      "iterations 2250 accuray : 0.9166141566897711  loss : 0.3752665483209028\n",
      "iterations 2251 accuray : 0.9166141566897711  loss : 0.37522886100572406\n",
      "iterations 2252 accuray : 0.9166141566897711  loss : 0.37518963465926347\n",
      "iterations 2253 accuray : 0.9166141566897711  loss : 0.3751502608280987\n",
      "iterations 2254 accuray : 0.9166141566897711  loss : 0.3751117939078969\n",
      "iterations 2255 accuray : 0.9166141566897711  loss : 0.3750733332471788\n",
      "iterations 2256 accuray : 0.9166141566897711  loss : 0.37503405899304026\n",
      "iterations 2257 accuray : 0.9166141566897711  loss : 0.3749955286209523\n",
      "iterations 2258 accuray : 0.9166141566897711  loss : 0.37495757990330464\n",
      "iterations 2259 accuray : 0.9166141566897711  loss : 0.3749193312923491\n",
      "iterations 2260 accuray : 0.9166141566897711  loss : 0.37488057365888877\n",
      "iterations 2261 accuray : 0.9166141566897711  loss : 0.37484200901815645\n",
      "iterations 2262 accuray : 0.9166141566897711  loss : 0.374804877626263\n",
      "iterations 2263 accuray : 0.9166141566897711  loss : 0.3747662628810214\n",
      "iterations 2264 accuray : 0.9166141566897711  loss : 0.374727275276565\n",
      "iterations 2265 accuray : 0.9166141566897711  loss : 0.37468956768638395\n",
      "iterations 2266 accuray : 0.9166141566897711  loss : 0.3746512505338592\n",
      "iterations 2267 accuray : 0.9166141566897711  loss : 0.3746132141403716\n",
      "iterations 2268 accuray : 0.9166141566897711  loss : 0.37457501698848855\n",
      "iterations 2269 accuray : 0.9166141566897711  loss : 0.3745356654487002\n",
      "iterations 2270 accuray : 0.9166141566897711  loss : 0.37449642717338655\n",
      "iterations 2271 accuray : 0.9166141566897711  loss : 0.37445800589453576\n",
      "iterations 2272 accuray : 0.9166141566897711  loss : 0.37442107663445146\n",
      "iterations 2273 accuray : 0.9166141566897711  loss : 0.3743827679875324\n",
      "iterations 2274 accuray : 0.9166141566897711  loss : 0.37434345306801015\n",
      "iterations 2275 accuray : 0.9168241965973535  loss : 0.37430536085007127\n",
      "iterations 2276 accuray : 0.9168241965973535  loss : 0.37426711856671807\n",
      "iterations 2277 accuray : 0.9168241965973535  loss : 0.37422826609464643\n",
      "iterations 2278 accuray : 0.9168241965973535  loss : 0.3741909688106549\n",
      "iterations 2279 accuray : 0.9168241965973535  loss : 0.37415294470105215\n",
      "iterations 2280 accuray : 0.9168241965973535  loss : 0.3741153998663717\n",
      "iterations 2281 accuray : 0.917034236504936  loss : 0.3740767646804304\n",
      "iterations 2282 accuray : 0.917034236504936  loss : 0.3740395199943469\n",
      "iterations 2283 accuray : 0.917034236504936  loss : 0.3740013362383828\n",
      "iterations 2284 accuray : 0.917034236504936  loss : 0.3739632802661172\n",
      "iterations 2285 accuray : 0.917034236504936  loss : 0.3739239895349487\n",
      "iterations 2286 accuray : 0.917034236504936  loss : 0.3738853241062219\n",
      "iterations 2287 accuray : 0.9172442764125184  loss : 0.37384733531057923\n",
      "iterations 2288 accuray : 0.9172442764125184  loss : 0.3738092262094036\n",
      "iterations 2289 accuray : 0.9172442764125184  loss : 0.37377218625281733\n",
      "iterations 2290 accuray : 0.9172442764125184  loss : 0.3737333681814433\n",
      "iterations 2291 accuray : 0.9172442764125184  loss : 0.37369565337622895\n",
      "iterations 2292 accuray : 0.9172442764125184  loss : 0.37365787215493457\n",
      "iterations 2293 accuray : 0.9172442764125184  loss : 0.37362045370946223\n",
      "iterations 2294 accuray : 0.9172442764125184  loss : 0.3735822725900468\n",
      "iterations 2295 accuray : 0.9172442764125184  loss : 0.37354369639370416\n",
      "iterations 2296 accuray : 0.9172442764125184  loss : 0.37350640757634984\n",
      "iterations 2297 accuray : 0.9172442764125184  loss : 0.3734684565189348\n",
      "iterations 2298 accuray : 0.9172442764125184  loss : 0.3734299432925406\n",
      "iterations 2299 accuray : 0.9172442764125184  loss : 0.3733923557674831\n",
      "iterations 2300 accuray : 0.9172442764125184  loss : 0.3733549450072709\n",
      "iterations 2301 accuray : 0.9172442764125184  loss : 0.37331742057764367\n",
      "iterations 2302 accuray : 0.9174543163201008  loss : 0.37327850721260686\n",
      "iterations 2303 accuray : 0.9174543163201008  loss : 0.37324004156016316\n",
      "iterations 2304 accuray : 0.9174543163201008  loss : 0.3732025806844305\n",
      "iterations 2305 accuray : 0.9174543163201008  loss : 0.3731648167318996\n",
      "iterations 2306 accuray : 0.9174543163201008  loss : 0.3731258594281245\n",
      "iterations 2307 accuray : 0.9174543163201008  loss : 0.3730872929937568\n",
      "iterations 2308 accuray : 0.9174543163201008  loss : 0.37304897866121456\n",
      "iterations 2309 accuray : 0.9174543163201008  loss : 0.37301000290175546\n",
      "iterations 2310 accuray : 0.9174543163201008  loss : 0.37297232294607724\n",
      "iterations 2311 accuray : 0.9176643562276833  loss : 0.37293539694171374\n",
      "iterations 2312 accuray : 0.9174543163201008  loss : 0.3728978059049346\n",
      "iterations 2313 accuray : 0.9176643562276833  loss : 0.3728610112488016\n",
      "iterations 2314 accuray : 0.9176643562276833  loss : 0.3728235340387053\n",
      "iterations 2315 accuray : 0.9176643562276833  loss : 0.372786056107494\n",
      "iterations 2316 accuray : 0.9176643562276833  loss : 0.3727489969269771\n",
      "iterations 2317 accuray : 0.9176643562276833  loss : 0.37271090971770543\n",
      "iterations 2318 accuray : 0.9176643562276833  loss : 0.3726738941902257\n",
      "iterations 2319 accuray : 0.9176643562276833  loss : 0.3726356805614773\n",
      "iterations 2320 accuray : 0.9180844360428482  loss : 0.37259775704142406\n",
      "iterations 2321 accuray : 0.9180844360428482  loss : 0.3725610020222709\n",
      "iterations 2322 accuray : 0.9180844360428482  loss : 0.3725236781751537\n",
      "iterations 2323 accuray : 0.9180844360428482  loss : 0.37248617938219875\n",
      "iterations 2324 accuray : 0.9180844360428482  loss : 0.3724494546184733\n",
      "iterations 2325 accuray : 0.9180844360428482  loss : 0.3724110885934882\n",
      "iterations 2326 accuray : 0.9180844360428482  loss : 0.3723742401680511\n",
      "iterations 2327 accuray : 0.9180844360428482  loss : 0.37233745435194604\n",
      "iterations 2328 accuray : 0.9182944759504306  loss : 0.3723001586794078\n",
      "iterations 2329 accuray : 0.9189245956731779  loss : 0.3722627840508448\n",
      "iterations 2330 accuray : 0.9189245956731779  loss : 0.372225152879731\n",
      "iterations 2331 accuray : 0.9191346355807604  loss : 0.37218791741037216\n",
      "iterations 2332 accuray : 0.9195547153959253  loss : 0.3721499965486087\n",
      "iterations 2333 accuray : 0.9193446754883428  loss : 0.372112892156927\n",
      "iterations 2334 accuray : 0.9197647553035077  loss : 0.37207628221489464\n",
      "iterations 2335 accuray : 0.9197647553035077  loss : 0.37203949240699585\n",
      "iterations 2336 accuray : 0.9197647553035077  loss : 0.37200221550962037\n",
      "iterations 2337 accuray : 0.9195547153959253  loss : 0.37196555954158583\n",
      "iterations 2338 accuray : 0.9195547153959253  loss : 0.3719282976841806\n",
      "iterations 2339 accuray : 0.9197647553035077  loss : 0.37189057059573066\n",
      "iterations 2340 accuray : 0.9197647553035077  loss : 0.3718540451986512\n",
      "iterations 2341 accuray : 0.9197647553035077  loss : 0.371816723179509\n",
      "iterations 2342 accuray : 0.9197647553035077  loss : 0.3717796185655244\n",
      "iterations 2343 accuray : 0.9199747952110902  loss : 0.3717418420892399\n",
      "iterations 2344 accuray : 0.9199747952110902  loss : 0.3717049108490175\n",
      "iterations 2345 accuray : 0.9199747952110902  loss : 0.37166866354395206\n",
      "iterations 2346 accuray : 0.9199747952110902  loss : 0.37163127810411883\n",
      "iterations 2347 accuray : 0.9199747952110902  loss : 0.3715945343733055\n",
      "iterations 2348 accuray : 0.9199747952110902  loss : 0.3715576604484776\n",
      "iterations 2349 accuray : 0.9199747952110902  loss : 0.3715200590298316\n",
      "iterations 2350 accuray : 0.9199747952110902  loss : 0.3714827396972364\n",
      "iterations 2351 accuray : 0.9199747952110902  loss : 0.37144647828227223\n",
      "iterations 2352 accuray : 0.9199747952110902  loss : 0.3714086824378312\n",
      "iterations 2353 accuray : 0.9199747952110902  loss : 0.3713721062099904\n",
      "iterations 2354 accuray : 0.9199747952110902  loss : 0.37133524108322996\n",
      "iterations 2355 accuray : 0.9199747952110902  loss : 0.3712976245402089\n",
      "iterations 2356 accuray : 0.9199747952110902  loss : 0.37126104369527113\n",
      "iterations 2357 accuray : 0.9199747952110902  loss : 0.3712236836805491\n",
      "iterations 2358 accuray : 0.9199747952110902  loss : 0.37118708847611054\n",
      "iterations 2359 accuray : 0.9199747952110902  loss : 0.37115016872072176\n",
      "iterations 2360 accuray : 0.9199747952110902  loss : 0.3711120614336037\n",
      "iterations 2361 accuray : 0.9199747952110902  loss : 0.3710753014220541\n",
      "iterations 2362 accuray : 0.9199747952110902  loss : 0.3710385137337166\n",
      "iterations 2363 accuray : 0.9201848351186726  loss : 0.3710008971649223\n",
      "iterations 2364 accuray : 0.9201848351186726  loss : 0.37096421005600827\n",
      "iterations 2365 accuray : 0.9201848351186726  loss : 0.3709279871954216\n",
      "iterations 2366 accuray : 0.9201848351186726  loss : 0.3708914883787546\n",
      "iterations 2367 accuray : 0.9201848351186726  loss : 0.37085550712202303\n",
      "iterations 2368 accuray : 0.9201848351186726  loss : 0.3708187997734573\n",
      "iterations 2369 accuray : 0.9201848351186726  loss : 0.37078269845155776\n",
      "iterations 2370 accuray : 0.9201848351186726  loss : 0.3707467127390747\n",
      "iterations 2371 accuray : 0.9201848351186726  loss : 0.370710858635507\n",
      "iterations 2372 accuray : 0.9201848351186726  loss : 0.37067417773694217\n",
      "iterations 2373 accuray : 0.9201848351186726  loss : 0.37063826200589417\n",
      "iterations 2374 accuray : 0.9201848351186726  loss : 0.37060226699903964\n",
      "iterations 2375 accuray : 0.9201848351186726  loss : 0.37056629993780715\n",
      "iterations 2376 accuray : 0.9201848351186726  loss : 0.3705294949083122\n",
      "iterations 2377 accuray : 0.9201848351186726  loss : 0.37049324931359795\n",
      "iterations 2378 accuray : 0.9201848351186726  loss : 0.37045716342891\n",
      "iterations 2379 accuray : 0.9201848351186726  loss : 0.37042051448554864\n",
      "iterations 2380 accuray : 0.9201848351186726  loss : 0.3703834697095686\n",
      "iterations 2381 accuray : 0.9201848351186726  loss : 0.3703474734873103\n",
      "iterations 2382 accuray : 0.9201848351186726  loss : 0.37031063173297607\n",
      "iterations 2383 accuray : 0.9201848351186726  loss : 0.3702742390044222\n",
      "iterations 2384 accuray : 0.9201848351186726  loss : 0.37023833503101683\n",
      "iterations 2385 accuray : 0.9201848351186726  loss : 0.3702021354355612\n",
      "iterations 2386 accuray : 0.9201848351186726  loss : 0.3701653678587026\n",
      "iterations 2387 accuray : 0.9201848351186726  loss : 0.37012982743826434\n",
      "iterations 2388 accuray : 0.9201848351186726  loss : 0.37009346408366367\n",
      "iterations 2389 accuray : 0.9201848351186726  loss : 0.3700572277147608\n",
      "iterations 2390 accuray : 0.9201848351186726  loss : 0.37002135331272945\n",
      "iterations 2391 accuray : 0.9201848351186726  loss : 0.36998564681260354\n",
      "iterations 2392 accuray : 0.9201848351186726  loss : 0.369949098763145\n",
      "iterations 2393 accuray : 0.9201848351186726  loss : 0.3699124602305658\n",
      "iterations 2394 accuray : 0.9201848351186726  loss : 0.3698763313210674\n",
      "iterations 2395 accuray : 0.9201848351186726  loss : 0.36984059760058074\n",
      "iterations 2396 accuray : 0.9201848351186726  loss : 0.369804797553821\n",
      "iterations 2397 accuray : 0.9201848351186726  loss : 0.36976853503379886\n",
      "iterations 2398 accuray : 0.9201848351186726  loss : 0.36973318266837807\n",
      "iterations 2399 accuray : 0.9201848351186726  loss : 0.3696966411048622\n",
      "iterations 2400 accuray : 0.9201848351186726  loss : 0.3696612947344401\n",
      "iterations 2401 accuray : 0.9201848351186726  loss : 0.36962521496584294\n",
      "iterations 2402 accuray : 0.9201848351186726  loss : 0.36958918986312206\n",
      "iterations 2403 accuray : 0.9201848351186726  loss : 0.3695528320115719\n",
      "iterations 2404 accuray : 0.9201848351186726  loss : 0.36951748442708743\n",
      "iterations 2405 accuray : 0.9206049149338374  loss : 0.3694817678733172\n",
      "iterations 2406 accuray : 0.9201848351186726  loss : 0.369446694225031\n",
      "iterations 2407 accuray : 0.9206049149338374  loss : 0.3694102943093564\n",
      "iterations 2408 accuray : 0.9208149548414198  loss : 0.36937330436213295\n",
      "iterations 2409 accuray : 0.9206049149338374  loss : 0.36933797249553696\n",
      "iterations 2410 accuray : 0.9208149548414198  loss : 0.3693024852582945\n",
      "iterations 2411 accuray : 0.9208149548414198  loss : 0.36926679961182063\n",
      "iterations 2412 accuray : 0.9208149548414198  loss : 0.36923121196930175\n",
      "iterations 2413 accuray : 0.9208149548414198  loss : 0.3691959694913185\n",
      "iterations 2414 accuray : 0.9208149548414198  loss : 0.3691606232338815\n",
      "iterations 2415 accuray : 0.9208149548414198  loss : 0.3691246944298891\n",
      "iterations 2416 accuray : 0.9210249947490023  loss : 0.3690884278686589\n",
      "iterations 2417 accuray : 0.9210249947490023  loss : 0.3690526261066545\n",
      "iterations 2418 accuray : 0.9210249947490023  loss : 0.36901664883767776\n",
      "iterations 2419 accuray : 0.9210249947490023  loss : 0.3689811150332326\n",
      "iterations 2420 accuray : 0.9210249947490023  loss : 0.36894537525418275\n",
      "iterations 2421 accuray : 0.9210249947490023  loss : 0.3689100790468695\n",
      "iterations 2422 accuray : 0.9210249947490023  loss : 0.3688738953376483\n",
      "iterations 2423 accuray : 0.9210249947490023  loss : 0.368838494501447\n",
      "iterations 2424 accuray : 0.9210249947490023  loss : 0.3688024357980957\n",
      "iterations 2425 accuray : 0.9212350346565847  loss : 0.3687660027475366\n",
      "iterations 2426 accuray : 0.9210249947490023  loss : 0.36872976927486495\n",
      "iterations 2427 accuray : 0.9210249947490023  loss : 0.3686946610532038\n",
      "iterations 2428 accuray : 0.9212350346565847  loss : 0.3686584134902942\n",
      "iterations 2429 accuray : 0.9214450745641672  loss : 0.3686232210756002\n",
      "iterations 2430 accuray : 0.9216551144717496  loss : 0.3685863788947697\n",
      "iterations 2431 accuray : 0.9220751942869145  loss : 0.3685501387544257\n",
      "iterations 2432 accuray : 0.9220751942869145  loss : 0.3685150000155613\n",
      "iterations 2433 accuray : 0.9220751942869145  loss : 0.3684800404207858\n",
      "iterations 2434 accuray : 0.9220751942869145  loss : 0.3684452828296973\n",
      "iterations 2435 accuray : 0.9220751942869145  loss : 0.3684098681688472\n",
      "iterations 2436 accuray : 0.9220751942869145  loss : 0.3683736585424722\n",
      "iterations 2437 accuray : 0.9220751942869145  loss : 0.3683383056296929\n",
      "iterations 2438 accuray : 0.9220751942869145  loss : 0.36830216138685923\n",
      "iterations 2439 accuray : 0.9220751942869145  loss : 0.368266918097079\n",
      "iterations 2440 accuray : 0.9220751942869145  loss : 0.3682305307714505\n",
      "iterations 2441 accuray : 0.9220751942869145  loss : 0.3681953667390921\n",
      "iterations 2442 accuray : 0.9220751942869145  loss : 0.36816021813978544\n",
      "iterations 2443 accuray : 0.9220751942869145  loss : 0.3681241842697883\n",
      "iterations 2444 accuray : 0.9220751942869145  loss : 0.3680889981944608\n",
      "iterations 2445 accuray : 0.9220751942869145  loss : 0.3680545513781871\n",
      "iterations 2446 accuray : 0.9220751942869145  loss : 0.36801974168812224\n",
      "iterations 2447 accuray : 0.9216551144717496  loss : 0.3679839135603422\n",
      "iterations 2448 accuray : 0.9216551144717496  loss : 0.3679481191787483\n",
      "iterations 2449 accuray : 0.9216551144717496  loss : 0.3679121230846748\n",
      "iterations 2450 accuray : 0.9216551144717496  loss : 0.36787653364442824\n",
      "iterations 2451 accuray : 0.9216551144717496  loss : 0.3678415121416195\n",
      "iterations 2452 accuray : 0.9216551144717496  loss : 0.36780499145367274\n",
      "iterations 2453 accuray : 0.9216551144717496  loss : 0.3677691355646984\n",
      "iterations 2454 accuray : 0.9216551144717496  loss : 0.36773394654682157\n",
      "iterations 2455 accuray : 0.9216551144717496  loss : 0.3676980568079667\n",
      "iterations 2456 accuray : 0.9216551144717496  loss : 0.3676630467093487\n",
      "iterations 2457 accuray : 0.9216551144717496  loss : 0.36762773526765713\n",
      "iterations 2458 accuray : 0.9216551144717496  loss : 0.36759331974836457\n",
      "iterations 2459 accuray : 0.9216551144717496  loss : 0.3675587238482535\n",
      "iterations 2460 accuray : 0.9216551144717496  loss : 0.3675230360029886\n",
      "iterations 2461 accuray : 0.9216551144717496  loss : 0.36748827329455275\n",
      "iterations 2462 accuray : 0.9216551144717496  loss : 0.3674529207641993\n",
      "iterations 2463 accuray : 0.921865154379332  loss : 0.3674169753483634\n",
      "iterations 2464 accuray : 0.921865154379332  loss : 0.36738179167990254\n",
      "iterations 2465 accuray : 0.921865154379332  loss : 0.3673466771652946\n",
      "iterations 2466 accuray : 0.921865154379332  loss : 0.36731113209078675\n",
      "iterations 2467 accuray : 0.921865154379332  loss : 0.3672760482593176\n",
      "iterations 2468 accuray : 0.9220751942869145  loss : 0.36723983728335513\n",
      "iterations 2469 accuray : 0.9220751942869145  loss : 0.3672046152234544\n",
      "iterations 2470 accuray : 0.9220751942869145  loss : 0.36716950536425874\n",
      "iterations 2471 accuray : 0.9222852341944969  loss : 0.3671338502673705\n",
      "iterations 2472 accuray : 0.9222852341944969  loss : 0.3670991782150607\n",
      "iterations 2473 accuray : 0.9222852341944969  loss : 0.3670638225542206\n",
      "iterations 2474 accuray : 0.9222852341944969  loss : 0.36703006382812464\n",
      "iterations 2475 accuray : 0.9222852341944969  loss : 0.3669965646037406\n",
      "iterations 2476 accuray : 0.9222852341944969  loss : 0.36696201024372\n",
      "iterations 2477 accuray : 0.9222852341944969  loss : 0.3669281138211765\n",
      "iterations 2478 accuray : 0.9222852341944969  loss : 0.36689341139875825\n",
      "iterations 2479 accuray : 0.9222852341944969  loss : 0.3668590164708559\n",
      "iterations 2480 accuray : 0.9222852341944969  loss : 0.3668233532978236\n",
      "iterations 2481 accuray : 0.9222852341944969  loss : 0.3667881748129131\n",
      "iterations 2482 accuray : 0.9222852341944969  loss : 0.3667538658084494\n",
      "iterations 2483 accuray : 0.9222852341944969  loss : 0.3667193602387563\n",
      "iterations 2484 accuray : 0.9222852341944969  loss : 0.36668499857551523\n",
      "iterations 2485 accuray : 0.9220751942869145  loss : 0.3666511094736521\n",
      "iterations 2486 accuray : 0.9220751942869145  loss : 0.3666168380438511\n",
      "iterations 2487 accuray : 0.9220751942869145  loss : 0.366581700528321\n",
      "iterations 2488 accuray : 0.9222852341944969  loss : 0.36654740798758706\n",
      "iterations 2489 accuray : 0.9220751942869145  loss : 0.36651336568849\n",
      "iterations 2490 accuray : 0.9220751942869145  loss : 0.3664781303365796\n",
      "iterations 2491 accuray : 0.9220751942869145  loss : 0.36644343931466544\n",
      "iterations 2492 accuray : 0.9220751942869145  loss : 0.3664091577434016\n",
      "iterations 2493 accuray : 0.9220751942869145  loss : 0.3663737169217877\n",
      "iterations 2494 accuray : 0.9222852341944969  loss : 0.3663385878647611\n",
      "iterations 2495 accuray : 0.9222852341944969  loss : 0.36630442839869415\n",
      "iterations 2496 accuray : 0.9222852341944969  loss : 0.36626951765131854\n",
      "iterations 2497 accuray : 0.9222852341944969  loss : 0.3662355330614936\n",
      "iterations 2498 accuray : 0.9222852341944969  loss : 0.36620109735345285\n",
      "iterations 2499 accuray : 0.9222852341944969  loss : 0.36616679887467135\n",
      "iterations 2500 accuray : 0.9222852341944969  loss : 0.3661322790648748\n",
      "iterations 2501 accuray : 0.9222852341944969  loss : 0.36609743847458787\n",
      "iterations 2502 accuray : 0.9222852341944969  loss : 0.36606183958347593\n",
      "iterations 2503 accuray : 0.9222852341944969  loss : 0.36602663983126715\n",
      "iterations 2504 accuray : 0.9224952741020794  loss : 0.3659918652396723\n",
      "iterations 2505 accuray : 0.9222852341944969  loss : 0.36595663724632455\n",
      "iterations 2506 accuray : 0.9224952741020794  loss : 0.36592223718274375\n",
      "iterations 2507 accuray : 0.9224952741020794  loss : 0.36588727769829044\n",
      "iterations 2508 accuray : 0.9224952741020794  loss : 0.36585264551438523\n",
      "iterations 2509 accuray : 0.9224952741020794  loss : 0.36581830006795174\n",
      "iterations 2510 accuray : 0.9229153539172443  loss : 0.36578372744532034\n",
      "iterations 2511 accuray : 0.9224952741020794  loss : 0.3657503256981709\n",
      "iterations 2512 accuray : 0.9224952741020794  loss : 0.3657159050061031\n",
      "iterations 2513 accuray : 0.9222852341944969  loss : 0.3656814797546994\n",
      "iterations 2514 accuray : 0.9224952741020794  loss : 0.3656461915034284\n",
      "iterations 2515 accuray : 0.9224952741020794  loss : 0.3656113886196721\n",
      "iterations 2516 accuray : 0.9227053140096618  loss : 0.3655774413018696\n",
      "iterations 2517 accuray : 0.9227053140096618  loss : 0.36554340011922687\n",
      "iterations 2518 accuray : 0.9224952741020794  loss : 0.3655095240438057\n",
      "iterations 2519 accuray : 0.9227053140096618  loss : 0.36547497974235116\n",
      "iterations 2520 accuray : 0.9229153539172443  loss : 0.36544070619141944\n",
      "iterations 2521 accuray : 0.9229153539172443  loss : 0.3654065394313596\n",
      "iterations 2522 accuray : 0.9229153539172443  loss : 0.3653728422857424\n",
      "iterations 2523 accuray : 0.9227053140096618  loss : 0.36533886806109667\n",
      "iterations 2524 accuray : 0.9227053140096618  loss : 0.36530445912966547\n",
      "iterations 2525 accuray : 0.9229153539172443  loss : 0.36527032871262755\n",
      "iterations 2526 accuray : 0.9229153539172443  loss : 0.3652361418956881\n",
      "iterations 2527 accuray : 0.9229153539172443  loss : 0.36520264425033755\n",
      "iterations 2528 accuray : 0.9229153539172443  loss : 0.3651685840636143\n",
      "iterations 2529 accuray : 0.9227053140096618  loss : 0.36513526218372666\n",
      "iterations 2530 accuray : 0.9229153539172443  loss : 0.36510143592238997\n",
      "iterations 2531 accuray : 0.9229153539172443  loss : 0.36506746298088766\n",
      "iterations 2532 accuray : 0.9227053140096618  loss : 0.36503486601280033\n",
      "iterations 2533 accuray : 0.9229153539172443  loss : 0.36500053047272746\n",
      "iterations 2534 accuray : 0.9229153539172443  loss : 0.36496717707969406\n",
      "iterations 2535 accuray : 0.9229153539172443  loss : 0.3649329945901827\n",
      "iterations 2536 accuray : 0.9229153539172443  loss : 0.3648982335174301\n",
      "iterations 2537 accuray : 0.9229153539172443  loss : 0.36486375181746006\n",
      "iterations 2538 accuray : 0.9229153539172443  loss : 0.3648298963060713\n",
      "iterations 2539 accuray : 0.9229153539172443  loss : 0.36479569882579893\n",
      "iterations 2540 accuray : 0.9229153539172443  loss : 0.3647606564428043\n",
      "iterations 2541 accuray : 0.9229153539172443  loss : 0.36472587592979694\n",
      "iterations 2542 accuray : 0.9229153539172443  loss : 0.3646915668307467\n",
      "iterations 2543 accuray : 0.9229153539172443  loss : 0.3646581086787444\n",
      "iterations 2544 accuray : 0.9229153539172443  loss : 0.36462393462001663\n",
      "iterations 2545 accuray : 0.9229153539172443  loss : 0.3645898703992107\n",
      "iterations 2546 accuray : 0.9229153539172443  loss : 0.36455535825120416\n",
      "iterations 2547 accuray : 0.9227053140096618  loss : 0.3645216699063582\n",
      "iterations 2548 accuray : 0.9227053140096618  loss : 0.36448831999950076\n",
      "iterations 2549 accuray : 0.9227053140096618  loss : 0.3644544054399632\n",
      "iterations 2550 accuray : 0.9229153539172443  loss : 0.36441961300914855\n",
      "iterations 2551 accuray : 0.9229153539172443  loss : 0.3643859535814251\n",
      "iterations 2552 accuray : 0.9231253938248267  loss : 0.36435226642835283\n",
      "iterations 2553 accuray : 0.9231253938248267  loss : 0.3643177035498132\n",
      "iterations 2554 accuray : 0.9231253938248267  loss : 0.3642839181521618\n",
      "iterations 2555 accuray : 0.9233354337324091  loss : 0.3642498762121508\n",
      "iterations 2556 accuray : 0.9235454736399916  loss : 0.3642156089451828\n",
      "iterations 2557 accuray : 0.9235454736399916  loss : 0.36418147075016966\n",
      "iterations 2558 accuray : 0.9233354337324091  loss : 0.36414797966033113\n",
      "iterations 2559 accuray : 0.9235454736399916  loss : 0.36411291035115906\n",
      "iterations 2560 accuray : 0.9235454736399916  loss : 0.3640787835251478\n",
      "iterations 2561 accuray : 0.9235454736399916  loss : 0.3640448117902189\n",
      "iterations 2562 accuray : 0.9235454736399916  loss : 0.36401048362290506\n",
      "iterations 2563 accuray : 0.9235454736399916  loss : 0.3639776431442299\n",
      "iterations 2564 accuray : 0.9235454736399916  loss : 0.36394396414222385\n",
      "iterations 2565 accuray : 0.9235454736399916  loss : 0.3639103271640978\n",
      "iterations 2566 accuray : 0.9235454736399916  loss : 0.36387674681783116\n",
      "iterations 2567 accuray : 0.9235454736399916  loss : 0.36384368294640396\n",
      "iterations 2568 accuray : 0.9235454736399916  loss : 0.36380986994370423\n",
      "iterations 2569 accuray : 0.9235454736399916  loss : 0.36377638081498176\n",
      "iterations 2570 accuray : 0.9235454736399916  loss : 0.363743875681697\n",
      "iterations 2571 accuray : 0.9235454736399916  loss : 0.36370998905891877\n",
      "iterations 2572 accuray : 0.9233354337324091  loss : 0.363676066023589\n",
      "iterations 2573 accuray : 0.9233354337324091  loss : 0.36364198875632237\n",
      "iterations 2574 accuray : 0.9233354337324091  loss : 0.3636085677481805\n",
      "iterations 2575 accuray : 0.9233354337324091  loss : 0.36357562680246447\n",
      "iterations 2576 accuray : 0.9235454736399916  loss : 0.36354223890973686\n",
      "iterations 2577 accuray : 0.9235454736399916  loss : 0.36350834327283726\n",
      "iterations 2578 accuray : 0.9235454736399916  loss : 0.3634747322099556\n",
      "iterations 2579 accuray : 0.9235454736399916  loss : 0.36344134791816174\n",
      "iterations 2580 accuray : 0.9239655534551565  loss : 0.3634060443501781\n",
      "iterations 2581 accuray : 0.9241755933627389  loss : 0.363371570947054\n",
      "iterations 2582 accuray : 0.9241755933627389  loss : 0.3633389651592541\n",
      "iterations 2583 accuray : 0.9241755933627389  loss : 0.36330617037455065\n",
      "iterations 2584 accuray : 0.9241755933627389  loss : 0.36327264919399505\n",
      "iterations 2585 accuray : 0.9241755933627389  loss : 0.3632390126884628\n",
      "iterations 2586 accuray : 0.9241755933627389  loss : 0.3632057578888744\n",
      "iterations 2587 accuray : 0.9241755933627389  loss : 0.3631729061524512\n",
      "iterations 2588 accuray : 0.9241755933627389  loss : 0.3631391672074383\n",
      "iterations 2589 accuray : 0.9243856332703214  loss : 0.36310466614888426\n",
      "iterations 2590 accuray : 0.9241755933627389  loss : 0.3630717920198159\n",
      "iterations 2591 accuray : 0.9243856332703214  loss : 0.36303834048549743\n",
      "iterations 2592 accuray : 0.9243856332703214  loss : 0.3630045755801134\n",
      "iterations 2593 accuray : 0.9243856332703214  loss : 0.36297182648667503\n",
      "iterations 2594 accuray : 0.9241755933627389  loss : 0.36293880403868056\n",
      "iterations 2595 accuray : 0.9243856332703214  loss : 0.3629047816324384\n",
      "iterations 2596 accuray : 0.9241755933627389  loss : 0.36287120719955257\n",
      "iterations 2597 accuray : 0.9241755933627389  loss : 0.3628389533915713\n",
      "iterations 2598 accuray : 0.9241755933627389  loss : 0.36280553852512687\n",
      "iterations 2599 accuray : 0.9241755933627389  loss : 0.3627727135317932\n",
      "iterations 2600 accuray : 0.9241755933627389  loss : 0.3627397584008794\n",
      "iterations 2601 accuray : 0.9241755933627389  loss : 0.36270572517034655\n",
      "iterations 2602 accuray : 0.9243856332703214  loss : 0.36267232117949616\n",
      "iterations 2603 accuray : 0.9243856332703214  loss : 0.3626394159040589\n",
      "iterations 2604 accuray : 0.9245956731779038  loss : 0.3626055952767295\n",
      "iterations 2605 accuray : 0.9245956731779038  loss : 0.36257251056837003\n",
      "iterations 2606 accuray : 0.9245956731779038  loss : 0.3625379115945531\n",
      "iterations 2607 accuray : 0.9245956731779038  loss : 0.3625052779048611\n",
      "iterations 2608 accuray : 0.9245956731779038  loss : 0.3624715344411699\n",
      "iterations 2609 accuray : 0.9245956731779038  loss : 0.362438120093644\n",
      "iterations 2610 accuray : 0.9245956731779038  loss : 0.36240474990012067\n",
      "iterations 2611 accuray : 0.9245956731779038  loss : 0.362370825324607\n",
      "iterations 2612 accuray : 0.9245956731779038  loss : 0.3623377412942382\n",
      "iterations 2613 accuray : 0.9245956731779038  loss : 0.36230407432788964\n",
      "iterations 2614 accuray : 0.9245956731779038  loss : 0.3622708804342894\n",
      "iterations 2615 accuray : 0.9248057130854862  loss : 0.3622377829181705\n",
      "iterations 2616 accuray : 0.9248057130854862  loss : 0.3622043373932142\n",
      "iterations 2617 accuray : 0.9248057130854862  loss : 0.3621712400367395\n",
      "iterations 2618 accuray : 0.9248057130854862  loss : 0.3621390368990774\n",
      "iterations 2619 accuray : 0.9248057130854862  loss : 0.3621065697467481\n",
      "iterations 2620 accuray : 0.9248057130854862  loss : 0.3620744578647547\n",
      "iterations 2621 accuray : 0.9248057130854862  loss : 0.36204235017152814\n",
      "iterations 2622 accuray : 0.9248057130854862  loss : 0.3620095738880506\n",
      "iterations 2623 accuray : 0.9248057130854862  loss : 0.36197592300311543\n",
      "iterations 2624 accuray : 0.9248057130854862  loss : 0.361943575180117\n",
      "iterations 2625 accuray : 0.9248057130854862  loss : 0.36191103707492717\n",
      "iterations 2626 accuray : 0.9248057130854862  loss : 0.3618786248123117\n",
      "iterations 2627 accuray : 0.9248057130854862  loss : 0.3618449728245682\n",
      "iterations 2628 accuray : 0.9248057130854862  loss : 0.3618122982249129\n",
      "iterations 2629 accuray : 0.9248057130854862  loss : 0.3617789938493539\n",
      "iterations 2630 accuray : 0.9250157529930687  loss : 0.3617450636359094\n",
      "iterations 2631 accuray : 0.9250157529930687  loss : 0.3617126127900999\n",
      "iterations 2632 accuray : 0.9250157529930687  loss : 0.3616806128569836\n",
      "iterations 2633 accuray : 0.9250157529930687  loss : 0.3616473951028706\n",
      "iterations 2634 accuray : 0.9250157529930687  loss : 0.3616149138974627\n",
      "iterations 2635 accuray : 0.9250157529930687  loss : 0.36158234826560576\n",
      "iterations 2636 accuray : 0.9250157529930687  loss : 0.3615503985025119\n",
      "iterations 2637 accuray : 0.9250157529930687  loss : 0.3615174850503323\n",
      "iterations 2638 accuray : 0.9250157529930687  loss : 0.36148552588559235\n",
      "iterations 2639 accuray : 0.9250157529930687  loss : 0.36145290400662217\n",
      "iterations 2640 accuray : 0.9252257929006511  loss : 0.36142022813279223\n",
      "iterations 2641 accuray : 0.9250157529930687  loss : 0.36138732367865517\n",
      "iterations 2642 accuray : 0.9252257929006511  loss : 0.36135486058147637\n",
      "iterations 2643 accuray : 0.9252257929006511  loss : 0.36132277983601\n",
      "iterations 2644 accuray : 0.9250157529930687  loss : 0.36129055355855355\n",
      "iterations 2645 accuray : 0.9252257929006511  loss : 0.36125782249946964\n",
      "iterations 2646 accuray : 0.9250157529930687  loss : 0.36122627884677705\n",
      "iterations 2647 accuray : 0.9250157529930687  loss : 0.3611935391844226\n",
      "iterations 2648 accuray : 0.9250157529930687  loss : 0.3611609460008282\n",
      "iterations 2649 accuray : 0.9250157529930687  loss : 0.3611281514968151\n",
      "iterations 2650 accuray : 0.9250157529930687  loss : 0.36109616275605005\n",
      "iterations 2651 accuray : 0.9250157529930687  loss : 0.36106314821333174\n",
      "iterations 2652 accuray : 0.9250157529930687  loss : 0.36102979994110834\n",
      "iterations 2653 accuray : 0.9250157529930687  loss : 0.3609960249799756\n",
      "iterations 2654 accuray : 0.9250157529930687  loss : 0.3609635869050766\n",
      "iterations 2655 accuray : 0.9250157529930687  loss : 0.36093053784925505\n",
      "iterations 2656 accuray : 0.9250157529930687  loss : 0.3608984674481539\n",
      "iterations 2657 accuray : 0.9250157529930687  loss : 0.3608670407360591\n",
      "iterations 2658 accuray : 0.9250157529930687  loss : 0.36083487519734636\n",
      "iterations 2659 accuray : 0.9250157529930687  loss : 0.3608017205714727\n",
      "iterations 2660 accuray : 0.9250157529930687  loss : 0.36076879982511256\n",
      "iterations 2661 accuray : 0.9250157529930687  loss : 0.3607364110619368\n",
      "iterations 2662 accuray : 0.9250157529930687  loss : 0.3607036570413954\n",
      "iterations 2663 accuray : 0.9250157529930687  loss : 0.3606712997448526\n",
      "iterations 2664 accuray : 0.9250157529930687  loss : 0.36063905448493716\n",
      "iterations 2665 accuray : 0.9250157529930687  loss : 0.3606073953821465\n",
      "iterations 2666 accuray : 0.9250157529930687  loss : 0.3605751248658916\n",
      "iterations 2667 accuray : 0.9250157529930687  loss : 0.3605429717487825\n",
      "iterations 2668 accuray : 0.9252257929006511  loss : 0.36051019358597175\n",
      "iterations 2669 accuray : 0.9252257929006511  loss : 0.36047766342158194\n",
      "iterations 2670 accuray : 0.9252257929006511  loss : 0.3604455207749347\n",
      "iterations 2671 accuray : 0.9252257929006511  loss : 0.3604123959718769\n",
      "iterations 2672 accuray : 0.9252257929006511  loss : 0.3603803596364175\n",
      "iterations 2673 accuray : 0.9252257929006511  loss : 0.3603489627537905\n",
      "iterations 2674 accuray : 0.9252257929006511  loss : 0.36031699876173984\n",
      "iterations 2675 accuray : 0.9254358328082336  loss : 0.36028537240036124\n",
      "iterations 2676 accuray : 0.9254358328082336  loss : 0.36025416908729396\n",
      "iterations 2677 accuray : 0.9254358328082336  loss : 0.3602226496339466\n",
      "iterations 2678 accuray : 0.9254358328082336  loss : 0.36018961363782087\n",
      "iterations 2679 accuray : 0.9254358328082336  loss : 0.3601576239152954\n",
      "iterations 2680 accuray : 0.9252257929006511  loss : 0.3601252217532966\n",
      "iterations 2681 accuray : 0.9252257929006511  loss : 0.3600935839521437\n",
      "iterations 2682 accuray : 0.9252257929006511  loss : 0.3600614575375026\n",
      "iterations 2683 accuray : 0.9252257929006511  loss : 0.36002910039986186\n",
      "iterations 2684 accuray : 0.9252257929006511  loss : 0.3599970942950535\n",
      "iterations 2685 accuray : 0.9252257929006511  loss : 0.3599643393086203\n",
      "iterations 2686 accuray : 0.9252257929006511  loss : 0.35993221770855705\n",
      "iterations 2687 accuray : 0.9252257929006511  loss : 0.35990037549185855\n",
      "iterations 2688 accuray : 0.9252257929006511  loss : 0.3598688493209413\n",
      "iterations 2689 accuray : 0.9252257929006511  loss : 0.3598369500443427\n",
      "iterations 2690 accuray : 0.9252257929006511  loss : 0.35980493270057273\n",
      "iterations 2691 accuray : 0.9252257929006511  loss : 0.35977284455061687\n",
      "iterations 2692 accuray : 0.9254358328082336  loss : 0.3597417587741694\n",
      "iterations 2693 accuray : 0.9254358328082336  loss : 0.35970885852575063\n",
      "iterations 2694 accuray : 0.9252257929006511  loss : 0.35967677512627527\n",
      "iterations 2695 accuray : 0.9252257929006511  loss : 0.35964576776056884\n",
      "iterations 2696 accuray : 0.9252257929006511  loss : 0.35961300803430857\n",
      "iterations 2697 accuray : 0.9252257929006511  loss : 0.35958067478687217\n",
      "iterations 2698 accuray : 0.9252257929006511  loss : 0.35954815077838703\n",
      "iterations 2699 accuray : 0.9254358328082336  loss : 0.3595156035815888\n",
      "iterations 2700 accuray : 0.9254358328082336  loss : 0.3594839509423673\n",
      "iterations 2701 accuray : 0.9254358328082336  loss : 0.3594523173059697\n",
      "iterations 2702 accuray : 0.925645872715816  loss : 0.359419990645972\n",
      "iterations 2703 accuray : 0.925645872715816  loss : 0.3593886777032805\n",
      "iterations 2704 accuray : 0.925645872715816  loss : 0.35935779107463156\n",
      "iterations 2705 accuray : 0.925645872715816  loss : 0.3593262565994559\n",
      "iterations 2706 accuray : 0.925645872715816  loss : 0.35929371036487445\n",
      "iterations 2707 accuray : 0.925645872715816  loss : 0.35926204436466797\n",
      "iterations 2708 accuray : 0.925645872715816  loss : 0.3592305062264502\n",
      "iterations 2709 accuray : 0.925645872715816  loss : 0.3591988961996755\n",
      "iterations 2710 accuray : 0.925645872715816  loss : 0.3591678476499555\n",
      "iterations 2711 accuray : 0.925645872715816  loss : 0.35913475499008046\n",
      "iterations 2712 accuray : 0.9258559126233984  loss : 0.3591023901251819\n",
      "iterations 2713 accuray : 0.9258559126233984  loss : 0.3590702459574222\n",
      "iterations 2714 accuray : 0.9258559126233984  loss : 0.35903792660611367\n",
      "iterations 2715 accuray : 0.9258559126233984  loss : 0.35900595677393343\n",
      "iterations 2716 accuray : 0.9258559126233984  loss : 0.3589745550497808\n",
      "iterations 2717 accuray : 0.9258559126233984  loss : 0.3589432212609478\n",
      "iterations 2718 accuray : 0.9260659525309809  loss : 0.35891099700481155\n",
      "iterations 2719 accuray : 0.9260659525309809  loss : 0.35887980920738555\n",
      "iterations 2720 accuray : 0.9260659525309809  loss : 0.35884825640454887\n",
      "iterations 2721 accuray : 0.9260659525309809  loss : 0.3588163125322775\n",
      "iterations 2722 accuray : 0.9260659525309809  loss : 0.35878540315229523\n",
      "iterations 2723 accuray : 0.9260659525309809  loss : 0.3587544511060292\n",
      "iterations 2724 accuray : 0.9260659525309809  loss : 0.3587226127254911\n",
      "iterations 2725 accuray : 0.9260659525309809  loss : 0.3586910482544615\n",
      "iterations 2726 accuray : 0.9260659525309809  loss : 0.35865955757081575\n",
      "iterations 2727 accuray : 0.9258559126233984  loss : 0.35862698368431684\n",
      "iterations 2728 accuray : 0.9258559126233984  loss : 0.35859544088059403\n",
      "iterations 2729 accuray : 0.9258559126233984  loss : 0.3585641785969291\n",
      "iterations 2730 accuray : 0.9258559126233984  loss : 0.3585334653015519\n",
      "iterations 2731 accuray : 0.9258559126233984  loss : 0.35850201596615894\n",
      "iterations 2732 accuray : 0.9258559126233984  loss : 0.3584697562761183\n",
      "iterations 2733 accuray : 0.9258559126233984  loss : 0.3584391852242853\n",
      "iterations 2734 accuray : 0.9258559126233984  loss : 0.35840720067576043\n",
      "iterations 2735 accuray : 0.9258559126233984  loss : 0.3583766153572261\n",
      "iterations 2736 accuray : 0.9260659525309809  loss : 0.35834596170385075\n",
      "iterations 2737 accuray : 0.9258559126233984  loss : 0.3583139234523801\n",
      "iterations 2738 accuray : 0.9258559126233984  loss : 0.3582819467856684\n",
      "iterations 2739 accuray : 0.9258559126233984  loss : 0.3582503990859037\n",
      "iterations 2740 accuray : 0.9258559126233984  loss : 0.3582184315779185\n",
      "iterations 2741 accuray : 0.9260659525309809  loss : 0.3581866906365393\n",
      "iterations 2742 accuray : 0.9260659525309809  loss : 0.3581554589371206\n",
      "iterations 2743 accuray : 0.9260659525309809  loss : 0.3581247934486403\n",
      "iterations 2744 accuray : 0.9260659525309809  loss : 0.358093441502134\n",
      "iterations 2745 accuray : 0.9260659525309809  loss : 0.35806206271713203\n",
      "iterations 2746 accuray : 0.9260659525309809  loss : 0.3580309304831342\n",
      "iterations 2747 accuray : 0.9260659525309809  loss : 0.3579995885021584\n",
      "iterations 2748 accuray : 0.9260659525309809  loss : 0.3579683771140892\n",
      "iterations 2749 accuray : 0.9260659525309809  loss : 0.35793701504613656\n",
      "iterations 2750 accuray : 0.9260659525309809  loss : 0.35790487397627063\n",
      "iterations 2751 accuray : 0.9260659525309809  loss : 0.35787261247666197\n",
      "iterations 2752 accuray : 0.9260659525309809  loss : 0.3578413598788655\n",
      "iterations 2753 accuray : 0.9260659525309809  loss : 0.3578099493517253\n",
      "iterations 2754 accuray : 0.9258559126233984  loss : 0.35777863028422713\n",
      "iterations 2755 accuray : 0.9258559126233984  loss : 0.35774858582749614\n",
      "iterations 2756 accuray : 0.9258559126233984  loss : 0.3577184786006276\n",
      "iterations 2757 accuray : 0.9258559126233984  loss : 0.3576873141500375\n",
      "iterations 2758 accuray : 0.9258559126233984  loss : 0.35765644320250667\n",
      "iterations 2759 accuray : 0.9258559126233984  loss : 0.3576249076380271\n",
      "iterations 2760 accuray : 0.9258559126233984  loss : 0.35759400259500973\n",
      "iterations 2761 accuray : 0.9258559126233984  loss : 0.3575634424591104\n",
      "iterations 2762 accuray : 0.9258559126233984  loss : 0.35753194227282076\n",
      "iterations 2763 accuray : 0.9258559126233984  loss : 0.357500144703306\n",
      "iterations 2764 accuray : 0.9258559126233984  loss : 0.35746924513395945\n",
      "iterations 2765 accuray : 0.9258559126233984  loss : 0.3574373876106091\n",
      "iterations 2766 accuray : 0.9258559126233984  loss : 0.3574073899286217\n",
      "iterations 2767 accuray : 0.9258559126233984  loss : 0.35737668651958837\n",
      "iterations 2768 accuray : 0.9258559126233984  loss : 0.3573452264924267\n",
      "iterations 2769 accuray : 0.9258559126233984  loss : 0.35731393005340467\n",
      "iterations 2770 accuray : 0.9258559126233984  loss : 0.3572832959863545\n",
      "iterations 2771 accuray : 0.9258559126233984  loss : 0.3572524922804047\n",
      "iterations 2772 accuray : 0.9258559126233984  loss : 0.35722134950285517\n",
      "iterations 2773 accuray : 0.9258559126233984  loss : 0.3571901857744703\n",
      "iterations 2774 accuray : 0.9258559126233984  loss : 0.3571594410185203\n",
      "iterations 2775 accuray : 0.9258559126233984  loss : 0.3571280697232116\n",
      "iterations 2776 accuray : 0.9258559126233984  loss : 0.3570965380893958\n",
      "iterations 2777 accuray : 0.9260659525309809  loss : 0.35706594070314734\n",
      "iterations 2778 accuray : 0.9260659525309809  loss : 0.3570351945179841\n",
      "iterations 2779 accuray : 0.9260659525309809  loss : 0.35700431656958465\n",
      "iterations 2780 accuray : 0.9258559126233984  loss : 0.356974232946031\n",
      "iterations 2781 accuray : 0.9258559126233984  loss : 0.3569454548702775\n",
      "iterations 2782 accuray : 0.9258559126233984  loss : 0.3569146190847949\n",
      "iterations 2783 accuray : 0.9258559126233984  loss : 0.35688373366374515\n",
      "iterations 2784 accuray : 0.9258559126233984  loss : 0.35685292500280735\n",
      "iterations 2785 accuray : 0.9258559126233984  loss : 0.3568225628548163\n",
      "iterations 2786 accuray : 0.9258559126233984  loss : 0.3567915224301349\n",
      "iterations 2787 accuray : 0.9258559126233984  loss : 0.3567614596455855\n",
      "iterations 2788 accuray : 0.9258559126233984  loss : 0.35673064177509467\n",
      "iterations 2789 accuray : 0.9258559126233984  loss : 0.3567005371570163\n",
      "iterations 2790 accuray : 0.9258559126233984  loss : 0.35666991540516196\n",
      "iterations 2791 accuray : 0.9260659525309809  loss : 0.35663901468110404\n",
      "iterations 2792 accuray : 0.9258559126233984  loss : 0.3566092886989378\n",
      "iterations 2793 accuray : 0.9258559126233984  loss : 0.35657866149958845\n",
      "iterations 2794 accuray : 0.9258559126233984  loss : 0.3565488696573367\n",
      "iterations 2795 accuray : 0.9258559126233984  loss : 0.3565183438934153\n",
      "iterations 2796 accuray : 0.9258559126233984  loss : 0.3564883602361087\n",
      "iterations 2797 accuray : 0.9258559126233984  loss : 0.3564571096439648\n",
      "iterations 2798 accuray : 0.9258559126233984  loss : 0.356426452903223\n",
      "iterations 2799 accuray : 0.9258559126233984  loss : 0.3563951647985983\n",
      "iterations 2800 accuray : 0.9260659525309809  loss : 0.35636547898925336\n",
      "iterations 2801 accuray : 0.9260659525309809  loss : 0.3563345036693137\n",
      "iterations 2802 accuray : 0.9258559126233984  loss : 0.3563043109609424\n",
      "iterations 2803 accuray : 0.9258559126233984  loss : 0.3562737416853375\n",
      "iterations 2804 accuray : 0.9258559126233984  loss : 0.3562437833807335\n",
      "iterations 2805 accuray : 0.9258559126233984  loss : 0.35621351982905336\n",
      "iterations 2806 accuray : 0.9260659525309809  loss : 0.35618280959245807\n",
      "iterations 2807 accuray : 0.9260659525309809  loss : 0.35615257464723654\n",
      "iterations 2808 accuray : 0.9260659525309809  loss : 0.3561213289779139\n",
      "iterations 2809 accuray : 0.9260659525309809  loss : 0.35609149265293993\n",
      "iterations 2810 accuray : 0.9260659525309809  loss : 0.35606097626317856\n",
      "iterations 2811 accuray : 0.9260659525309809  loss : 0.3560312746774048\n",
      "iterations 2812 accuray : 0.9260659525309809  loss : 0.356000807516716\n",
      "iterations 2813 accuray : 0.9260659525309809  loss : 0.35597060694538885\n",
      "iterations 2814 accuray : 0.9258559126233984  loss : 0.35594068087811603\n",
      "iterations 2815 accuray : 0.9258559126233984  loss : 0.3559105523747777\n",
      "iterations 2816 accuray : 0.9258559126233984  loss : 0.3558805818271333\n",
      "iterations 2817 accuray : 0.9260659525309809  loss : 0.3558500837596254\n",
      "iterations 2818 accuray : 0.9260659525309809  loss : 0.355820357550843\n",
      "iterations 2819 accuray : 0.9260659525309809  loss : 0.35578967105850434\n",
      "iterations 2820 accuray : 0.9260659525309809  loss : 0.35575929141409807\n",
      "iterations 2821 accuray : 0.9260659525309809  loss : 0.35572915816222406\n",
      "iterations 2822 accuray : 0.9258559126233984  loss : 0.35569848033829504\n",
      "iterations 2823 accuray : 0.9258559126233984  loss : 0.35566794306378574\n",
      "iterations 2824 accuray : 0.9258559126233984  loss : 0.35563671172474076\n",
      "iterations 2825 accuray : 0.9258559126233984  loss : 0.35560728303681627\n",
      "iterations 2826 accuray : 0.9258559126233984  loss : 0.35557674123842264\n",
      "iterations 2827 accuray : 0.9258559126233984  loss : 0.3555459934345169\n",
      "iterations 2828 accuray : 0.9258559126233984  loss : 0.35551572195403824\n",
      "iterations 2829 accuray : 0.9258559126233984  loss : 0.3554851227515024\n",
      "iterations 2830 accuray : 0.9258559126233984  loss : 0.3554555629287459\n",
      "iterations 2831 accuray : 0.9258559126233984  loss : 0.3554256004966391\n",
      "iterations 2832 accuray : 0.9258559126233984  loss : 0.3553956592090135\n",
      "iterations 2833 accuray : 0.9258559126233984  loss : 0.355365627014545\n",
      "iterations 2834 accuray : 0.9258559126233984  loss : 0.3553355385560394\n",
      "iterations 2835 accuray : 0.9258559126233984  loss : 0.3553057037057019\n",
      "iterations 2836 accuray : 0.9258559126233984  loss : 0.35527587700501917\n",
      "iterations 2837 accuray : 0.9258559126233984  loss : 0.35524577785033706\n",
      "iterations 2838 accuray : 0.9258559126233984  loss : 0.35521604270586576\n",
      "iterations 2839 accuray : 0.9258559126233984  loss : 0.355185596993178\n",
      "iterations 2840 accuray : 0.9258559126233984  loss : 0.3551557413251566\n",
      "iterations 2841 accuray : 0.9258559126233984  loss : 0.35512540946288423\n",
      "iterations 2842 accuray : 0.9258559126233984  loss : 0.3550949361477092\n",
      "iterations 2843 accuray : 0.9260659525309809  loss : 0.35506529398510656\n",
      "iterations 2844 accuray : 0.9260659525309809  loss : 0.35503527805117935\n",
      "iterations 2845 accuray : 0.9260659525309809  loss : 0.3550049934466712\n",
      "iterations 2846 accuray : 0.9260659525309809  loss : 0.35497485189639894\n",
      "iterations 2847 accuray : 0.9260659525309809  loss : 0.3549453794448697\n",
      "iterations 2848 accuray : 0.9260659525309809  loss : 0.3549152967874683\n",
      "iterations 2849 accuray : 0.9260659525309809  loss : 0.3548853637868936\n",
      "iterations 2850 accuray : 0.9262759924385633  loss : 0.35485637641370665\n",
      "iterations 2851 accuray : 0.9262759924385633  loss : 0.35482661105352303\n",
      "iterations 2852 accuray : 0.9262759924385633  loss : 0.35479621671353506\n",
      "iterations 2853 accuray : 0.9262759924385633  loss : 0.3547661817878012\n",
      "iterations 2854 accuray : 0.9262759924385633  loss : 0.35473666070816273\n",
      "iterations 2855 accuray : 0.9262759924385633  loss : 0.3547071241603147\n",
      "iterations 2856 accuray : 0.9262759924385633  loss : 0.354677545277201\n",
      "iterations 2857 accuray : 0.9262759924385633  loss : 0.35464727119190065\n",
      "iterations 2858 accuray : 0.9262759924385633  loss : 0.3546182211878445\n",
      "iterations 2859 accuray : 0.9264860323461458  loss : 0.3545885721871677\n",
      "iterations 2860 accuray : 0.9264860323461458  loss : 0.35455881636532904\n",
      "iterations 2861 accuray : 0.9264860323461458  loss : 0.35452886679859225\n",
      "iterations 2862 accuray : 0.9269061121613107  loss : 0.3544993404422632\n",
      "iterations 2863 accuray : 0.9269061121613107  loss : 0.3544695816267897\n",
      "iterations 2864 accuray : 0.9269061121613107  loss : 0.3544393823084356\n",
      "iterations 2865 accuray : 0.9266960722537282  loss : 0.35440900129010794\n",
      "iterations 2866 accuray : 0.9269061121613107  loss : 0.3543791201267176\n",
      "iterations 2867 accuray : 0.9269061121613107  loss : 0.3543494385849955\n",
      "iterations 2868 accuray : 0.9269061121613107  loss : 0.3543193231013462\n",
      "iterations 2869 accuray : 0.9269061121613107  loss : 0.3542894460156507\n",
      "iterations 2870 accuray : 0.9269061121613107  loss : 0.35426032522928613\n",
      "iterations 2871 accuray : 0.9269061121613107  loss : 0.3542309450201515\n",
      "iterations 2872 accuray : 0.9269061121613107  loss : 0.35420082319777135\n",
      "iterations 2873 accuray : 0.9269061121613107  loss : 0.35417125964185653\n",
      "iterations 2874 accuray : 0.9269061121613107  loss : 0.3541417827538414\n",
      "iterations 2875 accuray : 0.9269061121613107  loss : 0.35411156554702333\n",
      "iterations 2876 accuray : 0.9269061121613107  loss : 0.354081349788485\n",
      "iterations 2877 accuray : 0.9269061121613107  loss : 0.3540512062727025\n",
      "iterations 2878 accuray : 0.9269061121613107  loss : 0.35402220170380005\n",
      "iterations 2879 accuray : 0.9269061121613107  loss : 0.35399253161690974\n",
      "iterations 2880 accuray : 0.9269061121613107  loss : 0.35396187207847757\n",
      "iterations 2881 accuray : 0.9269061121613107  loss : 0.3539324324315203\n",
      "iterations 2882 accuray : 0.9269061121613107  loss : 0.3539027636215465\n",
      "iterations 2883 accuray : 0.9269061121613107  loss : 0.3538727380804347\n",
      "iterations 2884 accuray : 0.9269061121613107  loss : 0.3538442778100074\n",
      "iterations 2885 accuray : 0.9269061121613107  loss : 0.35381429674687\n",
      "iterations 2886 accuray : 0.9269061121613107  loss : 0.35378454850253427\n",
      "iterations 2887 accuray : 0.9266960722537282  loss : 0.35375466758357443\n",
      "iterations 2888 accuray : 0.9266960722537282  loss : 0.35372501574362436\n",
      "iterations 2889 accuray : 0.9266960722537282  loss : 0.3536962569280791\n",
      "iterations 2890 accuray : 0.9266960722537282  loss : 0.35366698563749127\n",
      "iterations 2891 accuray : 0.9266960722537282  loss : 0.3536372572344626\n",
      "iterations 2892 accuray : 0.9266960722537282  loss : 0.35360744316263376\n",
      "iterations 2893 accuray : 0.9266960722537282  loss : 0.35357777580375116\n",
      "iterations 2894 accuray : 0.9266960722537282  loss : 0.35354833940087704\n",
      "iterations 2895 accuray : 0.9266960722537282  loss : 0.3535196616204283\n",
      "iterations 2896 accuray : 0.9266960722537282  loss : 0.3534907335089841\n",
      "iterations 2897 accuray : 0.9266960722537282  loss : 0.3534609003957371\n",
      "iterations 2898 accuray : 0.9266960722537282  loss : 0.3534320088101692\n",
      "iterations 2899 accuray : 0.9266960722537282  loss : 0.3534035138067798\n",
      "iterations 2900 accuray : 0.9269061121613107  loss : 0.35337315581130246\n",
      "iterations 2901 accuray : 0.9269061121613107  loss : 0.35334391851978597\n",
      "iterations 2902 accuray : 0.9266960722537282  loss : 0.35331568593621865\n",
      "iterations 2903 accuray : 0.9269061121613107  loss : 0.35328676880716353\n",
      "iterations 2904 accuray : 0.9269061121613107  loss : 0.35325737675481694\n",
      "iterations 2905 accuray : 0.9266960722537282  loss : 0.3532291032031253\n",
      "iterations 2906 accuray : 0.9266960722537282  loss : 0.3532002173397554\n",
      "iterations 2907 accuray : 0.9269061121613107  loss : 0.35317031047863\n",
      "iterations 2908 accuray : 0.9266960722537282  loss : 0.35314144543293036\n",
      "iterations 2909 accuray : 0.9269061121613107  loss : 0.3531115268216697\n",
      "iterations 2910 accuray : 0.9269061121613107  loss : 0.35308285496191155\n",
      "iterations 2911 accuray : 0.9269061121613107  loss : 0.35305330507515065\n",
      "iterations 2912 accuray : 0.9269061121613107  loss : 0.3530241718275748\n",
      "iterations 2913 accuray : 0.9266960722537282  loss : 0.35299506541296066\n",
      "iterations 2914 accuray : 0.9269061121613107  loss : 0.35296546568351395\n",
      "iterations 2915 accuray : 0.9269061121613107  loss : 0.3529367767901527\n",
      "iterations 2916 accuray : 0.9269061121613107  loss : 0.35290729713143876\n",
      "iterations 2917 accuray : 0.9269061121613107  loss : 0.35287824091960734\n",
      "iterations 2918 accuray : 0.9269061121613107  loss : 0.35284860085999825\n",
      "iterations 2919 accuray : 0.9271161520688931  loss : 0.3528205921527921\n",
      "iterations 2920 accuray : 0.9271161520688931  loss : 0.3527916155103736\n",
      "iterations 2921 accuray : 0.9271161520688931  loss : 0.35276183040704423\n",
      "iterations 2922 accuray : 0.9271161520688931  loss : 0.3527320934334427\n",
      "iterations 2923 accuray : 0.9271161520688931  loss : 0.3527036464724606\n",
      "iterations 2924 accuray : 0.9271161520688931  loss : 0.35267492968517067\n",
      "iterations 2925 accuray : 0.9271161520688931  loss : 0.35264583752067274\n",
      "iterations 2926 accuray : 0.9269061121613107  loss : 0.3526166062475743\n",
      "iterations 2927 accuray : 0.9271161520688931  loss : 0.35258905652984446\n",
      "iterations 2928 accuray : 0.9271161520688931  loss : 0.3525609275832396\n",
      "iterations 2929 accuray : 0.9271161520688931  loss : 0.35253208708407147\n",
      "iterations 2930 accuray : 0.9269061121613107  loss : 0.35250221744300536\n",
      "iterations 2931 accuray : 0.9269061121613107  loss : 0.3524734792800717\n",
      "iterations 2932 accuray : 0.9269061121613107  loss : 0.3524443844884181\n",
      "iterations 2933 accuray : 0.9269061121613107  loss : 0.35241553694029837\n",
      "iterations 2934 accuray : 0.9269061121613107  loss : 0.3523865360706817\n",
      "iterations 2935 accuray : 0.9271161520688931  loss : 0.35235728801715127\n",
      "iterations 2936 accuray : 0.9271161520688931  loss : 0.35232836217061664\n",
      "iterations 2937 accuray : 0.9271161520688931  loss : 0.3522993928904666\n",
      "iterations 2938 accuray : 0.9271161520688931  loss : 0.35227129420647685\n",
      "iterations 2939 accuray : 0.9271161520688931  loss : 0.3522424141204424\n",
      "iterations 2940 accuray : 0.9271161520688931  loss : 0.35221330055035305\n",
      "iterations 2941 accuray : 0.9271161520688931  loss : 0.352184826016317\n",
      "iterations 2942 accuray : 0.9271161520688931  loss : 0.35215519607318685\n",
      "iterations 2943 accuray : 0.9271161520688931  loss : 0.35212702559484105\n",
      "iterations 2944 accuray : 0.9271161520688931  loss : 0.35209793574623155\n",
      "iterations 2945 accuray : 0.9271161520688931  loss : 0.3520691496479974\n",
      "iterations 2946 accuray : 0.9271161520688931  loss : 0.35204033056679135\n",
      "iterations 2947 accuray : 0.9271161520688931  loss : 0.3520112574183014\n",
      "iterations 2948 accuray : 0.9271161520688931  loss : 0.35198321728435794\n",
      "iterations 2949 accuray : 0.9271161520688931  loss : 0.35195397287614\n",
      "iterations 2950 accuray : 0.9273261919764755  loss : 0.3519252840533663\n",
      "iterations 2951 accuray : 0.927536231884058  loss : 0.35189585862201356\n",
      "iterations 2952 accuray : 0.927536231884058  loss : 0.35186634195721933\n",
      "iterations 2953 accuray : 0.927536231884058  loss : 0.3518380538878829\n",
      "iterations 2954 accuray : 0.927536231884058  loss : 0.3518087658125816\n",
      "iterations 2955 accuray : 0.927536231884058  loss : 0.3517807881754409\n",
      "iterations 2956 accuray : 0.927536231884058  loss : 0.3517524920030689\n",
      "iterations 2957 accuray : 0.927536231884058  loss : 0.3517242188923361\n",
      "iterations 2958 accuray : 0.927536231884058  loss : 0.351694821187158\n",
      "iterations 2959 accuray : 0.927536231884058  loss : 0.35166654745962633\n",
      "iterations 2960 accuray : 0.927536231884058  loss : 0.3516368823491367\n",
      "iterations 2961 accuray : 0.927536231884058  loss : 0.3516089515703602\n",
      "iterations 2962 accuray : 0.9277462717916404  loss : 0.3515799643476892\n",
      "iterations 2963 accuray : 0.9277462717916404  loss : 0.3515509550139236\n",
      "iterations 2964 accuray : 0.9277462717916404  loss : 0.3515218378194419\n",
      "iterations 2965 accuray : 0.9279563116992229  loss : 0.3514930578090889\n",
      "iterations 2966 accuray : 0.9279563116992229  loss : 0.3514639495260559\n",
      "iterations 2967 accuray : 0.9279563116992229  loss : 0.35143648748166745\n",
      "iterations 2968 accuray : 0.9281663516068053  loss : 0.3514074962715208\n",
      "iterations 2969 accuray : 0.9279563116992229  loss : 0.3513792412226951\n",
      "iterations 2970 accuray : 0.9281663516068053  loss : 0.3513502751753997\n",
      "iterations 2971 accuray : 0.9285864314219702  loss : 0.35132175156812046\n",
      "iterations 2972 accuray : 0.9283763915143878  loss : 0.35129306621842044\n",
      "iterations 2973 accuray : 0.9283763915143878  loss : 0.35126543926848136\n",
      "iterations 2974 accuray : 0.9283763915143878  loss : 0.3512374764956911\n",
      "iterations 2975 accuray : 0.9285864314219702  loss : 0.3512088781852628\n",
      "iterations 2976 accuray : 0.9285864314219702  loss : 0.35118026730129687\n",
      "iterations 2977 accuray : 0.9285864314219702  loss : 0.35115228209864713\n",
      "iterations 2978 accuray : 0.9290065112371351  loss : 0.3511240771700732\n",
      "iterations 2979 accuray : 0.9290065112371351  loss : 0.351095857097828\n",
      "iterations 2980 accuray : 0.9292165511447175  loss : 0.35106643649923924\n",
      "iterations 2981 accuray : 0.9292165511447175  loss : 0.351037122568264\n",
      "iterations 2982 accuray : 0.9292165511447175  loss : 0.3510092994217475\n",
      "iterations 2983 accuray : 0.9292165511447175  loss : 0.35098161831103347\n",
      "iterations 2984 accuray : 0.9292165511447175  loss : 0.35095375150623276\n",
      "iterations 2985 accuray : 0.9292165511447175  loss : 0.3509250517104145\n",
      "iterations 2986 accuray : 0.9294265910523  loss : 0.35089613185934015\n",
      "iterations 2987 accuray : 0.9294265910523  loss : 0.3508675468632924\n",
      "iterations 2988 accuray : 0.9294265910523  loss : 0.3508385106376021\n",
      "iterations 2989 accuray : 0.9296366309598824  loss : 0.35080972090791257\n",
      "iterations 2990 accuray : 0.9296366309598824  loss : 0.3507813172566605\n",
      "iterations 2991 accuray : 0.9296366309598824  loss : 0.3507526877379396\n",
      "iterations 2992 accuray : 0.9296366309598824  loss : 0.35072450545694306\n",
      "iterations 2993 accuray : 0.9296366309598824  loss : 0.35069527525074357\n",
      "iterations 2994 accuray : 0.9294265910523  loss : 0.3506671203954535\n",
      "iterations 2995 accuray : 0.9292165511447175  loss : 0.3506389690344902\n",
      "iterations 2996 accuray : 0.9294265910523  loss : 0.35061074652979385\n",
      "iterations 2997 accuray : 0.9294265910523  loss : 0.3505826052101114\n",
      "iterations 2998 accuray : 0.9296366309598824  loss : 0.3505554461336906\n",
      "iterations 2999 accuray : 0.9296366309598824  loss : 0.3505278630884928\n",
      "iterations 3000 accuray : 0.9296366309598824  loss : 0.35050012229277505\n",
      "iterations 3001 accuray : 0.9296366309598824  loss : 0.3504726689384755\n",
      "iterations 3002 accuray : 0.9296366309598824  loss : 0.35044300672446815\n",
      "iterations 3003 accuray : 0.9296366309598824  loss : 0.35041481235801364\n",
      "iterations 3004 accuray : 0.9296366309598824  loss : 0.35038708425791726\n",
      "iterations 3005 accuray : 0.9296366309598824  loss : 0.3503588225446955\n",
      "iterations 3006 accuray : 0.9296366309598824  loss : 0.35033036050763855\n",
      "iterations 3007 accuray : 0.9296366309598824  loss : 0.35030216545292053\n",
      "iterations 3008 accuray : 0.9296366309598824  loss : 0.35027296598022484\n",
      "iterations 3009 accuray : 0.9296366309598824  loss : 0.3502453412302847\n",
      "iterations 3010 accuray : 0.9292165511447175  loss : 0.35021705097982087\n",
      "iterations 3011 accuray : 0.9292165511447175  loss : 0.3501886009025459\n",
      "iterations 3012 accuray : 0.9292165511447175  loss : 0.3501599052350065\n",
      "iterations 3013 accuray : 0.9292165511447175  loss : 0.35013253781233145\n",
      "iterations 3014 accuray : 0.9292165511447175  loss : 0.35010552043992216\n",
      "iterations 3015 accuray : 0.9292165511447175  loss : 0.350077023047911\n",
      "iterations 3016 accuray : 0.9292165511447175  loss : 0.35004881144887445\n",
      "iterations 3017 accuray : 0.9292165511447175  loss : 0.35002191695025076\n",
      "iterations 3018 accuray : 0.9292165511447175  loss : 0.3499931792738787\n",
      "iterations 3019 accuray : 0.9292165511447175  loss : 0.3499653968746626\n",
      "iterations 3020 accuray : 0.9292165511447175  loss : 0.34993741050613286\n",
      "iterations 3021 accuray : 0.9292165511447175  loss : 0.3499098404843337\n",
      "iterations 3022 accuray : 0.9292165511447175  loss : 0.34988231851879964\n",
      "iterations 3023 accuray : 0.9292165511447175  loss : 0.34985448247076234\n",
      "iterations 3024 accuray : 0.9292165511447175  loss : 0.3498262719289861\n",
      "iterations 3025 accuray : 0.9292165511447175  loss : 0.3497990098383001\n",
      "iterations 3026 accuray : 0.9292165511447175  loss : 0.3497707047854516\n",
      "iterations 3027 accuray : 0.9292165511447175  loss : 0.3497424721305538\n",
      "iterations 3028 accuray : 0.9292165511447175  loss : 0.3497151354926011\n",
      "iterations 3029 accuray : 0.9292165511447175  loss : 0.3496867565322828\n",
      "iterations 3030 accuray : 0.9292165511447175  loss : 0.3496583861136392\n",
      "iterations 3031 accuray : 0.9290065112371351  loss : 0.34963059348061376\n",
      "iterations 3032 accuray : 0.9290065112371351  loss : 0.34960232114008866\n",
      "iterations 3033 accuray : 0.9290065112371351  loss : 0.3495744820404568\n",
      "iterations 3034 accuray : 0.9290065112371351  loss : 0.3495459061756133\n",
      "iterations 3035 accuray : 0.9290065112371351  loss : 0.3495185503047049\n",
      "iterations 3036 accuray : 0.9290065112371351  loss : 0.3494909836934417\n",
      "iterations 3037 accuray : 0.9290065112371351  loss : 0.34946374515530754\n",
      "iterations 3038 accuray : 0.9290065112371351  loss : 0.34943583700842534\n",
      "iterations 3039 accuray : 0.9290065112371351  loss : 0.3494081036451282\n",
      "iterations 3040 accuray : 0.9290065112371351  loss : 0.34938079853098564\n",
      "iterations 3041 accuray : 0.9290065112371351  loss : 0.3493528444572499\n",
      "iterations 3042 accuray : 0.9290065112371351  loss : 0.3493249368674832\n",
      "iterations 3043 accuray : 0.9290065112371351  loss : 0.3492968984021\n",
      "iterations 3044 accuray : 0.9290065112371351  loss : 0.34926956718883273\n",
      "iterations 3045 accuray : 0.9290065112371351  loss : 0.3492422933954113\n",
      "iterations 3046 accuray : 0.9290065112371351  loss : 0.3492138113919518\n",
      "iterations 3047 accuray : 0.9290065112371351  loss : 0.34918592574048846\n",
      "iterations 3048 accuray : 0.9292165511447175  loss : 0.34915876923589234\n",
      "iterations 3049 accuray : 0.9292165511447175  loss : 0.3491305722113484\n",
      "iterations 3050 accuray : 0.9290065112371351  loss : 0.34910269097845753\n",
      "iterations 3051 accuray : 0.9292165511447175  loss : 0.3490748506205453\n",
      "iterations 3052 accuray : 0.9294265910523  loss : 0.34904686421708264\n",
      "iterations 3053 accuray : 0.9294265910523  loss : 0.3490187591469507\n",
      "iterations 3054 accuray : 0.9294265910523  loss : 0.3489906883685505\n",
      "iterations 3055 accuray : 0.9294265910523  loss : 0.34896273973730585\n",
      "iterations 3056 accuray : 0.9294265910523  loss : 0.34893520727536315\n",
      "iterations 3057 accuray : 0.9294265910523  loss : 0.34890779487845464\n",
      "iterations 3058 accuray : 0.9294265910523  loss : 0.34888064380200223\n",
      "iterations 3059 accuray : 0.9294265910523  loss : 0.3488534998357606\n",
      "iterations 3060 accuray : 0.9294265910523  loss : 0.34882681477724387\n",
      "iterations 3061 accuray : 0.9294265910523  loss : 0.3487991802503875\n",
      "iterations 3062 accuray : 0.9294265910523  loss : 0.34877138325156215\n",
      "iterations 3063 accuray : 0.9294265910523  loss : 0.34874362080279564\n",
      "iterations 3064 accuray : 0.9294265910523  loss : 0.348715143656468\n",
      "iterations 3065 accuray : 0.9294265910523  loss : 0.34868702673130664\n",
      "iterations 3066 accuray : 0.9294265910523  loss : 0.34865993055360783\n",
      "iterations 3067 accuray : 0.9294265910523  loss : 0.3486318385459211\n",
      "iterations 3068 accuray : 0.9294265910523  loss : 0.3486044347128848\n",
      "iterations 3069 accuray : 0.9294265910523  loss : 0.34857678135697706\n",
      "iterations 3070 accuray : 0.9290065112371351  loss : 0.3485484487010933\n",
      "iterations 3071 accuray : 0.9290065112371351  loss : 0.3485209801876772\n",
      "iterations 3072 accuray : 0.9290065112371351  loss : 0.34849337919192436\n",
      "iterations 3073 accuray : 0.9290065112371351  loss : 0.34846556851939076\n",
      "iterations 3074 accuray : 0.9290065112371351  loss : 0.34843761665938283\n",
      "iterations 3075 accuray : 0.9287964713295526  loss : 0.34840987856008176\n",
      "iterations 3076 accuray : 0.9290065112371351  loss : 0.3483811883598564\n",
      "iterations 3077 accuray : 0.9290065112371351  loss : 0.3483538965541963\n",
      "iterations 3078 accuray : 0.9290065112371351  loss : 0.3483267014008979\n",
      "iterations 3079 accuray : 0.9292165511447175  loss : 0.3482991397625773\n",
      "iterations 3080 accuray : 0.9292165511447175  loss : 0.34827168867717817\n",
      "iterations 3081 accuray : 0.9292165511447175  loss : 0.34824514127132883\n",
      "iterations 3082 accuray : 0.9292165511447175  loss : 0.3482172436202725\n",
      "iterations 3083 accuray : 0.9292165511447175  loss : 0.34819056107225327\n",
      "iterations 3084 accuray : 0.9292165511447175  loss : 0.3481634306688355\n",
      "iterations 3085 accuray : 0.9292165511447175  loss : 0.34813524109740906\n",
      "iterations 3086 accuray : 0.9290065112371351  loss : 0.34810788186414354\n",
      "iterations 3087 accuray : 0.9292165511447175  loss : 0.3480800480167698\n",
      "iterations 3088 accuray : 0.9292165511447175  loss : 0.3480523478600886\n",
      "iterations 3089 accuray : 0.9292165511447175  loss : 0.34802582798079645\n",
      "iterations 3090 accuray : 0.9290065112371351  loss : 0.34799933186138915\n",
      "iterations 3091 accuray : 0.9292165511447175  loss : 0.3479722184425926\n",
      "iterations 3092 accuray : 0.9292165511447175  loss : 0.34794415336162526\n",
      "iterations 3093 accuray : 0.9292165511447175  loss : 0.3479173288668681\n",
      "iterations 3094 accuray : 0.9290065112371351  loss : 0.34788973676295504\n",
      "iterations 3095 accuray : 0.9292165511447175  loss : 0.34786194330226267\n",
      "iterations 3096 accuray : 0.9290065112371351  loss : 0.3478353603393591\n",
      "iterations 3097 accuray : 0.9292165511447175  loss : 0.34780918788889315\n",
      "iterations 3098 accuray : 0.9292165511447175  loss : 0.3477817250613609\n",
      "iterations 3099 accuray : 0.9290065112371351  loss : 0.3477545443322396\n",
      "iterations 3100 accuray : 0.9292165511447175  loss : 0.3477275283954211\n",
      "iterations 3101 accuray : 0.9292165511447175  loss : 0.3477003176758061\n",
      "iterations 3102 accuray : 0.9290065112371351  loss : 0.347673381443236\n",
      "iterations 3103 accuray : 0.9292165511447175  loss : 0.3476459109082136\n",
      "iterations 3104 accuray : 0.9292165511447175  loss : 0.3476190318652242\n",
      "iterations 3105 accuray : 0.9292165511447175  loss : 0.34759165876729003\n",
      "iterations 3106 accuray : 0.9292165511447175  loss : 0.34756435495615884\n",
      "iterations 3107 accuray : 0.9294265910523  loss : 0.3475374266645332\n",
      "iterations 3108 accuray : 0.9294265910523  loss : 0.3475098899836679\n",
      "iterations 3109 accuray : 0.9292165511447175  loss : 0.34748207880269727\n",
      "iterations 3110 accuray : 0.9292165511447175  loss : 0.3474545461642307\n",
      "iterations 3111 accuray : 0.9290065112371351  loss : 0.3474273912064385\n",
      "iterations 3112 accuray : 0.9290065112371351  loss : 0.34740032043971125\n",
      "iterations 3113 accuray : 0.9290065112371351  loss : 0.3473726199202522\n",
      "iterations 3114 accuray : 0.9290065112371351  loss : 0.34734486622436983\n",
      "iterations 3115 accuray : 0.9290065112371351  loss : 0.3473175227285352\n",
      "iterations 3116 accuray : 0.9290065112371351  loss : 0.34729063838821517\n",
      "iterations 3117 accuray : 0.9292165511447175  loss : 0.34726380938007784\n",
      "iterations 3118 accuray : 0.9290065112371351  loss : 0.34723662996246757\n",
      "iterations 3119 accuray : 0.9290065112371351  loss : 0.3472101383091914\n",
      "iterations 3120 accuray : 0.9292165511447175  loss : 0.3471830173345364\n",
      "iterations 3121 accuray : 0.9292165511447175  loss : 0.3471558399230965\n",
      "iterations 3122 accuray : 0.9292165511447175  loss : 0.3471281972858232\n",
      "iterations 3123 accuray : 0.9292165511447175  loss : 0.3471018018375223\n",
      "iterations 3124 accuray : 0.9292165511447175  loss : 0.3470751377474624\n",
      "iterations 3125 accuray : 0.9292165511447175  loss : 0.3470482795001923\n",
      "iterations 3126 accuray : 0.9292165511447175  loss : 0.34702124906265913\n",
      "iterations 3127 accuray : 0.9292165511447175  loss : 0.34699398930374725\n",
      "iterations 3128 accuray : 0.9292165511447175  loss : 0.346966728248676\n",
      "iterations 3129 accuray : 0.9292165511447175  loss : 0.3469394575963748\n",
      "iterations 3130 accuray : 0.9292165511447175  loss : 0.3469127936791762\n",
      "iterations 3131 accuray : 0.9292165511447175  loss : 0.34688572592680433\n",
      "iterations 3132 accuray : 0.9292165511447175  loss : 0.34685918599246623\n",
      "iterations 3133 accuray : 0.9292165511447175  loss : 0.3468326360257042\n",
      "iterations 3134 accuray : 0.9292165511447175  loss : 0.3468053985083562\n",
      "iterations 3135 accuray : 0.9292165511447175  loss : 0.34677881788448583\n",
      "iterations 3136 accuray : 0.9292165511447175  loss : 0.34675288536816395\n",
      "iterations 3137 accuray : 0.9292165511447175  loss : 0.34672606053957555\n",
      "iterations 3138 accuray : 0.9292165511447175  loss : 0.3466999848368748\n",
      "iterations 3139 accuray : 0.9292165511447175  loss : 0.3466737990118969\n",
      "iterations 3140 accuray : 0.9292165511447175  loss : 0.3466475219548709\n",
      "iterations 3141 accuray : 0.9292165511447175  loss : 0.34662046077883113\n",
      "iterations 3142 accuray : 0.9292165511447175  loss : 0.3465941282745938\n",
      "iterations 3143 accuray : 0.9292165511447175  loss : 0.34656701178656496\n",
      "iterations 3144 accuray : 0.9292165511447175  loss : 0.3465405120882466\n",
      "iterations 3145 accuray : 0.9292165511447175  loss : 0.3465143016100205\n",
      "iterations 3146 accuray : 0.9292165511447175  loss : 0.3464873889089864\n",
      "iterations 3147 accuray : 0.9292165511447175  loss : 0.3464610480778986\n",
      "iterations 3148 accuray : 0.9292165511447175  loss : 0.34643503589981983\n",
      "iterations 3149 accuray : 0.9292165511447175  loss : 0.3464081544471334\n",
      "iterations 3150 accuray : 0.9292165511447175  loss : 0.3463822152582017\n",
      "iterations 3151 accuray : 0.9292165511447175  loss : 0.34635557727803445\n",
      "iterations 3152 accuray : 0.9292165511447175  loss : 0.34632856614974805\n",
      "iterations 3153 accuray : 0.9292165511447175  loss : 0.34630271512821115\n",
      "iterations 3154 accuray : 0.9292165511447175  loss : 0.34627631413934395\n",
      "iterations 3155 accuray : 0.9292165511447175  loss : 0.3462505890589648\n",
      "iterations 3156 accuray : 0.9292165511447175  loss : 0.34622366174737623\n",
      "iterations 3157 accuray : 0.9292165511447175  loss : 0.34619676523562637\n",
      "iterations 3158 accuray : 0.9292165511447175  loss : 0.3461703313449281\n",
      "iterations 3159 accuray : 0.9292165511447175  loss : 0.3461435908095944\n",
      "iterations 3160 accuray : 0.9294265910523  loss : 0.34611682146435147\n",
      "iterations 3161 accuray : 0.9294265910523  loss : 0.34608977844311295\n",
      "iterations 3162 accuray : 0.9292165511447175  loss : 0.3460634189058528\n",
      "iterations 3163 accuray : 0.9292165511447175  loss : 0.34603683311040395\n",
      "iterations 3164 accuray : 0.9292165511447175  loss : 0.34601110030980115\n",
      "iterations 3165 accuray : 0.9292165511447175  loss : 0.3459845893565753\n",
      "iterations 3166 accuray : 0.9292165511447175  loss : 0.34595900012097924\n",
      "iterations 3167 accuray : 0.9292165511447175  loss : 0.3459325177186601\n",
      "iterations 3168 accuray : 0.9292165511447175  loss : 0.34590653146053985\n",
      "iterations 3169 accuray : 0.9294265910523  loss : 0.3458806029313573\n",
      "iterations 3170 accuray : 0.9294265910523  loss : 0.34585459604496954\n",
      "iterations 3171 accuray : 0.9292165511447175  loss : 0.34582793477244494\n",
      "iterations 3172 accuray : 0.9292165511447175  loss : 0.34580137387349497\n",
      "iterations 3173 accuray : 0.9292165511447175  loss : 0.3457748453203027\n",
      "iterations 3174 accuray : 0.9292165511447175  loss : 0.3457486274813999\n",
      "iterations 3175 accuray : 0.9292165511447175  loss : 0.345722515304405\n",
      "iterations 3176 accuray : 0.9292165511447175  loss : 0.34569666592369247\n",
      "iterations 3177 accuray : 0.9292165511447175  loss : 0.3456699324290496\n",
      "iterations 3178 accuray : 0.9292165511447175  loss : 0.3456436309887289\n",
      "iterations 3179 accuray : 0.9292165511447175  loss : 0.34561691999475647\n",
      "iterations 3180 accuray : 0.9292165511447175  loss : 0.3455912147622915\n",
      "iterations 3181 accuray : 0.9292165511447175  loss : 0.34556513590672877\n",
      "iterations 3182 accuray : 0.9292165511447175  loss : 0.3455394965792755\n",
      "iterations 3183 accuray : 0.9292165511447175  loss : 0.3455137696660486\n",
      "iterations 3184 accuray : 0.9292165511447175  loss : 0.34548710991881415\n",
      "iterations 3185 accuray : 0.9292165511447175  loss : 0.34546070515435656\n",
      "iterations 3186 accuray : 0.9292165511447175  loss : 0.3454343677417281\n",
      "iterations 3187 accuray : 0.9294265910523  loss : 0.3454085280202945\n",
      "iterations 3188 accuray : 0.9294265910523  loss : 0.34538258799516924\n",
      "iterations 3189 accuray : 0.9294265910523  loss : 0.34535615541923315\n",
      "iterations 3190 accuray : 0.9294265910523  loss : 0.345330426663203\n",
      "iterations 3191 accuray : 0.9294265910523  loss : 0.34530486167200775\n",
      "iterations 3192 accuray : 0.9294265910523  loss : 0.3452785359092451\n",
      "iterations 3193 accuray : 0.9294265910523  loss : 0.34525202761002033\n",
      "iterations 3194 accuray : 0.9292165511447175  loss : 0.3452261931296134\n",
      "iterations 3195 accuray : 0.9292165511447175  loss : 0.34519921177165497\n",
      "iterations 3196 accuray : 0.9292165511447175  loss : 0.3451731487651725\n",
      "iterations 3197 accuray : 0.9292165511447175  loss : 0.3451468468630137\n",
      "iterations 3198 accuray : 0.9292165511447175  loss : 0.3451209520467599\n",
      "iterations 3199 accuray : 0.9292165511447175  loss : 0.34509434765644276\n",
      "iterations 3200 accuray : 0.9292165511447175  loss : 0.3450687983221704\n",
      "iterations 3201 accuray : 0.9292165511447175  loss : 0.3450425192687905\n",
      "iterations 3202 accuray : 0.9292165511447175  loss : 0.34501665197345516\n",
      "iterations 3203 accuray : 0.9292165511447175  loss : 0.34499059976402674\n",
      "iterations 3204 accuray : 0.9292165511447175  loss : 0.34496423973406853\n",
      "iterations 3205 accuray : 0.9292165511447175  loss : 0.3449377298037865\n",
      "iterations 3206 accuray : 0.9294265910523  loss : 0.3449114375093703\n",
      "iterations 3207 accuray : 0.9294265910523  loss : 0.3448854679188063\n",
      "iterations 3208 accuray : 0.9294265910523  loss : 0.34485942396306224\n",
      "iterations 3209 accuray : 0.9294265910523  loss : 0.34483310363021163\n",
      "iterations 3210 accuray : 0.9294265910523  loss : 0.34480664074812173\n",
      "iterations 3211 accuray : 0.9294265910523  loss : 0.34478079301620096\n",
      "iterations 3212 accuray : 0.9294265910523  loss : 0.3447558124260939\n",
      "iterations 3213 accuray : 0.9294265910523  loss : 0.3447300191032503\n",
      "iterations 3214 accuray : 0.9294265910523  loss : 0.34470433741115614\n",
      "iterations 3215 accuray : 0.9294265910523  loss : 0.3446779540243883\n",
      "iterations 3216 accuray : 0.9294265910523  loss : 0.3446518730438786\n",
      "iterations 3217 accuray : 0.9292165511447175  loss : 0.34462524591481364\n",
      "iterations 3218 accuray : 0.9292165511447175  loss : 0.3445997638209214\n",
      "iterations 3219 accuray : 0.9292165511447175  loss : 0.34457420889586293\n",
      "iterations 3220 accuray : 0.9292165511447175  loss : 0.344548331765834\n",
      "iterations 3221 accuray : 0.9294265910523  loss : 0.3445227195680955\n",
      "iterations 3222 accuray : 0.9292165511447175  loss : 0.34449657562811964\n",
      "iterations 3223 accuray : 0.9292165511447175  loss : 0.3444704063498662\n",
      "iterations 3224 accuray : 0.9292165511447175  loss : 0.344444644601729\n",
      "iterations 3225 accuray : 0.9292165511447175  loss : 0.3444185862616909\n",
      "iterations 3226 accuray : 0.9292165511447175  loss : 0.34439220944458887\n",
      "iterations 3227 accuray : 0.9292165511447175  loss : 0.3443663816971747\n",
      "iterations 3228 accuray : 0.9292165511447175  loss : 0.344340306607893\n",
      "iterations 3229 accuray : 0.9292165511447175  loss : 0.3443144939593457\n",
      "iterations 3230 accuray : 0.9292165511447175  loss : 0.3442888934148356\n",
      "iterations 3231 accuray : 0.9292165511447175  loss : 0.344263610625363\n",
      "iterations 3232 accuray : 0.9292165511447175  loss : 0.3442376462830479\n",
      "iterations 3233 accuray : 0.9292165511447175  loss : 0.34421245743913165\n",
      "iterations 3234 accuray : 0.9292165511447175  loss : 0.344186434399731\n",
      "iterations 3235 accuray : 0.9292165511447175  loss : 0.34416038959881434\n",
      "iterations 3236 accuray : 0.9292165511447175  loss : 0.3441341272659602\n",
      "iterations 3237 accuray : 0.9292165511447175  loss : 0.3441078849787753\n",
      "iterations 3238 accuray : 0.9294265910523  loss : 0.3440818005131136\n",
      "iterations 3239 accuray : 0.9292165511447175  loss : 0.34405549699178317\n",
      "iterations 3240 accuray : 0.9292165511447175  loss : 0.3440293202952707\n",
      "iterations 3241 accuray : 0.9292165511447175  loss : 0.3440031127130554\n",
      "iterations 3242 accuray : 0.9292165511447175  loss : 0.3439773167945184\n",
      "iterations 3243 accuray : 0.9292165511447175  loss : 0.3439519740020022\n",
      "iterations 3244 accuray : 0.9292165511447175  loss : 0.34392652849858796\n",
      "iterations 3245 accuray : 0.9292165511447175  loss : 0.3439008650125756\n",
      "iterations 3246 accuray : 0.9292165511447175  loss : 0.3438751333777993\n",
      "iterations 3247 accuray : 0.9292165511447175  loss : 0.34385035993031154\n",
      "iterations 3248 accuray : 0.9292165511447175  loss : 0.3438240574097616\n",
      "iterations 3249 accuray : 0.9292165511447175  loss : 0.3437992430133209\n",
      "iterations 3250 accuray : 0.9292165511447175  loss : 0.3437736926441915\n",
      "iterations 3251 accuray : 0.9292165511447175  loss : 0.3437484117944482\n",
      "iterations 3252 accuray : 0.9292165511447175  loss : 0.34372282856414854\n",
      "iterations 3253 accuray : 0.9292165511447175  loss : 0.3436974072847201\n",
      "iterations 3254 accuray : 0.9292165511447175  loss : 0.34367208274932876\n",
      "iterations 3255 accuray : 0.9292165511447175  loss : 0.34364664964475516\n",
      "iterations 3256 accuray : 0.9290065112371351  loss : 0.3436207636364156\n",
      "iterations 3257 accuray : 0.9290065112371351  loss : 0.34359495881336616\n",
      "iterations 3258 accuray : 0.9292165511447175  loss : 0.34356856412646536\n",
      "iterations 3259 accuray : 0.9292165511447175  loss : 0.3435434474370221\n",
      "iterations 3260 accuray : 0.9292165511447175  loss : 0.34351835860559293\n",
      "iterations 3261 accuray : 0.9290065112371351  loss : 0.3434928457668921\n",
      "iterations 3262 accuray : 0.9290065112371351  loss : 0.3434679281379148\n",
      "iterations 3263 accuray : 0.9290065112371351  loss : 0.3434429387575848\n",
      "iterations 3264 accuray : 0.9290065112371351  loss : 0.3434171155639244\n",
      "iterations 3265 accuray : 0.9290065112371351  loss : 0.34339206136671263\n",
      "iterations 3266 accuray : 0.9290065112371351  loss : 0.34336566893332704\n",
      "iterations 3267 accuray : 0.9290065112371351  loss : 0.34334160417118603\n",
      "iterations 3268 accuray : 0.9290065112371351  loss : 0.34331560527488936\n",
      "iterations 3269 accuray : 0.9290065112371351  loss : 0.3432900410652747\n",
      "iterations 3270 accuray : 0.9290065112371351  loss : 0.3432649894569444\n",
      "iterations 3271 accuray : 0.9290065112371351  loss : 0.34323932478879227\n",
      "iterations 3272 accuray : 0.9290065112371351  loss : 0.34321340446974763\n",
      "iterations 3273 accuray : 0.9287964713295526  loss : 0.34318823851785746\n",
      "iterations 3274 accuray : 0.9287964713295526  loss : 0.3431626217892375\n",
      "iterations 3275 accuray : 0.9287964713295526  loss : 0.3431373808259003\n",
      "iterations 3276 accuray : 0.9290065112371351  loss : 0.34311218867517834\n",
      "iterations 3277 accuray : 0.9290065112371351  loss : 0.3430864279073778\n",
      "iterations 3278 accuray : 0.9285864314219702  loss : 0.34306078378437993\n",
      "iterations 3279 accuray : 0.9285864314219702  loss : 0.34303517289650043\n",
      "iterations 3280 accuray : 0.9285864314219702  loss : 0.3430100187406328\n",
      "iterations 3281 accuray : 0.9285864314219702  loss : 0.3429841464508951\n",
      "iterations 3282 accuray : 0.9285864314219702  loss : 0.34295817083083546\n",
      "iterations 3283 accuray : 0.9285864314219702  loss : 0.34293333199253756\n",
      "iterations 3284 accuray : 0.9285864314219702  loss : 0.3429080427460008\n",
      "iterations 3285 accuray : 0.9285864314219702  loss : 0.3428829371694694\n",
      "iterations 3286 accuray : 0.9285864314219702  loss : 0.34285764829534543\n",
      "iterations 3287 accuray : 0.9285864314219702  loss : 0.34283179794899704\n",
      "iterations 3288 accuray : 0.9285864314219702  loss : 0.3428069703801757\n",
      "iterations 3289 accuray : 0.9285864314219702  loss : 0.3427818910528725\n",
      "iterations 3290 accuray : 0.9285864314219702  loss : 0.3427573955940623\n",
      "iterations 3291 accuray : 0.9285864314219702  loss : 0.34273234753691534\n",
      "iterations 3292 accuray : 0.9285864314219702  loss : 0.3427070501186919\n",
      "iterations 3293 accuray : 0.9287964713295526  loss : 0.34268125750599354\n",
      "iterations 3294 accuray : 0.9287964713295526  loss : 0.34265606426038797\n",
      "iterations 3295 accuray : 0.9287964713295526  loss : 0.34263129674602294\n",
      "iterations 3296 accuray : 0.9287964713295526  loss : 0.34260690834843543\n",
      "iterations 3297 accuray : 0.9287964713295526  loss : 0.34258176143095315\n",
      "iterations 3298 accuray : 0.9287964713295526  loss : 0.3425566319355081\n",
      "iterations 3299 accuray : 0.9287964713295526  loss : 0.34253091321452406\n",
      "iterations 3300 accuray : 0.9287964713295526  loss : 0.34250587122600895\n",
      "iterations 3301 accuray : 0.9287964713295526  loss : 0.3424807533278741\n",
      "iterations 3302 accuray : 0.9287964713295526  loss : 0.34245584721889816\n",
      "iterations 3303 accuray : 0.9287964713295526  loss : 0.34243129086771357\n",
      "iterations 3304 accuray : 0.9287964713295526  loss : 0.3424052357136436\n",
      "iterations 3305 accuray : 0.9287964713295526  loss : 0.34238087475416223\n",
      "iterations 3306 accuray : 0.9287964713295526  loss : 0.3423557027077308\n",
      "iterations 3307 accuray : 0.9287964713295526  loss : 0.34233058896962354\n",
      "iterations 3308 accuray : 0.9287964713295526  loss : 0.34230488259114455\n",
      "iterations 3309 accuray : 0.9287964713295526  loss : 0.34228055033187327\n",
      "iterations 3310 accuray : 0.9287964713295526  loss : 0.34225560468360666\n",
      "iterations 3311 accuray : 0.9287964713295526  loss : 0.3422303765807862\n",
      "iterations 3312 accuray : 0.9287964713295526  loss : 0.34220561475437766\n",
      "iterations 3313 accuray : 0.9287964713295526  loss : 0.34218103952174517\n",
      "iterations 3314 accuray : 0.9287964713295526  loss : 0.3421557494767694\n",
      "iterations 3315 accuray : 0.9287964713295526  loss : 0.3421304114438297\n",
      "iterations 3316 accuray : 0.9287964713295526  loss : 0.3421059961708349\n",
      "iterations 3317 accuray : 0.9287964713295526  loss : 0.34208164945935154\n",
      "iterations 3318 accuray : 0.9287964713295526  loss : 0.3420564428095352\n",
      "iterations 3319 accuray : 0.9287964713295526  loss : 0.3420313503233463\n",
      "iterations 3320 accuray : 0.9287964713295526  loss : 0.3420062925045665\n",
      "iterations 3321 accuray : 0.9287964713295526  loss : 0.3419812247394838\n",
      "iterations 3322 accuray : 0.9287964713295526  loss : 0.34195667280560177\n",
      "iterations 3323 accuray : 0.9287964713295526  loss : 0.34193156354387977\n",
      "iterations 3324 accuray : 0.9287964713295526  loss : 0.34190633721029084\n",
      "iterations 3325 accuray : 0.9287964713295526  loss : 0.3418818138754101\n",
      "iterations 3326 accuray : 0.9287964713295526  loss : 0.3418564571773628\n",
      "iterations 3327 accuray : 0.9287964713295526  loss : 0.3418314415789287\n",
      "iterations 3328 accuray : 0.9287964713295526  loss : 0.3418065819068732\n",
      "iterations 3329 accuray : 0.9287964713295526  loss : 0.3417817753981551\n",
      "iterations 3330 accuray : 0.9287964713295526  loss : 0.3417568946358343\n",
      "iterations 3331 accuray : 0.9287964713295526  loss : 0.341731230371751\n",
      "iterations 3332 accuray : 0.9287964713295526  loss : 0.3417067098520338\n",
      "iterations 3333 accuray : 0.9287964713295526  loss : 0.34168131669581964\n",
      "iterations 3334 accuray : 0.9287964713295526  loss : 0.34165511227176354\n",
      "iterations 3335 accuray : 0.9287964713295526  loss : 0.3416303817868261\n",
      "iterations 3336 accuray : 0.9287964713295526  loss : 0.34160554333195353\n",
      "iterations 3337 accuray : 0.9287964713295526  loss : 0.3415808298405715\n",
      "iterations 3338 accuray : 0.9287964713295526  loss : 0.34155652736773184\n",
      "iterations 3339 accuray : 0.9287964713295526  loss : 0.34153198673194834\n",
      "iterations 3340 accuray : 0.9285864314219702  loss : 0.3415066717585246\n",
      "iterations 3341 accuray : 0.9287964713295526  loss : 0.34148258475562915\n",
      "iterations 3342 accuray : 0.9287964713295526  loss : 0.34145780104871276\n",
      "iterations 3343 accuray : 0.9287964713295526  loss : 0.34143310460996984\n",
      "iterations 3344 accuray : 0.9287964713295526  loss : 0.34140812049687125\n",
      "iterations 3345 accuray : 0.9285864314219702  loss : 0.34138309970363306\n",
      "iterations 3346 accuray : 0.9285864314219702  loss : 0.3413575346464427\n",
      "iterations 3347 accuray : 0.9285864314219702  loss : 0.34133257424772473\n",
      "iterations 3348 accuray : 0.9285864314219702  loss : 0.34130697115101055\n",
      "iterations 3349 accuray : 0.9285864314219702  loss : 0.34128225266189616\n",
      "iterations 3350 accuray : 0.9285864314219702  loss : 0.3412572282948167\n",
      "iterations 3351 accuray : 0.9283763915143878  loss : 0.3412323288670844\n",
      "iterations 3352 accuray : 0.9283763915143878  loss : 0.34120760642944176\n",
      "iterations 3353 accuray : 0.9283763915143878  loss : 0.34118264624894573\n",
      "iterations 3354 accuray : 0.9283763915143878  loss : 0.3411580211030123\n",
      "iterations 3355 accuray : 0.9285864314219702  loss : 0.34113222170789437\n",
      "iterations 3356 accuray : 0.9285864314219702  loss : 0.3411072774896523\n",
      "iterations 3357 accuray : 0.9285864314219702  loss : 0.34108243908689007\n",
      "iterations 3358 accuray : 0.9285864314219702  loss : 0.3410575956763826\n",
      "iterations 3359 accuray : 0.9285864314219702  loss : 0.3410325049382481\n",
      "iterations 3360 accuray : 0.9285864314219702  loss : 0.3410077205142789\n",
      "iterations 3361 accuray : 0.9285864314219702  loss : 0.3409820582601428\n",
      "iterations 3362 accuray : 0.9285864314219702  loss : 0.34095744363736924\n",
      "iterations 3363 accuray : 0.9285864314219702  loss : 0.34093332477807853\n",
      "iterations 3364 accuray : 0.9285864314219702  loss : 0.3409080441977525\n",
      "iterations 3365 accuray : 0.9285864314219702  loss : 0.34088325259109326\n",
      "iterations 3366 accuray : 0.9285864314219702  loss : 0.3408587931203612\n",
      "iterations 3367 accuray : 0.9285864314219702  loss : 0.34083337422041077\n",
      "iterations 3368 accuray : 0.9285864314219702  loss : 0.34080899671044407\n",
      "iterations 3369 accuray : 0.9285864314219702  loss : 0.3407848778198959\n",
      "iterations 3370 accuray : 0.9287964713295526  loss : 0.3407592271415951\n",
      "iterations 3371 accuray : 0.9287964713295526  loss : 0.3407346126319087\n",
      "iterations 3372 accuray : 0.9287964713295526  loss : 0.34071005688504535\n",
      "iterations 3373 accuray : 0.9287964713295526  loss : 0.34068544795917954\n",
      "iterations 3374 accuray : 0.9287964713295526  loss : 0.34066069385889475\n",
      "iterations 3375 accuray : 0.9287964713295526  loss : 0.3406361127679515\n",
      "iterations 3376 accuray : 0.9285864314219702  loss : 0.3406118697595386\n",
      "iterations 3377 accuray : 0.9287964713295526  loss : 0.34058742933770725\n",
      "iterations 3378 accuray : 0.9285864314219702  loss : 0.3405635255384305\n",
      "iterations 3379 accuray : 0.9287964713295526  loss : 0.3405389408984103\n",
      "iterations 3380 accuray : 0.9287964713295526  loss : 0.34051409948382855\n",
      "iterations 3381 accuray : 0.9287964713295526  loss : 0.34048996248769775\n",
      "iterations 3382 accuray : 0.9285864314219702  loss : 0.3404647813181416\n",
      "iterations 3383 accuray : 0.9285864314219702  loss : 0.34044033685516606\n",
      "iterations 3384 accuray : 0.9285864314219702  loss : 0.34041572887031335\n",
      "iterations 3385 accuray : 0.9287964713295526  loss : 0.3403914538961938\n",
      "iterations 3386 accuray : 0.9287964713295526  loss : 0.34036718528003046\n",
      "iterations 3387 accuray : 0.9287964713295526  loss : 0.34034286853795437\n",
      "iterations 3388 accuray : 0.9285864314219702  loss : 0.3403191455186351\n",
      "iterations 3389 accuray : 0.9285864314219702  loss : 0.340295412371906\n",
      "iterations 3390 accuray : 0.9285864314219702  loss : 0.3402711964186093\n",
      "iterations 3391 accuray : 0.9285864314219702  loss : 0.34024712887435793\n",
      "iterations 3392 accuray : 0.9285864314219702  loss : 0.3402231978350716\n",
      "iterations 3393 accuray : 0.9287964713295526  loss : 0.34019822425972623\n",
      "iterations 3394 accuray : 0.9285864314219702  loss : 0.34017463445854185\n",
      "iterations 3395 accuray : 0.9285864314219702  loss : 0.34015045215631873\n",
      "iterations 3396 accuray : 0.9285864314219702  loss : 0.3401259689596717\n",
      "iterations 3397 accuray : 0.9285864314219702  loss : 0.340100810010401\n",
      "iterations 3398 accuray : 0.9287964713295526  loss : 0.3400764141310155\n",
      "iterations 3399 accuray : 0.9285864314219702  loss : 0.3400518773340577\n",
      "iterations 3400 accuray : 0.9285864314219702  loss : 0.3400276405757317\n",
      "iterations 3401 accuray : 0.9287964713295526  loss : 0.3400027154385978\n",
      "iterations 3402 accuray : 0.9287964713295526  loss : 0.33997827681766873\n",
      "iterations 3403 accuray : 0.9287964713295526  loss : 0.33995462642689767\n",
      "iterations 3404 accuray : 0.9287964713295526  loss : 0.33993073857699424\n",
      "iterations 3405 accuray : 0.9287964713295526  loss : 0.3399071146768918\n",
      "iterations 3406 accuray : 0.9285864314219702  loss : 0.33988286490708325\n",
      "iterations 3407 accuray : 0.9285864314219702  loss : 0.33985911145281505\n",
      "iterations 3408 accuray : 0.9285864314219702  loss : 0.33983498552212654\n",
      "iterations 3409 accuray : 0.9285864314219702  loss : 0.3398114979295735\n",
      "iterations 3410 accuray : 0.9285864314219702  loss : 0.3397877698388408\n",
      "iterations 3411 accuray : 0.9285864314219702  loss : 0.3397637683815571\n",
      "iterations 3412 accuray : 0.9287964713295526  loss : 0.3397395150166983\n",
      "iterations 3413 accuray : 0.9285864314219702  loss : 0.33971535236659617\n",
      "iterations 3414 accuray : 0.9285864314219702  loss : 0.33969085498985563\n",
      "iterations 3415 accuray : 0.9285864314219702  loss : 0.33966617952623307\n",
      "iterations 3416 accuray : 0.9285864314219702  loss : 0.33964239725787787\n",
      "iterations 3417 accuray : 0.9285864314219702  loss : 0.3396176642228609\n",
      "iterations 3418 accuray : 0.9283763915143878  loss : 0.33959340352606815\n",
      "iterations 3419 accuray : 0.9285864314219702  loss : 0.33956961109859873\n",
      "iterations 3420 accuray : 0.9285864314219702  loss : 0.33954521139079935\n",
      "iterations 3421 accuray : 0.9283763915143878  loss : 0.3395211927442932\n",
      "iterations 3422 accuray : 0.9283763915143878  loss : 0.3394971394475205\n",
      "iterations 3423 accuray : 0.9283763915143878  loss : 0.3394722992526234\n",
      "iterations 3424 accuray : 0.9283763915143878  loss : 0.339448419353317\n",
      "iterations 3425 accuray : 0.9283763915143878  loss : 0.33942498041747626\n",
      "iterations 3426 accuray : 0.9283763915143878  loss : 0.3394005079216024\n",
      "iterations 3427 accuray : 0.9283763915143878  loss : 0.3393760309000975\n",
      "iterations 3428 accuray : 0.9283763915143878  loss : 0.3393522490411177\n",
      "iterations 3429 accuray : 0.9283763915143878  loss : 0.33932776078510046\n",
      "iterations 3430 accuray : 0.9283763915143878  loss : 0.33930395915010675\n",
      "iterations 3431 accuray : 0.9283763915143878  loss : 0.33928025615127694\n",
      "iterations 3432 accuray : 0.9283763915143878  loss : 0.3392562247397881\n",
      "iterations 3433 accuray : 0.9283763915143878  loss : 0.33923208560878043\n",
      "iterations 3434 accuray : 0.9283763915143878  loss : 0.3392083166905934\n",
      "iterations 3435 accuray : 0.9283763915143878  loss : 0.3391848409751876\n",
      "iterations 3436 accuray : 0.9283763915143878  loss : 0.33916041655214446\n",
      "iterations 3437 accuray : 0.9283763915143878  loss : 0.3391367131250012\n",
      "iterations 3438 accuray : 0.9283763915143878  loss : 0.33911300383942733\n",
      "iterations 3439 accuray : 0.9283763915143878  loss : 0.3390884575702004\n",
      "iterations 3440 accuray : 0.9283763915143878  loss : 0.3390654937239236\n",
      "iterations 3441 accuray : 0.9283763915143878  loss : 0.3390416619132971\n",
      "iterations 3442 accuray : 0.9283763915143878  loss : 0.33901733750780155\n",
      "iterations 3443 accuray : 0.9283763915143878  loss : 0.3389932251277384\n",
      "iterations 3444 accuray : 0.9283763915143878  loss : 0.33896990173934655\n",
      "iterations 3445 accuray : 0.9283763915143878  loss : 0.3389461201159872\n",
      "iterations 3446 accuray : 0.9283763915143878  loss : 0.3389224871500027\n",
      "iterations 3447 accuray : 0.9283763915143878  loss : 0.33889856799982815\n",
      "iterations 3448 accuray : 0.9283763915143878  loss : 0.33887501758556304\n",
      "iterations 3449 accuray : 0.9283763915143878  loss : 0.33885056892718346\n",
      "iterations 3450 accuray : 0.9283763915143878  loss : 0.33882671916762885\n",
      "iterations 3451 accuray : 0.9283763915143878  loss : 0.33880168316745396\n",
      "iterations 3452 accuray : 0.9283763915143878  loss : 0.3387771996634174\n",
      "iterations 3453 accuray : 0.9283763915143878  loss : 0.3387536552814249\n",
      "iterations 3454 accuray : 0.9283763915143878  loss : 0.33873027884625845\n",
      "iterations 3455 accuray : 0.9283763915143878  loss : 0.33870562418362005\n",
      "iterations 3456 accuray : 0.9283763915143878  loss : 0.33868226500606685\n",
      "iterations 3457 accuray : 0.9283763915143878  loss : 0.3386589999067077\n",
      "iterations 3458 accuray : 0.9283763915143878  loss : 0.3386349052255663\n",
      "iterations 3459 accuray : 0.9283763915143878  loss : 0.3386117262728132\n",
      "iterations 3460 accuray : 0.9283763915143878  loss : 0.33858753552354304\n",
      "iterations 3461 accuray : 0.9283763915143878  loss : 0.3385637034129752\n",
      "iterations 3462 accuray : 0.9283763915143878  loss : 0.338539306865828\n",
      "iterations 3463 accuray : 0.9283763915143878  loss : 0.3385154132711281\n",
      "iterations 3464 accuray : 0.9283763915143878  loss : 0.33849105291508613\n",
      "iterations 3465 accuray : 0.9283763915143878  loss : 0.3384674435948655\n",
      "iterations 3466 accuray : 0.9283763915143878  loss : 0.33844399694382254\n",
      "iterations 3467 accuray : 0.9283763915143878  loss : 0.3384205646895528\n",
      "iterations 3468 accuray : 0.9283763915143878  loss : 0.3383976143643954\n",
      "iterations 3469 accuray : 0.9283763915143878  loss : 0.33837463948354596\n",
      "iterations 3470 accuray : 0.9283763915143878  loss : 0.33835126024726797\n",
      "iterations 3471 accuray : 0.9283763915143878  loss : 0.3383274500801203\n",
      "iterations 3472 accuray : 0.9283763915143878  loss : 0.33830348906434315\n",
      "iterations 3473 accuray : 0.9283763915143878  loss : 0.3382808292060137\n",
      "iterations 3474 accuray : 0.9283763915143878  loss : 0.33825705339626283\n",
      "iterations 3475 accuray : 0.9283763915143878  loss : 0.3382335562692209\n",
      "iterations 3476 accuray : 0.9283763915143878  loss : 0.3382107726040579\n",
      "iterations 3477 accuray : 0.9283763915143878  loss : 0.33818587024491786\n",
      "iterations 3478 accuray : 0.9283763915143878  loss : 0.338162110531599\n",
      "iterations 3479 accuray : 0.9283763915143878  loss : 0.338138989714358\n",
      "iterations 3480 accuray : 0.9283763915143878  loss : 0.3381157864646279\n",
      "iterations 3481 accuray : 0.9283763915143878  loss : 0.33809209927879624\n",
      "iterations 3482 accuray : 0.9283763915143878  loss : 0.33806847699277603\n",
      "iterations 3483 accuray : 0.9283763915143878  loss : 0.33804523415609805\n",
      "iterations 3484 accuray : 0.9283763915143878  loss : 0.3380207327733919\n",
      "iterations 3485 accuray : 0.9283763915143878  loss : 0.33799685316747485\n",
      "iterations 3486 accuray : 0.9283763915143878  loss : 0.33797362580609114\n",
      "iterations 3487 accuray : 0.9283763915143878  loss : 0.33795007122125276\n",
      "iterations 3488 accuray : 0.9283763915143878  loss : 0.3379259601674422\n",
      "iterations 3489 accuray : 0.9283763915143878  loss : 0.33790227826831787\n",
      "iterations 3490 accuray : 0.9283763915143878  loss : 0.33787847569109863\n",
      "iterations 3491 accuray : 0.9283763915143878  loss : 0.33785528743174786\n",
      "iterations 3492 accuray : 0.9283763915143878  loss : 0.33783156539060977\n",
      "iterations 3493 accuray : 0.9283763915143878  loss : 0.3378080814747272\n",
      "iterations 3494 accuray : 0.9281663516068053  loss : 0.33778487688845793\n",
      "iterations 3495 accuray : 0.9281663516068053  loss : 0.33776118588868353\n",
      "iterations 3496 accuray : 0.9283763915143878  loss : 0.33773772578496547\n",
      "iterations 3497 accuray : 0.9281663516068053  loss : 0.3377146807158217\n",
      "iterations 3498 accuray : 0.9281663516068053  loss : 0.3376912865394598\n",
      "iterations 3499 accuray : 0.9281663516068053  loss : 0.33766808810131155\n",
      "iterations 3500 accuray : 0.9281663516068053  loss : 0.3376440501405946\n",
      "iterations 3501 accuray : 0.9281663516068053  loss : 0.33762081430750024\n",
      "iterations 3502 accuray : 0.9281663516068053  loss : 0.33759768453371175\n",
      "iterations 3503 accuray : 0.9281663516068053  loss : 0.33757442200298854\n",
      "iterations 3504 accuray : 0.9281663516068053  loss : 0.3375506128660471\n",
      "iterations 3505 accuray : 0.9281663516068053  loss : 0.3375268642992376\n",
      "iterations 3506 accuray : 0.9285864314219702  loss : 0.3375033594710881\n",
      "iterations 3507 accuray : 0.9285864314219702  loss : 0.3374804901056811\n",
      "iterations 3508 accuray : 0.9285864314219702  loss : 0.33745725635784063\n",
      "iterations 3509 accuray : 0.9285864314219702  loss : 0.33743461289889165\n",
      "iterations 3510 accuray : 0.9283763915143878  loss : 0.33741142444469785\n",
      "iterations 3511 accuray : 0.9281663516068053  loss : 0.3373878539431059\n",
      "iterations 3512 accuray : 0.9281663516068053  loss : 0.337364184501724\n",
      "iterations 3513 accuray : 0.9281663516068053  loss : 0.337341475896598\n",
      "iterations 3514 accuray : 0.9281663516068053  loss : 0.3373184233326352\n",
      "iterations 3515 accuray : 0.9281663516068053  loss : 0.33729537868457615\n",
      "iterations 3516 accuray : 0.9281663516068053  loss : 0.33727185316710834\n",
      "iterations 3517 accuray : 0.9281663516068053  loss : 0.337248826063056\n",
      "iterations 3518 accuray : 0.9281663516068053  loss : 0.3372259701431855\n",
      "iterations 3519 accuray : 0.9281663516068053  loss : 0.33720284253963595\n",
      "iterations 3520 accuray : 0.9281663516068053  loss : 0.33717927152479465\n",
      "iterations 3521 accuray : 0.9281663516068053  loss : 0.33715599968006493\n",
      "iterations 3522 accuray : 0.9283763915143878  loss : 0.33713217536032003\n",
      "iterations 3523 accuray : 0.9283763915143878  loss : 0.3371093254754874\n",
      "iterations 3524 accuray : 0.9281663516068053  loss : 0.33708627386884643\n",
      "iterations 3525 accuray : 0.9283763915143878  loss : 0.33706281034595315\n",
      "iterations 3526 accuray : 0.9285864314219702  loss : 0.33703947539314605\n",
      "iterations 3527 accuray : 0.9283763915143878  loss : 0.3370167409395487\n",
      "iterations 3528 accuray : 0.9287964713295526  loss : 0.33699307629213704\n",
      "iterations 3529 accuray : 0.9287964713295526  loss : 0.3369697684358304\n",
      "iterations 3530 accuray : 0.9287964713295526  loss : 0.3369461028293168\n",
      "iterations 3531 accuray : 0.9287964713295526  loss : 0.3369234027482946\n",
      "iterations 3532 accuray : 0.9287964713295526  loss : 0.3369000520646457\n",
      "iterations 3533 accuray : 0.9287964713295526  loss : 0.336876926287554\n",
      "iterations 3534 accuray : 0.9287964713295526  loss : 0.3368536385368462\n",
      "iterations 3535 accuray : 0.9287964713295526  loss : 0.33683043881734476\n",
      "iterations 3536 accuray : 0.9287964713295526  loss : 0.3368078594939828\n",
      "iterations 3537 accuray : 0.9287964713295526  loss : 0.33678491207152467\n",
      "iterations 3538 accuray : 0.9285864314219702  loss : 0.3367616001895141\n",
      "iterations 3539 accuray : 0.9285864314219702  loss : 0.33673861573160385\n",
      "iterations 3540 accuray : 0.9283763915143878  loss : 0.3367156050076632\n",
      "iterations 3541 accuray : 0.9283763915143878  loss : 0.33669294911302167\n",
      "iterations 3542 accuray : 0.9283763915143878  loss : 0.33666947712086703\n",
      "iterations 3543 accuray : 0.9285864314219702  loss : 0.33664561516937846\n",
      "iterations 3544 accuray : 0.9283763915143878  loss : 0.33662298018709963\n",
      "iterations 3545 accuray : 0.9285864314219702  loss : 0.3366002010572743\n",
      "iterations 3546 accuray : 0.9285864314219702  loss : 0.3365769958446414\n",
      "iterations 3547 accuray : 0.9283763915143878  loss : 0.3365543700146121\n",
      "iterations 3548 accuray : 0.9285864314219702  loss : 0.3365311823859364\n",
      "iterations 3549 accuray : 0.9285864314219702  loss : 0.33650836835206405\n",
      "iterations 3550 accuray : 0.9287964713295526  loss : 0.3364839659109035\n",
      "iterations 3551 accuray : 0.9285864314219702  loss : 0.3364610030914769\n",
      "iterations 3552 accuray : 0.9285864314219702  loss : 0.33643744994118324\n",
      "iterations 3553 accuray : 0.9285864314219702  loss : 0.3364147205154173\n",
      "iterations 3554 accuray : 0.9285864314219702  loss : 0.3363912131184214\n",
      "iterations 3555 accuray : 0.9285864314219702  loss : 0.3363687136432822\n",
      "iterations 3556 accuray : 0.9287964713295526  loss : 0.3363456209486498\n",
      "iterations 3557 accuray : 0.9287964713295526  loss : 0.3363220058652182\n",
      "iterations 3558 accuray : 0.9287964713295526  loss : 0.33629854725031244\n",
      "iterations 3559 accuray : 0.9287964713295526  loss : 0.33627638882994243\n",
      "iterations 3560 accuray : 0.9287964713295526  loss : 0.33625285511839026\n",
      "iterations 3561 accuray : 0.9287964713295526  loss : 0.33622954691151463\n",
      "iterations 3562 accuray : 0.9287964713295526  loss : 0.33620683694555936\n",
      "iterations 3563 accuray : 0.9287964713295526  loss : 0.3361843338815709\n",
      "iterations 3564 accuray : 0.9287964713295526  loss : 0.336161531751363\n",
      "iterations 3565 accuray : 0.9287964713295526  loss : 0.3361398658678117\n",
      "iterations 3566 accuray : 0.9287964713295526  loss : 0.3361160707420031\n",
      "iterations 3567 accuray : 0.9287964713295526  loss : 0.3360936450545846\n",
      "iterations 3568 accuray : 0.9287964713295526  loss : 0.3360701481210567\n",
      "iterations 3569 accuray : 0.9290065112371351  loss : 0.33604733752034527\n",
      "iterations 3570 accuray : 0.9287964713295526  loss : 0.33602429435350706\n",
      "iterations 3571 accuray : 0.9290065112371351  loss : 0.33600141493574076\n",
      "iterations 3572 accuray : 0.9290065112371351  loss : 0.3359787525519653\n",
      "iterations 3573 accuray : 0.9290065112371351  loss : 0.3359556886948948\n",
      "iterations 3574 accuray : 0.9290065112371351  loss : 0.33593287682602213\n",
      "iterations 3575 accuray : 0.9290065112371351  loss : 0.3359105247938035\n",
      "iterations 3576 accuray : 0.9290065112371351  loss : 0.3358882921165725\n",
      "iterations 3577 accuray : 0.9290065112371351  loss : 0.3358659232256235\n",
      "iterations 3578 accuray : 0.9290065112371351  loss : 0.33584315546972804\n",
      "iterations 3579 accuray : 0.9290065112371351  loss : 0.3358201887269501\n",
      "iterations 3580 accuray : 0.9290065112371351  loss : 0.3357970793136587\n",
      "iterations 3581 accuray : 0.9290065112371351  loss : 0.3357748592239707\n",
      "iterations 3582 accuray : 0.9290065112371351  loss : 0.33575191969612156\n",
      "iterations 3583 accuray : 0.9290065112371351  loss : 0.33572903378915286\n",
      "iterations 3584 accuray : 0.9290065112371351  loss : 0.33570616177092905\n",
      "iterations 3585 accuray : 0.9290065112371351  loss : 0.3356839904863965\n",
      "iterations 3586 accuray : 0.9290065112371351  loss : 0.33566123449618207\n",
      "iterations 3587 accuray : 0.9290065112371351  loss : 0.33563897917921676\n",
      "iterations 3588 accuray : 0.9290065112371351  loss : 0.33561633122642204\n",
      "iterations 3589 accuray : 0.9290065112371351  loss : 0.33559363353665866\n",
      "iterations 3590 accuray : 0.9290065112371351  loss : 0.33557090602563067\n",
      "iterations 3591 accuray : 0.9290065112371351  loss : 0.3355487014790436\n",
      "iterations 3592 accuray : 0.9290065112371351  loss : 0.3355263060391294\n",
      "iterations 3593 accuray : 0.9290065112371351  loss : 0.335503624177408\n",
      "iterations 3594 accuray : 0.9290065112371351  loss : 0.33548018620906056\n",
      "iterations 3595 accuray : 0.9290065112371351  loss : 0.335457626074388\n",
      "iterations 3596 accuray : 0.9290065112371351  loss : 0.3354346978656359\n",
      "iterations 3597 accuray : 0.9290065112371351  loss : 0.3354121686876244\n",
      "iterations 3598 accuray : 0.9290065112371351  loss : 0.33538936463171803\n",
      "iterations 3599 accuray : 0.9287964713295526  loss : 0.33536702840822913\n",
      "iterations 3600 accuray : 0.9287964713295526  loss : 0.3353439359251461\n",
      "iterations 3601 accuray : 0.9287964713295526  loss : 0.335321810874156\n",
      "iterations 3602 accuray : 0.9287964713295526  loss : 0.33529927387927755\n",
      "iterations 3603 accuray : 0.9287964713295526  loss : 0.33527564847234786\n",
      "iterations 3604 accuray : 0.9290065112371351  loss : 0.3352534897494475\n",
      "iterations 3605 accuray : 0.9287964713295526  loss : 0.3352301558986486\n",
      "iterations 3606 accuray : 0.9287964713295526  loss : 0.3352080934080944\n",
      "iterations 3607 accuray : 0.9287964713295526  loss : 0.3351851686541157\n",
      "iterations 3608 accuray : 0.9287964713295526  loss : 0.33516200930876944\n",
      "iterations 3609 accuray : 0.9287964713295526  loss : 0.3351400630685212\n",
      "iterations 3610 accuray : 0.9287964713295526  loss : 0.3351167557536572\n",
      "iterations 3611 accuray : 0.9287964713295526  loss : 0.3350935894027635\n",
      "iterations 3612 accuray : 0.9287964713295526  loss : 0.33507093737022425\n",
      "iterations 3613 accuray : 0.9287964713295526  loss : 0.33504877060925475\n",
      "iterations 3614 accuray : 0.9287964713295526  loss : 0.3350268837657951\n",
      "iterations 3615 accuray : 0.9287964713295526  loss : 0.3350048476497371\n",
      "iterations 3616 accuray : 0.9287964713295526  loss : 0.3349820682437585\n",
      "iterations 3617 accuray : 0.9287964713295526  loss : 0.33495989557362504\n",
      "iterations 3618 accuray : 0.9287964713295526  loss : 0.3349369266788059\n",
      "iterations 3619 accuray : 0.9287964713295526  loss : 0.33491418218106234\n",
      "iterations 3620 accuray : 0.9287964713295526  loss : 0.3348919562261479\n",
      "iterations 3621 accuray : 0.9287964713295526  loss : 0.33486964478739184\n",
      "iterations 3622 accuray : 0.9287964713295526  loss : 0.3348477515104676\n",
      "iterations 3623 accuray : 0.9287964713295526  loss : 0.3348249264599878\n",
      "iterations 3624 accuray : 0.9287964713295526  loss : 0.3348025487534327\n",
      "iterations 3625 accuray : 0.9287964713295526  loss : 0.3347805684866612\n",
      "iterations 3626 accuray : 0.9287964713295526  loss : 0.33475895935700367\n",
      "iterations 3627 accuray : 0.9287964713295526  loss : 0.3347370428197124\n",
      "iterations 3628 accuray : 0.9287964713295526  loss : 0.33471509776555725\n",
      "iterations 3629 accuray : 0.9287964713295526  loss : 0.33469279801511426\n",
      "iterations 3630 accuray : 0.9287964713295526  loss : 0.3346702389437934\n",
      "iterations 3631 accuray : 0.9285864314219702  loss : 0.3346471525829166\n",
      "iterations 3632 accuray : 0.9287964713295526  loss : 0.3346253111442461\n",
      "iterations 3633 accuray : 0.9287964713295526  loss : 0.3346021181000935\n",
      "iterations 3634 accuray : 0.9287964713295526  loss : 0.3345801459356355\n",
      "iterations 3635 accuray : 0.9285864314219702  loss : 0.3345574894732105\n",
      "iterations 3636 accuray : 0.9285864314219702  loss : 0.33453441835540326\n",
      "iterations 3637 accuray : 0.9285864314219702  loss : 0.3345117614309639\n",
      "iterations 3638 accuray : 0.9285864314219702  loss : 0.33448864693580316\n",
      "iterations 3639 accuray : 0.9287964713295526  loss : 0.33446599467470245\n",
      "iterations 3640 accuray : 0.9287964713295526  loss : 0.3344435654020708\n",
      "iterations 3641 accuray : 0.9287964713295526  loss : 0.3344212575410243\n",
      "iterations 3642 accuray : 0.9287964713295526  loss : 0.3343985996280607\n",
      "iterations 3643 accuray : 0.9287964713295526  loss : 0.33437576424188387\n",
      "iterations 3644 accuray : 0.9287964713295526  loss : 0.3343535754046883\n",
      "iterations 3645 accuray : 0.9287964713295526  loss : 0.3343312813380869\n",
      "iterations 3646 accuray : 0.9287964713295526  loss : 0.33430946950756724\n",
      "iterations 3647 accuray : 0.9287964713295526  loss : 0.3342866484904166\n",
      "iterations 3648 accuray : 0.9287964713295526  loss : 0.3342642154965502\n",
      "iterations 3649 accuray : 0.9287964713295526  loss : 0.3342414532748388\n",
      "iterations 3650 accuray : 0.9287964713295526  loss : 0.3342189388983469\n",
      "iterations 3651 accuray : 0.9287964713295526  loss : 0.334197430736139\n",
      "iterations 3652 accuray : 0.9290065112371351  loss : 0.3341749112973243\n",
      "iterations 3653 accuray : 0.9287964713295526  loss : 0.33415301425808897\n",
      "iterations 3654 accuray : 0.9287964713295526  loss : 0.33413115566314283\n",
      "iterations 3655 accuray : 0.9287964713295526  loss : 0.3341096019977458\n",
      "iterations 3656 accuray : 0.9287964713295526  loss : 0.33408791372657465\n",
      "iterations 3657 accuray : 0.9290065112371351  loss : 0.3340657518523306\n",
      "iterations 3658 accuray : 0.9287964713295526  loss : 0.33404355857399715\n",
      "iterations 3659 accuray : 0.9290065112371351  loss : 0.33402108091087845\n",
      "iterations 3660 accuray : 0.9290065112371351  loss : 0.33399906169088356\n",
      "iterations 3661 accuray : 0.9290065112371351  loss : 0.3339768581087524\n",
      "iterations 3662 accuray : 0.9290065112371351  loss : 0.3339547899505946\n",
      "iterations 3663 accuray : 0.9290065112371351  loss : 0.3339327900470741\n",
      "iterations 3664 accuray : 0.9290065112371351  loss : 0.3339105469062776\n",
      "iterations 3665 accuray : 0.9290065112371351  loss : 0.33388796340434707\n",
      "iterations 3666 accuray : 0.9290065112371351  loss : 0.3338655449831696\n",
      "iterations 3667 accuray : 0.9287964713295526  loss : 0.3338432131673885\n",
      "iterations 3668 accuray : 0.9287964713295526  loss : 0.33382115427171144\n",
      "iterations 3669 accuray : 0.9287964713295526  loss : 0.3337988581548876\n",
      "iterations 3670 accuray : 0.9290065112371351  loss : 0.33377698767149216\n",
      "iterations 3671 accuray : 0.9290065112371351  loss : 0.33375558625718693\n",
      "iterations 3672 accuray : 0.9290065112371351  loss : 0.3337330381227409\n",
      "iterations 3673 accuray : 0.9287964713295526  loss : 0.333710729955442\n",
      "iterations 3674 accuray : 0.9287964713295526  loss : 0.33368859722888145\n",
      "iterations 3675 accuray : 0.9287964713295526  loss : 0.33366665360271874\n",
      "iterations 3676 accuray : 0.9287964713295526  loss : 0.33364415487905935\n",
      "iterations 3677 accuray : 0.9287964713295526  loss : 0.3336218981384983\n",
      "iterations 3678 accuray : 0.9287964713295526  loss : 0.3336000681272354\n",
      "iterations 3679 accuray : 0.9287964713295526  loss : 0.3335777188318966\n",
      "iterations 3680 accuray : 0.9287964713295526  loss : 0.3335558826952897\n",
      "iterations 3681 accuray : 0.9287964713295526  loss : 0.33353382148216526\n",
      "iterations 3682 accuray : 0.9285864314219702  loss : 0.33351198277137234\n",
      "iterations 3683 accuray : 0.9285864314219702  loss : 0.3334907259690186\n",
      "iterations 3684 accuray : 0.9285864314219702  loss : 0.33346862807529826\n",
      "iterations 3685 accuray : 0.9285864314219702  loss : 0.3334461794323685\n",
      "iterations 3686 accuray : 0.9287964713295526  loss : 0.333424330738347\n",
      "iterations 3687 accuray : 0.9285864314219702  loss : 0.3334022699587653\n",
      "iterations 3688 accuray : 0.9287964713295526  loss : 0.333380242807699\n",
      "iterations 3689 accuray : 0.9287964713295526  loss : 0.3333582955068177\n",
      "iterations 3690 accuray : 0.9287964713295526  loss : 0.3333367357077611\n",
      "iterations 3691 accuray : 0.9287964713295526  loss : 0.33331513858534667\n",
      "iterations 3692 accuray : 0.9287964713295526  loss : 0.33329377021754164\n",
      "iterations 3693 accuray : 0.9287964713295526  loss : 0.3332722343713673\n",
      "iterations 3694 accuray : 0.9287964713295526  loss : 0.3332512056369219\n",
      "iterations 3695 accuray : 0.9287964713295526  loss : 0.3332293949706064\n",
      "iterations 3696 accuray : 0.9287964713295526  loss : 0.3332074922819746\n",
      "iterations 3697 accuray : 0.9287964713295526  loss : 0.3331854489728368\n",
      "iterations 3698 accuray : 0.9287964713295526  loss : 0.3331637753506113\n",
      "iterations 3699 accuray : 0.9287964713295526  loss : 0.33314174073053904\n",
      "iterations 3700 accuray : 0.9287964713295526  loss : 0.3331194779881621\n",
      "iterations 3701 accuray : 0.9287964713295526  loss : 0.33309789004878626\n",
      "iterations 3702 accuray : 0.9287964713295526  loss : 0.33307633282317206\n",
      "iterations 3703 accuray : 0.9287964713295526  loss : 0.3330547975019951\n",
      "iterations 3704 accuray : 0.9287964713295526  loss : 0.33303320314360096\n",
      "iterations 3705 accuray : 0.9287964713295526  loss : 0.3330112851724841\n",
      "iterations 3706 accuray : 0.9287964713295526  loss : 0.33298990401436895\n",
      "iterations 3707 accuray : 0.9287964713295526  loss : 0.33296708518660956\n",
      "iterations 3708 accuray : 0.9287964713295526  loss : 0.3329463520519899\n",
      "iterations 3709 accuray : 0.9287964713295526  loss : 0.332925367929478\n",
      "iterations 3710 accuray : 0.9287964713295526  loss : 0.33290266539526037\n",
      "iterations 3711 accuray : 0.9287964713295526  loss : 0.33288051641447797\n",
      "iterations 3712 accuray : 0.9287964713295526  loss : 0.3328589460536717\n",
      "iterations 3713 accuray : 0.9287964713295526  loss : 0.33283741274231154\n",
      "iterations 3714 accuray : 0.9287964713295526  loss : 0.33281554907640354\n",
      "iterations 3715 accuray : 0.9287964713295526  loss : 0.33279330875068197\n",
      "iterations 3716 accuray : 0.9287964713295526  loss : 0.3327717823902616\n",
      "iterations 3717 accuray : 0.9287964713295526  loss : 0.3327499684251012\n",
      "iterations 3718 accuray : 0.9287964713295526  loss : 0.3327287429376175\n",
      "iterations 3719 accuray : 0.9287964713295526  loss : 0.33270731879226684\n",
      "iterations 3720 accuray : 0.9287964713295526  loss : 0.33268608218881435\n",
      "iterations 3721 accuray : 0.9287964713295526  loss : 0.3326649762270175\n",
      "iterations 3722 accuray : 0.9287964713295526  loss : 0.3326430210558983\n",
      "iterations 3723 accuray : 0.9287964713295526  loss : 0.3326211120127001\n",
      "iterations 3724 accuray : 0.9287964713295526  loss : 0.33260004842200663\n",
      "iterations 3725 accuray : 0.9287964713295526  loss : 0.33257831508865127\n",
      "iterations 3726 accuray : 0.9287964713295526  loss : 0.3325568289116193\n",
      "iterations 3727 accuray : 0.9287964713295526  loss : 0.3325352373208071\n",
      "iterations 3728 accuray : 0.9285864314219702  loss : 0.3325130040106405\n",
      "iterations 3729 accuray : 0.9285864314219702  loss : 0.33249185919696717\n",
      "iterations 3730 accuray : 0.9285864314219702  loss : 0.3324707142805123\n",
      "iterations 3731 accuray : 0.9285864314219702  loss : 0.33244895923772516\n",
      "iterations 3732 accuray : 0.9285864314219702  loss : 0.33242744814491304\n",
      "iterations 3733 accuray : 0.9287964713295526  loss : 0.3324064940801845\n",
      "iterations 3734 accuray : 0.9287964713295526  loss : 0.33238450293404936\n",
      "iterations 3735 accuray : 0.9287964713295526  loss : 0.33236374499548565\n",
      "iterations 3736 accuray : 0.9287964713295526  loss : 0.3323425652833436\n",
      "iterations 3737 accuray : 0.9285864314219702  loss : 0.3323205233521412\n",
      "iterations 3738 accuray : 0.9285864314219702  loss : 0.33229894158128653\n",
      "iterations 3739 accuray : 0.9285864314219702  loss : 0.3322774252234215\n",
      "iterations 3740 accuray : 0.9285864314219702  loss : 0.33225586288108633\n",
      "iterations 3741 accuray : 0.9285864314219702  loss : 0.3322342894336192\n",
      "iterations 3742 accuray : 0.9285864314219702  loss : 0.33221350120413484\n",
      "iterations 3743 accuray : 0.9285864314219702  loss : 0.3321916159886129\n",
      "iterations 3744 accuray : 0.9285864314219702  loss : 0.3321701338088824\n",
      "iterations 3745 accuray : 0.9285864314219702  loss : 0.33214839968280885\n",
      "iterations 3746 accuray : 0.9287964713295526  loss : 0.3321278750442257\n",
      "iterations 3747 accuray : 0.9287964713295526  loss : 0.33210630083009046\n",
      "iterations 3748 accuray : 0.9285864314219702  loss : 0.3320850011204346\n",
      "iterations 3749 accuray : 0.9285864314219702  loss : 0.3320630368893819\n",
      "iterations 3750 accuray : 0.9285864314219702  loss : 0.3320409832177202\n",
      "iterations 3751 accuray : 0.9283763915143878  loss : 0.3320188055098839\n",
      "iterations 3752 accuray : 0.9283763915143878  loss : 0.3319966025868096\n",
      "iterations 3753 accuray : 0.9283763915143878  loss : 0.33197489379835005\n",
      "iterations 3754 accuray : 0.9283763915143878  loss : 0.33195332510247305\n",
      "iterations 3755 accuray : 0.9283763915143878  loss : 0.3319328991154512\n",
      "iterations 3756 accuray : 0.9283763915143878  loss : 0.3319115652766892\n",
      "iterations 3757 accuray : 0.9283763915143878  loss : 0.3318905316911381\n",
      "iterations 3758 accuray : 0.9283763915143878  loss : 0.3318690630200915\n",
      "iterations 3759 accuray : 0.9283763915143878  loss : 0.33184772628614867\n",
      "iterations 3760 accuray : 0.9283763915143878  loss : 0.33182694924424916\n",
      "iterations 3761 accuray : 0.9283763915143878  loss : 0.33180532634884435\n",
      "iterations 3762 accuray : 0.9283763915143878  loss : 0.3317840767070628\n",
      "iterations 3763 accuray : 0.9283763915143878  loss : 0.33176306709342407\n",
      "iterations 3764 accuray : 0.9283763915143878  loss : 0.3317418481870014\n",
      "iterations 3765 accuray : 0.9283763915143878  loss : 0.33172083574561045\n",
      "iterations 3766 accuray : 0.9283763915143878  loss : 0.33169952165645233\n",
      "iterations 3767 accuray : 0.9283763915143878  loss : 0.33167826352066787\n",
      "iterations 3768 accuray : 0.9283763915143878  loss : 0.3316570505430101\n",
      "iterations 3769 accuray : 0.9283763915143878  loss : 0.3316361736182781\n",
      "iterations 3770 accuray : 0.9283763915143878  loss : 0.3316145409108896\n",
      "iterations 3771 accuray : 0.9283763915143878  loss : 0.33159331600188524\n",
      "iterations 3772 accuray : 0.9283763915143878  loss : 0.33157213953564657\n",
      "iterations 3773 accuray : 0.9283763915143878  loss : 0.33155053852550154\n",
      "iterations 3774 accuray : 0.9283763915143878  loss : 0.33152924364482156\n",
      "iterations 3775 accuray : 0.9283763915143878  loss : 0.33150796191782633\n",
      "iterations 3776 accuray : 0.9283763915143878  loss : 0.3314862273303418\n",
      "iterations 3777 accuray : 0.9283763915143878  loss : 0.33146517849221346\n",
      "iterations 3778 accuray : 0.9283763915143878  loss : 0.3314444030500006\n",
      "iterations 3779 accuray : 0.9283763915143878  loss : 0.3314230249258213\n",
      "iterations 3780 accuray : 0.9283763915143878  loss : 0.3314015298448409\n",
      "iterations 3781 accuray : 0.9283763915143878  loss : 0.33138017915942586\n",
      "iterations 3782 accuray : 0.9283763915143878  loss : 0.3313589203457072\n",
      "iterations 3783 accuray : 0.9283763915143878  loss : 0.33133749012840086\n",
      "iterations 3784 accuray : 0.9281663516068053  loss : 0.33131609387503747\n",
      "iterations 3785 accuray : 0.9281663516068053  loss : 0.3312947049649096\n",
      "iterations 3786 accuray : 0.9281663516068053  loss : 0.33127270460785196\n",
      "iterations 3787 accuray : 0.9281663516068053  loss : 0.3312510453079298\n",
      "iterations 3788 accuray : 0.9281663516068053  loss : 0.3312305365362186\n",
      "iterations 3789 accuray : 0.9281663516068053  loss : 0.3312090829193068\n",
      "iterations 3790 accuray : 0.9281663516068053  loss : 0.33118788973537133\n",
      "iterations 3791 accuray : 0.9281663516068053  loss : 0.3311662474989653\n",
      "iterations 3792 accuray : 0.9281663516068053  loss : 0.3311459629082043\n",
      "iterations 3793 accuray : 0.9281663516068053  loss : 0.3311240577159066\n",
      "iterations 3794 accuray : 0.9281663516068053  loss : 0.33110272560027093\n",
      "iterations 3795 accuray : 0.9281663516068053  loss : 0.33108229131909894\n",
      "iterations 3796 accuray : 0.9281663516068053  loss : 0.33106184908574904\n",
      "iterations 3797 accuray : 0.9281663516068053  loss : 0.331040881899922\n",
      "iterations 3798 accuray : 0.9281663516068053  loss : 0.3310196722768997\n",
      "iterations 3799 accuray : 0.9281663516068053  loss : 0.33099918975491466\n",
      "iterations 3800 accuray : 0.9281663516068053  loss : 0.3309788109806839\n",
      "iterations 3801 accuray : 0.9281663516068053  loss : 0.33095763325503696\n",
      "iterations 3802 accuray : 0.9281663516068053  loss : 0.33093650027713034\n",
      "iterations 3803 accuray : 0.9281663516068053  loss : 0.33091480659317407\n",
      "iterations 3804 accuray : 0.9281663516068053  loss : 0.3308936355965325\n",
      "iterations 3805 accuray : 0.9281663516068053  loss : 0.33087274176369863\n",
      "iterations 3806 accuray : 0.9281663516068053  loss : 0.33085146255835185\n",
      "iterations 3807 accuray : 0.9281663516068053  loss : 0.33083054091445546\n",
      "iterations 3808 accuray : 0.9281663516068053  loss : 0.33081001361008716\n",
      "iterations 3809 accuray : 0.9281663516068053  loss : 0.3307890369004827\n",
      "iterations 3810 accuray : 0.9281663516068053  loss : 0.33076798205993907\n",
      "iterations 3811 accuray : 0.9281663516068053  loss : 0.3307467699871659\n",
      "iterations 3812 accuray : 0.9281663516068053  loss : 0.33072512488645633\n",
      "iterations 3813 accuray : 0.9281663516068053  loss : 0.3307048006909075\n",
      "iterations 3814 accuray : 0.9281663516068053  loss : 0.3306838071480031\n",
      "iterations 3815 accuray : 0.9281663516068053  loss : 0.3306623656610129\n",
      "iterations 3816 accuray : 0.9281663516068053  loss : 0.33064162915580686\n",
      "iterations 3817 accuray : 0.9281663516068053  loss : 0.3306212829486876\n",
      "iterations 3818 accuray : 0.9281663516068053  loss : 0.330600449774396\n",
      "iterations 3819 accuray : 0.9281663516068053  loss : 0.33057929203603825\n",
      "iterations 3820 accuray : 0.9281663516068053  loss : 0.3305585269348349\n",
      "iterations 3821 accuray : 0.9281663516068053  loss : 0.33053782489606853\n",
      "iterations 3822 accuray : 0.9281663516068053  loss : 0.3305167775638122\n",
      "iterations 3823 accuray : 0.9281663516068053  loss : 0.33049628779098944\n",
      "iterations 3824 accuray : 0.9281663516068053  loss : 0.33047528406721555\n",
      "iterations 3825 accuray : 0.9277462717916404  loss : 0.3304540175924198\n",
      "iterations 3826 accuray : 0.9277462717916404  loss : 0.3304332265334604\n",
      "iterations 3827 accuray : 0.9281663516068053  loss : 0.3304123415515057\n",
      "iterations 3828 accuray : 0.9281663516068053  loss : 0.33039141263809896\n",
      "iterations 3829 accuray : 0.9281663516068053  loss : 0.3303705611753049\n",
      "iterations 3830 accuray : 0.9281663516068053  loss : 0.33034973591697236\n",
      "iterations 3831 accuray : 0.9281663516068053  loss : 0.33032888226831353\n",
      "iterations 3832 accuray : 0.9281663516068053  loss : 0.33030839373811577\n",
      "iterations 3833 accuray : 0.9281663516068053  loss : 0.3302872730053773\n",
      "iterations 3834 accuray : 0.9277462717916404  loss : 0.3302660043735341\n",
      "iterations 3835 accuray : 0.9277462717916404  loss : 0.33024514647411357\n",
      "iterations 3836 accuray : 0.9281663516068053  loss : 0.3302248485468401\n",
      "iterations 3837 accuray : 0.9281663516068053  loss : 0.3302033634414744\n",
      "iterations 3838 accuray : 0.9281663516068053  loss : 0.330182270888596\n",
      "iterations 3839 accuray : 0.9277462717916404  loss : 0.3301613406562845\n",
      "iterations 3840 accuray : 0.9279563116992229  loss : 0.33014013665742264\n",
      "iterations 3841 accuray : 0.9281663516068053  loss : 0.33011938339728547\n",
      "iterations 3842 accuray : 0.9279563116992229  loss : 0.3300991428979722\n",
      "iterations 3843 accuray : 0.9281663516068053  loss : 0.33007822164699396\n",
      "iterations 3844 accuray : 0.9281663516068053  loss : 0.33005745934486586\n",
      "iterations 3845 accuray : 0.9279563116992229  loss : 0.33003677695046335\n",
      "iterations 3846 accuray : 0.9281663516068053  loss : 0.3300155981111118\n",
      "iterations 3847 accuray : 0.9281663516068053  loss : 0.3299952375010111\n",
      "iterations 3848 accuray : 0.9281663516068053  loss : 0.32997431063746585\n",
      "iterations 3849 accuray : 0.9281663516068053  loss : 0.32995364391078497\n",
      "iterations 3850 accuray : 0.9281663516068053  loss : 0.32993270737646907\n",
      "iterations 3851 accuray : 0.9281663516068053  loss : 0.3299114967989658\n",
      "iterations 3852 accuray : 0.9281663516068053  loss : 0.32989034084964125\n",
      "iterations 3853 accuray : 0.9281663516068053  loss : 0.3298694391967869\n",
      "iterations 3854 accuray : 0.9281663516068053  loss : 0.3298491896843461\n",
      "iterations 3855 accuray : 0.9281663516068053  loss : 0.3298285998637777\n",
      "iterations 3856 accuray : 0.9281663516068053  loss : 0.32980830362414826\n",
      "iterations 3857 accuray : 0.9281663516068053  loss : 0.32978813715966854\n",
      "iterations 3858 accuray : 0.9281663516068053  loss : 0.3297666078351573\n",
      "iterations 3859 accuray : 0.9281663516068053  loss : 0.32974551700453486\n",
      "iterations 3860 accuray : 0.9281663516068053  loss : 0.32972398149188775\n",
      "iterations 3861 accuray : 0.9281663516068053  loss : 0.32970306717664194\n",
      "iterations 3862 accuray : 0.9283763915143878  loss : 0.3296824856261665\n",
      "iterations 3863 accuray : 0.9285864314219702  loss : 0.329662347907483\n",
      "iterations 3864 accuray : 0.9285864314219702  loss : 0.32964104890445556\n",
      "iterations 3865 accuray : 0.9285864314219702  loss : 0.3296206588629332\n",
      "iterations 3866 accuray : 0.9285864314219702  loss : 0.32960006182721663\n",
      "iterations 3867 accuray : 0.9285864314219702  loss : 0.32957932511283183\n",
      "iterations 3868 accuray : 0.9285864314219702  loss : 0.32955832614248665\n",
      "iterations 3869 accuray : 0.9285864314219702  loss : 0.32953769244402964\n",
      "iterations 3870 accuray : 0.9283763915143878  loss : 0.3295174875745538\n",
      "iterations 3871 accuray : 0.9283763915143878  loss : 0.32949618542110937\n",
      "iterations 3872 accuray : 0.9283763915143878  loss : 0.32947571208907456\n",
      "iterations 3873 accuray : 0.9283763915143878  loss : 0.3294544964387834\n",
      "iterations 3874 accuray : 0.9283763915143878  loss : 0.32943462036298693\n",
      "iterations 3875 accuray : 0.9283763915143878  loss : 0.32941428197812905\n",
      "iterations 3876 accuray : 0.9283763915143878  loss : 0.3293939415003134\n",
      "iterations 3877 accuray : 0.9283763915143878  loss : 0.32937377177860383\n",
      "iterations 3878 accuray : 0.9283763915143878  loss : 0.3293524636224092\n",
      "iterations 3879 accuray : 0.9283763915143878  loss : 0.3293311259493952\n",
      "iterations 3880 accuray : 0.9285864314219702  loss : 0.329310031737105\n",
      "iterations 3881 accuray : 0.9285864314219702  loss : 0.3292896352088355\n",
      "iterations 3882 accuray : 0.9285864314219702  loss : 0.32926846519463787\n",
      "iterations 3883 accuray : 0.9285864314219702  loss : 0.32924811247341373\n",
      "iterations 3884 accuray : 0.9285864314219702  loss : 0.3292275801725238\n",
      "iterations 3885 accuray : 0.9285864314219702  loss : 0.3292062491115999\n",
      "iterations 3886 accuray : 0.9285864314219702  loss : 0.3291851549444141\n",
      "iterations 3887 accuray : 0.9285864314219702  loss : 0.3291648038012653\n",
      "iterations 3888 accuray : 0.9285864314219702  loss : 0.32914427252669054\n",
      "iterations 3889 accuray : 0.9285864314219702  loss : 0.3291239738599937\n",
      "iterations 3890 accuray : 0.9285864314219702  loss : 0.3291038759119005\n",
      "iterations 3891 accuray : 0.9285864314219702  loss : 0.3290842570806063\n",
      "iterations 3892 accuray : 0.9285864314219702  loss : 0.32906348927741647\n",
      "iterations 3893 accuray : 0.9285864314219702  loss : 0.3290420442539725\n",
      "iterations 3894 accuray : 0.9285864314219702  loss : 0.3290218823462349\n",
      "iterations 3895 accuray : 0.9285864314219702  loss : 0.32900105411553254\n",
      "iterations 3896 accuray : 0.9285864314219702  loss : 0.3289797613059459\n",
      "iterations 3897 accuray : 0.9285864314219702  loss : 0.3289592154033991\n",
      "iterations 3898 accuray : 0.9285864314219702  loss : 0.32893961373930564\n",
      "iterations 3899 accuray : 0.9285864314219702  loss : 0.3289198394538952\n",
      "iterations 3900 accuray : 0.9285864314219702  loss : 0.32889910208825934\n",
      "iterations 3901 accuray : 0.9285864314219702  loss : 0.32887902342259684\n",
      "iterations 3902 accuray : 0.9285864314219702  loss : 0.32885869477515633\n",
      "iterations 3903 accuray : 0.9285864314219702  loss : 0.3288383462436944\n",
      "iterations 3904 accuray : 0.9285864314219702  loss : 0.3288187777718116\n",
      "iterations 3905 accuray : 0.9285864314219702  loss : 0.32879864211818843\n",
      "iterations 3906 accuray : 0.9285864314219702  loss : 0.3287779271749021\n",
      "iterations 3907 accuray : 0.9283763915143878  loss : 0.3287573458186463\n",
      "iterations 3908 accuray : 0.9283763915143878  loss : 0.328737108373835\n",
      "iterations 3909 accuray : 0.9285864314219702  loss : 0.3287168024070094\n",
      "iterations 3910 accuray : 0.9285864314219702  loss : 0.32869613216896515\n",
      "iterations 3911 accuray : 0.9285864314219702  loss : 0.32867631859595137\n",
      "iterations 3912 accuray : 0.9285864314219702  loss : 0.3286564519722015\n",
      "iterations 3913 accuray : 0.9285864314219702  loss : 0.32863587450062104\n",
      "iterations 3914 accuray : 0.9285864314219702  loss : 0.32861529503387926\n",
      "iterations 3915 accuray : 0.9285864314219702  loss : 0.3285954336562284\n",
      "iterations 3916 accuray : 0.9285864314219702  loss : 0.3285752985836399\n",
      "iterations 3917 accuray : 0.9285864314219702  loss : 0.32855524721848856\n",
      "iterations 3918 accuray : 0.9283763915143878  loss : 0.3285342999562166\n",
      "iterations 3919 accuray : 0.9283763915143878  loss : 0.3285142047170437\n",
      "iterations 3920 accuray : 0.9283763915143878  loss : 0.32849367824491016\n",
      "iterations 3921 accuray : 0.9285864314219702  loss : 0.32847370467086134\n",
      "iterations 3922 accuray : 0.9285864314219702  loss : 0.32845415914431236\n",
      "iterations 3923 accuray : 0.9285864314219702  loss : 0.3284343989538225\n",
      "iterations 3924 accuray : 0.9285864314219702  loss : 0.3284143357603329\n",
      "iterations 3925 accuray : 0.9285864314219702  loss : 0.32839405131741956\n",
      "iterations 3926 accuray : 0.9285864314219702  loss : 0.3283736968397389\n",
      "iterations 3927 accuray : 0.9285864314219702  loss : 0.3283540222747229\n",
      "iterations 3928 accuray : 0.9283763915143878  loss : 0.32833402732040134\n",
      "iterations 3929 accuray : 0.9283763915143878  loss : 0.3283142308783239\n",
      "iterations 3930 accuray : 0.9285864314219702  loss : 0.3282940193533178\n",
      "iterations 3931 accuray : 0.9285864314219702  loss : 0.328273237494697\n",
      "iterations 3932 accuray : 0.9285864314219702  loss : 0.3282534820378441\n",
      "iterations 3933 accuray : 0.9285864314219702  loss : 0.32823338795648543\n",
      "iterations 3934 accuray : 0.9285864314219702  loss : 0.32821292005921643\n",
      "iterations 3935 accuray : 0.9285864314219702  loss : 0.3281929326574659\n",
      "iterations 3936 accuray : 0.9283763915143878  loss : 0.32817203307060144\n",
      "iterations 3937 accuray : 0.9283763915143878  loss : 0.3281520626967153\n",
      "iterations 3938 accuray : 0.9283763915143878  loss : 0.32813188666315624\n",
      "iterations 3939 accuray : 0.9283763915143878  loss : 0.3281114097213938\n",
      "iterations 3940 accuray : 0.9283763915143878  loss : 0.3280911345668592\n",
      "iterations 3941 accuray : 0.9283763915143878  loss : 0.328071386148083\n",
      "iterations 3942 accuray : 0.9283763915143878  loss : 0.32805167043115047\n",
      "iterations 3943 accuray : 0.9283763915143878  loss : 0.32803145658837923\n",
      "iterations 3944 accuray : 0.9283763915143878  loss : 0.32801102749534455\n",
      "iterations 3945 accuray : 0.9283763915143878  loss : 0.32799043092074587\n",
      "iterations 3946 accuray : 0.9283763915143878  loss : 0.3279704510036631\n",
      "iterations 3947 accuray : 0.9283763915143878  loss : 0.32795091519645075\n",
      "iterations 3948 accuray : 0.9283763915143878  loss : 0.3279311809255313\n",
      "iterations 3949 accuray : 0.9283763915143878  loss : 0.3279103355484861\n",
      "iterations 3950 accuray : 0.9283763915143878  loss : 0.3278906326960125\n",
      "iterations 3951 accuray : 0.9283763915143878  loss : 0.3278706052114185\n",
      "iterations 3952 accuray : 0.9283763915143878  loss : 0.32785037996414956\n",
      "iterations 3953 accuray : 0.9283763915143878  loss : 0.32783028482529775\n",
      "iterations 3954 accuray : 0.9283763915143878  loss : 0.3278104294296434\n",
      "iterations 3955 accuray : 0.9283763915143878  loss : 0.32778983646815757\n",
      "iterations 3956 accuray : 0.9283763915143878  loss : 0.32777036418723643\n",
      "iterations 3957 accuray : 0.9283763915143878  loss : 0.32774965137810114\n",
      "iterations 3958 accuray : 0.9283763915143878  loss : 0.32772935699214834\n",
      "iterations 3959 accuray : 0.9283763915143878  loss : 0.3277091330574635\n",
      "iterations 3960 accuray : 0.9283763915143878  loss : 0.32768891428752867\n",
      "iterations 3961 accuray : 0.9283763915143878  loss : 0.32766922749002\n",
      "iterations 3962 accuray : 0.9283763915143878  loss : 0.32764949238944574\n",
      "iterations 3963 accuray : 0.9283763915143878  loss : 0.32762942827127906\n",
      "iterations 3964 accuray : 0.9283763915143878  loss : 0.3276097603852898\n",
      "iterations 3965 accuray : 0.9283763915143878  loss : 0.3275892591435228\n",
      "iterations 3966 accuray : 0.9283763915143878  loss : 0.32756973034789016\n",
      "iterations 3967 accuray : 0.9283763915143878  loss : 0.3275494358838656\n",
      "iterations 3968 accuray : 0.9283763915143878  loss : 0.3275298879772884\n",
      "iterations 3969 accuray : 0.9283763915143878  loss : 0.3275103110995287\n",
      "iterations 3970 accuray : 0.9283763915143878  loss : 0.32749053371286213\n",
      "iterations 3971 accuray : 0.9283763915143878  loss : 0.3274702807028934\n",
      "iterations 3972 accuray : 0.9283763915143878  loss : 0.3274506760220202\n",
      "iterations 3973 accuray : 0.9283763915143878  loss : 0.32743021117938986\n",
      "iterations 3974 accuray : 0.9283763915143878  loss : 0.3274105822953131\n",
      "iterations 3975 accuray : 0.9283763915143878  loss : 0.3273905197038264\n",
      "iterations 3976 accuray : 0.9283763915143878  loss : 0.32737053017686457\n",
      "iterations 3977 accuray : 0.9283763915143878  loss : 0.32735076892822806\n",
      "iterations 3978 accuray : 0.9283763915143878  loss : 0.32733101419926564\n",
      "iterations 3979 accuray : 0.9283763915143878  loss : 0.32731061548903245\n",
      "iterations 3980 accuray : 0.9283763915143878  loss : 0.3272912969369006\n",
      "iterations 3981 accuray : 0.9283763915143878  loss : 0.3272717502835635\n",
      "iterations 3982 accuray : 0.9283763915143878  loss : 0.3272517298373627\n",
      "iterations 3983 accuray : 0.9283763915143878  loss : 0.3272317233982634\n",
      "iterations 3984 accuray : 0.9283763915143878  loss : 0.3272128560234697\n",
      "iterations 3985 accuray : 0.9283763915143878  loss : 0.3271927076424401\n",
      "iterations 3986 accuray : 0.9283763915143878  loss : 0.32717310711343345\n",
      "iterations 3987 accuray : 0.9283763915143878  loss : 0.32715295345025647\n",
      "iterations 3988 accuray : 0.9283763915143878  loss : 0.3271327340375411\n",
      "iterations 3989 accuray : 0.9283763915143878  loss : 0.32711254438396653\n",
      "iterations 3990 accuray : 0.9283763915143878  loss : 0.3270918814541371\n",
      "iterations 3991 accuray : 0.9283763915143878  loss : 0.3270723988621891\n",
      "iterations 3992 accuray : 0.9283763915143878  loss : 0.3270523390273208\n",
      "iterations 3993 accuray : 0.9283763915143878  loss : 0.3270322929627955\n",
      "iterations 3994 accuray : 0.9283763915143878  loss : 0.32701242879282216\n",
      "iterations 3995 accuray : 0.9283763915143878  loss : 0.3269920718831531\n",
      "iterations 3996 accuray : 0.9283763915143878  loss : 0.326972658285982\n",
      "iterations 3997 accuray : 0.9283763915143878  loss : 0.32695301152419143\n",
      "iterations 3998 accuray : 0.9283763915143878  loss : 0.3269332331745063\n",
      "iterations 3999 accuray : 0.9283763915143878  loss : 0.32691327809373716\n",
      "iterations 4000 accuray : 0.9283763915143878  loss : 0.326893323958783\n",
      "iterations 4001 accuray : 0.9283763915143878  loss : 0.3268737596546014\n",
      "iterations 4002 accuray : 0.9283763915143878  loss : 0.3268538241857713\n",
      "iterations 4003 accuray : 0.9283763915143878  loss : 0.3268338108071549\n",
      "iterations 4004 accuray : 0.9283763915143878  loss : 0.32681425055682195\n",
      "iterations 4005 accuray : 0.9283763915143878  loss : 0.3267950756711489\n",
      "iterations 4006 accuray : 0.9283763915143878  loss : 0.326775633390763\n",
      "iterations 4007 accuray : 0.9283763915143878  loss : 0.3267557015008209\n",
      "iterations 4008 accuray : 0.9283763915143878  loss : 0.32673587810452404\n",
      "iterations 4009 accuray : 0.9283763915143878  loss : 0.32671630774362015\n",
      "iterations 4010 accuray : 0.9283763915143878  loss : 0.3266966005111818\n",
      "iterations 4011 accuray : 0.9283763915143878  loss : 0.3266772325269319\n",
      "iterations 4012 accuray : 0.9283763915143878  loss : 0.3266579070997099\n",
      "iterations 4013 accuray : 0.9283763915143878  loss : 0.3266381119294294\n",
      "iterations 4014 accuray : 0.9283763915143878  loss : 0.3266181788166785\n",
      "iterations 4015 accuray : 0.9283763915143878  loss : 0.32659796887996284\n",
      "iterations 4016 accuray : 0.9283763915143878  loss : 0.32657732001652073\n",
      "iterations 4017 accuray : 0.9283763915143878  loss : 0.32655764576715185\n",
      "iterations 4018 accuray : 0.9283763915143878  loss : 0.3265387037277514\n",
      "iterations 4019 accuray : 0.9283763915143878  loss : 0.32651965255287585\n",
      "iterations 4020 accuray : 0.9283763915143878  loss : 0.3265000005456603\n",
      "iterations 4021 accuray : 0.9283763915143878  loss : 0.3264805379734938\n",
      "iterations 4022 accuray : 0.9283763915143878  loss : 0.3264603363332713\n",
      "iterations 4023 accuray : 0.9283763915143878  loss : 0.3264403060413272\n",
      "iterations 4024 accuray : 0.9283763915143878  loss : 0.3264210160376607\n",
      "iterations 4025 accuray : 0.9283763915143878  loss : 0.326401037553186\n",
      "iterations 4026 accuray : 0.9283763915143878  loss : 0.32638175427956917\n",
      "iterations 4027 accuray : 0.9283763915143878  loss : 0.32636200255028175\n",
      "iterations 4028 accuray : 0.9283763915143878  loss : 0.32634240422177313\n",
      "iterations 4029 accuray : 0.9283763915143878  loss : 0.32632328891598683\n",
      "iterations 4030 accuray : 0.9283763915143878  loss : 0.3263031420630936\n",
      "iterations 4031 accuray : 0.9283763915143878  loss : 0.32628332339188765\n",
      "iterations 4032 accuray : 0.9283763915143878  loss : 0.32626388809376183\n",
      "iterations 4033 accuray : 0.9283763915143878  loss : 0.3262443606537972\n",
      "iterations 4034 accuray : 0.9283763915143878  loss : 0.32622469607545607\n",
      "iterations 4035 accuray : 0.9283763915143878  loss : 0.3262046548975821\n",
      "iterations 4036 accuray : 0.9283763915143878  loss : 0.3261844515813987\n",
      "iterations 4037 accuray : 0.9283763915143878  loss : 0.3261646451294795\n",
      "iterations 4038 accuray : 0.9283763915143878  loss : 0.3261444891395737\n",
      "iterations 4039 accuray : 0.9283763915143878  loss : 0.32612485670120317\n",
      "iterations 4040 accuray : 0.9283763915143878  loss : 0.3261050520561297\n",
      "iterations 4041 accuray : 0.9283763915143878  loss : 0.32608585867998013\n",
      "iterations 4042 accuray : 0.9283763915143878  loss : 0.32606590255166806\n",
      "iterations 4043 accuray : 0.9283763915143878  loss : 0.32604714383057715\n",
      "iterations 4044 accuray : 0.9283763915143878  loss : 0.3260275570570456\n",
      "iterations 4045 accuray : 0.9283763915143878  loss : 0.3260079034257399\n",
      "iterations 4046 accuray : 0.9283763915143878  loss : 0.3259883137905889\n",
      "iterations 4047 accuray : 0.9283763915143878  loss : 0.3259688957780765\n",
      "iterations 4048 accuray : 0.9281663516068053  loss : 0.32594903398213587\n",
      "iterations 4049 accuray : 0.9281663516068053  loss : 0.3259294786919866\n",
      "iterations 4050 accuray : 0.9281663516068053  loss : 0.32591025798946194\n",
      "iterations 4051 accuray : 0.9283763915143878  loss : 0.32589046474617694\n",
      "iterations 4052 accuray : 0.9283763915143878  loss : 0.32587063462168026\n",
      "iterations 4053 accuray : 0.9283763915143878  loss : 0.32585171654569\n",
      "iterations 4054 accuray : 0.9283763915143878  loss : 0.3258323466966587\n",
      "iterations 4055 accuray : 0.9281663516068053  loss : 0.3258129679027874\n",
      "iterations 4056 accuray : 0.9283763915143878  loss : 0.3257942795423261\n",
      "iterations 4057 accuray : 0.9283763915143878  loss : 0.32577533350252347\n",
      "iterations 4058 accuray : 0.9281663516068053  loss : 0.32575616572693705\n",
      "iterations 4059 accuray : 0.9283763915143878  loss : 0.3257368933968666\n",
      "iterations 4060 accuray : 0.9281663516068053  loss : 0.3257168626196757\n",
      "iterations 4061 accuray : 0.9281663516068053  loss : 0.3256978121835599\n",
      "iterations 4062 accuray : 0.9283763915143878  loss : 0.3256785996650935\n",
      "iterations 4063 accuray : 0.9281663516068053  loss : 0.32565928485281387\n",
      "iterations 4064 accuray : 0.9281663516068053  loss : 0.32564007795653455\n",
      "iterations 4065 accuray : 0.9283763915143878  loss : 0.32562013220637703\n",
      "iterations 4066 accuray : 0.9283763915143878  loss : 0.3256006989297904\n",
      "iterations 4067 accuray : 0.9283763915143878  loss : 0.3255820771174792\n",
      "iterations 4068 accuray : 0.9281663516068053  loss : 0.3255632988802601\n",
      "iterations 4069 accuray : 0.9283763915143878  loss : 0.32554425791160785\n",
      "iterations 4070 accuray : 0.9283763915143878  loss : 0.3255250914289333\n",
      "iterations 4071 accuray : 0.9283763915143878  loss : 0.3255060796259797\n",
      "iterations 4072 accuray : 0.9283763915143878  loss : 0.3254868637919333\n",
      "iterations 4073 accuray : 0.9283763915143878  loss : 0.32546761411930925\n",
      "iterations 4074 accuray : 0.9283763915143878  loss : 0.3254482112639809\n",
      "iterations 4075 accuray : 0.9283763915143878  loss : 0.3254286917285053\n",
      "iterations 4076 accuray : 0.9281663516068053  loss : 0.32540875977048783\n",
      "iterations 4077 accuray : 0.9283763915143878  loss : 0.32538925109795447\n",
      "iterations 4078 accuray : 0.9283763915143878  loss : 0.32536987941649775\n",
      "iterations 4079 accuray : 0.9283763915143878  loss : 0.3253508781171056\n",
      "iterations 4080 accuray : 0.9283763915143878  loss : 0.32533223998581495\n",
      "iterations 4081 accuray : 0.9283763915143878  loss : 0.3253133328377714\n",
      "iterations 4082 accuray : 0.9283763915143878  loss : 0.32529390949854\n",
      "iterations 4083 accuray : 0.9283763915143878  loss : 0.32527533018061683\n",
      "iterations 4084 accuray : 0.9283763915143878  loss : 0.32525686081295957\n",
      "iterations 4085 accuray : 0.9283763915143878  loss : 0.32523777720209357\n",
      "iterations 4086 accuray : 0.9283763915143878  loss : 0.32521857373769064\n",
      "iterations 4087 accuray : 0.9281663516068053  loss : 0.32519948823274436\n",
      "iterations 4088 accuray : 0.9281663516068053  loss : 0.3251796965428009\n",
      "iterations 4089 accuray : 0.9281663516068053  loss : 0.3251608045497645\n",
      "iterations 4090 accuray : 0.9281663516068053  loss : 0.3251419937336487\n",
      "iterations 4091 accuray : 0.9283763915143878  loss : 0.32512252061642394\n",
      "iterations 4092 accuray : 0.9283763915143878  loss : 0.32510382491386297\n",
      "iterations 4093 accuray : 0.9281663516068053  loss : 0.32508394213885433\n",
      "iterations 4094 accuray : 0.9283763915143878  loss : 0.32506586332817744\n",
      "iterations 4095 accuray : 0.9281663516068053  loss : 0.32504671773863\n",
      "iterations 4096 accuray : 0.9283763915143878  loss : 0.32502842145492483\n",
      "iterations 4097 accuray : 0.9281663516068053  loss : 0.32500888160394076\n",
      "iterations 4098 accuray : 0.9283763915143878  loss : 0.32499057121406316\n",
      "iterations 4099 accuray : 0.9281663516068053  loss : 0.3249710078444634\n",
      "iterations 4100 accuray : 0.9281663516068053  loss : 0.3249522589485011\n",
      "iterations 4101 accuray : 0.9281663516068053  loss : 0.3249332168136931\n",
      "iterations 4102 accuray : 0.9283763915143878  loss : 0.32491481236245773\n",
      "iterations 4103 accuray : 0.9283763915143878  loss : 0.32489664684220554\n",
      "iterations 4104 accuray : 0.9283763915143878  loss : 0.3248777798025051\n",
      "iterations 4105 accuray : 0.9283763915143878  loss : 0.32485825317157896\n",
      "iterations 4106 accuray : 0.9283763915143878  loss : 0.3248390075527809\n",
      "iterations 4107 accuray : 0.9283763915143878  loss : 0.32482040788162203\n",
      "iterations 4108 accuray : 0.9283763915143878  loss : 0.324800799995263\n",
      "iterations 4109 accuray : 0.9283763915143878  loss : 0.3247818204356713\n",
      "iterations 4110 accuray : 0.9281663516068053  loss : 0.32476207949791264\n",
      "iterations 4111 accuray : 0.9281663516068053  loss : 0.32474271168390034\n",
      "iterations 4112 accuray : 0.9283763915143878  loss : 0.32472439449443496\n",
      "iterations 4113 accuray : 0.9283763915143878  loss : 0.3247060834214889\n",
      "iterations 4114 accuray : 0.9283763915143878  loss : 0.32468728859041857\n",
      "iterations 4115 accuray : 0.9283763915143878  loss : 0.32466804275413724\n",
      "iterations 4116 accuray : 0.9281663516068053  loss : 0.3246482131626869\n",
      "iterations 4117 accuray : 0.9283763915143878  loss : 0.3246295372280833\n",
      "iterations 4118 accuray : 0.9283763915143878  loss : 0.3246109371510448\n",
      "iterations 4119 accuray : 0.9283763915143878  loss : 0.3245923208007033\n",
      "iterations 4120 accuray : 0.9283763915143878  loss : 0.3245737788306639\n",
      "iterations 4121 accuray : 0.9283763915143878  loss : 0.3245555295923575\n",
      "iterations 4122 accuray : 0.9283763915143878  loss : 0.32453569616971234\n",
      "iterations 4123 accuray : 0.9281663516068053  loss : 0.32451684488764737\n",
      "iterations 4124 accuray : 0.9281663516068053  loss : 0.3244975737629278\n",
      "iterations 4125 accuray : 0.9285864314219702  loss : 0.3244778666322152\n",
      "iterations 4126 accuray : 0.9285864314219702  loss : 0.324459019671809\n",
      "iterations 4127 accuray : 0.9285864314219702  loss : 0.32444002539385564\n",
      "iterations 4128 accuray : 0.9285864314219702  loss : 0.3244214495123171\n",
      "iterations 4129 accuray : 0.9283763915143878  loss : 0.32440241556008736\n",
      "iterations 4130 accuray : 0.9281663516068053  loss : 0.32438389236528553\n",
      "iterations 4131 accuray : 0.9281663516068053  loss : 0.3243648625146272\n",
      "iterations 4132 accuray : 0.9281663516068053  loss : 0.3243467594116737\n",
      "iterations 4133 accuray : 0.9281663516068053  loss : 0.32432823487200385\n",
      "iterations 4134 accuray : 0.9281663516068053  loss : 0.324310081470498\n",
      "iterations 4135 accuray : 0.9281663516068053  loss : 0.324291119445759\n",
      "iterations 4136 accuray : 0.9281663516068053  loss : 0.32427184310238716\n",
      "iterations 4137 accuray : 0.9285864314219702  loss : 0.32425229916866094\n",
      "iterations 4138 accuray : 0.9281663516068053  loss : 0.32423431971967387\n",
      "iterations 4139 accuray : 0.9281663516068053  loss : 0.32421552034379086\n",
      "iterations 4140 accuray : 0.9281663516068053  loss : 0.3241967334768411\n",
      "iterations 4141 accuray : 0.9285864314219702  loss : 0.32417751052032\n",
      "iterations 4142 accuray : 0.9285864314219702  loss : 0.3241575747733059\n",
      "iterations 4143 accuray : 0.9285864314219702  loss : 0.3241386485951837\n",
      "iterations 4144 accuray : 0.9281663516068053  loss : 0.3241204150342367\n",
      "iterations 4145 accuray : 0.9285864314219702  loss : 0.324101225743921\n",
      "iterations 4146 accuray : 0.9285864314219702  loss : 0.324082430533503\n",
      "iterations 4147 accuray : 0.9281663516068053  loss : 0.32406393673769013\n",
      "iterations 4148 accuray : 0.9285864314219702  loss : 0.3240449217048243\n",
      "iterations 4149 accuray : 0.9285864314219702  loss : 0.324027005147504\n",
      "iterations 4150 accuray : 0.9285864314219702  loss : 0.32400859840534924\n",
      "iterations 4151 accuray : 0.9281663516068053  loss : 0.3239897470565225\n",
      "iterations 4152 accuray : 0.9281663516068053  loss : 0.32397139572265965\n",
      "iterations 4153 accuray : 0.9281663516068053  loss : 0.3239523414196597\n",
      "iterations 4154 accuray : 0.9281663516068053  loss : 0.32393382775964963\n",
      "iterations 4155 accuray : 0.9281663516068053  loss : 0.3239153023046066\n",
      "iterations 4156 accuray : 0.9281663516068053  loss : 0.32389660841070134\n",
      "iterations 4157 accuray : 0.9281663516068053  loss : 0.3238776281296397\n",
      "iterations 4158 accuray : 0.9281663516068053  loss : 0.32385914861415743\n",
      "iterations 4159 accuray : 0.9281663516068053  loss : 0.32384049638973006\n",
      "iterations 4160 accuray : 0.9281663516068053  loss : 0.3238217299155963\n",
      "iterations 4161 accuray : 0.9281663516068053  loss : 0.3238029834930364\n",
      "iterations 4162 accuray : 0.9281663516068053  loss : 0.3237844705976844\n",
      "iterations 4163 accuray : 0.9281663516068053  loss : 0.3237662169142957\n",
      "iterations 4164 accuray : 0.9281663516068053  loss : 0.3237474742830475\n",
      "iterations 4165 accuray : 0.9281663516068053  loss : 0.32372884823450204\n",
      "iterations 4166 accuray : 0.9285864314219702  loss : 0.32371014294439393\n",
      "iterations 4167 accuray : 0.9285864314219702  loss : 0.3236906297549228\n",
      "iterations 4168 accuray : 0.9285864314219702  loss : 0.3236715732623631\n",
      "iterations 4169 accuray : 0.9285864314219702  loss : 0.32365226686740795\n",
      "iterations 4170 accuray : 0.9287964713295526  loss : 0.3236325433310908\n",
      "iterations 4171 accuray : 0.9285864314219702  loss : 0.3236138291427612\n",
      "iterations 4172 accuray : 0.9285864314219702  loss : 0.3235951647449956\n",
      "iterations 4173 accuray : 0.9285864314219702  loss : 0.3235762686525227\n",
      "iterations 4174 accuray : 0.9287964713295526  loss : 0.32355763627523415\n",
      "iterations 4175 accuray : 0.9287964713295526  loss : 0.32353881887522323\n",
      "iterations 4176 accuray : 0.9287964713295526  loss : 0.3235195566361056\n",
      "iterations 4177 accuray : 0.9287964713295526  loss : 0.32350054496180475\n",
      "iterations 4178 accuray : 0.9287964713295526  loss : 0.32348262109462494\n",
      "iterations 4179 accuray : 0.9287964713295526  loss : 0.3234638364228875\n",
      "iterations 4180 accuray : 0.9287964713295526  loss : 0.3234451711248632\n",
      "iterations 4181 accuray : 0.9287964713295526  loss : 0.3234264770347655\n",
      "iterations 4182 accuray : 0.9285864314219702  loss : 0.323407883650982\n",
      "iterations 4183 accuray : 0.9287964713295526  loss : 0.3233897550231957\n",
      "iterations 4184 accuray : 0.9285864314219702  loss : 0.32337145024118363\n",
      "iterations 4185 accuray : 0.9287964713295526  loss : 0.3233535844733057\n",
      "iterations 4186 accuray : 0.9287964713295526  loss : 0.3233351545692126\n",
      "iterations 4187 accuray : 0.9285864314219702  loss : 0.3233164304972808\n",
      "iterations 4188 accuray : 0.9285864314219702  loss : 0.32329770018462095\n",
      "iterations 4189 accuray : 0.9285864314219702  loss : 0.32327925434764804\n",
      "iterations 4190 accuray : 0.9285864314219702  loss : 0.32326056634448047\n",
      "iterations 4191 accuray : 0.9285864314219702  loss : 0.32324111996054233\n",
      "iterations 4192 accuray : 0.9285864314219702  loss : 0.32322314905554583\n",
      "iterations 4193 accuray : 0.9285864314219702  loss : 0.3232040590415031\n",
      "iterations 4194 accuray : 0.9285864314219702  loss : 0.3231853629029473\n",
      "iterations 4195 accuray : 0.9285864314219702  loss : 0.3231672222469501\n",
      "iterations 4196 accuray : 0.9285864314219702  loss : 0.323149231378612\n",
      "iterations 4197 accuray : 0.9285864314219702  loss : 0.32313056823317343\n",
      "iterations 4198 accuray : 0.9285864314219702  loss : 0.32311207214253646\n",
      "iterations 4199 accuray : 0.9285864314219702  loss : 0.3230934047787821\n",
      "iterations 4200 accuray : 0.9285864314219702  loss : 0.32307500665649064\n",
      "iterations 4201 accuray : 0.9285864314219702  loss : 0.3230563353804669\n",
      "iterations 4202 accuray : 0.9285864314219702  loss : 0.32303756878406664\n",
      "iterations 4203 accuray : 0.9287964713295526  loss : 0.32301826124613603\n",
      "iterations 4204 accuray : 0.9287964713295526  loss : 0.322999344406568\n",
      "iterations 4205 accuray : 0.9287964713295526  loss : 0.32298054903597484\n",
      "iterations 4206 accuray : 0.9287964713295526  loss : 0.32296183697642356\n",
      "iterations 4207 accuray : 0.9287964713295526  loss : 0.32294414057688875\n",
      "iterations 4208 accuray : 0.9287964713295526  loss : 0.3229260832826634\n",
      "iterations 4209 accuray : 0.9287964713295526  loss : 0.3229081633529127\n",
      "iterations 4210 accuray : 0.9287964713295526  loss : 0.3228893882637859\n",
      "iterations 4211 accuray : 0.9287964713295526  loss : 0.32287077613416904\n",
      "iterations 4212 accuray : 0.9287964713295526  loss : 0.32285210826624366\n",
      "iterations 4213 accuray : 0.9287964713295526  loss : 0.32283411853038574\n",
      "iterations 4214 accuray : 0.9287964713295526  loss : 0.3228162803858893\n",
      "iterations 4215 accuray : 0.9287964713295526  loss : 0.32279840302301727\n",
      "iterations 4216 accuray : 0.9287964713295526  loss : 0.3227801402564232\n",
      "iterations 4217 accuray : 0.9287964713295526  loss : 0.322762282094868\n",
      "iterations 4218 accuray : 0.9287964713295526  loss : 0.3227441093403214\n",
      "iterations 4219 accuray : 0.9287964713295526  loss : 0.3227255220385704\n",
      "iterations 4220 accuray : 0.9287964713295526  loss : 0.3227067999807274\n",
      "iterations 4221 accuray : 0.9285864314219702  loss : 0.32268866279135455\n",
      "iterations 4222 accuray : 0.9287964713295526  loss : 0.32267030556398785\n",
      "iterations 4223 accuray : 0.9285864314219702  loss : 0.32265266353367217\n",
      "iterations 4224 accuray : 0.9285864314219702  loss : 0.3226344573464132\n",
      "iterations 4225 accuray : 0.9285864314219702  loss : 0.3226160247534087\n",
      "iterations 4226 accuray : 0.9285864314219702  loss : 0.32259805953964915\n",
      "iterations 4227 accuray : 0.9285864314219702  loss : 0.3225797372477206\n",
      "iterations 4228 accuray : 0.9285864314219702  loss : 0.32256190031431325\n",
      "iterations 4229 accuray : 0.9287964713295526  loss : 0.32254282063738027\n",
      "iterations 4230 accuray : 0.9287964713295526  loss : 0.3225241240783712\n",
      "iterations 4231 accuray : 0.9287964713295526  loss : 0.322506172451439\n",
      "iterations 4232 accuray : 0.9287964713295526  loss : 0.3224874593836105\n",
      "iterations 4233 accuray : 0.9287964713295526  loss : 0.3224689024776811\n",
      "iterations 4234 accuray : 0.9287964713295526  loss : 0.32245106742538615\n",
      "iterations 4235 accuray : 0.9285864314219702  loss : 0.32243313745513175\n",
      "iterations 4236 accuray : 0.9287964713295526  loss : 0.32241456514032485\n",
      "iterations 4237 accuray : 0.9287964713295526  loss : 0.3223955182467655\n",
      "iterations 4238 accuray : 0.9287964713295526  loss : 0.3223774184842659\n",
      "iterations 4239 accuray : 0.9287964713295526  loss : 0.32235834291771137\n",
      "iterations 4240 accuray : 0.9287964713295526  loss : 0.32234015678328376\n",
      "iterations 4241 accuray : 0.9287964713295526  loss : 0.3223215476054973\n",
      "iterations 4242 accuray : 0.9287964713295526  loss : 0.3223033433255149\n",
      "iterations 4243 accuray : 0.9287964713295526  loss : 0.32228490903143386\n",
      "iterations 4244 accuray : 0.9287964713295526  loss : 0.32226625655886537\n",
      "iterations 4245 accuray : 0.9287964713295526  loss : 0.32224819536141575\n",
      "iterations 4246 accuray : 0.9287964713295526  loss : 0.3222299040017276\n",
      "iterations 4247 accuray : 0.9287964713295526  loss : 0.3222123594187118\n",
      "iterations 4248 accuray : 0.9287964713295526  loss : 0.32219382623950626\n",
      "iterations 4249 accuray : 0.9287964713295526  loss : 0.3221750229426638\n",
      "iterations 4250 accuray : 0.9287964713295526  loss : 0.32215689776853806\n",
      "iterations 4251 accuray : 0.9287964713295526  loss : 0.3221390297886066\n",
      "iterations 4252 accuray : 0.9287964713295526  loss : 0.3221208266737609\n",
      "iterations 4253 accuray : 0.9287964713295526  loss : 0.32210243850831816\n",
      "iterations 4254 accuray : 0.9287964713295526  loss : 0.3220837153297499\n",
      "iterations 4255 accuray : 0.9287964713295526  loss : 0.32206599769050887\n",
      "iterations 4256 accuray : 0.9287964713295526  loss : 0.32204682660643463\n",
      "iterations 4257 accuray : 0.9287964713295526  loss : 0.3220286453407694\n",
      "iterations 4258 accuray : 0.9287964713295526  loss : 0.32201064435072213\n",
      "iterations 4259 accuray : 0.9287964713295526  loss : 0.3219914983733108\n",
      "iterations 4260 accuray : 0.9287964713295526  loss : 0.3219732733856097\n",
      "iterations 4261 accuray : 0.9287964713295526  loss : 0.32195534152720934\n",
      "iterations 4262 accuray : 0.9287964713295526  loss : 0.3219374999063908\n",
      "iterations 4263 accuray : 0.9287964713295526  loss : 0.3219197874883835\n",
      "iterations 4264 accuray : 0.9287964713295526  loss : 0.32190201572446847\n",
      "iterations 4265 accuray : 0.9287964713295526  loss : 0.3218829844675146\n",
      "iterations 4266 accuray : 0.9287964713295526  loss : 0.3218642137830772\n",
      "iterations 4267 accuray : 0.9287964713295526  loss : 0.3218462976570588\n",
      "iterations 4268 accuray : 0.9287964713295526  loss : 0.32182832443609377\n",
      "iterations 4269 accuray : 0.9287964713295526  loss : 0.3218101836415474\n",
      "iterations 4270 accuray : 0.9287964713295526  loss : 0.3217921845833899\n",
      "iterations 4271 accuray : 0.9287964713295526  loss : 0.3217742067005415\n",
      "iterations 4272 accuray : 0.9287964713295526  loss : 0.3217556355727048\n",
      "iterations 4273 accuray : 0.9290065112371351  loss : 0.32173716914465156\n",
      "iterations 4274 accuray : 0.9290065112371351  loss : 0.32171799058512046\n",
      "iterations 4275 accuray : 0.9292165511447175  loss : 0.3216995679851072\n",
      "iterations 4276 accuray : 0.9292165511447175  loss : 0.3216812659972952\n",
      "iterations 4277 accuray : 0.9292165511447175  loss : 0.3216629522943143\n",
      "iterations 4278 accuray : 0.9292165511447175  loss : 0.3216449922915012\n",
      "iterations 4279 accuray : 0.9294265910523  loss : 0.32162644723229517\n",
      "iterations 4280 accuray : 0.9292165511447175  loss : 0.3216089433575829\n",
      "iterations 4281 accuray : 0.9292165511447175  loss : 0.32159145670194217\n",
      "iterations 4282 accuray : 0.9292165511447175  loss : 0.32157322069829447\n",
      "iterations 4283 accuray : 0.9292165511447175  loss : 0.32155475006418527\n",
      "iterations 4284 accuray : 0.9294265910523  loss : 0.3215368622804193\n",
      "iterations 4285 accuray : 0.9292165511447175  loss : 0.32151917090045223\n",
      "iterations 4286 accuray : 0.9294265910523  loss : 0.3215007318315114\n",
      "iterations 4287 accuray : 0.9294265910523  loss : 0.3214831390090532\n",
      "iterations 4288 accuray : 0.9294265910523  loss : 0.3214648651397594\n",
      "iterations 4289 accuray : 0.9294265910523  loss : 0.32144677244503356\n",
      "iterations 4290 accuray : 0.9292165511447175  loss : 0.32142928680262445\n",
      "iterations 4291 accuray : 0.9292165511447175  loss : 0.32141126964161204\n",
      "iterations 4292 accuray : 0.9294265910523  loss : 0.3213924472817351\n",
      "iterations 4293 accuray : 0.9294265910523  loss : 0.3213744273028322\n",
      "iterations 4294 accuray : 0.9294265910523  loss : 0.32135675261903285\n",
      "iterations 4295 accuray : 0.9294265910523  loss : 0.3213398111516401\n",
      "iterations 4296 accuray : 0.9294265910523  loss : 0.32132109241380097\n",
      "iterations 4297 accuray : 0.9294265910523  loss : 0.321302724817567\n",
      "iterations 4298 accuray : 0.9294265910523  loss : 0.32128496292787484\n",
      "iterations 4299 accuray : 0.9294265910523  loss : 0.32126741467024894\n",
      "iterations 4300 accuray : 0.9294265910523  loss : 0.3212495495864413\n",
      "iterations 4301 accuray : 0.9294265910523  loss : 0.3212319262584271\n",
      "iterations 4302 accuray : 0.9294265910523  loss : 0.3212139909650541\n",
      "iterations 4303 accuray : 0.9294265910523  loss : 0.32119598321879017\n",
      "iterations 4304 accuray : 0.9294265910523  loss : 0.32117813046473065\n",
      "iterations 4305 accuray : 0.9294265910523  loss : 0.3211600516854511\n",
      "iterations 4306 accuray : 0.9294265910523  loss : 0.32114228614352336\n",
      "iterations 4307 accuray : 0.9294265910523  loss : 0.3211235013984101\n",
      "iterations 4308 accuray : 0.9294265910523  loss : 0.3211049851140002\n",
      "iterations 4309 accuray : 0.9294265910523  loss : 0.3210873809393534\n",
      "iterations 4310 accuray : 0.9294265910523  loss : 0.3210690635222174\n",
      "iterations 4311 accuray : 0.9294265910523  loss : 0.32105105952292523\n",
      "iterations 4312 accuray : 0.9294265910523  loss : 0.3210335829944514\n",
      "iterations 4313 accuray : 0.9294265910523  loss : 0.32101506204927305\n",
      "iterations 4314 accuray : 0.9294265910523  loss : 0.3209974163676055\n",
      "iterations 4315 accuray : 0.9294265910523  loss : 0.3209791144162612\n",
      "iterations 4316 accuray : 0.9294265910523  loss : 0.3209608777363975\n",
      "iterations 4317 accuray : 0.9294265910523  loss : 0.3209433873671105\n",
      "iterations 4318 accuray : 0.9294265910523  loss : 0.3209248238413947\n",
      "iterations 4319 accuray : 0.9294265910523  loss : 0.32090653518640505\n",
      "iterations 4320 accuray : 0.9294265910523  loss : 0.3208889639165665\n",
      "iterations 4321 accuray : 0.9292165511447175  loss : 0.3208701195598653\n",
      "iterations 4322 accuray : 0.9292165511447175  loss : 0.32085177605802734\n",
      "iterations 4323 accuray : 0.9292165511447175  loss : 0.32083398306012767\n",
      "iterations 4324 accuray : 0.9292165511447175  loss : 0.32081632583503017\n",
      "iterations 4325 accuray : 0.9292165511447175  loss : 0.3207982095318384\n",
      "iterations 4326 accuray : 0.9292165511447175  loss : 0.3207804665949877\n",
      "iterations 4327 accuray : 0.9292165511447175  loss : 0.32076252823324297\n",
      "iterations 4328 accuray : 0.9292165511447175  loss : 0.32074488180838007\n",
      "iterations 4329 accuray : 0.9292165511447175  loss : 0.3207273938123969\n",
      "iterations 4330 accuray : 0.9292165511447175  loss : 0.32070896419503925\n",
      "iterations 4331 accuray : 0.9292165511447175  loss : 0.3206918080337658\n",
      "iterations 4332 accuray : 0.9292165511447175  loss : 0.3206746325015902\n",
      "iterations 4333 accuray : 0.9292165511447175  loss : 0.3206565859579642\n",
      "iterations 4334 accuray : 0.9292165511447175  loss : 0.3206383020252302\n",
      "iterations 4335 accuray : 0.9292165511447175  loss : 0.32062077577344267\n",
      "iterations 4336 accuray : 0.9292165511447175  loss : 0.320602591329769\n",
      "iterations 4337 accuray : 0.9292165511447175  loss : 0.32058512070684086\n",
      "iterations 4338 accuray : 0.9292165511447175  loss : 0.32056817846136254\n",
      "iterations 4339 accuray : 0.9292165511447175  loss : 0.32055029665979845\n",
      "iterations 4340 accuray : 0.9292165511447175  loss : 0.32053213080147797\n",
      "iterations 4341 accuray : 0.9292165511447175  loss : 0.32051419191450586\n",
      "iterations 4342 accuray : 0.9292165511447175  loss : 0.32049663582470517\n",
      "iterations 4343 accuray : 0.9292165511447175  loss : 0.32047908045937856\n",
      "iterations 4344 accuray : 0.9292165511447175  loss : 0.3204605856492101\n",
      "iterations 4345 accuray : 0.9292165511447175  loss : 0.3204425746810323\n",
      "iterations 4346 accuray : 0.9292165511447175  loss : 0.3204244507158166\n",
      "iterations 4347 accuray : 0.9290065112371351  loss : 0.3204065588186672\n",
      "iterations 4348 accuray : 0.9290065112371351  loss : 0.32038830008919106\n",
      "iterations 4349 accuray : 0.9290065112371351  loss : 0.32037060837239684\n",
      "iterations 4350 accuray : 0.9290065112371351  loss : 0.32035363644909265\n",
      "iterations 4351 accuray : 0.9290065112371351  loss : 0.320335688277996\n",
      "iterations 4352 accuray : 0.9290065112371351  loss : 0.3203177487956974\n",
      "iterations 4353 accuray : 0.9290065112371351  loss : 0.32029934748485406\n",
      "iterations 4354 accuray : 0.9290065112371351  loss : 0.32028173419777406\n",
      "iterations 4355 accuray : 0.9290065112371351  loss : 0.3202640900532054\n",
      "iterations 4356 accuray : 0.9290065112371351  loss : 0.3202468251292858\n",
      "iterations 4357 accuray : 0.9290065112371351  loss : 0.3202287043992112\n",
      "iterations 4358 accuray : 0.9290065112371351  loss : 0.3202105066019229\n",
      "iterations 4359 accuray : 0.9290065112371351  loss : 0.3201935498309343\n",
      "iterations 4360 accuray : 0.9290065112371351  loss : 0.3201755572681892\n",
      "iterations 4361 accuray : 0.9290065112371351  loss : 0.3201579280241969\n",
      "iterations 4362 accuray : 0.9290065112371351  loss : 0.32014014675329944\n",
      "iterations 4363 accuray : 0.9290065112371351  loss : 0.32012288559474417\n",
      "iterations 4364 accuray : 0.9290065112371351  loss : 0.32010456583700453\n",
      "iterations 4365 accuray : 0.9290065112371351  loss : 0.32008736003409777\n",
      "iterations 4366 accuray : 0.9290065112371351  loss : 0.32006998320574664\n",
      "iterations 4367 accuray : 0.9290065112371351  loss : 0.3200528089164737\n",
      "iterations 4368 accuray : 0.9290065112371351  loss : 0.32003570369833073\n",
      "iterations 4369 accuray : 0.9290065112371351  loss : 0.3200178085643261\n",
      "iterations 4370 accuray : 0.9290065112371351  loss : 0.3200005108823624\n",
      "iterations 4371 accuray : 0.9290065112371351  loss : 0.3199830493103095\n",
      "iterations 4372 accuray : 0.9290065112371351  loss : 0.31996581933176077\n",
      "iterations 4373 accuray : 0.9290065112371351  loss : 0.31994842327178563\n",
      "iterations 4374 accuray : 0.9290065112371351  loss : 0.3199311656426061\n",
      "iterations 4375 accuray : 0.9290065112371351  loss : 0.3199133050073373\n",
      "iterations 4376 accuray : 0.9290065112371351  loss : 0.3198961367792463\n",
      "iterations 4377 accuray : 0.9290065112371351  loss : 0.3198793837768024\n",
      "iterations 4378 accuray : 0.9290065112371351  loss : 0.3198621434816347\n",
      "iterations 4379 accuray : 0.9290065112371351  loss : 0.3198438530463645\n",
      "iterations 4380 accuray : 0.9290065112371351  loss : 0.3198257033703053\n",
      "iterations 4381 accuray : 0.9290065112371351  loss : 0.319807844293602\n",
      "iterations 4382 accuray : 0.9290065112371351  loss : 0.3197901488724343\n",
      "iterations 4383 accuray : 0.9290065112371351  loss : 0.3197723432604028\n",
      "iterations 4384 accuray : 0.9290065112371351  loss : 0.3197544760728208\n",
      "iterations 4385 accuray : 0.9290065112371351  loss : 0.31973757996443614\n",
      "iterations 4386 accuray : 0.9290065112371351  loss : 0.3197200627432163\n",
      "iterations 4387 accuray : 0.9290065112371351  loss : 0.31970236290605514\n",
      "iterations 4388 accuray : 0.9290065112371351  loss : 0.3196848000941294\n",
      "iterations 4389 accuray : 0.9287964713295526  loss : 0.31966684469761253\n",
      "iterations 4390 accuray : 0.9287964713295526  loss : 0.319649227754159\n",
      "iterations 4391 accuray : 0.9287964713295526  loss : 0.3196316294164949\n",
      "iterations 4392 accuray : 0.9287964713295526  loss : 0.319614373145502\n",
      "iterations 4393 accuray : 0.9287964713295526  loss : 0.3195968236595294\n",
      "iterations 4394 accuray : 0.9287964713295526  loss : 0.31957997962321966\n",
      "iterations 4395 accuray : 0.9287964713295526  loss : 0.31956277187961857\n",
      "iterations 4396 accuray : 0.9287964713295526  loss : 0.31954550853809127\n",
      "iterations 4397 accuray : 0.9287964713295526  loss : 0.3195283239093978\n",
      "iterations 4398 accuray : 0.9287964713295526  loss : 0.31951061438400435\n",
      "iterations 4399 accuray : 0.9287964713295526  loss : 0.3194935714249717\n",
      "iterations 4400 accuray : 0.9287964713295526  loss : 0.31947604559053344\n",
      "iterations 4401 accuray : 0.9287964713295526  loss : 0.3194582521751766\n",
      "iterations 4402 accuray : 0.9287964713295526  loss : 0.3194408573919231\n",
      "iterations 4403 accuray : 0.9287964713295526  loss : 0.31942397151463575\n",
      "iterations 4404 accuray : 0.9287964713295526  loss : 0.3194063768674643\n",
      "iterations 4405 accuray : 0.9287964713295526  loss : 0.3193888742784636\n",
      "iterations 4406 accuray : 0.9287964713295526  loss : 0.31937164276419505\n",
      "iterations 4407 accuray : 0.9287964713295526  loss : 0.3193543640095901\n",
      "iterations 4408 accuray : 0.9287964713295526  loss : 0.31933675547866447\n",
      "iterations 4409 accuray : 0.9287964713295526  loss : 0.31931921513727185\n",
      "iterations 4410 accuray : 0.9287964713295526  loss : 0.3193025193968035\n",
      "iterations 4411 accuray : 0.9287964713295526  loss : 0.31928500457427916\n",
      "iterations 4412 accuray : 0.9287964713295526  loss : 0.31926774624078363\n",
      "iterations 4413 accuray : 0.9287964713295526  loss : 0.3192505286698738\n",
      "iterations 4414 accuray : 0.9287964713295526  loss : 0.31923302618507005\n",
      "iterations 4415 accuray : 0.9287964713295526  loss : 0.3192158825089425\n",
      "iterations 4416 accuray : 0.9287964713295526  loss : 0.31919863277882204\n",
      "iterations 4417 accuray : 0.9287964713295526  loss : 0.31918124125232855\n",
      "iterations 4418 accuray : 0.9287964713295526  loss : 0.31916343756783383\n",
      "iterations 4419 accuray : 0.9287964713295526  loss : 0.3191458927148556\n",
      "iterations 4420 accuray : 0.9287964713295526  loss : 0.31912880272363825\n",
      "iterations 4421 accuray : 0.9287964713295526  loss : 0.31911188321647826\n",
      "iterations 4422 accuray : 0.9287964713295526  loss : 0.31909391821923205\n",
      "iterations 4423 accuray : 0.9287964713295526  loss : 0.3190767303698139\n",
      "iterations 4424 accuray : 0.9287964713295526  loss : 0.31905978014153336\n",
      "iterations 4425 accuray : 0.9287964713295526  loss : 0.31904325471483236\n",
      "iterations 4426 accuray : 0.9287964713295526  loss : 0.3190267823631208\n",
      "iterations 4427 accuray : 0.9287964713295526  loss : 0.3190083714432482\n",
      "iterations 4428 accuray : 0.9287964713295526  loss : 0.31899071762260284\n",
      "iterations 4429 accuray : 0.9287964713295526  loss : 0.3189731747853437\n",
      "iterations 4430 accuray : 0.9287964713295526  loss : 0.3189560268846201\n",
      "iterations 4431 accuray : 0.9287964713295526  loss : 0.31893895843662623\n",
      "iterations 4432 accuray : 0.9287964713295526  loss : 0.31892112693906294\n",
      "iterations 4433 accuray : 0.9287964713295526  loss : 0.3189034936372803\n",
      "iterations 4434 accuray : 0.9287964713295526  loss : 0.3188857326035327\n",
      "iterations 4435 accuray : 0.9287964713295526  loss : 0.31886940125141555\n",
      "iterations 4436 accuray : 0.9287964713295526  loss : 0.31885185386815273\n",
      "iterations 4437 accuray : 0.9287964713295526  loss : 0.31883507319951165\n",
      "iterations 4438 accuray : 0.9287964713295526  loss : 0.31881856884410514\n",
      "iterations 4439 accuray : 0.9287964713295526  loss : 0.3188017588404681\n",
      "iterations 4440 accuray : 0.9287964713295526  loss : 0.318785180810152\n",
      "iterations 4441 accuray : 0.9287964713295526  loss : 0.31876817702802995\n",
      "iterations 4442 accuray : 0.9287964713295526  loss : 0.31875085260323405\n",
      "iterations 4443 accuray : 0.9287964713295526  loss : 0.318733576764113\n",
      "iterations 4444 accuray : 0.9287964713295526  loss : 0.31871685660461613\n",
      "iterations 4445 accuray : 0.9287964713295526  loss : 0.31869913722554233\n",
      "iterations 4446 accuray : 0.9287964713295526  loss : 0.3186819292515244\n",
      "iterations 4447 accuray : 0.9287964713295526  loss : 0.318664966768272\n",
      "iterations 4448 accuray : 0.9287964713295526  loss : 0.31864782051884255\n",
      "iterations 4449 accuray : 0.9287964713295526  loss : 0.318631341383035\n",
      "iterations 4450 accuray : 0.9287964713295526  loss : 0.318614447499937\n",
      "iterations 4451 accuray : 0.9287964713295526  loss : 0.31859702828787984\n",
      "iterations 4452 accuray : 0.9287964713295526  loss : 0.3185802698235569\n",
      "iterations 4453 accuray : 0.9287964713295526  loss : 0.3185632040501469\n",
      "iterations 4454 accuray : 0.9287964713295526  loss : 0.31854663235672903\n",
      "iterations 4455 accuray : 0.9287964713295526  loss : 0.31852912579194687\n",
      "iterations 4456 accuray : 0.9287964713295526  loss : 0.318511964837237\n",
      "iterations 4457 accuray : 0.9287964713295526  loss : 0.3184947633411633\n",
      "iterations 4458 accuray : 0.9287964713295526  loss : 0.31847790865047165\n",
      "iterations 4459 accuray : 0.9287964713295526  loss : 0.3184604677726477\n",
      "iterations 4460 accuray : 0.9287964713295526  loss : 0.318442803120979\n",
      "iterations 4461 accuray : 0.9287964713295526  loss : 0.3184258581559511\n",
      "iterations 4462 accuray : 0.9287964713295526  loss : 0.3184079400076993\n",
      "iterations 4463 accuray : 0.9287964713295526  loss : 0.3183911039805815\n",
      "iterations 4464 accuray : 0.9287964713295526  loss : 0.3183741506334906\n",
      "iterations 4465 accuray : 0.9290065112371351  loss : 0.3183565006909838\n",
      "iterations 4466 accuray : 0.9290065112371351  loss : 0.31833897998902466\n",
      "iterations 4467 accuray : 0.9287964713295526  loss : 0.3183227084489619\n",
      "iterations 4468 accuray : 0.9287964713295526  loss : 0.3183052254207544\n",
      "iterations 4469 accuray : 0.9290065112371351  loss : 0.31828784800110305\n",
      "iterations 4470 accuray : 0.9290065112371351  loss : 0.3182711538688553\n",
      "iterations 4471 accuray : 0.9290065112371351  loss : 0.31825364060469014\n",
      "iterations 4472 accuray : 0.9290065112371351  loss : 0.3182366094800534\n",
      "iterations 4473 accuray : 0.9290065112371351  loss : 0.3182199221042804\n",
      "iterations 4474 accuray : 0.9290065112371351  loss : 0.31820301954759384\n",
      "iterations 4475 accuray : 0.9290065112371351  loss : 0.318186629216931\n",
      "iterations 4476 accuray : 0.9290065112371351  loss : 0.31816928822485824\n",
      "iterations 4477 accuray : 0.9290065112371351  loss : 0.3181516586097735\n",
      "iterations 4478 accuray : 0.9290065112371351  loss : 0.3181344759280691\n",
      "iterations 4479 accuray : 0.9290065112371351  loss : 0.3181174800765747\n",
      "iterations 4480 accuray : 0.9287964713295526  loss : 0.3180994594583257\n",
      "iterations 4481 accuray : 0.9285864314219702  loss : 0.3180821840665991\n",
      "iterations 4482 accuray : 0.9285864314219702  loss : 0.3180647837182104\n",
      "iterations 4483 accuray : 0.9285864314219702  loss : 0.3180477397916759\n",
      "iterations 4484 accuray : 0.9285864314219702  loss : 0.3180307596456568\n",
      "iterations 4485 accuray : 0.9285864314219702  loss : 0.3180135364576969\n",
      "iterations 4486 accuray : 0.9285864314219702  loss : 0.31799628578132355\n",
      "iterations 4487 accuray : 0.9285864314219702  loss : 0.31797853304035484\n",
      "iterations 4488 accuray : 0.9285864314219702  loss : 0.31796190586441836\n",
      "iterations 4489 accuray : 0.9285864314219702  loss : 0.317945344302485\n",
      "iterations 4490 accuray : 0.9285864314219702  loss : 0.3179284188907256\n",
      "iterations 4491 accuray : 0.9285864314219702  loss : 0.31791130293377895\n",
      "iterations 4492 accuray : 0.9285864314219702  loss : 0.31789473652503636\n",
      "iterations 4493 accuray : 0.9285864314219702  loss : 0.31787770527750747\n",
      "iterations 4494 accuray : 0.9285864314219702  loss : 0.3178606150513401\n",
      "iterations 4495 accuray : 0.9285864314219702  loss : 0.3178436281926357\n",
      "iterations 4496 accuray : 0.9285864314219702  loss : 0.3178269675503226\n",
      "iterations 4497 accuray : 0.9285864314219702  loss : 0.3178102191956421\n",
      "iterations 4498 accuray : 0.9285864314219702  loss : 0.3177935373766228\n",
      "iterations 4499 accuray : 0.9285864314219702  loss : 0.31777724474276253\n",
      "iterations 4500 accuray : 0.9285864314219702  loss : 0.3177603688893463\n",
      "iterations 4501 accuray : 0.9285864314219702  loss : 0.3177436883618247\n",
      "iterations 4502 accuray : 0.9287964713295526  loss : 0.3177276077325168\n",
      "iterations 4503 accuray : 0.9285864314219702  loss : 0.31771031707064\n",
      "iterations 4504 accuray : 0.9285864314219702  loss : 0.3176937568375133\n",
      "iterations 4505 accuray : 0.9285864314219702  loss : 0.3176767077456222\n",
      "iterations 4506 accuray : 0.9285864314219702  loss : 0.3176600329694265\n",
      "iterations 4507 accuray : 0.9285864314219702  loss : 0.31764353795642747\n",
      "iterations 4508 accuray : 0.9287964713295526  loss : 0.3176269164127096\n",
      "iterations 4509 accuray : 0.9285864314219702  loss : 0.31760964970898137\n",
      "iterations 4510 accuray : 0.9285864314219702  loss : 0.31759254682026195\n",
      "iterations 4511 accuray : 0.9285864314219702  loss : 0.3175757179111933\n",
      "iterations 4512 accuray : 0.9285864314219702  loss : 0.31755811744787255\n",
      "iterations 4513 accuray : 0.9285864314219702  loss : 0.317540803466306\n",
      "iterations 4514 accuray : 0.9283763915143878  loss : 0.31752413097094406\n",
      "iterations 4515 accuray : 0.9283763915143878  loss : 0.31750675456855976\n",
      "iterations 4516 accuray : 0.9283763915143878  loss : 0.3174905233012224\n",
      "iterations 4517 accuray : 0.9283763915143878  loss : 0.31747304488896566\n",
      "iterations 4518 accuray : 0.9283763915143878  loss : 0.31745614298867425\n",
      "iterations 4519 accuray : 0.9283763915143878  loss : 0.3174395293656887\n",
      "iterations 4520 accuray : 0.9283763915143878  loss : 0.31742231713868335\n",
      "iterations 4521 accuray : 0.9283763915143878  loss : 0.3174061450575833\n",
      "iterations 4522 accuray : 0.9283763915143878  loss : 0.3173897067789723\n",
      "iterations 4523 accuray : 0.9283763915143878  loss : 0.3173727176034037\n",
      "iterations 4524 accuray : 0.9283763915143878  loss : 0.31735601509313066\n",
      "iterations 4525 accuray : 0.9283763915143878  loss : 0.3173396826906809\n",
      "iterations 4526 accuray : 0.9283763915143878  loss : 0.3173235115670855\n",
      "iterations 4527 accuray : 0.9283763915143878  loss : 0.3173065581019095\n",
      "iterations 4528 accuray : 0.9283763915143878  loss : 0.31728983229293717\n",
      "iterations 4529 accuray : 0.9283763915143878  loss : 0.3172730498595197\n",
      "iterations 4530 accuray : 0.9283763915143878  loss : 0.3172563846654291\n",
      "iterations 4531 accuray : 0.9283763915143878  loss : 0.3172395233928546\n",
      "iterations 4532 accuray : 0.9283763915143878  loss : 0.3172229529196587\n",
      "iterations 4533 accuray : 0.9283763915143878  loss : 0.31720601694953066\n",
      "iterations 4534 accuray : 0.9283763915143878  loss : 0.31718980588864737\n",
      "iterations 4535 accuray : 0.9283763915143878  loss : 0.31717257303551216\n",
      "iterations 4536 accuray : 0.9283763915143878  loss : 0.3171557561661983\n",
      "iterations 4537 accuray : 0.9283763915143878  loss : 0.3171390907800833\n",
      "iterations 4538 accuray : 0.9285864314219702  loss : 0.3171232496533693\n",
      "iterations 4539 accuray : 0.9283763915143878  loss : 0.31710625105954116\n",
      "iterations 4540 accuray : 0.9283763915143878  loss : 0.3170892763515479\n",
      "iterations 4541 accuray : 0.9283763915143878  loss : 0.3170729655017767\n",
      "iterations 4542 accuray : 0.9283763915143878  loss : 0.31705579129079914\n",
      "iterations 4543 accuray : 0.9283763915143878  loss : 0.31703931932812934\n",
      "iterations 4544 accuray : 0.9283763915143878  loss : 0.3170213525064515\n",
      "iterations 4545 accuray : 0.9283763915143878  loss : 0.3170043511233205\n",
      "iterations 4546 accuray : 0.9283763915143878  loss : 0.3169878403351096\n",
      "iterations 4547 accuray : 0.9283763915143878  loss : 0.3169715033050081\n",
      "iterations 4548 accuray : 0.9283763915143878  loss : 0.31695476606988493\n",
      "iterations 4549 accuray : 0.9283763915143878  loss : 0.3169380305743798\n",
      "iterations 4550 accuray : 0.9283763915143878  loss : 0.3169212029925631\n",
      "iterations 4551 accuray : 0.9283763915143878  loss : 0.3169042319136808\n",
      "iterations 4552 accuray : 0.9283763915143878  loss : 0.31688817282543663\n",
      "iterations 4553 accuray : 0.9283763915143878  loss : 0.31687120835304045\n",
      "iterations 4554 accuray : 0.9283763915143878  loss : 0.3168541028094285\n",
      "iterations 4555 accuray : 0.9283763915143878  loss : 0.31683784535752674\n",
      "iterations 4556 accuray : 0.9283763915143878  loss : 0.31682170337994664\n",
      "iterations 4557 accuray : 0.9283763915143878  loss : 0.3168051769245086\n",
      "iterations 4558 accuray : 0.9283763915143878  loss : 0.31678871076917053\n",
      "iterations 4559 accuray : 0.9283763915143878  loss : 0.3167716283586546\n",
      "iterations 4560 accuray : 0.9283763915143878  loss : 0.31675501557239644\n",
      "iterations 4561 accuray : 0.9283763915143878  loss : 0.31673739520979144\n",
      "iterations 4562 accuray : 0.9283763915143878  loss : 0.31672124045978006\n",
      "iterations 4563 accuray : 0.9283763915143878  loss : 0.31670455474914594\n",
      "iterations 4564 accuray : 0.9283763915143878  loss : 0.3166880852766364\n",
      "iterations 4565 accuray : 0.9281663516068053  loss : 0.3166711126824144\n",
      "iterations 4566 accuray : 0.9281663516068053  loss : 0.31665450256534294\n",
      "iterations 4567 accuray : 0.9281663516068053  loss : 0.31663742768636577\n",
      "iterations 4568 accuray : 0.9281663516068053  loss : 0.3166211723359998\n",
      "iterations 4569 accuray : 0.9281663516068053  loss : 0.3166050788056966\n",
      "iterations 4570 accuray : 0.9281663516068053  loss : 0.316588362505627\n",
      "iterations 4571 accuray : 0.9281663516068053  loss : 0.3165724142786819\n",
      "iterations 4572 accuray : 0.9281663516068053  loss : 0.31655660277212444\n",
      "iterations 4573 accuray : 0.9281663516068053  loss : 0.31653924014714574\n",
      "iterations 4574 accuray : 0.9281663516068053  loss : 0.31652218636200813\n",
      "iterations 4575 accuray : 0.9281663516068053  loss : 0.3165055413909989\n",
      "iterations 4576 accuray : 0.9281663516068053  loss : 0.3164893281363527\n",
      "iterations 4577 accuray : 0.9281663516068053  loss : 0.31647210830652855\n",
      "iterations 4578 accuray : 0.9281663516068053  loss : 0.3164552947353741\n",
      "iterations 4579 accuray : 0.9281663516068053  loss : 0.31643867656124397\n",
      "iterations 4580 accuray : 0.9281663516068053  loss : 0.3164220614179604\n",
      "iterations 4581 accuray : 0.9281663516068053  loss : 0.3164058478869494\n",
      "iterations 4582 accuray : 0.9281663516068053  loss : 0.31638906366277036\n",
      "iterations 4583 accuray : 0.9281663516068053  loss : 0.31637177956841467\n",
      "iterations 4584 accuray : 0.9281663516068053  loss : 0.3163550522090881\n",
      "iterations 4585 accuray : 0.9281663516068053  loss : 0.31633862455669703\n",
      "iterations 4586 accuray : 0.9281663516068053  loss : 0.316321949992588\n",
      "iterations 4587 accuray : 0.9281663516068053  loss : 0.3163056749796807\n",
      "iterations 4588 accuray : 0.9281663516068053  loss : 0.3162893008712848\n",
      "iterations 4589 accuray : 0.9281663516068053  loss : 0.31627246434236866\n",
      "iterations 4590 accuray : 0.9281663516068053  loss : 0.31625539890878923\n",
      "iterations 4591 accuray : 0.9281663516068053  loss : 0.31623861941264286\n",
      "iterations 4592 accuray : 0.9281663516068053  loss : 0.31622180676189604\n",
      "iterations 4593 accuray : 0.9281663516068053  loss : 0.31620517874835935\n",
      "iterations 4594 accuray : 0.9281663516068053  loss : 0.3161889875100165\n",
      "iterations 4595 accuray : 0.9281663516068053  loss : 0.3161719589102134\n",
      "iterations 4596 accuray : 0.9281663516068053  loss : 0.3161562462663187\n",
      "iterations 4597 accuray : 0.9281663516068053  loss : 0.3161403042931427\n",
      "iterations 4598 accuray : 0.9281663516068053  loss : 0.31612392918679694\n",
      "iterations 4599 accuray : 0.9281663516068053  loss : 0.316107559932667\n",
      "iterations 4600 accuray : 0.9281663516068053  loss : 0.316090969508678\n",
      "iterations 4601 accuray : 0.9281663516068053  loss : 0.3160739194097302\n",
      "iterations 4602 accuray : 0.9281663516068053  loss : 0.3160572921253168\n",
      "iterations 4603 accuray : 0.9281663516068053  loss : 0.31604014436870204\n",
      "iterations 4604 accuray : 0.9281663516068053  loss : 0.3160238754639709\n",
      "iterations 4605 accuray : 0.9281663516068053  loss : 0.31600597799089086\n",
      "iterations 4606 accuray : 0.9281663516068053  loss : 0.3159891684562119\n",
      "iterations 4607 accuray : 0.9279563116992229  loss : 0.3159726668869994\n",
      "iterations 4608 accuray : 0.9281663516068053  loss : 0.31595617024821027\n",
      "iterations 4609 accuray : 0.9279563116992229  loss : 0.315939794895406\n",
      "iterations 4610 accuray : 0.9279563116992229  loss : 0.31592320370782767\n",
      "iterations 4611 accuray : 0.9281663516068053  loss : 0.31590734484343447\n",
      "iterations 4612 accuray : 0.9279563116992229  loss : 0.31589046787658076\n",
      "iterations 4613 accuray : 0.9281663516068053  loss : 0.31587388171667946\n",
      "iterations 4614 accuray : 0.9279563116992229  loss : 0.3158576208692532\n",
      "iterations 4615 accuray : 0.9279563116992229  loss : 0.31584102043143664\n",
      "iterations 4616 accuray : 0.9279563116992229  loss : 0.3158242897160646\n",
      "iterations 4617 accuray : 0.9281663516068053  loss : 0.31580786007285416\n",
      "iterations 4618 accuray : 0.9281663516068053  loss : 0.3157913522592141\n",
      "iterations 4619 accuray : 0.9281663516068053  loss : 0.31577518883372574\n",
      "iterations 4620 accuray : 0.9281663516068053  loss : 0.3157588843426996\n",
      "iterations 4621 accuray : 0.9283763915143878  loss : 0.3157423603314576\n",
      "iterations 4622 accuray : 0.9283763915143878  loss : 0.31572584118546493\n",
      "iterations 4623 accuray : 0.9283763915143878  loss : 0.31570934287603314\n",
      "iterations 4624 accuray : 0.9283763915143878  loss : 0.31569297378359373\n",
      "iterations 4625 accuray : 0.9283763915143878  loss : 0.3156766646653273\n",
      "iterations 4626 accuray : 0.9283763915143878  loss : 0.31566054013547584\n",
      "iterations 4627 accuray : 0.9283763915143878  loss : 0.3156440996471286\n",
      "iterations 4628 accuray : 0.9283763915143878  loss : 0.3156280935682648\n",
      "iterations 4629 accuray : 0.9283763915143878  loss : 0.31561209192105294\n",
      "iterations 4630 accuray : 0.9283763915143878  loss : 0.3155955821458163\n",
      "iterations 4631 accuray : 0.9283763915143878  loss : 0.3155794905588018\n",
      "iterations 4632 accuray : 0.9283763915143878  loss : 0.31556362558423606\n",
      "iterations 4633 accuray : 0.9283763915143878  loss : 0.3155477371889414\n",
      "iterations 4634 accuray : 0.9283763915143878  loss : 0.315531568327161\n",
      "iterations 4635 accuray : 0.9283763915143878  loss : 0.31551519781453974\n",
      "iterations 4636 accuray : 0.9283763915143878  loss : 0.31549911623570903\n",
      "iterations 4637 accuray : 0.9283763915143878  loss : 0.3154828193807483\n",
      "iterations 4638 accuray : 0.9283763915143878  loss : 0.3154671497786214\n",
      "iterations 4639 accuray : 0.9283763915143878  loss : 0.3154506606584321\n",
      "iterations 4640 accuray : 0.9283763915143878  loss : 0.31543491070922625\n",
      "iterations 4641 accuray : 0.9283763915143878  loss : 0.31541834714880385\n",
      "iterations 4642 accuray : 0.9283763915143878  loss : 0.31540243769842713\n",
      "iterations 4643 accuray : 0.9283763915143878  loss : 0.315386648327995\n",
      "iterations 4644 accuray : 0.9283763915143878  loss : 0.31537047504936105\n",
      "iterations 4645 accuray : 0.9283763915143878  loss : 0.3153534624910047\n",
      "iterations 4646 accuray : 0.9283763915143878  loss : 0.31533814168384766\n",
      "iterations 4647 accuray : 0.9283763915143878  loss : 0.3153221204088565\n",
      "iterations 4648 accuray : 0.9283763915143878  loss : 0.3153057781819457\n",
      "iterations 4649 accuray : 0.9283763915143878  loss : 0.31528956151642823\n",
      "iterations 4650 accuray : 0.9283763915143878  loss : 0.3152732417337678\n",
      "iterations 4651 accuray : 0.9283763915143878  loss : 0.31525757855288755\n",
      "iterations 4652 accuray : 0.9283763915143878  loss : 0.3152412136921295\n",
      "iterations 4653 accuray : 0.9283763915143878  loss : 0.31522472568124305\n",
      "iterations 4654 accuray : 0.9283763915143878  loss : 0.31520860563713804\n",
      "iterations 4655 accuray : 0.9283763915143878  loss : 0.3151914492990473\n",
      "iterations 4656 accuray : 0.9283763915143878  loss : 0.31517558502199033\n",
      "iterations 4657 accuray : 0.9283763915143878  loss : 0.31515929308823654\n",
      "iterations 4658 accuray : 0.9283763915143878  loss : 0.315143087148942\n",
      "iterations 4659 accuray : 0.9283763915143878  loss : 0.3151270791467083\n",
      "iterations 4660 accuray : 0.9283763915143878  loss : 0.3151120883954848\n",
      "iterations 4661 accuray : 0.9283763915143878  loss : 0.3150960054114347\n",
      "iterations 4662 accuray : 0.9283763915143878  loss : 0.3150797910738449\n",
      "iterations 4663 accuray : 0.9283763915143878  loss : 0.3150632064916385\n",
      "iterations 4664 accuray : 0.9283763915143878  loss : 0.3150466393822896\n",
      "iterations 4665 accuray : 0.9283763915143878  loss : 0.3150302224520773\n",
      "iterations 4666 accuray : 0.9283763915143878  loss : 0.31501389332794905\n",
      "iterations 4667 accuray : 0.9283763915143878  loss : 0.3149979545448174\n",
      "iterations 4668 accuray : 0.9283763915143878  loss : 0.3149819975938881\n",
      "iterations 4669 accuray : 0.9283763915143878  loss : 0.31496629893561007\n",
      "iterations 4670 accuray : 0.9283763915143878  loss : 0.3149502583681178\n",
      "iterations 4671 accuray : 0.9283763915143878  loss : 0.3149343393461428\n",
      "iterations 4672 accuray : 0.9283763915143878  loss : 0.3149183267562567\n",
      "iterations 4673 accuray : 0.9283763915143878  loss : 0.3149019837930302\n",
      "iterations 4674 accuray : 0.9283763915143878  loss : 0.3148864869748314\n",
      "iterations 4675 accuray : 0.9283763915143878  loss : 0.3148706949160827\n",
      "iterations 4676 accuray : 0.9283763915143878  loss : 0.31485541773365766\n",
      "iterations 4677 accuray : 0.9283763915143878  loss : 0.3148394607808235\n",
      "iterations 4678 accuray : 0.9283763915143878  loss : 0.31482336552793194\n",
      "iterations 4679 accuray : 0.9283763915143878  loss : 0.31480764351436125\n",
      "iterations 4680 accuray : 0.9283763915143878  loss : 0.3147917074115432\n",
      "iterations 4681 accuray : 0.9283763915143878  loss : 0.31477575779837125\n",
      "iterations 4682 accuray : 0.9283763915143878  loss : 0.31475955000333045\n",
      "iterations 4683 accuray : 0.9283763915143878  loss : 0.31474374358220997\n",
      "iterations 4684 accuray : 0.9283763915143878  loss : 0.3147276095437775\n",
      "iterations 4685 accuray : 0.9283763915143878  loss : 0.3147119763290937\n",
      "iterations 4686 accuray : 0.9283763915143878  loss : 0.3146960751899164\n",
      "iterations 4687 accuray : 0.9283763915143878  loss : 0.31468036741145505\n",
      "iterations 4688 accuray : 0.9283763915143878  loss : 0.3146641585189465\n",
      "iterations 4689 accuray : 0.9283763915143878  loss : 0.3146482677183665\n",
      "iterations 4690 accuray : 0.9283763915143878  loss : 0.31463173614057816\n",
      "iterations 4691 accuray : 0.9283763915143878  loss : 0.3146157817177558\n",
      "iterations 4692 accuray : 0.9283763915143878  loss : 0.3146003563911046\n",
      "iterations 4693 accuray : 0.9283763915143878  loss : 0.3145841426729665\n",
      "iterations 4694 accuray : 0.9283763915143878  loss : 0.3145687357091789\n",
      "iterations 4695 accuray : 0.9283763915143878  loss : 0.3145529412412962\n",
      "iterations 4696 accuray : 0.9283763915143878  loss : 0.3145364517908049\n",
      "iterations 4697 accuray : 0.9283763915143878  loss : 0.3145212332578033\n",
      "iterations 4698 accuray : 0.9283763915143878  loss : 0.3145051200866199\n",
      "iterations 4699 accuray : 0.9283763915143878  loss : 0.31448886130143167\n",
      "iterations 4700 accuray : 0.9283763915143878  loss : 0.31447315564199924\n",
      "iterations 4701 accuray : 0.9283763915143878  loss : 0.3144565664717861\n",
      "iterations 4702 accuray : 0.9283763915143878  loss : 0.31444000661322324\n",
      "iterations 4703 accuray : 0.9283763915143878  loss : 0.31442446926277745\n",
      "iterations 4704 accuray : 0.9283763915143878  loss : 0.3144081753123431\n",
      "iterations 4705 accuray : 0.9283763915143878  loss : 0.3143927945076176\n",
      "iterations 4706 accuray : 0.9283763915143878  loss : 0.31437694504943364\n",
      "iterations 4707 accuray : 0.9283763915143878  loss : 0.3143611840725571\n",
      "iterations 4708 accuray : 0.9283763915143878  loss : 0.3143457675892175\n",
      "iterations 4709 accuray : 0.9283763915143878  loss : 0.314329743558698\n",
      "iterations 4710 accuray : 0.9283763915143878  loss : 0.3143140880730946\n",
      "iterations 4711 accuray : 0.9283763915143878  loss : 0.3142983545601786\n",
      "iterations 4712 accuray : 0.9283763915143878  loss : 0.31428252305861715\n",
      "iterations 4713 accuray : 0.9283763915143878  loss : 0.31426647915157446\n",
      "iterations 4714 accuray : 0.9283763915143878  loss : 0.31425091511957687\n",
      "iterations 4715 accuray : 0.9283763915143878  loss : 0.3142345989100155\n",
      "iterations 4716 accuray : 0.9283763915143878  loss : 0.31421844578613545\n",
      "iterations 4717 accuray : 0.9283763915143878  loss : 0.31420268676518653\n",
      "iterations 4718 accuray : 0.9283763915143878  loss : 0.3141859325403291\n",
      "iterations 4719 accuray : 0.9283763915143878  loss : 0.31417026660842007\n",
      "iterations 4720 accuray : 0.9283763915143878  loss : 0.3141545364756601\n",
      "iterations 4721 accuray : 0.9283763915143878  loss : 0.31413793261753475\n",
      "iterations 4722 accuray : 0.9283763915143878  loss : 0.3141228236981323\n",
      "iterations 4723 accuray : 0.9283763915143878  loss : 0.3141066662137485\n",
      "iterations 4724 accuray : 0.9283763915143878  loss : 0.31409106102032097\n",
      "iterations 4725 accuray : 0.9283763915143878  loss : 0.31407524172480117\n",
      "iterations 4726 accuray : 0.9283763915143878  loss : 0.31405973212013144\n",
      "iterations 4727 accuray : 0.9283763915143878  loss : 0.31404408151856705\n",
      "iterations 4728 accuray : 0.9281663516068053  loss : 0.31402863263786174\n",
      "iterations 4729 accuray : 0.9281663516068053  loss : 0.3140130387966456\n",
      "iterations 4730 accuray : 0.9281663516068053  loss : 0.3139978311529121\n",
      "iterations 4731 accuray : 0.9283763915143878  loss : 0.313982591361701\n",
      "iterations 4732 accuray : 0.9281663516068053  loss : 0.31396683891249605\n",
      "iterations 4733 accuray : 0.9281663516068053  loss : 0.31395131430835715\n",
      "iterations 4734 accuray : 0.9281663516068053  loss : 0.3139355525229461\n",
      "iterations 4735 accuray : 0.9281663516068053  loss : 0.3139194847648139\n",
      "iterations 4736 accuray : 0.9281663516068053  loss : 0.31390383563899876\n",
      "iterations 4737 accuray : 0.9281663516068053  loss : 0.3138882634406497\n",
      "iterations 4738 accuray : 0.9281663516068053  loss : 0.313872533408978\n",
      "iterations 4739 accuray : 0.9283763915143878  loss : 0.3138571925613781\n",
      "iterations 4740 accuray : 0.9283763915143878  loss : 0.3138414103087903\n",
      "iterations 4741 accuray : 0.9283763915143878  loss : 0.3138260667285858\n",
      "iterations 4742 accuray : 0.9283763915143878  loss : 0.3138107825108796\n",
      "iterations 4743 accuray : 0.9283763915143878  loss : 0.31379493022253185\n",
      "iterations 4744 accuray : 0.9283763915143878  loss : 0.31377904903628834\n",
      "iterations 4745 accuray : 0.9283763915143878  loss : 0.31376235815262177\n",
      "iterations 4746 accuray : 0.9283763915143878  loss : 0.3137466312259577\n",
      "iterations 4747 accuray : 0.9283763915143878  loss : 0.3137309702807661\n",
      "iterations 4748 accuray : 0.9283763915143878  loss : 0.3137146022067469\n",
      "iterations 4749 accuray : 0.9283763915143878  loss : 0.31369845505731686\n",
      "iterations 4750 accuray : 0.9281663516068053  loss : 0.313682858098692\n",
      "iterations 4751 accuray : 0.9281663516068053  loss : 0.313666556708777\n",
      "iterations 4752 accuray : 0.9281663516068053  loss : 0.31365103864873334\n",
      "iterations 4753 accuray : 0.9281663516068053  loss : 0.31363502899554274\n",
      "iterations 4754 accuray : 0.9281663516068053  loss : 0.3136196291387046\n",
      "iterations 4755 accuray : 0.9281663516068053  loss : 0.3136043593607677\n",
      "iterations 4756 accuray : 0.9281663516068053  loss : 0.3135882549503811\n",
      "iterations 4757 accuray : 0.9281663516068053  loss : 0.3135726711351932\n",
      "iterations 4758 accuray : 0.9281663516068053  loss : 0.3135575479092377\n",
      "iterations 4759 accuray : 0.9281663516068053  loss : 0.3135422140032736\n",
      "iterations 4760 accuray : 0.9281663516068053  loss : 0.31352605242293313\n",
      "iterations 4761 accuray : 0.9281663516068053  loss : 0.3135108141476959\n",
      "iterations 4762 accuray : 0.9281663516068053  loss : 0.3134953117210917\n",
      "iterations 4763 accuray : 0.9281663516068053  loss : 0.3134796454697003\n",
      "iterations 4764 accuray : 0.9279563116992229  loss : 0.3134640960724053\n",
      "iterations 4765 accuray : 0.9281663516068053  loss : 0.31344819502818955\n",
      "iterations 4766 accuray : 0.9281663516068053  loss : 0.31343208424275104\n",
      "iterations 4767 accuray : 0.9279563116992229  loss : 0.313416739674954\n",
      "iterations 4768 accuray : 0.9279563116992229  loss : 0.31340096707991577\n",
      "iterations 4769 accuray : 0.9279563116992229  loss : 0.31338516143621337\n",
      "iterations 4770 accuray : 0.9281663516068053  loss : 0.3133700150652515\n",
      "iterations 4771 accuray : 0.9281663516068053  loss : 0.3133545130930371\n",
      "iterations 4772 accuray : 0.9279563116992229  loss : 0.31333925232802\n",
      "iterations 4773 accuray : 0.9279563116992229  loss : 0.3133231573919097\n",
      "iterations 4774 accuray : 0.9279563116992229  loss : 0.31330766623396406\n",
      "iterations 4775 accuray : 0.9279563116992229  loss : 0.3132921990693392\n",
      "iterations 4776 accuray : 0.9279563116992229  loss : 0.3132767524011185\n",
      "iterations 4777 accuray : 0.9279563116992229  loss : 0.3132609790527037\n",
      "iterations 4778 accuray : 0.9279563116992229  loss : 0.3132460098264429\n",
      "iterations 4779 accuray : 0.9279563116992229  loss : 0.3132307733173348\n",
      "iterations 4780 accuray : 0.9279563116992229  loss : 0.31321509607459747\n",
      "iterations 4781 accuray : 0.9279563116992229  loss : 0.313199719667304\n",
      "iterations 4782 accuray : 0.9279563116992229  loss : 0.3131844684510176\n",
      "iterations 4783 accuray : 0.9279563116992229  loss : 0.31316834959950346\n",
      "iterations 4784 accuray : 0.9279563116992229  loss : 0.3131516520198175\n",
      "iterations 4785 accuray : 0.9279563116992229  loss : 0.3131367296644743\n",
      "iterations 4786 accuray : 0.9279563116992229  loss : 0.3131217786391837\n",
      "iterations 4787 accuray : 0.9279563116992229  loss : 0.31310608997354694\n",
      "iterations 4788 accuray : 0.9279563116992229  loss : 0.31309036909542504\n",
      "iterations 4789 accuray : 0.9279563116992229  loss : 0.31307480477452315\n",
      "iterations 4790 accuray : 0.9279563116992229  loss : 0.3130590345957336\n",
      "iterations 4791 accuray : 0.9279563116992229  loss : 0.31304401173614504\n",
      "iterations 4792 accuray : 0.9279563116992229  loss : 0.3130276462100626\n",
      "iterations 4793 accuray : 0.9279563116992229  loss : 0.3130114007440732\n",
      "iterations 4794 accuray : 0.9279563116992229  loss : 0.31299616420383447\n",
      "iterations 4795 accuray : 0.9279563116992229  loss : 0.3129803845696599\n",
      "iterations 4796 accuray : 0.9279563116992229  loss : 0.3129654216757764\n",
      "iterations 4797 accuray : 0.9279563116992229  loss : 0.31294962757227285\n",
      "iterations 4798 accuray : 0.9279563116992229  loss : 0.3129340757117665\n",
      "iterations 4799 accuray : 0.9279563116992229  loss : 0.312919109138833\n",
      "iterations 4800 accuray : 0.9279563116992229  loss : 0.3129030386602452\n",
      "iterations 4801 accuray : 0.9279563116992229  loss : 0.3128868798328565\n",
      "iterations 4802 accuray : 0.9279563116992229  loss : 0.3128713777623723\n",
      "iterations 4803 accuray : 0.9279563116992229  loss : 0.31285557923191315\n",
      "iterations 4804 accuray : 0.9279563116992229  loss : 0.31284027445401524\n",
      "iterations 4805 accuray : 0.9279563116992229  loss : 0.3128245605780969\n",
      "iterations 4806 accuray : 0.9279563116992229  loss : 0.312809413192509\n",
      "iterations 4807 accuray : 0.9279563116992229  loss : 0.31279395065862853\n",
      "iterations 4808 accuray : 0.9279563116992229  loss : 0.31277844812690214\n",
      "iterations 4809 accuray : 0.9279563116992229  loss : 0.31276232390319203\n",
      "iterations 4810 accuray : 0.9279563116992229  loss : 0.3127472729725852\n",
      "iterations 4811 accuray : 0.9279563116992229  loss : 0.31273211153561303\n",
      "iterations 4812 accuray : 0.9279563116992229  loss : 0.3127167834651762\n",
      "iterations 4813 accuray : 0.9279563116992229  loss : 0.3127012303924995\n",
      "iterations 4814 accuray : 0.9279563116992229  loss : 0.31268555912235424\n",
      "iterations 4815 accuray : 0.9279563116992229  loss : 0.31266989758185076\n",
      "iterations 4816 accuray : 0.9279563116992229  loss : 0.3126544700443503\n",
      "iterations 4817 accuray : 0.9279563116992229  loss : 0.3126395092312043\n",
      "iterations 4818 accuray : 0.9279563116992229  loss : 0.3126241591006513\n",
      "iterations 4819 accuray : 0.9279563116992229  loss : 0.31260857552980686\n",
      "iterations 4820 accuray : 0.9279563116992229  loss : 0.31259379340433263\n",
      "iterations 4821 accuray : 0.9279563116992229  loss : 0.31257906157726056\n",
      "iterations 4822 accuray : 0.9279563116992229  loss : 0.312563754167491\n",
      "iterations 4823 accuray : 0.9279563116992229  loss : 0.3125487785786048\n",
      "iterations 4824 accuray : 0.9279563116992229  loss : 0.31253375416157725\n",
      "iterations 4825 accuray : 0.9279563116992229  loss : 0.312518235542079\n",
      "iterations 4826 accuray : 0.9279563116992229  loss : 0.3125029759514749\n",
      "iterations 4827 accuray : 0.9279563116992229  loss : 0.31248759295739736\n",
      "iterations 4828 accuray : 0.9279563116992229  loss : 0.312472452393616\n",
      "iterations 4829 accuray : 0.9279563116992229  loss : 0.3124568913540033\n",
      "iterations 4830 accuray : 0.9279563116992229  loss : 0.31244085954114503\n",
      "iterations 4831 accuray : 0.9279563116992229  loss : 0.3124253824288412\n",
      "iterations 4832 accuray : 0.9279563116992229  loss : 0.31240952743844835\n",
      "iterations 4833 accuray : 0.9279563116992229  loss : 0.3123944407671494\n",
      "iterations 4834 accuray : 0.9279563116992229  loss : 0.31237840000773026\n",
      "iterations 4835 accuray : 0.9279563116992229  loss : 0.31236308598950663\n",
      "iterations 4836 accuray : 0.9279563116992229  loss : 0.3123471919967952\n",
      "iterations 4837 accuray : 0.9279563116992229  loss : 0.3123322705771543\n",
      "iterations 4838 accuray : 0.9279563116992229  loss : 0.31231629246584713\n",
      "iterations 4839 accuray : 0.9279563116992229  loss : 0.3123013594618812\n",
      "iterations 4840 accuray : 0.9281663516068053  loss : 0.31228592656598964\n",
      "iterations 4841 accuray : 0.9279563116992229  loss : 0.3122712510854096\n",
      "iterations 4842 accuray : 0.9279563116992229  loss : 0.3122564958649121\n",
      "iterations 4843 accuray : 0.9279563116992229  loss : 0.312241267187576\n",
      "iterations 4844 accuray : 0.9279563116992229  loss : 0.31222557326667294\n",
      "iterations 4845 accuray : 0.9279563116992229  loss : 0.31221037856486056\n",
      "iterations 4846 accuray : 0.9279563116992229  loss : 0.31219500679643314\n",
      "iterations 4847 accuray : 0.9279563116992229  loss : 0.3121798247971622\n",
      "iterations 4848 accuray : 0.9279563116992229  loss : 0.31216456644705215\n",
      "iterations 4849 accuray : 0.9279563116992229  loss : 0.31214911524832417\n",
      "iterations 4850 accuray : 0.9279563116992229  loss : 0.31213348975191335\n",
      "iterations 4851 accuray : 0.9279563116992229  loss : 0.3121184743569866\n",
      "iterations 4852 accuray : 0.9279563116992229  loss : 0.31210382827421806\n",
      "iterations 4853 accuray : 0.9279563116992229  loss : 0.31208944639174524\n",
      "iterations 4854 accuray : 0.9279563116992229  loss : 0.312074070154227\n",
      "iterations 4855 accuray : 0.9279563116992229  loss : 0.31205783787553065\n",
      "iterations 4856 accuray : 0.9279563116992229  loss : 0.31204259713635973\n",
      "iterations 4857 accuray : 0.9279563116992229  loss : 0.31202731992505545\n",
      "iterations 4858 accuray : 0.9279563116992229  loss : 0.3120124522298356\n",
      "iterations 4859 accuray : 0.9279563116992229  loss : 0.31199732999889934\n",
      "iterations 4860 accuray : 0.9279563116992229  loss : 0.3119826048311649\n",
      "iterations 4861 accuray : 0.9279563116992229  loss : 0.31196726722863416\n",
      "iterations 4862 accuray : 0.9281663516068053  loss : 0.3119521447038061\n",
      "iterations 4863 accuray : 0.9281663516068053  loss : 0.311936738073194\n",
      "iterations 4864 accuray : 0.9281663516068053  loss : 0.311921618385934\n",
      "iterations 4865 accuray : 0.9281663516068053  loss : 0.31190608963527733\n",
      "iterations 4866 accuray : 0.9281663516068053  loss : 0.3118912543825476\n",
      "iterations 4867 accuray : 0.9281663516068053  loss : 0.31187620197168786\n",
      "iterations 4868 accuray : 0.9281663516068053  loss : 0.3118610594251734\n",
      "iterations 4869 accuray : 0.9281663516068053  loss : 0.3118459100907618\n",
      "iterations 4870 accuray : 0.9281663516068053  loss : 0.3118310782287552\n",
      "iterations 4871 accuray : 0.9281663516068053  loss : 0.3118156287558649\n",
      "iterations 4872 accuray : 0.9281663516068053  loss : 0.3118006676124638\n",
      "iterations 4873 accuray : 0.9281663516068053  loss : 0.31178574777452595\n",
      "iterations 4874 accuray : 0.9281663516068053  loss : 0.31177096768276824\n",
      "iterations 4875 accuray : 0.9281663516068053  loss : 0.31175623244430184\n",
      "iterations 4876 accuray : 0.9281663516068053  loss : 0.31174095665879237\n",
      "iterations 4877 accuray : 0.9281663516068053  loss : 0.3117254747506306\n",
      "iterations 4878 accuray : 0.9281663516068053  loss : 0.3117104068000156\n",
      "iterations 4879 accuray : 0.9279563116992229  loss : 0.31169491765116164\n",
      "iterations 4880 accuray : 0.9279563116992229  loss : 0.311679612274414\n",
      "iterations 4881 accuray : 0.9281663516068053  loss : 0.31166453837732305\n",
      "iterations 4882 accuray : 0.9279563116992229  loss : 0.3116488964662451\n",
      "iterations 4883 accuray : 0.9281663516068053  loss : 0.3116341054465068\n",
      "iterations 4884 accuray : 0.9279563116992229  loss : 0.31161817618984916\n",
      "iterations 4885 accuray : 0.9279563116992229  loss : 0.3116031706440549\n",
      "iterations 4886 accuray : 0.9279563116992229  loss : 0.3115879549225025\n",
      "iterations 4887 accuray : 0.9279563116992229  loss : 0.3115732597259657\n",
      "iterations 4888 accuray : 0.9279563116992229  loss : 0.31155881525931317\n",
      "iterations 4889 accuray : 0.9281663516068053  loss : 0.31154402226623973\n",
      "iterations 4890 accuray : 0.9281663516068053  loss : 0.31152892786622927\n",
      "iterations 4891 accuray : 0.9279563116992229  loss : 0.3115135556731399\n",
      "iterations 4892 accuray : 0.9279563116992229  loss : 0.3114987217627739\n",
      "iterations 4893 accuray : 0.9279563116992229  loss : 0.3114842957273116\n",
      "iterations 4894 accuray : 0.9281663516068053  loss : 0.3114691776867308\n",
      "iterations 4895 accuray : 0.9281663516068053  loss : 0.31145387945494907\n",
      "iterations 4896 accuray : 0.9279563116992229  loss : 0.3114385613788669\n",
      "iterations 4897 accuray : 0.9281663516068053  loss : 0.3114235529353776\n",
      "iterations 4898 accuray : 0.9279563116992229  loss : 0.31140801646540545\n",
      "iterations 4899 accuray : 0.9281663516068053  loss : 0.31139348789563004\n",
      "iterations 4900 accuray : 0.9281663516068053  loss : 0.3113788667705897\n",
      "iterations 4901 accuray : 0.9281663516068053  loss : 0.31136384480485785\n",
      "iterations 4902 accuray : 0.9281663516068053  loss : 0.3113488289119664\n",
      "iterations 4903 accuray : 0.9281663516068053  loss : 0.3113332813102549\n",
      "iterations 4904 accuray : 0.9279563116992229  loss : 0.3113181522508208\n",
      "iterations 4905 accuray : 0.9279563116992229  loss : 0.31130262669654896\n",
      "iterations 4906 accuray : 0.9279563116992229  loss : 0.31128722883017085\n",
      "iterations 4907 accuray : 0.9279563116992229  loss : 0.3112724191964647\n",
      "iterations 4908 accuray : 0.9281663516068053  loss : 0.31125785421101354\n",
      "iterations 4909 accuray : 0.9281663516068053  loss : 0.3112430208337543\n",
      "iterations 4910 accuray : 0.9281663516068053  loss : 0.3112277791137327\n",
      "iterations 4911 accuray : 0.9281663516068053  loss : 0.31121280223561526\n",
      "iterations 4912 accuray : 0.9279563116992229  loss : 0.31119714612464416\n",
      "iterations 4913 accuray : 0.9279563116992229  loss : 0.31118194824153017\n",
      "iterations 4914 accuray : 0.9279563116992229  loss : 0.3111668601186773\n",
      "iterations 4915 accuray : 0.9279563116992229  loss : 0.3111510991561499\n",
      "iterations 4916 accuray : 0.9279563116992229  loss : 0.3111359578543559\n",
      "iterations 4917 accuray : 0.9279563116992229  loss : 0.31112106476251405\n",
      "iterations 4918 accuray : 0.9279563116992229  loss : 0.31110597284310665\n",
      "iterations 4919 accuray : 0.9279563116992229  loss : 0.31109172361637566\n",
      "iterations 4920 accuray : 0.9279563116992229  loss : 0.3110767287686132\n",
      "iterations 4921 accuray : 0.9277462717916404  loss : 0.31106184951105864\n",
      "iterations 4922 accuray : 0.9277462717916404  loss : 0.31104635526857527\n",
      "iterations 4923 accuray : 0.9279563116992229  loss : 0.31103154173379743\n",
      "iterations 4924 accuray : 0.9279563116992229  loss : 0.3110169127100267\n",
      "iterations 4925 accuray : 0.9279563116992229  loss : 0.31100186925884665\n",
      "iterations 4926 accuray : 0.9279563116992229  loss : 0.3109871958298986\n",
      "iterations 4927 accuray : 0.9279563116992229  loss : 0.3109730613069704\n",
      "iterations 4928 accuray : 0.9279563116992229  loss : 0.31095845390767785\n",
      "iterations 4929 accuray : 0.9279563116992229  loss : 0.31094426470161524\n",
      "iterations 4930 accuray : 0.9279563116992229  loss : 0.31092942626603204\n",
      "iterations 4931 accuray : 0.9279563116992229  loss : 0.31091453994539364\n",
      "iterations 4932 accuray : 0.9279563116992229  loss : 0.3108997801444745\n",
      "iterations 4933 accuray : 0.9279563116992229  loss : 0.31088569637696445\n",
      "iterations 4934 accuray : 0.9279563116992229  loss : 0.31087069552809005\n",
      "iterations 4935 accuray : 0.9279563116992229  loss : 0.31085544536527265\n",
      "iterations 4936 accuray : 0.9277462717916404  loss : 0.3108400572967848\n",
      "iterations 4937 accuray : 0.9277462717916404  loss : 0.31082517346973537\n",
      "iterations 4938 accuray : 0.9277462717916404  loss : 0.3108099233423102\n",
      "iterations 4939 accuray : 0.9279563116992229  loss : 0.3107954055165189\n",
      "iterations 4940 accuray : 0.9277462717916404  loss : 0.3107805341428562\n",
      "iterations 4941 accuray : 0.9277462717916404  loss : 0.31076549828831296\n",
      "iterations 4942 accuray : 0.9279563116992229  loss : 0.3107507637257264\n",
      "iterations 4943 accuray : 0.9279563116992229  loss : 0.3107366098712834\n",
      "iterations 4944 accuray : 0.9279563116992229  loss : 0.31072150437569845\n",
      "iterations 4945 accuray : 0.9279563116992229  loss : 0.3107066413543254\n",
      "iterations 4946 accuray : 0.9279563116992229  loss : 0.31069189063731956\n",
      "iterations 4947 accuray : 0.9279563116992229  loss : 0.3106766903803153\n",
      "iterations 4948 accuray : 0.9277462717916404  loss : 0.31066157399703387\n",
      "iterations 4949 accuray : 0.9277462717916404  loss : 0.31064676486311066\n",
      "iterations 4950 accuray : 0.9277462717916404  loss : 0.3106322938309456\n",
      "iterations 4951 accuray : 0.9277462717916404  loss : 0.3106172843798297\n",
      "iterations 4952 accuray : 0.9277462717916404  loss : 0.3106028292543192\n",
      "iterations 4953 accuray : 0.9277462717916404  loss : 0.3105874567378518\n",
      "iterations 4954 accuray : 0.9277462717916404  loss : 0.3105725183103808\n",
      "iterations 4955 accuray : 0.9277462717916404  loss : 0.31055723955595343\n",
      "iterations 4956 accuray : 0.9277462717916404  loss : 0.31054281137469486\n",
      "iterations 4957 accuray : 0.9277462717916404  loss : 0.31052794115668375\n",
      "iterations 4958 accuray : 0.9277462717916404  loss : 0.3105135926835395\n",
      "iterations 4959 accuray : 0.927536231884058  loss : 0.31049897137483184\n",
      "iterations 4960 accuray : 0.927536231884058  loss : 0.31048406492045705\n",
      "iterations 4961 accuray : 0.927536231884058  loss : 0.3104695290800241\n",
      "iterations 4962 accuray : 0.927536231884058  loss : 0.31045475015718077\n",
      "iterations 4963 accuray : 0.927536231884058  loss : 0.3104398986983381\n",
      "iterations 4964 accuray : 0.927536231884058  loss : 0.3104251722642951\n",
      "iterations 4965 accuray : 0.927536231884058  loss : 0.31041038421005906\n",
      "iterations 4966 accuray : 0.927536231884058  loss : 0.310395612745907\n",
      "iterations 4967 accuray : 0.927536231884058  loss : 0.31038109000192243\n",
      "iterations 4968 accuray : 0.927536231884058  loss : 0.31036596013056317\n",
      "iterations 4969 accuray : 0.927536231884058  loss : 0.3103510327954898\n",
      "iterations 4970 accuray : 0.927536231884058  loss : 0.3103357429561925\n",
      "iterations 4971 accuray : 0.927536231884058  loss : 0.31032062353299955\n",
      "iterations 4972 accuray : 0.927536231884058  loss : 0.3103057252776755\n",
      "iterations 4973 accuray : 0.927536231884058  loss : 0.3102909643611415\n",
      "iterations 4974 accuray : 0.9277462717916404  loss : 0.3102766376176826\n",
      "iterations 4975 accuray : 0.927536231884058  loss : 0.3102620708285457\n",
      "iterations 4976 accuray : 0.927536231884058  loss : 0.3102470772567697\n",
      "iterations 4977 accuray : 0.927536231884058  loss : 0.3102321709313539\n",
      "iterations 4978 accuray : 0.927536231884058  loss : 0.310217538453874\n",
      "iterations 4979 accuray : 0.927536231884058  loss : 0.31020314725558784\n",
      "iterations 4980 accuray : 0.927536231884058  loss : 0.3101890298075176\n",
      "iterations 4981 accuray : 0.927536231884058  loss : 0.310174366608966\n",
      "iterations 4982 accuray : 0.927536231884058  loss : 0.3101599126353222\n",
      "iterations 4983 accuray : 0.927536231884058  loss : 0.31014531531737977\n",
      "iterations 4984 accuray : 0.927536231884058  loss : 0.31013059649874225\n",
      "iterations 4985 accuray : 0.927536231884058  loss : 0.3101160579789043\n",
      "iterations 4986 accuray : 0.927536231884058  loss : 0.31010115916976805\n",
      "iterations 4987 accuray : 0.927536231884058  loss : 0.3100865554892607\n",
      "iterations 4988 accuray : 0.927536231884058  loss : 0.3100720294026695\n",
      "iterations 4989 accuray : 0.9277462717916404  loss : 0.31005739677998784\n",
      "iterations 4990 accuray : 0.927536231884058  loss : 0.31004284706132207\n",
      "iterations 4991 accuray : 0.927536231884058  loss : 0.31002837146705725\n",
      "iterations 4992 accuray : 0.927536231884058  loss : 0.31001424979791875\n",
      "iterations 4993 accuray : 0.927536231884058  loss : 0.3099997762671802\n",
      "iterations 4994 accuray : 0.9277462717916404  loss : 0.3099846644980045\n",
      "iterations 4995 accuray : 0.9277462717916404  loss : 0.30996983250065135\n",
      "iterations 4996 accuray : 0.9277462717916404  loss : 0.3099551079779895\n",
      "iterations 4997 accuray : 0.9277462717916404  loss : 0.30993971624106453\n",
      "iterations 4998 accuray : 0.9277462717916404  loss : 0.309924964170371\n",
      "iterations 4999 accuray : 0.9277462717916404  loss : 0.3099109938486463\n",
      "iterations 5000 accuray : 0.9277462717916404  loss : 0.30989585675985354\n",
      "iterations 5001 accuray : 0.9277462717916404  loss : 0.30988162032521893\n",
      "iterations 5002 accuray : 0.9277462717916404  loss : 0.3098670890662566\n",
      "iterations 5003 accuray : 0.9277462717916404  loss : 0.309852454587488\n",
      "iterations 5004 accuray : 0.9277462717916404  loss : 0.3098380548317084\n",
      "iterations 5005 accuray : 0.9277462717916404  loss : 0.3098231211090857\n",
      "iterations 5006 accuray : 0.9277462717916404  loss : 0.3098080826334703\n",
      "iterations 5007 accuray : 0.9277462717916404  loss : 0.3097937943556138\n",
      "iterations 5008 accuray : 0.9277462717916404  loss : 0.30977935977785637\n",
      "iterations 5009 accuray : 0.9277462717916404  loss : 0.30976497132050634\n",
      "iterations 5010 accuray : 0.9277462717916404  loss : 0.3097511539775497\n",
      "iterations 5011 accuray : 0.9277462717916404  loss : 0.30973709255320897\n",
      "iterations 5012 accuray : 0.9277462717916404  loss : 0.3097228846500438\n",
      "iterations 5013 accuray : 0.9277462717916404  loss : 0.30970849150160557\n",
      "iterations 5014 accuray : 0.9277462717916404  loss : 0.3096936325662058\n",
      "iterations 5015 accuray : 0.9277462717916404  loss : 0.3096787322725278\n",
      "iterations 5016 accuray : 0.9277462717916404  loss : 0.3096640662400598\n",
      "iterations 5017 accuray : 0.9277462717916404  loss : 0.3096496701277235\n",
      "iterations 5018 accuray : 0.9277462717916404  loss : 0.3096352197287716\n",
      "iterations 5019 accuray : 0.9277462717916404  loss : 0.30962111205636905\n",
      "iterations 5020 accuray : 0.9277462717916404  loss : 0.3096063796863879\n",
      "iterations 5021 accuray : 0.9277462717916404  loss : 0.30959145458769105\n",
      "iterations 5022 accuray : 0.9277462717916404  loss : 0.30957672940697134\n",
      "iterations 5023 accuray : 0.9277462717916404  loss : 0.30956183509029916\n",
      "iterations 5024 accuray : 0.927536231884058  loss : 0.3095470736387864\n",
      "iterations 5025 accuray : 0.927536231884058  loss : 0.3095322555983313\n",
      "iterations 5026 accuray : 0.927536231884058  loss : 0.30951786285700683\n",
      "iterations 5027 accuray : 0.927536231884058  loss : 0.3095034001397185\n",
      "iterations 5028 accuray : 0.927536231884058  loss : 0.30948930490155035\n",
      "iterations 5029 accuray : 0.9277462717916404  loss : 0.3094749338585334\n",
      "iterations 5030 accuray : 0.9277462717916404  loss : 0.30946102090929445\n",
      "iterations 5031 accuray : 0.9277462717916404  loss : 0.30944607000710905\n",
      "iterations 5032 accuray : 0.9277462717916404  loss : 0.3094309577455992\n",
      "iterations 5033 accuray : 0.9277462717916404  loss : 0.30941705421337473\n",
      "iterations 5034 accuray : 0.9277462717916404  loss : 0.3094028573941135\n",
      "iterations 5035 accuray : 0.9277462717916404  loss : 0.3093891869832806\n",
      "iterations 5036 accuray : 0.9277462717916404  loss : 0.3093748888401502\n",
      "iterations 5037 accuray : 0.9277462717916404  loss : 0.3093606513024464\n",
      "iterations 5038 accuray : 0.9277462717916404  loss : 0.3093466547049856\n",
      "iterations 5039 accuray : 0.9277462717916404  loss : 0.309332241320348\n",
      "iterations 5040 accuray : 0.9277462717916404  loss : 0.30931747709178753\n",
      "iterations 5041 accuray : 0.9277462717916404  loss : 0.3093028218051102\n",
      "iterations 5042 accuray : 0.9277462717916404  loss : 0.30928890968621287\n",
      "iterations 5043 accuray : 0.9277462717916404  loss : 0.3092741842322973\n",
      "iterations 5044 accuray : 0.9277462717916404  loss : 0.3092599052299263\n",
      "iterations 5045 accuray : 0.9277462717916404  loss : 0.309245713242845\n",
      "iterations 5046 accuray : 0.9277462717916404  loss : 0.30923178096521653\n",
      "iterations 5047 accuray : 0.9277462717916404  loss : 0.309217176358805\n",
      "iterations 5048 accuray : 0.9277462717916404  loss : 0.30920308672171964\n",
      "iterations 5049 accuray : 0.9277462717916404  loss : 0.30918872875828995\n",
      "iterations 5050 accuray : 0.9277462717916404  loss : 0.30917444410063394\n",
      "iterations 5051 accuray : 0.9277462717916404  loss : 0.3091602309132574\n",
      "iterations 5052 accuray : 0.9277462717916404  loss : 0.30914583396325795\n",
      "iterations 5053 accuray : 0.9277462717916404  loss : 0.3091310988488049\n",
      "iterations 5054 accuray : 0.9277462717916404  loss : 0.30911658998131397\n",
      "iterations 5055 accuray : 0.9277462717916404  loss : 0.30910281502340214\n",
      "iterations 5056 accuray : 0.9277462717916404  loss : 0.3090880905893855\n",
      "iterations 5057 accuray : 0.9277462717916404  loss : 0.3090738994711517\n",
      "iterations 5058 accuray : 0.9277462717916404  loss : 0.30905977079732433\n",
      "iterations 5059 accuray : 0.9277462717916404  loss : 0.3090456737531045\n",
      "iterations 5060 accuray : 0.9277462717916404  loss : 0.3090314047423703\n",
      "iterations 5061 accuray : 0.9277462717916404  loss : 0.30901718146824425\n",
      "iterations 5062 accuray : 0.9277462717916404  loss : 0.30900308744576205\n",
      "iterations 5063 accuray : 0.9277462717916404  loss : 0.3089881701756733\n",
      "iterations 5064 accuray : 0.9277462717916404  loss : 0.3089737804101845\n",
      "iterations 5065 accuray : 0.9277462717916404  loss : 0.3089597768940241\n",
      "iterations 5066 accuray : 0.9277462717916404  loss : 0.308945336425908\n",
      "iterations 5067 accuray : 0.9277462717916404  loss : 0.30893113238135234\n",
      "iterations 5068 accuray : 0.9277462717916404  loss : 0.30891686761950693\n",
      "iterations 5069 accuray : 0.9277462717916404  loss : 0.30890295872657886\n",
      "iterations 5070 accuray : 0.9277462717916404  loss : 0.30888792881331484\n",
      "iterations 5071 accuray : 0.9277462717916404  loss : 0.30887333537383793\n",
      "iterations 5072 accuray : 0.9277462717916404  loss : 0.308858671544694\n",
      "iterations 5073 accuray : 0.9277462717916404  loss : 0.30884441634872467\n",
      "iterations 5074 accuray : 0.9277462717916404  loss : 0.308830038042766\n",
      "iterations 5075 accuray : 0.9277462717916404  loss : 0.30881612855259444\n",
      "iterations 5076 accuray : 0.9277462717916404  loss : 0.30880151771270764\n",
      "iterations 5077 accuray : 0.9277462717916404  loss : 0.30878688912265084\n",
      "iterations 5078 accuray : 0.9277462717916404  loss : 0.3087729003399185\n",
      "iterations 5079 accuray : 0.9277462717916404  loss : 0.30875859556789303\n",
      "iterations 5080 accuray : 0.9277462717916404  loss : 0.3087442779578105\n",
      "iterations 5081 accuray : 0.9277462717916404  loss : 0.3087302369659318\n",
      "iterations 5082 accuray : 0.9277462717916404  loss : 0.30871578289905327\n",
      "iterations 5083 accuray : 0.9277462717916404  loss : 0.30870169066131775\n",
      "iterations 5084 accuray : 0.9277462717916404  loss : 0.3086872757509596\n",
      "iterations 5085 accuray : 0.927536231884058  loss : 0.30867266454047454\n",
      "iterations 5086 accuray : 0.927536231884058  loss : 0.30865845791696866\n",
      "iterations 5087 accuray : 0.9277462717916404  loss : 0.30864417692871854\n",
      "iterations 5088 accuray : 0.9277462717916404  loss : 0.3086302718747187\n",
      "iterations 5089 accuray : 0.9277462717916404  loss : 0.3086168506107981\n",
      "iterations 5090 accuray : 0.9277462717916404  loss : 0.30860309187559803\n",
      "iterations 5091 accuray : 0.9277462717916404  loss : 0.3085882097708051\n",
      "iterations 5092 accuray : 0.9277462717916404  loss : 0.30857412285666014\n",
      "iterations 5093 accuray : 0.9277462717916404  loss : 0.30855951137811644\n",
      "iterations 5094 accuray : 0.927536231884058  loss : 0.30854461836437874\n",
      "iterations 5095 accuray : 0.927536231884058  loss : 0.3085303353318872\n",
      "iterations 5096 accuray : 0.9277462717916404  loss : 0.3085160343192752\n",
      "iterations 5097 accuray : 0.927536231884058  loss : 0.30850177575175447\n",
      "iterations 5098 accuray : 0.927536231884058  loss : 0.30848721472596713\n",
      "iterations 5099 accuray : 0.927536231884058  loss : 0.30847290700388613\n",
      "iterations 5100 accuray : 0.927536231884058  loss : 0.30845845221408785\n",
      "iterations 5101 accuray : 0.927536231884058  loss : 0.30844449640116856\n",
      "iterations 5102 accuray : 0.927536231884058  loss : 0.3084300117946548\n",
      "iterations 5103 accuray : 0.927536231884058  loss : 0.30841514330135894\n",
      "iterations 5104 accuray : 0.927536231884058  loss : 0.30840137834715187\n",
      "iterations 5105 accuray : 0.927536231884058  loss : 0.3083871010498909\n",
      "iterations 5106 accuray : 0.927536231884058  loss : 0.3083730116392275\n",
      "iterations 5107 accuray : 0.927536231884058  loss : 0.30835956205329945\n",
      "iterations 5108 accuray : 0.927536231884058  loss : 0.3083447815903573\n",
      "iterations 5109 accuray : 0.927536231884058  loss : 0.30833019890535074\n",
      "iterations 5110 accuray : 0.927536231884058  loss : 0.3083164972810695\n",
      "iterations 5111 accuray : 0.927536231884058  loss : 0.3083020566815014\n",
      "iterations 5112 accuray : 0.927536231884058  loss : 0.3082880908445562\n",
      "iterations 5113 accuray : 0.927536231884058  loss : 0.30827405117140494\n",
      "iterations 5114 accuray : 0.927536231884058  loss : 0.30825942014470953\n",
      "iterations 5115 accuray : 0.927536231884058  loss : 0.3082459418411984\n",
      "iterations 5116 accuray : 0.927536231884058  loss : 0.30823165124473034\n",
      "iterations 5117 accuray : 0.927536231884058  loss : 0.3082171213940668\n",
      "iterations 5118 accuray : 0.927536231884058  loss : 0.30820268073703266\n",
      "iterations 5119 accuray : 0.927536231884058  loss : 0.30818866298049574\n",
      "iterations 5120 accuray : 0.927536231884058  loss : 0.30817502956247605\n",
      "iterations 5121 accuray : 0.927536231884058  loss : 0.3081605675005124\n",
      "iterations 5122 accuray : 0.927536231884058  loss : 0.308146688881151\n",
      "iterations 5123 accuray : 0.927536231884058  loss : 0.3081325619902013\n",
      "iterations 5124 accuray : 0.927536231884058  loss : 0.30811859909374106\n",
      "iterations 5125 accuray : 0.927536231884058  loss : 0.308103912643562\n",
      "iterations 5126 accuray : 0.927536231884058  loss : 0.30808967932025444\n",
      "iterations 5127 accuray : 0.927536231884058  loss : 0.3080753622487035\n",
      "iterations 5128 accuray : 0.927536231884058  loss : 0.308061642135092\n",
      "iterations 5129 accuray : 0.927536231884058  loss : 0.3080477342594523\n",
      "iterations 5130 accuray : 0.927536231884058  loss : 0.30803322601680194\n",
      "iterations 5131 accuray : 0.927536231884058  loss : 0.3080187504931255\n",
      "iterations 5132 accuray : 0.927536231884058  loss : 0.3080045512189775\n",
      "iterations 5133 accuray : 0.927536231884058  loss : 0.3079904766637862\n",
      "iterations 5134 accuray : 0.927536231884058  loss : 0.30797613708939353\n",
      "iterations 5135 accuray : 0.927536231884058  loss : 0.3079617321886508\n",
      "iterations 5136 accuray : 0.927536231884058  loss : 0.3079476061720148\n",
      "iterations 5137 accuray : 0.927536231884058  loss : 0.30793309377007566\n",
      "iterations 5138 accuray : 0.9277462717916404  loss : 0.30791855732158957\n",
      "iterations 5139 accuray : 0.927536231884058  loss : 0.30790457736025795\n",
      "iterations 5140 accuray : 0.927536231884058  loss : 0.3078907136331834\n",
      "iterations 5141 accuray : 0.927536231884058  loss : 0.30787633769688627\n",
      "iterations 5142 accuray : 0.927536231884058  loss : 0.30786230561968225\n",
      "iterations 5143 accuray : 0.9277462717916404  loss : 0.3078483846234527\n",
      "iterations 5144 accuray : 0.9277462717916404  loss : 0.30783489299900674\n",
      "iterations 5145 accuray : 0.9277462717916404  loss : 0.3078209444477987\n",
      "iterations 5146 accuray : 0.9277462717916404  loss : 0.30780684263988467\n",
      "iterations 5147 accuray : 0.9277462717916404  loss : 0.30779282139154623\n",
      "iterations 5148 accuray : 0.927536231884058  loss : 0.307778924834525\n",
      "iterations 5149 accuray : 0.927536231884058  loss : 0.30776511757380814\n",
      "iterations 5150 accuray : 0.927536231884058  loss : 0.3077507753698927\n",
      "iterations 5151 accuray : 0.927536231884058  loss : 0.3077373305010334\n",
      "iterations 5152 accuray : 0.927536231884058  loss : 0.307723586610056\n",
      "iterations 5153 accuray : 0.9277462717916404  loss : 0.30770935315841336\n",
      "iterations 5154 accuray : 0.9277462717916404  loss : 0.30769490684253165\n",
      "iterations 5155 accuray : 0.9277462717916404  loss : 0.3076803113894891\n",
      "iterations 5156 accuray : 0.9277462717916404  loss : 0.3076662548486345\n",
      "iterations 5157 accuray : 0.9277462717916404  loss : 0.30765218932673283\n",
      "iterations 5158 accuray : 0.9277462717916404  loss : 0.307638187805806\n",
      "iterations 5159 accuray : 0.9277462717916404  loss : 0.3076248690682839\n",
      "iterations 5160 accuray : 0.9277462717916404  loss : 0.30761089655125023\n",
      "iterations 5161 accuray : 0.9277462717916404  loss : 0.3075974015675897\n",
      "iterations 5162 accuray : 0.9277462717916404  loss : 0.3075830159039686\n",
      "iterations 5163 accuray : 0.9277462717916404  loss : 0.3075690920707141\n",
      "iterations 5164 accuray : 0.9277462717916404  loss : 0.30755481690821534\n",
      "iterations 5165 accuray : 0.9277462717916404  loss : 0.3075404682889048\n",
      "iterations 5166 accuray : 0.9277462717916404  loss : 0.3075262824320776\n",
      "iterations 5167 accuray : 0.9277462717916404  loss : 0.30751212488822444\n",
      "iterations 5168 accuray : 0.9277462717916404  loss : 0.3074987645281451\n",
      "iterations 5169 accuray : 0.9277462717916404  loss : 0.30748514559702916\n",
      "iterations 5170 accuray : 0.9277462717916404  loss : 0.307471351907676\n",
      "iterations 5171 accuray : 0.9277462717916404  loss : 0.3074575503779808\n",
      "iterations 5172 accuray : 0.9277462717916404  loss : 0.307443580350775\n",
      "iterations 5173 accuray : 0.9277462717916404  loss : 0.3074301535156764\n",
      "iterations 5174 accuray : 0.9277462717916404  loss : 0.3074164702513458\n",
      "iterations 5175 accuray : 0.9277462717916404  loss : 0.30740193768154367\n",
      "iterations 5176 accuray : 0.9277462717916404  loss : 0.30738796639089194\n",
      "iterations 5177 accuray : 0.9277462717916404  loss : 0.3073747103725911\n",
      "iterations 5178 accuray : 0.9277462717916404  loss : 0.3073611549025551\n",
      "iterations 5179 accuray : 0.9277462717916404  loss : 0.3073471646319544\n",
      "iterations 5180 accuray : 0.9277462717916404  loss : 0.3073329395616466\n",
      "iterations 5181 accuray : 0.9277462717916404  loss : 0.30731924936483734\n",
      "iterations 5182 accuray : 0.9277462717916404  loss : 0.30730540308343895\n",
      "iterations 5183 accuray : 0.9277462717916404  loss : 0.3072913579291637\n",
      "iterations 5184 accuray : 0.9277462717916404  loss : 0.30727763577184747\n",
      "iterations 5185 accuray : 0.9277462717916404  loss : 0.30726435980070005\n",
      "iterations 5186 accuray : 0.9277462717916404  loss : 0.30725073742246817\n",
      "iterations 5187 accuray : 0.9277462717916404  loss : 0.3072374894495778\n",
      "iterations 5188 accuray : 0.9277462717916404  loss : 0.307223837140362\n",
      "iterations 5189 accuray : 0.9277462717916404  loss : 0.30721057402419466\n",
      "iterations 5190 accuray : 0.9277462717916404  loss : 0.30719681892394773\n",
      "iterations 5191 accuray : 0.9277462717916404  loss : 0.3071829660069368\n",
      "iterations 5192 accuray : 0.9277462717916404  loss : 0.30716941943925574\n",
      "iterations 5193 accuray : 0.9277462717916404  loss : 0.30715605480388547\n",
      "iterations 5194 accuray : 0.9277462717916404  loss : 0.3071414935323235\n",
      "iterations 5195 accuray : 0.9277462717916404  loss : 0.30712783174509645\n",
      "iterations 5196 accuray : 0.9277462717916404  loss : 0.3071140185316354\n",
      "iterations 5197 accuray : 0.9277462717916404  loss : 0.3071003411032839\n",
      "iterations 5198 accuray : 0.9277462717916404  loss : 0.3070870343775697\n",
      "iterations 5199 accuray : 0.9277462717916404  loss : 0.30707318906391673\n",
      "iterations 5200 accuray : 0.9277462717916404  loss : 0.3070597070760622\n",
      "iterations 5201 accuray : 0.9277462717916404  loss : 0.30704584079013214\n",
      "iterations 5202 accuray : 0.9277462717916404  loss : 0.30703277056627926\n",
      "iterations 5203 accuray : 0.9277462717916404  loss : 0.3070178698334304\n",
      "iterations 5204 accuray : 0.9273261919764755  loss : 0.30700367624956765\n",
      "iterations 5205 accuray : 0.9273261919764755  loss : 0.30698997396381117\n",
      "iterations 5206 accuray : 0.9277462717916404  loss : 0.3069766315115343\n",
      "iterations 5207 accuray : 0.9277462717916404  loss : 0.30696359274444796\n",
      "iterations 5208 accuray : 0.9277462717916404  loss : 0.3069499300054949\n",
      "iterations 5209 accuray : 0.927536231884058  loss : 0.306936504098934\n",
      "iterations 5210 accuray : 0.927536231884058  loss : 0.3069230579071333\n",
      "iterations 5211 accuray : 0.9277462717916404  loss : 0.3069095197148975\n",
      "iterations 5212 accuray : 0.9277462717916404  loss : 0.30689608957363845\n",
      "iterations 5213 accuray : 0.927536231884058  loss : 0.3068818943172312\n",
      "iterations 5214 accuray : 0.927536231884058  loss : 0.3068678144232876\n",
      "iterations 5215 accuray : 0.927536231884058  loss : 0.3068541639899229\n",
      "iterations 5216 accuray : 0.9273261919764755  loss : 0.30684019091144354\n",
      "iterations 5217 accuray : 0.9273261919764755  loss : 0.3068263084252501\n",
      "iterations 5218 accuray : 0.9273261919764755  loss : 0.306812238161553\n",
      "iterations 5219 accuray : 0.9273261919764755  loss : 0.30679876517008586\n",
      "iterations 5220 accuray : 0.9273261919764755  loss : 0.30678511230563116\n",
      "iterations 5221 accuray : 0.9273261919764755  loss : 0.30677088130303237\n",
      "iterations 5222 accuray : 0.9273261919764755  loss : 0.30675705729337466\n",
      "iterations 5223 accuray : 0.9273261919764755  loss : 0.30674382105276865\n",
      "iterations 5224 accuray : 0.9273261919764755  loss : 0.30673002281980527\n",
      "iterations 5225 accuray : 0.9273261919764755  loss : 0.3067165299158489\n",
      "iterations 5226 accuray : 0.9273261919764755  loss : 0.3067029177156904\n",
      "iterations 5227 accuray : 0.9273261919764755  loss : 0.3066890897709456\n",
      "iterations 5228 accuray : 0.9273261919764755  loss : 0.3066751220414374\n",
      "iterations 5229 accuray : 0.9273261919764755  loss : 0.30666190055236225\n",
      "iterations 5230 accuray : 0.927536231884058  loss : 0.3066478962732717\n",
      "iterations 5231 accuray : 0.927536231884058  loss : 0.30663437747889255\n",
      "iterations 5232 accuray : 0.927536231884058  loss : 0.3066204411447174\n",
      "iterations 5233 accuray : 0.927536231884058  loss : 0.3066072117210595\n",
      "iterations 5234 accuray : 0.9277462717916404  loss : 0.3065934339752173\n",
      "iterations 5235 accuray : 0.9277462717916404  loss : 0.3065795871514157\n",
      "iterations 5236 accuray : 0.927536231884058  loss : 0.30656557737472695\n",
      "iterations 5237 accuray : 0.927536231884058  loss : 0.30655172917126533\n",
      "iterations 5238 accuray : 0.9273261919764755  loss : 0.30653866307936634\n",
      "iterations 5239 accuray : 0.9273261919764755  loss : 0.3065247913336121\n",
      "iterations 5240 accuray : 0.927536231884058  loss : 0.30651139784300213\n",
      "iterations 5241 accuray : 0.9273261919764755  loss : 0.3064973130811699\n",
      "iterations 5242 accuray : 0.9273261919764755  loss : 0.3064831345495868\n",
      "iterations 5243 accuray : 0.9273261919764755  loss : 0.30646878518363296\n",
      "iterations 5244 accuray : 0.9273261919764755  loss : 0.3064549551489746\n",
      "iterations 5245 accuray : 0.9271161520688931  loss : 0.3064412837593083\n",
      "iterations 5246 accuray : 0.9269061121613107  loss : 0.3064272946229829\n",
      "iterations 5247 accuray : 0.9269061121613107  loss : 0.30641398898924815\n",
      "iterations 5248 accuray : 0.9269061121613107  loss : 0.30640035428060597\n",
      "iterations 5249 accuray : 0.9269061121613107  loss : 0.306386373906702\n",
      "iterations 5250 accuray : 0.9269061121613107  loss : 0.30637266641722616\n",
      "iterations 5251 accuray : 0.9269061121613107  loss : 0.30635868457122367\n",
      "iterations 5252 accuray : 0.9269061121613107  loss : 0.3063443756418452\n",
      "iterations 5253 accuray : 0.9269061121613107  loss : 0.30633026721267875\n",
      "iterations 5254 accuray : 0.9269061121613107  loss : 0.3063162953969006\n",
      "iterations 5255 accuray : 0.9269061121613107  loss : 0.3063031842187668\n",
      "iterations 5256 accuray : 0.9269061121613107  loss : 0.3062895314246243\n",
      "iterations 5257 accuray : 0.9269061121613107  loss : 0.30627555476199186\n",
      "iterations 5258 accuray : 0.9269061121613107  loss : 0.3062617403994302\n",
      "iterations 5259 accuray : 0.9269061121613107  loss : 0.30624838829987505\n",
      "iterations 5260 accuray : 0.9269061121613107  loss : 0.30623430107278965\n",
      "iterations 5261 accuray : 0.9269061121613107  loss : 0.3062212259682894\n",
      "iterations 5262 accuray : 0.9269061121613107  loss : 0.3062077064953199\n",
      "iterations 5263 accuray : 0.9269061121613107  loss : 0.3061937925199701\n",
      "iterations 5264 accuray : 0.9269061121613107  loss : 0.3061802126760716\n",
      "iterations 5265 accuray : 0.9269061121613107  loss : 0.3061664853062584\n",
      "iterations 5266 accuray : 0.9269061121613107  loss : 0.3061527616757798\n",
      "iterations 5267 accuray : 0.9269061121613107  loss : 0.3061398151642314\n",
      "iterations 5268 accuray : 0.9269061121613107  loss : 0.3061262778939872\n",
      "iterations 5269 accuray : 0.9269061121613107  loss : 0.30611240924615646\n",
      "iterations 5270 accuray : 0.9269061121613107  loss : 0.3060995881209315\n",
      "iterations 5271 accuray : 0.9269061121613107  loss : 0.3060859196093187\n",
      "iterations 5272 accuray : 0.9269061121613107  loss : 0.3060725454983912\n",
      "iterations 5273 accuray : 0.9269061121613107  loss : 0.3060589770432048\n",
      "iterations 5274 accuray : 0.9269061121613107  loss : 0.3060452947911874\n",
      "iterations 5275 accuray : 0.9269061121613107  loss : 0.3060323593347897\n",
      "iterations 5276 accuray : 0.9269061121613107  loss : 0.30601872435085553\n",
      "iterations 5277 accuray : 0.9269061121613107  loss : 0.3060052905082964\n",
      "iterations 5278 accuray : 0.9269061121613107  loss : 0.30599241131348426\n",
      "iterations 5279 accuray : 0.9269061121613107  loss : 0.30597949319073103\n",
      "iterations 5280 accuray : 0.9269061121613107  loss : 0.3059659733149247\n",
      "iterations 5281 accuray : 0.9269061121613107  loss : 0.30595280595433816\n",
      "iterations 5282 accuray : 0.9269061121613107  loss : 0.3059392028245656\n",
      "iterations 5283 accuray : 0.9269061121613107  loss : 0.30592491835097724\n",
      "iterations 5284 accuray : 0.9269061121613107  loss : 0.30591068861509046\n",
      "iterations 5285 accuray : 0.9269061121613107  loss : 0.3058970380450555\n",
      "iterations 5286 accuray : 0.9269061121613107  loss : 0.30588364063223866\n",
      "iterations 5287 accuray : 0.9269061121613107  loss : 0.3058703742412481\n",
      "iterations 5288 accuray : 0.9269061121613107  loss : 0.30585611660161793\n",
      "iterations 5289 accuray : 0.9269061121613107  loss : 0.30584236826323213\n",
      "iterations 5290 accuray : 0.9269061121613107  loss : 0.3058283592773595\n",
      "iterations 5291 accuray : 0.9269061121613107  loss : 0.305815519009617\n",
      "iterations 5292 accuray : 0.9269061121613107  loss : 0.30580167722010765\n",
      "iterations 5293 accuray : 0.9269061121613107  loss : 0.30578829621505854\n",
      "iterations 5294 accuray : 0.9269061121613107  loss : 0.3057747687068781\n",
      "iterations 5295 accuray : 0.9269061121613107  loss : 0.30576111046768195\n",
      "iterations 5296 accuray : 0.9269061121613107  loss : 0.30574741202906786\n",
      "iterations 5297 accuray : 0.9269061121613107  loss : 0.30573336395688605\n",
      "iterations 5298 accuray : 0.9269061121613107  loss : 0.30571933392768313\n",
      "iterations 5299 accuray : 0.9269061121613107  loss : 0.3057064845175336\n",
      "iterations 5300 accuray : 0.9269061121613107  loss : 0.3056926853359834\n",
      "iterations 5301 accuray : 0.9269061121613107  loss : 0.30567963999397496\n",
      "iterations 5302 accuray : 0.9269061121613107  loss : 0.30566594488579696\n",
      "iterations 5303 accuray : 0.9269061121613107  loss : 0.30565314790611287\n",
      "iterations 5304 accuray : 0.9269061121613107  loss : 0.30563942230674207\n",
      "iterations 5305 accuray : 0.9269061121613107  loss : 0.3056269682666947\n",
      "iterations 5306 accuray : 0.9269061121613107  loss : 0.3056136552539844\n",
      "iterations 5307 accuray : 0.9269061121613107  loss : 0.3056004245604368\n",
      "iterations 5308 accuray : 0.9269061121613107  loss : 0.3055871977931593\n",
      "iterations 5309 accuray : 0.9269061121613107  loss : 0.3055736093559261\n",
      "iterations 5310 accuray : 0.9269061121613107  loss : 0.30555990703651265\n",
      "iterations 5311 accuray : 0.9269061121613107  loss : 0.305546028912988\n",
      "iterations 5312 accuray : 0.9269061121613107  loss : 0.3055325163575458\n",
      "iterations 5313 accuray : 0.9269061121613107  loss : 0.3055194082676933\n",
      "iterations 5314 accuray : 0.9271161520688931  loss : 0.3055054168495072\n",
      "iterations 5315 accuray : 0.9269061121613107  loss : 0.30549238134513285\n",
      "iterations 5316 accuray : 0.9271161520688931  loss : 0.3054786729165524\n",
      "iterations 5317 accuray : 0.9271161520688931  loss : 0.3054653420758517\n",
      "iterations 5318 accuray : 0.9271161520688931  loss : 0.30545180455923365\n",
      "iterations 5319 accuray : 0.9271161520688931  loss : 0.3054385515055874\n",
      "iterations 5320 accuray : 0.9271161520688931  loss : 0.30542506836323996\n",
      "iterations 5321 accuray : 0.9271161520688931  loss : 0.3054120670070382\n",
      "iterations 5322 accuray : 0.9271161520688931  loss : 0.30539852916939497\n",
      "iterations 5323 accuray : 0.9271161520688931  loss : 0.30538531892662407\n",
      "iterations 5324 accuray : 0.9271161520688931  loss : 0.305371925278942\n",
      "iterations 5325 accuray : 0.9271161520688931  loss : 0.3053588759335368\n",
      "iterations 5326 accuray : 0.9269061121613107  loss : 0.3053458010312542\n",
      "iterations 5327 accuray : 0.9269061121613107  loss : 0.3053324581536796\n",
      "iterations 5328 accuray : 0.9269061121613107  loss : 0.3053186629531763\n",
      "iterations 5329 accuray : 0.9269061121613107  loss : 0.30530544708196317\n",
      "iterations 5330 accuray : 0.9269061121613107  loss : 0.30529198953479275\n",
      "iterations 5331 accuray : 0.9269061121613107  loss : 0.30527928159303813\n",
      "iterations 5332 accuray : 0.9271161520688931  loss : 0.3052664687343936\n",
      "iterations 5333 accuray : 0.9269061121613107  loss : 0.3052528518511268\n",
      "iterations 5334 accuray : 0.9271161520688931  loss : 0.3052396879176113\n",
      "iterations 5335 accuray : 0.9271161520688931  loss : 0.30522645722139796\n",
      "iterations 5336 accuray : 0.9271161520688931  loss : 0.3052127559577328\n",
      "iterations 5337 accuray : 0.9269061121613107  loss : 0.30519986033127494\n",
      "iterations 5338 accuray : 0.9269061121613107  loss : 0.3051862777114825\n",
      "iterations 5339 accuray : 0.9269061121613107  loss : 0.30517372583982527\n",
      "iterations 5340 accuray : 0.9269061121613107  loss : 0.3051609414251252\n",
      "iterations 5341 accuray : 0.9269061121613107  loss : 0.3051475103297863\n",
      "iterations 5342 accuray : 0.9269061121613107  loss : 0.3051344525474515\n",
      "iterations 5343 accuray : 0.9269061121613107  loss : 0.3051213083593749\n",
      "iterations 5344 accuray : 0.9269061121613107  loss : 0.30510904814143186\n",
      "iterations 5345 accuray : 0.9269061121613107  loss : 0.3050953090721746\n",
      "iterations 5346 accuray : 0.9269061121613107  loss : 0.3050816023168349\n",
      "iterations 5347 accuray : 0.9271161520688931  loss : 0.3050678072298753\n",
      "iterations 5348 accuray : 0.9269061121613107  loss : 0.30505394077595976\n",
      "iterations 5349 accuray : 0.9269061121613107  loss : 0.30504082135395166\n",
      "iterations 5350 accuray : 0.9269061121613107  loss : 0.30502744770817014\n",
      "iterations 5351 accuray : 0.9269061121613107  loss : 0.3050142370882349\n",
      "iterations 5352 accuray : 0.9269061121613107  loss : 0.3050012783880068\n",
      "iterations 5353 accuray : 0.9269061121613107  loss : 0.3049881752502721\n",
      "iterations 5354 accuray : 0.9269061121613107  loss : 0.3049747949944636\n",
      "iterations 5355 accuray : 0.9269061121613107  loss : 0.30496123752894966\n",
      "iterations 5356 accuray : 0.9269061121613107  loss : 0.3049479547903036\n",
      "iterations 5357 accuray : 0.9269061121613107  loss : 0.3049346692388747\n",
      "iterations 5358 accuray : 0.9266960722537282  loss : 0.30492123399440096\n",
      "iterations 5359 accuray : 0.9266960722537282  loss : 0.30490772388998943\n",
      "iterations 5360 accuray : 0.9266960722537282  loss : 0.30489488013925975\n",
      "iterations 5361 accuray : 0.9266960722537282  loss : 0.3048813026221761\n",
      "iterations 5362 accuray : 0.9266960722537282  loss : 0.30486786560394374\n",
      "iterations 5363 accuray : 0.9266960722537282  loss : 0.30485490612088406\n",
      "iterations 5364 accuray : 0.9266960722537282  loss : 0.3048419019359301\n",
      "iterations 5365 accuray : 0.9266960722537282  loss : 0.3048289477412765\n",
      "iterations 5366 accuray : 0.9266960722537282  loss : 0.3048158841184227\n",
      "iterations 5367 accuray : 0.9266960722537282  loss : 0.3048024953586886\n",
      "iterations 5368 accuray : 0.9266960722537282  loss : 0.3047893877434594\n",
      "iterations 5369 accuray : 0.9266960722537282  loss : 0.304776266689858\n",
      "iterations 5370 accuray : 0.9266960722537282  loss : 0.3047632908809485\n",
      "iterations 5371 accuray : 0.9266960722537282  loss : 0.304750097975082\n",
      "iterations 5372 accuray : 0.9266960722537282  loss : 0.3047367773234972\n",
      "iterations 5373 accuray : 0.9266960722537282  loss : 0.30472349953776956\n",
      "iterations 5374 accuray : 0.9266960722537282  loss : 0.304710067718\n",
      "iterations 5375 accuray : 0.9266960722537282  loss : 0.3046965098524376\n",
      "iterations 5376 accuray : 0.9266960722537282  loss : 0.30468386995376767\n",
      "iterations 5377 accuray : 0.9266960722537282  loss : 0.3046710733741167\n",
      "iterations 5378 accuray : 0.9266960722537282  loss : 0.3046573134438911\n",
      "iterations 5379 accuray : 0.9266960722537282  loss : 0.30464389611005205\n",
      "iterations 5380 accuray : 0.9266960722537282  loss : 0.30463076024167185\n",
      "iterations 5381 accuray : 0.9266960722537282  loss : 0.30461728376885133\n",
      "iterations 5382 accuray : 0.9266960722537282  loss : 0.30460403582420587\n",
      "iterations 5383 accuray : 0.9266960722537282  loss : 0.3045908703617719\n",
      "iterations 5384 accuray : 0.9266960722537282  loss : 0.30457771088876345\n",
      "iterations 5385 accuray : 0.9266960722537282  loss : 0.30456418083056724\n",
      "iterations 5386 accuray : 0.9266960722537282  loss : 0.30455113247522164\n",
      "iterations 5387 accuray : 0.9266960722537282  loss : 0.3045378251738711\n",
      "iterations 5388 accuray : 0.9266960722537282  loss : 0.3045245980586707\n",
      "iterations 5389 accuray : 0.9266960722537282  loss : 0.3045115161588209\n",
      "iterations 5390 accuray : 0.9266960722537282  loss : 0.30449878515134843\n",
      "iterations 5391 accuray : 0.9266960722537282  loss : 0.304485853388713\n",
      "iterations 5392 accuray : 0.9266960722537282  loss : 0.30447270114648517\n",
      "iterations 5393 accuray : 0.9266960722537282  loss : 0.3044594551318022\n",
      "iterations 5394 accuray : 0.9266960722537282  loss : 0.3044464644439974\n",
      "iterations 5395 accuray : 0.9266960722537282  loss : 0.3044333256088219\n",
      "iterations 5396 accuray : 0.9266960722537282  loss : 0.30442054312077016\n",
      "iterations 5397 accuray : 0.9266960722537282  loss : 0.3044081253589697\n",
      "iterations 5398 accuray : 0.9266960722537282  loss : 0.30439461235752696\n",
      "iterations 5399 accuray : 0.9266960722537282  loss : 0.3043816580680812\n",
      "iterations 5400 accuray : 0.9266960722537282  loss : 0.3043691035594583\n",
      "iterations 5401 accuray : 0.9266960722537282  loss : 0.3043558467000338\n",
      "iterations 5402 accuray : 0.9266960722537282  loss : 0.30434304759339187\n",
      "iterations 5403 accuray : 0.9266960722537282  loss : 0.3043302505166645\n",
      "iterations 5404 accuray : 0.9266960722537282  loss : 0.3043171966931379\n",
      "iterations 5405 accuray : 0.9266960722537282  loss : 0.30430413144728863\n",
      "iterations 5406 accuray : 0.9266960722537282  loss : 0.3042909432249602\n",
      "iterations 5407 accuray : 0.9266960722537282  loss : 0.3042782593040218\n",
      "iterations 5408 accuray : 0.9264860323461458  loss : 0.3042646419280256\n",
      "iterations 5409 accuray : 0.9264860323461458  loss : 0.3042515093785873\n",
      "iterations 5410 accuray : 0.9264860323461458  loss : 0.3042379929268205\n",
      "iterations 5411 accuray : 0.9264860323461458  loss : 0.30422438918225925\n",
      "iterations 5412 accuray : 0.9264860323461458  loss : 0.3042111427424201\n",
      "iterations 5413 accuray : 0.9264860323461458  loss : 0.3041976567714645\n",
      "iterations 5414 accuray : 0.9264860323461458  loss : 0.30418418659583824\n",
      "iterations 5415 accuray : 0.9264860323461458  loss : 0.30417087828223055\n",
      "iterations 5416 accuray : 0.9264860323461458  loss : 0.3041579739137704\n",
      "iterations 5417 accuray : 0.9264860323461458  loss : 0.3041446131192303\n",
      "iterations 5418 accuray : 0.9264860323461458  loss : 0.30413168785478223\n",
      "iterations 5419 accuray : 0.9264860323461458  loss : 0.30411876991825276\n",
      "iterations 5420 accuray : 0.9264860323461458  loss : 0.30410530220608156\n",
      "iterations 5421 accuray : 0.9264860323461458  loss : 0.30409260832004364\n",
      "iterations 5422 accuray : 0.9264860323461458  loss : 0.30407939556909147\n",
      "iterations 5423 accuray : 0.9264860323461458  loss : 0.30406674091165503\n",
      "iterations 5424 accuray : 0.9264860323461458  loss : 0.30405409922120735\n",
      "iterations 5425 accuray : 0.9264860323461458  loss : 0.304040996351399\n",
      "iterations 5426 accuray : 0.9264860323461458  loss : 0.30402776991901026\n",
      "iterations 5427 accuray : 0.9264860323461458  loss : 0.3040143798974448\n",
      "iterations 5428 accuray : 0.9264860323461458  loss : 0.30400081643566707\n",
      "iterations 5429 accuray : 0.9264860323461458  loss : 0.3039876327696353\n",
      "iterations 5430 accuray : 0.9264860323461458  loss : 0.3039749784732167\n",
      "iterations 5431 accuray : 0.9264860323461458  loss : 0.3039616451222676\n",
      "iterations 5432 accuray : 0.9264860323461458  loss : 0.30394892802729095\n",
      "iterations 5433 accuray : 0.9264860323461458  loss : 0.3039355220053125\n",
      "iterations 5434 accuray : 0.9264860323461458  loss : 0.3039220520338807\n",
      "iterations 5435 accuray : 0.9264860323461458  loss : 0.3039092159654166\n",
      "iterations 5436 accuray : 0.9264860323461458  loss : 0.3038960093753074\n",
      "iterations 5437 accuray : 0.9264860323461458  loss : 0.30388326558724366\n",
      "iterations 5438 accuray : 0.9264860323461458  loss : 0.3038710903635965\n",
      "iterations 5439 accuray : 0.9264860323461458  loss : 0.3038579036855986\n",
      "iterations 5440 accuray : 0.9264860323461458  loss : 0.30384494672150547\n",
      "iterations 5441 accuray : 0.9264860323461458  loss : 0.3038322728212244\n",
      "iterations 5442 accuray : 0.9264860323461458  loss : 0.3038196043009188\n",
      "iterations 5443 accuray : 0.9264860323461458  loss : 0.3038062761225218\n",
      "iterations 5444 accuray : 0.9264860323461458  loss : 0.30379341707769275\n",
      "iterations 5445 accuray : 0.9264860323461458  loss : 0.303780786340171\n",
      "iterations 5446 accuray : 0.9264860323461458  loss : 0.3037683354919972\n",
      "iterations 5447 accuray : 0.9264860323461458  loss : 0.3037546617884839\n",
      "iterations 5448 accuray : 0.9264860323461458  loss : 0.30374225912018255\n",
      "iterations 5449 accuray : 0.9262759924385633  loss : 0.3037290776403196\n",
      "iterations 5450 accuray : 0.9264860323461458  loss : 0.3037164249178251\n",
      "iterations 5451 accuray : 0.9262759924385633  loss : 0.3037030333595766\n",
      "iterations 5452 accuray : 0.9262759924385633  loss : 0.30369018039931933\n",
      "iterations 5453 accuray : 0.9262759924385633  loss : 0.30367726502205566\n",
      "iterations 5454 accuray : 0.9262759924385633  loss : 0.30366406938811946\n",
      "iterations 5455 accuray : 0.9262759924385633  loss : 0.3036513842861943\n",
      "iterations 5456 accuray : 0.9264860323461458  loss : 0.3036387216277374\n",
      "iterations 5457 accuray : 0.9262759924385633  loss : 0.3036257152136165\n",
      "iterations 5458 accuray : 0.9262759924385633  loss : 0.30361320365485567\n",
      "iterations 5459 accuray : 0.9262759924385633  loss : 0.3035999637545235\n",
      "iterations 5460 accuray : 0.9262759924385633  loss : 0.30358663526683105\n",
      "iterations 5461 accuray : 0.9262759924385633  loss : 0.3035738920849016\n",
      "iterations 5462 accuray : 0.9262759924385633  loss : 0.3035611193170131\n",
      "iterations 5463 accuray : 0.9262759924385633  loss : 0.30354792997291125\n",
      "iterations 5464 accuray : 0.9262759924385633  loss : 0.30353533867651655\n",
      "iterations 5465 accuray : 0.9262759924385633  loss : 0.30352255501400693\n",
      "iterations 5466 accuray : 0.9262759924385633  loss : 0.3035093494659131\n",
      "iterations 5467 accuray : 0.9262759924385633  loss : 0.30349668610935177\n",
      "iterations 5468 accuray : 0.9262759924385633  loss : 0.30348375523168203\n",
      "iterations 5469 accuray : 0.9262759924385633  loss : 0.3034712385578917\n",
      "iterations 5470 accuray : 0.9262759924385633  loss : 0.3034583333091674\n",
      "iterations 5471 accuray : 0.9262759924385633  loss : 0.30344540566681405\n",
      "iterations 5472 accuray : 0.9262759924385633  loss : 0.3034333051402732\n",
      "iterations 5473 accuray : 0.9262759924385633  loss : 0.30341973144332346\n",
      "iterations 5474 accuray : 0.9264860323461458  loss : 0.3034071857635538\n",
      "iterations 5475 accuray : 0.9264860323461458  loss : 0.30339485243557685\n",
      "iterations 5476 accuray : 0.9264860323461458  loss : 0.30338254225207606\n",
      "iterations 5477 accuray : 0.9264860323461458  loss : 0.3033701361628412\n",
      "iterations 5478 accuray : 0.9264860323461458  loss : 0.30335741647838677\n",
      "iterations 5479 accuray : 0.9262759924385633  loss : 0.3033446867201247\n",
      "iterations 5480 accuray : 0.9262759924385633  loss : 0.30333155488912045\n",
      "iterations 5481 accuray : 0.9262759924385633  loss : 0.30331897169707756\n",
      "iterations 5482 accuray : 0.9264860323461458  loss : 0.30330591536760904\n",
      "iterations 5483 accuray : 0.9264860323461458  loss : 0.30329292666839935\n",
      "iterations 5484 accuray : 0.9262759924385633  loss : 0.3032798139058242\n",
      "iterations 5485 accuray : 0.9262759924385633  loss : 0.3032672259068348\n",
      "iterations 5486 accuray : 0.9262759924385633  loss : 0.3032536708808972\n",
      "iterations 5487 accuray : 0.9262759924385633  loss : 0.30324131808974714\n",
      "iterations 5488 accuray : 0.9262759924385633  loss : 0.303228243220985\n",
      "iterations 5489 accuray : 0.9262759924385633  loss : 0.3032155914933137\n",
      "iterations 5490 accuray : 0.9262759924385633  loss : 0.30320278351240765\n",
      "iterations 5491 accuray : 0.9262759924385633  loss : 0.30318975926037706\n",
      "iterations 5492 accuray : 0.9262759924385633  loss : 0.3031769662449961\n",
      "iterations 5493 accuray : 0.9262759924385633  loss : 0.30316451759736257\n",
      "iterations 5494 accuray : 0.9262759924385633  loss : 0.303151350051364\n",
      "iterations 5495 accuray : 0.9262759924385633  loss : 0.3031387431273501\n",
      "iterations 5496 accuray : 0.9262759924385633  loss : 0.30312603296203355\n",
      "iterations 5497 accuray : 0.9262759924385633  loss : 0.30311353428867643\n",
      "iterations 5498 accuray : 0.9262759924385633  loss : 0.30310066122136176\n",
      "iterations 5499 accuray : 0.9262759924385633  loss : 0.3030886652418587\n",
      "iterations 5500 accuray : 0.9262759924385633  loss : 0.30307591164156583\n",
      "iterations 5501 accuray : 0.9262759924385633  loss : 0.3030633542865313\n",
      "iterations 5502 accuray : 0.9262759924385633  loss : 0.303050768720386\n",
      "iterations 5503 accuray : 0.9262759924385633  loss : 0.30303779198145203\n",
      "iterations 5504 accuray : 0.9262759924385633  loss : 0.3030249193165359\n",
      "iterations 5505 accuray : 0.9266960722537282  loss : 0.30301150126042337\n",
      "iterations 5506 accuray : 0.9266960722537282  loss : 0.3029985665703489\n",
      "iterations 5507 accuray : 0.9266960722537282  loss : 0.30298511559652946\n",
      "iterations 5508 accuray : 0.9266960722537282  loss : 0.30297219801952574\n",
      "iterations 5509 accuray : 0.9266960722537282  loss : 0.3029590112333485\n",
      "iterations 5510 accuray : 0.9266960722537282  loss : 0.3029463465683426\n",
      "iterations 5511 accuray : 0.9266960722537282  loss : 0.3029333564793598\n",
      "iterations 5512 accuray : 0.9266960722537282  loss : 0.30292135398801284\n",
      "iterations 5513 accuray : 0.9266960722537282  loss : 0.3029092512534005\n",
      "iterations 5514 accuray : 0.9266960722537282  loss : 0.3028967775857119\n",
      "iterations 5515 accuray : 0.9266960722537282  loss : 0.30288432406136767\n",
      "iterations 5516 accuray : 0.9266960722537282  loss : 0.30287095365660166\n",
      "iterations 5517 accuray : 0.9266960722537282  loss : 0.3028581908408601\n",
      "iterations 5518 accuray : 0.9266960722537282  loss : 0.30284565424927684\n",
      "iterations 5519 accuray : 0.9266960722537282  loss : 0.3028327880389886\n",
      "iterations 5520 accuray : 0.9266960722537282  loss : 0.30282034949662495\n",
      "iterations 5521 accuray : 0.9266960722537282  loss : 0.3028075319690024\n",
      "iterations 5522 accuray : 0.9264860323461458  loss : 0.3027943980150016\n",
      "iterations 5523 accuray : 0.9264860323461458  loss : 0.3027815854309743\n",
      "iterations 5524 accuray : 0.9264860323461458  loss : 0.30276834761028426\n",
      "iterations 5525 accuray : 0.9264860323461458  loss : 0.3027555006854595\n",
      "iterations 5526 accuray : 0.9266960722537282  loss : 0.30274344193540714\n",
      "iterations 5527 accuray : 0.9266960722537282  loss : 0.30273087360787226\n",
      "iterations 5528 accuray : 0.9266960722537282  loss : 0.302718068555584\n",
      "iterations 5529 accuray : 0.9266960722537282  loss : 0.30270571056763595\n",
      "iterations 5530 accuray : 0.9266960722537282  loss : 0.3026935315652489\n",
      "iterations 5531 accuray : 0.9266960722537282  loss : 0.3026809601168258\n",
      "iterations 5532 accuray : 0.9266960722537282  loss : 0.30266901544624036\n",
      "iterations 5533 accuray : 0.9266960722537282  loss : 0.3026567622651565\n",
      "iterations 5534 accuray : 0.9266960722537282  loss : 0.30264356114761504\n",
      "iterations 5535 accuray : 0.9266960722537282  loss : 0.3026305659554612\n",
      "iterations 5536 accuray : 0.9266960722537282  loss : 0.30261771074869454\n",
      "iterations 5537 accuray : 0.9266960722537282  loss : 0.30260544097004377\n",
      "iterations 5538 accuray : 0.9266960722537282  loss : 0.3025928672477269\n",
      "iterations 5539 accuray : 0.9266960722537282  loss : 0.3025803346183076\n",
      "iterations 5540 accuray : 0.9266960722537282  loss : 0.30256763614203436\n",
      "iterations 5541 accuray : 0.9266960722537282  loss : 0.30255517059289766\n",
      "iterations 5542 accuray : 0.9266960722537282  loss : 0.30254265645646927\n",
      "iterations 5543 accuray : 0.9266960722537282  loss : 0.30252980542597774\n",
      "iterations 5544 accuray : 0.9266960722537282  loss : 0.30251710647989355\n",
      "iterations 5545 accuray : 0.9266960722537282  loss : 0.30250469429974963\n",
      "iterations 5546 accuray : 0.9266960722537282  loss : 0.30249202302200606\n",
      "iterations 5547 accuray : 0.9266960722537282  loss : 0.30247961110909927\n",
      "iterations 5548 accuray : 0.9266960722537282  loss : 0.30246678165756613\n",
      "iterations 5549 accuray : 0.9266960722537282  loss : 0.3024545725036911\n",
      "iterations 5550 accuray : 0.9266960722537282  loss : 0.3024422744288906\n",
      "iterations 5551 accuray : 0.9266960722537282  loss : 0.3024300073274266\n",
      "iterations 5552 accuray : 0.9266960722537282  loss : 0.30241732201784643\n",
      "iterations 5553 accuray : 0.9266960722537282  loss : 0.30240542953066996\n",
      "iterations 5554 accuray : 0.9266960722537282  loss : 0.30239252760800434\n",
      "iterations 5555 accuray : 0.9266960722537282  loss : 0.3023801175973414\n",
      "iterations 5556 accuray : 0.9266960722537282  loss : 0.3023684312260387\n",
      "iterations 5557 accuray : 0.9264860323461458  loss : 0.30235613454929317\n",
      "iterations 5558 accuray : 0.9262759924385633  loss : 0.30234375420246373\n",
      "iterations 5559 accuray : 0.9262759924385633  loss : 0.3023315342635407\n",
      "iterations 5560 accuray : 0.9262759924385633  loss : 0.30231923640654507\n",
      "iterations 5561 accuray : 0.9262759924385633  loss : 0.3023065404981886\n",
      "iterations 5562 accuray : 0.9262759924385633  loss : 0.30229426494140604\n",
      "iterations 5563 accuray : 0.9262759924385633  loss : 0.30228144949799973\n",
      "iterations 5564 accuray : 0.9262759924385633  loss : 0.3022687115215748\n",
      "iterations 5565 accuray : 0.9262759924385633  loss : 0.3022565235397425\n",
      "iterations 5566 accuray : 0.9266960722537282  loss : 0.30224303946528064\n",
      "iterations 5567 accuray : 0.9266960722537282  loss : 0.30223097572153385\n",
      "iterations 5568 accuray : 0.9262759924385633  loss : 0.30221861565078934\n",
      "iterations 5569 accuray : 0.9262759924385633  loss : 0.3022059413538375\n",
      "iterations 5570 accuray : 0.9262759924385633  loss : 0.3021936620982459\n",
      "iterations 5571 accuray : 0.9262759924385633  loss : 0.30218085984772725\n",
      "iterations 5572 accuray : 0.9262759924385633  loss : 0.30216811041404845\n",
      "iterations 5573 accuray : 0.9262759924385633  loss : 0.3021557577157095\n",
      "iterations 5574 accuray : 0.9262759924385633  loss : 0.3021428549341433\n",
      "iterations 5575 accuray : 0.9262759924385633  loss : 0.30213062344472036\n",
      "iterations 5576 accuray : 0.9262759924385633  loss : 0.3021181470761231\n",
      "iterations 5577 accuray : 0.9262759924385633  loss : 0.302106032633904\n",
      "iterations 5578 accuray : 0.9262759924385633  loss : 0.30209335171852886\n",
      "iterations 5579 accuray : 0.9264860323461458  loss : 0.3020804231058838\n",
      "iterations 5580 accuray : 0.9262759924385633  loss : 0.3020682141907638\n",
      "iterations 5581 accuray : 0.9264860323461458  loss : 0.302055231478478\n",
      "iterations 5582 accuray : 0.9262759924385633  loss : 0.30204314866062415\n",
      "iterations 5583 accuray : 0.9262759924385633  loss : 0.302030654830405\n",
      "iterations 5584 accuray : 0.9262759924385633  loss : 0.3020185780801914\n",
      "iterations 5585 accuray : 0.9262759924385633  loss : 0.3020057879974859\n",
      "iterations 5586 accuray : 0.9266960722537282  loss : 0.30199314075135614\n",
      "iterations 5587 accuray : 0.9266960722537282  loss : 0.30198010284129967\n",
      "iterations 5588 accuray : 0.9266960722537282  loss : 0.3019680934477045\n",
      "iterations 5589 accuray : 0.9266960722537282  loss : 0.3019548760853031\n",
      "iterations 5590 accuray : 0.9266960722537282  loss : 0.30194230586234294\n",
      "iterations 5591 accuray : 0.9266960722537282  loss : 0.301930387949245\n",
      "iterations 5592 accuray : 0.9266960722537282  loss : 0.30191767407200015\n",
      "iterations 5593 accuray : 0.9266960722537282  loss : 0.301905235044786\n",
      "iterations 5594 accuray : 0.9266960722537282  loss : 0.3018927631832791\n",
      "iterations 5595 accuray : 0.9266960722537282  loss : 0.301880661886869\n",
      "iterations 5596 accuray : 0.9266960722537282  loss : 0.3018687413453731\n",
      "iterations 5597 accuray : 0.9266960722537282  loss : 0.3018564171929302\n",
      "iterations 5598 accuray : 0.9266960722537282  loss : 0.3018442845712728\n",
      "iterations 5599 accuray : 0.9266960722537282  loss : 0.3018312484923546\n",
      "iterations 5600 accuray : 0.9266960722537282  loss : 0.30181867270907653\n",
      "iterations 5601 accuray : 0.9266960722537282  loss : 0.30180630647672685\n",
      "iterations 5602 accuray : 0.9266960722537282  loss : 0.30179416490303096\n",
      "iterations 5603 accuray : 0.9266960722537282  loss : 0.301781544638748\n",
      "iterations 5604 accuray : 0.9266960722537282  loss : 0.30176967894061996\n",
      "iterations 5605 accuray : 0.9266960722537282  loss : 0.30175662459991864\n",
      "iterations 5606 accuray : 0.9264860323461458  loss : 0.3017434671805892\n",
      "iterations 5607 accuray : 0.9266960722537282  loss : 0.301731455316137\n",
      "iterations 5608 accuray : 0.9264860323461458  loss : 0.3017186943085477\n",
      "iterations 5609 accuray : 0.9264860323461458  loss : 0.3017064823837466\n",
      "iterations 5610 accuray : 0.9264860323461458  loss : 0.3016940437996173\n",
      "iterations 5611 accuray : 0.9264860323461458  loss : 0.30168193517930664\n",
      "iterations 5612 accuray : 0.9264860323461458  loss : 0.3016692935519185\n",
      "iterations 5613 accuray : 0.9264860323461458  loss : 0.30165695930831415\n",
      "iterations 5614 accuray : 0.9264860323461458  loss : 0.30164512947153654\n",
      "iterations 5615 accuray : 0.9264860323461458  loss : 0.3016330542052781\n",
      "iterations 5616 accuray : 0.9264860323461458  loss : 0.3016210008672766\n",
      "iterations 5617 accuray : 0.9264860323461458  loss : 0.30160868391901635\n",
      "iterations 5618 accuray : 0.9264860323461458  loss : 0.30159578237689577\n",
      "iterations 5619 accuray : 0.9264860323461458  loss : 0.3015832512615799\n",
      "iterations 5620 accuray : 0.9264860323461458  loss : 0.30157110545089083\n",
      "iterations 5621 accuray : 0.9264860323461458  loss : 0.3015589636486983\n",
      "iterations 5622 accuray : 0.9264860323461458  loss : 0.3015467928020196\n",
      "iterations 5623 accuray : 0.9262759924385633  loss : 0.30153393350259317\n",
      "iterations 5624 accuray : 0.9264860323461458  loss : 0.30152150319311805\n",
      "iterations 5625 accuray : 0.9264860323461458  loss : 0.3015085198941303\n",
      "iterations 5626 accuray : 0.9262759924385633  loss : 0.3014961213817955\n",
      "iterations 5627 accuray : 0.9262759924385633  loss : 0.30148388595839654\n",
      "iterations 5628 accuray : 0.9262759924385633  loss : 0.3014720273475715\n",
      "iterations 5629 accuray : 0.9262759924385633  loss : 0.3014591919084958\n",
      "iterations 5630 accuray : 0.9262759924385633  loss : 0.3014467496358036\n",
      "iterations 5631 accuray : 0.9262759924385633  loss : 0.3014341066973904\n",
      "iterations 5632 accuray : 0.9260659525309809  loss : 0.30142135731406805\n",
      "iterations 5633 accuray : 0.9264860323461458  loss : 0.3014086215524069\n",
      "iterations 5634 accuray : 0.9264860323461458  loss : 0.30139538137381766\n",
      "iterations 5635 accuray : 0.9264860323461458  loss : 0.30138352263354523\n",
      "iterations 5636 accuray : 0.9264860323461458  loss : 0.30137100797189925\n",
      "iterations 5637 accuray : 0.9264860323461458  loss : 0.3013590065376974\n",
      "iterations 5638 accuray : 0.9264860323461458  loss : 0.30134667178425484\n",
      "iterations 5639 accuray : 0.9264860323461458  loss : 0.301334318165278\n",
      "iterations 5640 accuray : 0.9264860323461458  loss : 0.30132150758323\n",
      "iterations 5641 accuray : 0.9264860323461458  loss : 0.30130964164013807\n",
      "iterations 5642 accuray : 0.9264860323461458  loss : 0.3012973659917103\n",
      "iterations 5643 accuray : 0.9264860323461458  loss : 0.3012848557226869\n",
      "iterations 5644 accuray : 0.9264860323461458  loss : 0.30127189885416455\n",
      "iterations 5645 accuray : 0.9264860323461458  loss : 0.3012596705581398\n",
      "iterations 5646 accuray : 0.9264860323461458  loss : 0.3012477763641591\n",
      "iterations 5647 accuray : 0.9264860323461458  loss : 0.30123562853440145\n",
      "iterations 5648 accuray : 0.9264860323461458  loss : 0.30122358108834774\n",
      "iterations 5649 accuray : 0.9264860323461458  loss : 0.3012113106105949\n",
      "iterations 5650 accuray : 0.9264860323461458  loss : 0.3011990318739178\n",
      "iterations 5651 accuray : 0.9264860323461458  loss : 0.3011867509024181\n",
      "iterations 5652 accuray : 0.9264860323461458  loss : 0.3011744569936163\n",
      "iterations 5653 accuray : 0.9264860323461458  loss : 0.30116161744999065\n",
      "iterations 5654 accuray : 0.9266960722537282  loss : 0.3011484322388477\n",
      "iterations 5655 accuray : 0.9266960722537282  loss : 0.30113570781142646\n",
      "iterations 5656 accuray : 0.9266960722537282  loss : 0.30112355145360403\n",
      "iterations 5657 accuray : 0.9266960722537282  loss : 0.3011111403282363\n",
      "iterations 5658 accuray : 0.9266960722537282  loss : 0.30109884990822405\n",
      "iterations 5659 accuray : 0.9264860323461458  loss : 0.30108691610116656\n",
      "iterations 5660 accuray : 0.9266960722537282  loss : 0.30107450830172094\n",
      "iterations 5661 accuray : 0.9266960722537282  loss : 0.3010615440334165\n",
      "iterations 5662 accuray : 0.9266960722537282  loss : 0.3010492316473019\n",
      "iterations 5663 accuray : 0.9266960722537282  loss : 0.3010371610801934\n",
      "iterations 5664 accuray : 0.9266960722537282  loss : 0.3010242293303528\n",
      "iterations 5665 accuray : 0.9266960722537282  loss : 0.30101198462747913\n",
      "iterations 5666 accuray : 0.9266960722537282  loss : 0.30100011570212176\n",
      "iterations 5667 accuray : 0.9266960722537282  loss : 0.3009877227399098\n",
      "iterations 5668 accuray : 0.9266960722537282  loss : 0.3009756584609672\n",
      "iterations 5669 accuray : 0.9266960722537282  loss : 0.300963062745608\n",
      "iterations 5670 accuray : 0.9266960722537282  loss : 0.3009509979575782\n",
      "iterations 5671 accuray : 0.9266960722537282  loss : 0.3009384234447123\n",
      "iterations 5672 accuray : 0.9266960722537282  loss : 0.3009261786656204\n",
      "iterations 5673 accuray : 0.9266960722537282  loss : 0.3009136460772146\n",
      "iterations 5674 accuray : 0.9266960722537282  loss : 0.30090134953299674\n",
      "iterations 5675 accuray : 0.9266960722537282  loss : 0.30089001362641465\n",
      "iterations 5676 accuray : 0.9266960722537282  loss : 0.3008777704826576\n",
      "iterations 5677 accuray : 0.9266960722537282  loss : 0.3008658071150083\n",
      "iterations 5678 accuray : 0.9266960722537282  loss : 0.30085298843556124\n",
      "iterations 5679 accuray : 0.9266960722537282  loss : 0.30084078658973945\n",
      "iterations 5680 accuray : 0.9266960722537282  loss : 0.3008292686956739\n",
      "iterations 5681 accuray : 0.9266960722537282  loss : 0.30081778756363214\n",
      "iterations 5682 accuray : 0.9266960722537282  loss : 0.30080538388143346\n",
      "iterations 5683 accuray : 0.9266960722537282  loss : 0.30079272947641583\n",
      "iterations 5684 accuray : 0.9266960722537282  loss : 0.30078067163787314\n",
      "iterations 5685 accuray : 0.9266960722537282  loss : 0.3007686596935638\n",
      "iterations 5686 accuray : 0.9266960722537282  loss : 0.3007560011666516\n",
      "iterations 5687 accuray : 0.9266960722537282  loss : 0.30074346521276435\n",
      "iterations 5688 accuray : 0.9266960722537282  loss : 0.30073112781866285\n",
      "iterations 5689 accuray : 0.9266960722537282  loss : 0.30071886939333997\n",
      "iterations 5690 accuray : 0.9266960722537282  loss : 0.3007067453351203\n",
      "iterations 5691 accuray : 0.9266960722537282  loss : 0.30069510039407504\n",
      "iterations 5692 accuray : 0.9266960722537282  loss : 0.3006834183068488\n",
      "iterations 5693 accuray : 0.9266960722537282  loss : 0.30067123465265194\n",
      "iterations 5694 accuray : 0.9266960722537282  loss : 0.3006593188637641\n",
      "iterations 5695 accuray : 0.9266960722537282  loss : 0.3006474435946026\n",
      "iterations 5696 accuray : 0.9266960722537282  loss : 0.30063590402951124\n",
      "iterations 5697 accuray : 0.9266960722537282  loss : 0.3006235158004724\n",
      "iterations 5698 accuray : 0.9266960722537282  loss : 0.3006116300409478\n",
      "iterations 5699 accuray : 0.9266960722537282  loss : 0.3005997172436986\n",
      "iterations 5700 accuray : 0.9266960722537282  loss : 0.30058703596230646\n",
      "iterations 5701 accuray : 0.9266960722537282  loss : 0.30057506421634034\n",
      "iterations 5702 accuray : 0.9266960722537282  loss : 0.3005631978518013\n",
      "iterations 5703 accuray : 0.9266960722537282  loss : 0.3005510136180744\n",
      "iterations 5704 accuray : 0.9266960722537282  loss : 0.30053884037682943\n",
      "iterations 5705 accuray : 0.9266960722537282  loss : 0.30052652322856604\n",
      "iterations 5706 accuray : 0.9266960722537282  loss : 0.30051416857346636\n",
      "iterations 5707 accuray : 0.9266960722537282  loss : 0.30050183348541015\n",
      "iterations 5708 accuray : 0.9266960722537282  loss : 0.3004899842644179\n",
      "iterations 5709 accuray : 0.9266960722537282  loss : 0.300478154104608\n",
      "iterations 5710 accuray : 0.9266960722537282  loss : 0.30046640551261256\n",
      "iterations 5711 accuray : 0.9266960722537282  loss : 0.3004541367628075\n",
      "iterations 5712 accuray : 0.9266960722537282  loss : 0.30044288381725687\n",
      "iterations 5713 accuray : 0.9266960722537282  loss : 0.30043020085515487\n",
      "iterations 5714 accuray : 0.9266960722537282  loss : 0.30041818314712104\n",
      "iterations 5715 accuray : 0.9266960722537282  loss : 0.3004060714106158\n",
      "iterations 5716 accuray : 0.9266960722537282  loss : 0.3003944234695011\n",
      "iterations 5717 accuray : 0.9266960722537282  loss : 0.3003825003558098\n",
      "iterations 5718 accuray : 0.9266960722537282  loss : 0.30036994366664244\n",
      "iterations 5719 accuray : 0.9266960722537282  loss : 0.3003581007126399\n",
      "iterations 5720 accuray : 0.9266960722537282  loss : 0.3003456268181367\n",
      "iterations 5721 accuray : 0.9266960722537282  loss : 0.300333368775008\n",
      "iterations 5722 accuray : 0.9266960722537282  loss : 0.3003212136846724\n",
      "iterations 5723 accuray : 0.9266960722537282  loss : 0.3003093316341689\n",
      "iterations 5724 accuray : 0.9264860323461458  loss : 0.3002969058580276\n",
      "iterations 5725 accuray : 0.9266960722537282  loss : 0.3002851165047017\n",
      "iterations 5726 accuray : 0.9266960722537282  loss : 0.3002727471475985\n",
      "iterations 5727 accuray : 0.9266960722537282  loss : 0.3002607585950151\n",
      "iterations 5728 accuray : 0.9266960722537282  loss : 0.30024932369845553\n",
      "iterations 5729 accuray : 0.9266960722537282  loss : 0.300236843645278\n",
      "iterations 5730 accuray : 0.9264860323461458  loss : 0.3002248642220502\n",
      "iterations 5731 accuray : 0.9266960722537282  loss : 0.30021302869002336\n",
      "iterations 5732 accuray : 0.9264860323461458  loss : 0.300200673742332\n",
      "iterations 5733 accuray : 0.9266960722537282  loss : 0.3001885289119553\n",
      "iterations 5734 accuray : 0.9264860323461458  loss : 0.30017624269935583\n",
      "iterations 5735 accuray : 0.9266960722537282  loss : 0.3001640604457523\n",
      "iterations 5736 accuray : 0.9264860323461458  loss : 0.30015194204272044\n",
      "iterations 5737 accuray : 0.9264860323461458  loss : 0.3001400089285235\n",
      "iterations 5738 accuray : 0.9264860323461458  loss : 0.30012851851364675\n",
      "iterations 5739 accuray : 0.9266960722537282  loss : 0.3001167299135668\n",
      "iterations 5740 accuray : 0.9264860323461458  loss : 0.3001046379807539\n",
      "iterations 5741 accuray : 0.9266960722537282  loss : 0.300092162268495\n",
      "iterations 5742 accuray : 0.9266960722537282  loss : 0.3000804120697049\n",
      "iterations 5743 accuray : 0.9266960722537282  loss : 0.3000690252874345\n",
      "iterations 5744 accuray : 0.9266960722537282  loss : 0.3000571960667974\n",
      "iterations 5745 accuray : 0.9266960722537282  loss : 0.3000447068626061\n",
      "iterations 5746 accuray : 0.9266960722537282  loss : 0.30003287991779526\n",
      "iterations 5747 accuray : 0.9266960722537282  loss : 0.3000204016794407\n",
      "iterations 5748 accuray : 0.9266960722537282  loss : 0.3000085843632798\n",
      "iterations 5749 accuray : 0.9266960722537282  loss : 0.2999965186226683\n",
      "iterations 5750 accuray : 0.9266960722537282  loss : 0.29998438401343425\n",
      "iterations 5751 accuray : 0.9266960722537282  loss : 0.2999722564746791\n",
      "iterations 5752 accuray : 0.9266960722537282  loss : 0.29996062028989784\n",
      "iterations 5753 accuray : 0.9266960722537282  loss : 0.29994880539258323\n",
      "iterations 5754 accuray : 0.9266960722537282  loss : 0.2999367912948357\n",
      "iterations 5755 accuray : 0.9266960722537282  loss : 0.2999246618848752\n",
      "iterations 5756 accuray : 0.9266960722537282  loss : 0.2999131018588274\n",
      "iterations 5757 accuray : 0.9266960722537282  loss : 0.29990131092899647\n",
      "iterations 5758 accuray : 0.9266960722537282  loss : 0.2998893167420275\n",
      "iterations 5759 accuray : 0.9266960722537282  loss : 0.2998770677555563\n",
      "iterations 5760 accuray : 0.9269061121613107  loss : 0.2998650224969061\n",
      "iterations 5761 accuray : 0.9266960722537282  loss : 0.29985346593366885\n",
      "iterations 5762 accuray : 0.9269061121613107  loss : 0.299841261827155\n",
      "iterations 5763 accuray : 0.9269061121613107  loss : 0.2998292721748392\n",
      "iterations 5764 accuray : 0.9269061121613107  loss : 0.2998170921616522\n",
      "iterations 5765 accuray : 0.9269061121613107  loss : 0.29980514392357066\n",
      "iterations 5766 accuray : 0.9269061121613107  loss : 0.2997932517204247\n",
      "iterations 5767 accuray : 0.9269061121613107  loss : 0.2997813547825987\n",
      "iterations 5768 accuray : 0.9269061121613107  loss : 0.2997688144255276\n",
      "iterations 5769 accuray : 0.9269061121613107  loss : 0.29975735652465557\n",
      "iterations 5770 accuray : 0.9269061121613107  loss : 0.29974473213748687\n",
      "iterations 5771 accuray : 0.9269061121613107  loss : 0.2997328169505597\n",
      "iterations 5772 accuray : 0.9269061121613107  loss : 0.29972109556608134\n",
      "iterations 5773 accuray : 0.9269061121613107  loss : 0.29970958931891784\n",
      "iterations 5774 accuray : 0.9269061121613107  loss : 0.2996978414477405\n",
      "iterations 5775 accuray : 0.9269061121613107  loss : 0.29968614058584186\n",
      "iterations 5776 accuray : 0.9269061121613107  loss : 0.29967529526484205\n",
      "iterations 5777 accuray : 0.9269061121613107  loss : 0.29966392598650304\n",
      "iterations 5778 accuray : 0.9269061121613107  loss : 0.29965185832601654\n",
      "iterations 5779 accuray : 0.9266960722537282  loss : 0.29964061518611484\n",
      "iterations 5780 accuray : 0.9266960722537282  loss : 0.2996287084387478\n",
      "iterations 5781 accuray : 0.9266960722537282  loss : 0.2996168919698001\n",
      "iterations 5782 accuray : 0.9266960722537282  loss : 0.2996053481482708\n",
      "iterations 5783 accuray : 0.9269061121613107  loss : 0.2995929712276177\n",
      "iterations 5784 accuray : 0.9269061121613107  loss : 0.2995816395475401\n",
      "iterations 5785 accuray : 0.9269061121613107  loss : 0.2995697418931429\n",
      "iterations 5786 accuray : 0.9269061121613107  loss : 0.29955742613544956\n",
      "iterations 5787 accuray : 0.9269061121613107  loss : 0.29954553491099023\n",
      "iterations 5788 accuray : 0.9269061121613107  loss : 0.29953397602795934\n",
      "iterations 5789 accuray : 0.9269061121613107  loss : 0.29952212873635115\n",
      "iterations 5790 accuray : 0.9269061121613107  loss : 0.2995099783884743\n",
      "iterations 5791 accuray : 0.9269061121613107  loss : 0.2994981212062492\n",
      "iterations 5792 accuray : 0.9269061121613107  loss : 0.29948595474163786\n",
      "iterations 5793 accuray : 0.9269061121613107  loss : 0.29947442674710284\n",
      "iterations 5794 accuray : 0.9269061121613107  loss : 0.29946244799714494\n",
      "iterations 5795 accuray : 0.9269061121613107  loss : 0.2994506411901969\n",
      "iterations 5796 accuray : 0.9269061121613107  loss : 0.2994387566917449\n",
      "iterations 5797 accuray : 0.9269061121613107  loss : 0.29942708925782\n",
      "iterations 5798 accuray : 0.9269061121613107  loss : 0.29941512072740023\n",
      "iterations 5799 accuray : 0.9269061121613107  loss : 0.29940336548481317\n",
      "iterations 5800 accuray : 0.9269061121613107  loss : 0.29939080379410743\n",
      "iterations 5801 accuray : 0.9269061121613107  loss : 0.2993795495938806\n",
      "iterations 5802 accuray : 0.9269061121613107  loss : 0.299368003029371\n",
      "iterations 5803 accuray : 0.9269061121613107  loss : 0.299356300927679\n",
      "iterations 5804 accuray : 0.9269061121613107  loss : 0.2993450998132387\n",
      "iterations 5805 accuray : 0.9269061121613107  loss : 0.29933328134220805\n",
      "iterations 5806 accuray : 0.9269061121613107  loss : 0.2993215323229831\n",
      "iterations 5807 accuray : 0.9269061121613107  loss : 0.2993097552671075\n",
      "iterations 5808 accuray : 0.9269061121613107  loss : 0.29929775983170653\n",
      "iterations 5809 accuray : 0.9269061121613107  loss : 0.29928579618870876\n",
      "iterations 5810 accuray : 0.9269061121613107  loss : 0.29927367711675806\n",
      "iterations 5811 accuray : 0.9269061121613107  loss : 0.29926174842026787\n",
      "iterations 5812 accuray : 0.9269061121613107  loss : 0.2992497205044233\n",
      "iterations 5813 accuray : 0.9269061121613107  loss : 0.29923782997028897\n",
      "iterations 5814 accuray : 0.9269061121613107  loss : 0.2992257426894694\n",
      "iterations 5815 accuray : 0.9269061121613107  loss : 0.29921419667535004\n",
      "iterations 5816 accuray : 0.9269061121613107  loss : 0.2992023469560554\n",
      "iterations 5817 accuray : 0.9269061121613107  loss : 0.29919122659477304\n",
      "iterations 5818 accuray : 0.9269061121613107  loss : 0.2991796713867534\n",
      "iterations 5819 accuray : 0.9269061121613107  loss : 0.29916805360524085\n",
      "iterations 5820 accuray : 0.9269061121613107  loss : 0.29915628012068873\n",
      "iterations 5821 accuray : 0.9269061121613107  loss : 0.2991446325207259\n",
      "iterations 5822 accuray : 0.9269061121613107  loss : 0.2991335276890071\n",
      "iterations 5823 accuray : 0.9269061121613107  loss : 0.2991219500452821\n",
      "iterations 5824 accuray : 0.9269061121613107  loss : 0.29911000735784826\n",
      "iterations 5825 accuray : 0.9269061121613107  loss : 0.2990986991878615\n",
      "iterations 5826 accuray : 0.9269061121613107  loss : 0.2990871725463306\n",
      "iterations 5827 accuray : 0.9269061121613107  loss : 0.29907564793559893\n",
      "iterations 5828 accuray : 0.9269061121613107  loss : 0.2990639637347708\n",
      "iterations 5829 accuray : 0.9269061121613107  loss : 0.2990524958390707\n",
      "iterations 5830 accuray : 0.9269061121613107  loss : 0.29904083732996856\n",
      "iterations 5831 accuray : 0.9269061121613107  loss : 0.29902950475238926\n",
      "iterations 5832 accuray : 0.9269061121613107  loss : 0.29901779601974343\n",
      "iterations 5833 accuray : 0.9269061121613107  loss : 0.2990060523883792\n",
      "iterations 5834 accuray : 0.9269061121613107  loss : 0.29899437388614225\n",
      "iterations 5835 accuray : 0.9269061121613107  loss : 0.29898260940057814\n",
      "iterations 5836 accuray : 0.9269061121613107  loss : 0.298970753913911\n",
      "iterations 5837 accuray : 0.9269061121613107  loss : 0.2989589036567653\n",
      "iterations 5838 accuray : 0.9269061121613107  loss : 0.2989475033225288\n",
      "iterations 5839 accuray : 0.9269061121613107  loss : 0.2989360163420098\n",
      "iterations 5840 accuray : 0.9269061121613107  loss : 0.29892383358191243\n",
      "iterations 5841 accuray : 0.9269061121613107  loss : 0.2989116735091683\n",
      "iterations 5842 accuray : 0.9269061121613107  loss : 0.29889986248477074\n",
      "iterations 5843 accuray : 0.9269061121613107  loss : 0.2988886913507122\n",
      "iterations 5844 accuray : 0.9269061121613107  loss : 0.29887617034267744\n",
      "iterations 5845 accuray : 0.9266960722537282  loss : 0.2988643254557904\n",
      "iterations 5846 accuray : 0.9269061121613107  loss : 0.2988531321466451\n",
      "iterations 5847 accuray : 0.9269061121613107  loss : 0.2988416372064226\n",
      "iterations 5848 accuray : 0.9269061121613107  loss : 0.29882971988820806\n",
      "iterations 5849 accuray : 0.9269061121613107  loss : 0.29881868518440063\n",
      "iterations 5850 accuray : 0.9269061121613107  loss : 0.2988062501657887\n",
      "iterations 5851 accuray : 0.9269061121613107  loss : 0.2987949219646522\n",
      "iterations 5852 accuray : 0.9269061121613107  loss : 0.29878254561396067\n",
      "iterations 5853 accuray : 0.9266960722537282  loss : 0.2987709278326709\n",
      "iterations 5854 accuray : 0.9269061121613107  loss : 0.29875955630166584\n",
      "iterations 5855 accuray : 0.9269061121613107  loss : 0.29874800172881355\n",
      "iterations 5856 accuray : 0.9269061121613107  loss : 0.29873636513238105\n",
      "iterations 5857 accuray : 0.9266960722537282  loss : 0.29872396053010575\n",
      "iterations 5858 accuray : 0.9269061121613107  loss : 0.29871328576300765\n",
      "iterations 5859 accuray : 0.9269061121613107  loss : 0.29870175235877033\n",
      "iterations 5860 accuray : 0.9269061121613107  loss : 0.29869097748073925\n",
      "iterations 5861 accuray : 0.9269061121613107  loss : 0.2986791359169286\n",
      "iterations 5862 accuray : 0.9266960722537282  loss : 0.2986674074012421\n",
      "iterations 5863 accuray : 0.9266960722537282  loss : 0.298655523298383\n",
      "iterations 5864 accuray : 0.9266960722537282  loss : 0.298643744767168\n",
      "iterations 5865 accuray : 0.9266960722537282  loss : 0.2986320104786557\n",
      "iterations 5866 accuray : 0.9266960722537282  loss : 0.2986198632561297\n",
      "iterations 5867 accuray : 0.9266960722537282  loss : 0.29860818219153995\n",
      "iterations 5868 accuray : 0.9266960722537282  loss : 0.29859596591073007\n",
      "iterations 5869 accuray : 0.9266960722537282  loss : 0.29858401627448894\n",
      "iterations 5870 accuray : 0.9266960722537282  loss : 0.2985724127021867\n",
      "iterations 5871 accuray : 0.9266960722537282  loss : 0.2985611038509395\n",
      "iterations 5872 accuray : 0.9266960722537282  loss : 0.29855015299510335\n",
      "iterations 5873 accuray : 0.9266960722537282  loss : 0.2985383909752168\n",
      "iterations 5874 accuray : 0.9266960722537282  loss : 0.2985269409685222\n",
      "iterations 5875 accuray : 0.9266960722537282  loss : 0.2985156476819482\n",
      "iterations 5876 accuray : 0.9266960722537282  loss : 0.29850394380042505\n",
      "iterations 5877 accuray : 0.9266960722537282  loss : 0.29849220911562124\n",
      "iterations 5878 accuray : 0.9266960722537282  loss : 0.29848034357010333\n",
      "iterations 5879 accuray : 0.9266960722537282  loss : 0.2984688964331095\n",
      "iterations 5880 accuray : 0.9266960722537282  loss : 0.2984568208688213\n",
      "iterations 5881 accuray : 0.9266960722537282  loss : 0.2984454867039881\n",
      "iterations 5882 accuray : 0.9266960722537282  loss : 0.29843448895637714\n",
      "iterations 5883 accuray : 0.9266960722537282  loss : 0.29842349305139143\n",
      "iterations 5884 accuray : 0.9266960722537282  loss : 0.2984119655136567\n",
      "iterations 5885 accuray : 0.9266960722537282  loss : 0.29840079550405474\n",
      "iterations 5886 accuray : 0.9266960722537282  loss : 0.2983890116855548\n",
      "iterations 5887 accuray : 0.9266960722537282  loss : 0.2983773106896916\n",
      "iterations 5888 accuray : 0.9266960722537282  loss : 0.2983654872382186\n",
      "iterations 5889 accuray : 0.9266960722537282  loss : 0.2983538931727071\n",
      "iterations 5890 accuray : 0.9266960722537282  loss : 0.2983428110073715\n",
      "iterations 5891 accuray : 0.9266960722537282  loss : 0.2983311884343632\n",
      "iterations 5892 accuray : 0.9266960722537282  loss : 0.2983202080115529\n",
      "iterations 5893 accuray : 0.9266960722537282  loss : 0.2983083941143784\n",
      "iterations 5894 accuray : 0.9266960722537282  loss : 0.298296335470586\n",
      "iterations 5895 accuray : 0.9266960722537282  loss : 0.2982843474585935\n",
      "iterations 5896 accuray : 0.9266960722537282  loss : 0.2982727732741202\n",
      "iterations 5897 accuray : 0.9266960722537282  loss : 0.2982609355626291\n",
      "iterations 5898 accuray : 0.9266960722537282  loss : 0.29824925351295145\n",
      "iterations 5899 accuray : 0.9266960722537282  loss : 0.2982372338950686\n",
      "iterations 5900 accuray : 0.9269061121613107  loss : 0.2982253971014201\n",
      "iterations 5901 accuray : 0.9266960722537282  loss : 0.29821333817851214\n",
      "iterations 5902 accuray : 0.9266960722537282  loss : 0.2982013888661587\n",
      "iterations 5903 accuray : 0.9264860323461458  loss : 0.2981893640214746\n",
      "iterations 5904 accuray : 0.9264860323461458  loss : 0.298178143490938\n",
      "iterations 5905 accuray : 0.9264860323461458  loss : 0.298166318783203\n",
      "iterations 5906 accuray : 0.9264860323461458  loss : 0.29815456849083743\n",
      "iterations 5907 accuray : 0.9264860323461458  loss : 0.29814335810069253\n",
      "iterations 5908 accuray : 0.9264860323461458  loss : 0.2981322334371169\n",
      "iterations 5909 accuray : 0.9264860323461458  loss : 0.29812093823627317\n",
      "iterations 5910 accuray : 0.9264860323461458  loss : 0.2981100909272892\n",
      "iterations 5911 accuray : 0.9264860323461458  loss : 0.2980986479607379\n",
      "iterations 5912 accuray : 0.9264860323461458  loss : 0.29808743061740156\n",
      "iterations 5913 accuray : 0.9264860323461458  loss : 0.29807597284457477\n",
      "iterations 5914 accuray : 0.9266960722537282  loss : 0.29806495629704677\n",
      "iterations 5915 accuray : 0.9266960722537282  loss : 0.2980537322260908\n",
      "iterations 5916 accuray : 0.9266960722537282  loss : 0.2980417784816049\n",
      "iterations 5917 accuray : 0.9264860323461458  loss : 0.2980297723425472\n",
      "iterations 5918 accuray : 0.9264860323461458  loss : 0.2980180381507926\n",
      "iterations 5919 accuray : 0.9264860323461458  loss : 0.2980069956671739\n",
      "iterations 5920 accuray : 0.9266960722537282  loss : 0.2979957797944143\n",
      "iterations 5921 accuray : 0.9266960722537282  loss : 0.297984217136386\n",
      "iterations 5922 accuray : 0.9266960722537282  loss : 0.2979733900930627\n",
      "iterations 5923 accuray : 0.9266960722537282  loss : 0.29796202856021914\n",
      "iterations 5924 accuray : 0.9264860323461458  loss : 0.2979500108065525\n",
      "iterations 5925 accuray : 0.9264860323461458  loss : 0.2979381032556282\n",
      "iterations 5926 accuray : 0.9264860323461458  loss : 0.297926792885535\n",
      "iterations 5927 accuray : 0.9264860323461458  loss : 0.29791558190554934\n",
      "iterations 5928 accuray : 0.9264860323461458  loss : 0.2979038018885742\n",
      "iterations 5929 accuray : 0.9264860323461458  loss : 0.2978921034258813\n",
      "iterations 5930 accuray : 0.9264860323461458  loss : 0.29788009461411186\n",
      "iterations 5931 accuray : 0.9264860323461458  loss : 0.29786907388098044\n",
      "iterations 5932 accuray : 0.9264860323461458  loss : 0.29785784491231854\n",
      "iterations 5933 accuray : 0.9264860323461458  loss : 0.2978460836080548\n",
      "iterations 5934 accuray : 0.9264860323461458  loss : 0.29783493264976796\n",
      "iterations 5935 accuray : 0.9264860323461458  loss : 0.29782312620642815\n",
      "iterations 5936 accuray : 0.9264860323461458  loss : 0.2978117345828705\n",
      "iterations 5937 accuray : 0.9264860323461458  loss : 0.2977999137844885\n",
      "iterations 5938 accuray : 0.9264860323461458  loss : 0.29778886436503127\n",
      "iterations 5939 accuray : 0.9264860323461458  loss : 0.29777713997979205\n",
      "iterations 5940 accuray : 0.9264860323461458  loss : 0.29776607788756615\n",
      "iterations 5941 accuray : 0.9264860323461458  loss : 0.2977544627073808\n",
      "iterations 5942 accuray : 0.9264860323461458  loss : 0.297742591125307\n",
      "iterations 5943 accuray : 0.9264860323461458  loss : 0.2977307815739378\n",
      "iterations 5944 accuray : 0.9264860323461458  loss : 0.29771986100462033\n",
      "iterations 5945 accuray : 0.9264860323461458  loss : 0.2977087069406668\n",
      "iterations 5946 accuray : 0.9264860323461458  loss : 0.2976970141314003\n",
      "iterations 5947 accuray : 0.9264860323461458  loss : 0.29768595930254343\n",
      "iterations 5948 accuray : 0.9264860323461458  loss : 0.29767536435292413\n",
      "iterations 5949 accuray : 0.9264860323461458  loss : 0.2976641184573455\n",
      "iterations 5950 accuray : 0.9264860323461458  loss : 0.29765322900551394\n",
      "iterations 5951 accuray : 0.9264860323461458  loss : 0.29764170630908526\n",
      "iterations 5952 accuray : 0.9264860323461458  loss : 0.29763037248690083\n",
      "iterations 5953 accuray : 0.9264860323461458  loss : 0.2976191323811867\n",
      "iterations 5954 accuray : 0.9264860323461458  loss : 0.29760740072952674\n",
      "iterations 5955 accuray : 0.9264860323461458  loss : 0.2975958399379875\n",
      "iterations 5956 accuray : 0.9264860323461458  loss : 0.29758448775069785\n",
      "iterations 5957 accuray : 0.9264860323461458  loss : 0.29757280546403\n",
      "iterations 5958 accuray : 0.9264860323461458  loss : 0.2975616829182667\n",
      "iterations 5959 accuray : 0.9264860323461458  loss : 0.29755015375054433\n",
      "iterations 5960 accuray : 0.9264860323461458  loss : 0.29753859351084405\n",
      "iterations 5961 accuray : 0.9262759924385633  loss : 0.2975267244024257\n",
      "iterations 5962 accuray : 0.9262759924385633  loss : 0.29751481921528444\n",
      "iterations 5963 accuray : 0.9262759924385633  loss : 0.29750350348119603\n",
      "iterations 5964 accuray : 0.9264860323461458  loss : 0.2974927561915544\n",
      "iterations 5965 accuray : 0.9262759924385633  loss : 0.29748098159210756\n",
      "iterations 5966 accuray : 0.9264860323461458  loss : 0.29747010734604445\n",
      "iterations 5967 accuray : 0.9264860323461458  loss : 0.29745923277521236\n",
      "iterations 5968 accuray : 0.9264860323461458  loss : 0.2974476570581751\n",
      "iterations 5969 accuray : 0.9264860323461458  loss : 0.29743666481777875\n",
      "iterations 5970 accuray : 0.9264860323461458  loss : 0.29742522472429\n",
      "iterations 5971 accuray : 0.9262759924385633  loss : 0.29741411351442126\n",
      "iterations 5972 accuray : 0.9262759924385633  loss : 0.29740318599826404\n",
      "iterations 5973 accuray : 0.9262759924385633  loss : 0.2973914403338387\n",
      "iterations 5974 accuray : 0.9262759924385633  loss : 0.29738003394147816\n",
      "iterations 5975 accuray : 0.9264860323461458  loss : 0.2973690456552481\n",
      "iterations 5976 accuray : 0.9262759924385633  loss : 0.29735761317376924\n",
      "iterations 5977 accuray : 0.9262759924385633  loss : 0.29734704570047177\n",
      "iterations 5978 accuray : 0.9262759924385633  loss : 0.2973359291309677\n",
      "iterations 5979 accuray : 0.9262759924385633  loss : 0.2973248493162242\n",
      "iterations 5980 accuray : 0.9264860323461458  loss : 0.29731399260828345\n",
      "iterations 5981 accuray : 0.9262759924385633  loss : 0.2973022356338166\n",
      "iterations 5982 accuray : 0.9262759924385633  loss : 0.29729083692761915\n",
      "iterations 5983 accuray : 0.9262759924385633  loss : 0.29727976787689436\n",
      "iterations 5984 accuray : 0.9264860323461458  loss : 0.29726897585593925\n",
      "iterations 5985 accuray : 0.9262759924385633  loss : 0.2972576359118146\n",
      "iterations 5986 accuray : 0.9262759924385633  loss : 0.29724650054788565\n",
      "iterations 5987 accuray : 0.9262759924385633  loss : 0.2972356018649596\n",
      "iterations 5988 accuray : 0.9264860323461458  loss : 0.29722449309452553\n",
      "iterations 5989 accuray : 0.9264860323461458  loss : 0.2972132954698964\n",
      "iterations 5990 accuray : 0.9264860323461458  loss : 0.29720177574663376\n",
      "iterations 5991 accuray : 0.9262759924385633  loss : 0.2971899026252927\n",
      "iterations 5992 accuray : 0.9262759924385633  loss : 0.2971781984604318\n",
      "iterations 5993 accuray : 0.9264860323461458  loss : 0.2971673983827847\n",
      "iterations 5994 accuray : 0.9264860323461458  loss : 0.29715599299741763\n",
      "iterations 5995 accuray : 0.9262759924385633  loss : 0.29714504494392163\n",
      "iterations 5996 accuray : 0.9262759924385633  loss : 0.2971335366465968\n",
      "iterations 5997 accuray : 0.9262759924385633  loss : 0.2971219248852026\n",
      "iterations 5998 accuray : 0.9262759924385633  loss : 0.2971104824852076\n",
      "iterations 5999 accuray : 0.9262759924385633  loss : 0.29709942518273064\n",
      "iterations 6000 accuray : 0.9262759924385633  loss : 0.2970878013359743\n",
      "iterations 6001 accuray : 0.9262759924385633  loss : 0.2970770836285447\n",
      "iterations 6002 accuray : 0.9262759924385633  loss : 0.2970655597284206\n",
      "iterations 6003 accuray : 0.9262759924385633  loss : 0.29705429615084106\n",
      "iterations 6004 accuray : 0.9262759924385633  loss : 0.2970430393093075\n",
      "iterations 6005 accuray : 0.9262759924385633  loss : 0.2970317225596354\n",
      "iterations 6006 accuray : 0.9262759924385633  loss : 0.2970209874938294\n",
      "iterations 6007 accuray : 0.9262759924385633  loss : 0.2970089219558089\n",
      "iterations 6008 accuray : 0.9262759924385633  loss : 0.29699798893385204\n",
      "iterations 6009 accuray : 0.9262759924385633  loss : 0.2969870232415062\n",
      "iterations 6010 accuray : 0.9262759924385633  loss : 0.2969764680950323\n",
      "iterations 6011 accuray : 0.9262759924385633  loss : 0.2969656189162655\n",
      "iterations 6012 accuray : 0.9262759924385633  loss : 0.2969546399203155\n",
      "iterations 6013 accuray : 0.9262759924385633  loss : 0.29694362274441444\n",
      "iterations 6014 accuray : 0.9262759924385633  loss : 0.29693270600028515\n",
      "iterations 6015 accuray : 0.9262759924385633  loss : 0.29692124043074547\n",
      "iterations 6016 accuray : 0.9262759924385633  loss : 0.29690995546652693\n",
      "iterations 6017 accuray : 0.9262759924385633  loss : 0.29689932744353004\n",
      "iterations 6018 accuray : 0.9262759924385633  loss : 0.2968881291955708\n",
      "iterations 6019 accuray : 0.9262759924385633  loss : 0.2968769050207719\n",
      "iterations 6020 accuray : 0.9262759924385633  loss : 0.29686543131951426\n",
      "iterations 6021 accuray : 0.9262759924385633  loss : 0.29685416914413154\n",
      "iterations 6022 accuray : 0.9262759924385633  loss : 0.29684322324123746\n",
      "iterations 6023 accuray : 0.9262759924385633  loss : 0.29683176162718256\n",
      "iterations 6024 accuray : 0.9262759924385633  loss : 0.296819936016179\n",
      "iterations 6025 accuray : 0.9262759924385633  loss : 0.29680918165277953\n",
      "iterations 6026 accuray : 0.9262759924385633  loss : 0.29679822953167934\n",
      "iterations 6027 accuray : 0.9262759924385633  loss : 0.29678736581653054\n",
      "iterations 6028 accuray : 0.9262759924385633  loss : 0.296776275238609\n",
      "iterations 6029 accuray : 0.9262759924385633  loss : 0.2967649932309632\n",
      "iterations 6030 accuray : 0.9262759924385633  loss : 0.2967537107716134\n",
      "iterations 6031 accuray : 0.9262759924385633  loss : 0.2967420371333911\n",
      "iterations 6032 accuray : 0.9262759924385633  loss : 0.2967308843094961\n",
      "iterations 6033 accuray : 0.9262759924385633  loss : 0.29671943718542\n",
      "iterations 6034 accuray : 0.9262759924385633  loss : 0.29670779466763136\n",
      "iterations 6035 accuray : 0.9262759924385633  loss : 0.29669632243899946\n",
      "iterations 6036 accuray : 0.9262759924385633  loss : 0.2966852405524871\n",
      "iterations 6037 accuray : 0.9262759924385633  loss : 0.2966741319524346\n",
      "iterations 6038 accuray : 0.9262759924385633  loss : 0.29666314689658885\n",
      "iterations 6039 accuray : 0.9262759924385633  loss : 0.29665193724597927\n",
      "iterations 6040 accuray : 0.9262759924385633  loss : 0.29664089053631704\n",
      "iterations 6041 accuray : 0.9262759924385633  loss : 0.29663013595853105\n",
      "iterations 6042 accuray : 0.9262759924385633  loss : 0.29661895466477195\n",
      "iterations 6043 accuray : 0.9262759924385633  loss : 0.29660786672433787\n",
      "iterations 6044 accuray : 0.9262759924385633  loss : 0.29659678368493425\n",
      "iterations 6045 accuray : 0.9262759924385633  loss : 0.29658567139677805\n",
      "iterations 6046 accuray : 0.9262759924385633  loss : 0.29657453135948353\n",
      "iterations 6047 accuray : 0.9262759924385633  loss : 0.2965629042291062\n",
      "iterations 6048 accuray : 0.9262759924385633  loss : 0.2965517085879473\n",
      "iterations 6049 accuray : 0.9262759924385633  loss : 0.2965405601052138\n",
      "iterations 6050 accuray : 0.9262759924385633  loss : 0.2965291978179888\n",
      "iterations 6051 accuray : 0.9262759924385633  loss : 0.2965186368909792\n",
      "iterations 6052 accuray : 0.9262759924385633  loss : 0.296508004886628\n",
      "iterations 6053 accuray : 0.9262759924385633  loss : 0.2964970538412085\n",
      "iterations 6054 accuray : 0.9262759924385633  loss : 0.29648556391087183\n",
      "iterations 6055 accuray : 0.9262759924385633  loss : 0.296475043939384\n",
      "iterations 6056 accuray : 0.9262759924385633  loss : 0.296464275384179\n",
      "iterations 6057 accuray : 0.9262759924385633  loss : 0.29645326221573376\n",
      "iterations 6058 accuray : 0.9262759924385633  loss : 0.2964419979802407\n",
      "iterations 6059 accuray : 0.9262759924385633  loss : 0.2964308634233084\n",
      "iterations 6060 accuray : 0.9262759924385633  loss : 0.2964194638943596\n",
      "iterations 6061 accuray : 0.9262759924385633  loss : 0.29640807828044063\n",
      "iterations 6062 accuray : 0.9262759924385633  loss : 0.2963969051698826\n",
      "iterations 6063 accuray : 0.9262759924385633  loss : 0.2963857231347732\n",
      "iterations 6064 accuray : 0.9262759924385633  loss : 0.2963751693752091\n",
      "iterations 6065 accuray : 0.9262759924385633  loss : 0.2963639335565781\n",
      "iterations 6066 accuray : 0.9262759924385633  loss : 0.2963530750024979\n",
      "iterations 6067 accuray : 0.9260659525309809  loss : 0.2963413757558716\n",
      "iterations 6068 accuray : 0.9262759924385633  loss : 0.2963307148977499\n",
      "iterations 6069 accuray : 0.9262759924385633  loss : 0.2963197199614277\n",
      "iterations 6070 accuray : 0.9262759924385633  loss : 0.29630887477957646\n",
      "iterations 6071 accuray : 0.9262759924385633  loss : 0.29629736010063\n",
      "iterations 6072 accuray : 0.9262759924385633  loss : 0.2962865085098853\n",
      "iterations 6073 accuray : 0.9262759924385633  loss : 0.29627546582545944\n",
      "iterations 6074 accuray : 0.9262759924385633  loss : 0.29626383212544916\n",
      "iterations 6075 accuray : 0.9260659525309809  loss : 0.29625249821673133\n",
      "iterations 6076 accuray : 0.9262759924385633  loss : 0.29624131239314383\n",
      "iterations 6077 accuray : 0.9262759924385633  loss : 0.2962303848061938\n",
      "iterations 6078 accuray : 0.9260659525309809  loss : 0.2962185789199418\n",
      "iterations 6079 accuray : 0.9260659525309809  loss : 0.29620791246531997\n",
      "iterations 6080 accuray : 0.9260659525309809  loss : 0.29619720046527376\n",
      "iterations 6081 accuray : 0.9260659525309809  loss : 0.29618630761479176\n",
      "iterations 6082 accuray : 0.9260659525309809  loss : 0.29617564968851406\n",
      "iterations 6083 accuray : 0.9262759924385633  loss : 0.29616460760297847\n",
      "iterations 6084 accuray : 0.9262759924385633  loss : 0.29615354856207343\n",
      "iterations 6085 accuray : 0.9260659525309809  loss : 0.29614260374156665\n",
      "iterations 6086 accuray : 0.9260659525309809  loss : 0.29613154249585144\n",
      "iterations 6087 accuray : 0.9260659525309809  loss : 0.2961200594749307\n",
      "iterations 6088 accuray : 0.9260659525309809  loss : 0.29610896996111585\n",
      "iterations 6089 accuray : 0.9260659525309809  loss : 0.29609782525812167\n",
      "iterations 6090 accuray : 0.9260659525309809  loss : 0.29608692092324\n",
      "iterations 6091 accuray : 0.9262759924385633  loss : 0.29607567783977373\n",
      "iterations 6092 accuray : 0.9260659525309809  loss : 0.2960643095849292\n",
      "iterations 6093 accuray : 0.9260659525309809  loss : 0.2960534117771537\n",
      "iterations 6094 accuray : 0.9260659525309809  loss : 0.2960428177685545\n",
      "iterations 6095 accuray : 0.9260659525309809  loss : 0.2960313995314663\n",
      "iterations 6096 accuray : 0.9260659525309809  loss : 0.2960207998799841\n",
      "iterations 6097 accuray : 0.9260659525309809  loss : 0.296009324337794\n",
      "iterations 6098 accuray : 0.9260659525309809  loss : 0.29599849915819687\n",
      "iterations 6099 accuray : 0.9260659525309809  loss : 0.29598754028785745\n",
      "iterations 6100 accuray : 0.9260659525309809  loss : 0.2959766896889184\n",
      "iterations 6101 accuray : 0.9260659525309809  loss : 0.2959659636685161\n",
      "iterations 6102 accuray : 0.9260659525309809  loss : 0.295955670093756\n",
      "iterations 6103 accuray : 0.9260659525309809  loss : 0.2959446574510677\n",
      "iterations 6104 accuray : 0.9260659525309809  loss : 0.29593340536373886\n",
      "iterations 6105 accuray : 0.9258559126233984  loss : 0.2959225009027561\n",
      "iterations 6106 accuray : 0.9258559126233984  loss : 0.2959117318428959\n",
      "iterations 6107 accuray : 0.9260659525309809  loss : 0.2959010252932706\n",
      "iterations 6108 accuray : 0.9260659525309809  loss : 0.295890205555056\n",
      "iterations 6109 accuray : 0.9260659525309809  loss : 0.2958791328963271\n",
      "iterations 6110 accuray : 0.9262759924385633  loss : 0.2958686384927492\n",
      "iterations 6111 accuray : 0.9262759924385633  loss : 0.295857787316649\n",
      "iterations 6112 accuray : 0.9262759924385633  loss : 0.29584681102668464\n",
      "iterations 6113 accuray : 0.9262759924385633  loss : 0.2958354436222342\n",
      "iterations 6114 accuray : 0.9262759924385633  loss : 0.2958237120965032\n",
      "iterations 6115 accuray : 0.9262759924385633  loss : 0.29581304143208176\n",
      "iterations 6116 accuray : 0.9262759924385633  loss : 0.29580180594759103\n",
      "iterations 6117 accuray : 0.9262759924385633  loss : 0.2957906571030429\n",
      "iterations 6118 accuray : 0.9262759924385633  loss : 0.2957794389449827\n",
      "iterations 6119 accuray : 0.9262759924385633  loss : 0.2957686638442119\n",
      "iterations 6120 accuray : 0.9262759924385633  loss : 0.2957579134054933\n",
      "iterations 6121 accuray : 0.9262759924385633  loss : 0.29574681449896995\n",
      "iterations 6122 accuray : 0.9262759924385633  loss : 0.2957352458560554\n",
      "iterations 6123 accuray : 0.9262759924385633  loss : 0.29572415800236324\n",
      "iterations 6124 accuray : 0.9260659525309809  loss : 0.29571296451535867\n",
      "iterations 6125 accuray : 0.9260659525309809  loss : 0.2957020425459052\n",
      "iterations 6126 accuray : 0.9260659525309809  loss : 0.2956913583720591\n",
      "iterations 6127 accuray : 0.9260659525309809  loss : 0.29568051479560525\n",
      "iterations 6128 accuray : 0.9260659525309809  loss : 0.2956691876494187\n",
      "iterations 6129 accuray : 0.9260659525309809  loss : 0.29565880050332144\n",
      "iterations 6130 accuray : 0.9260659525309809  loss : 0.2956480173172775\n",
      "iterations 6131 accuray : 0.9258559126233984  loss : 0.2956368947769368\n",
      "iterations 6132 accuray : 0.9258559126233984  loss : 0.29562573942996867\n",
      "iterations 6133 accuray : 0.9258559126233984  loss : 0.2956149571619256\n",
      "iterations 6134 accuray : 0.9258559126233984  loss : 0.2956031471383649\n",
      "iterations 6135 accuray : 0.9258559126233984  loss : 0.29559230364966393\n",
      "iterations 6136 accuray : 0.9258559126233984  loss : 0.2955807899795812\n",
      "iterations 6137 accuray : 0.9258559126233984  loss : 0.29556989327380573\n",
      "iterations 6138 accuray : 0.9258559126233984  loss : 0.2955590845276835\n",
      "iterations 6139 accuray : 0.9258559126233984  loss : 0.29554801520763185\n",
      "iterations 6140 accuray : 0.9258559126233984  loss : 0.29553683424500254\n",
      "iterations 6141 accuray : 0.9258559126233984  loss : 0.2955259781516056\n",
      "iterations 6142 accuray : 0.9258559126233984  loss : 0.29551515415493296\n",
      "iterations 6143 accuray : 0.9258559126233984  loss : 0.29550429636105857\n",
      "iterations 6144 accuray : 0.9258559126233984  loss : 0.29549318811153574\n",
      "iterations 6145 accuray : 0.9258559126233984  loss : 0.29548225790261096\n",
      "iterations 6146 accuray : 0.9258559126233984  loss : 0.2954716802768676\n",
      "iterations 6147 accuray : 0.9258559126233984  loss : 0.2954608673421243\n",
      "iterations 6148 accuray : 0.9258559126233984  loss : 0.29545006661037887\n",
      "iterations 6149 accuray : 0.9258559126233984  loss : 0.2954387661583948\n",
      "iterations 6150 accuray : 0.9258559126233984  loss : 0.29542772745514223\n",
      "iterations 6151 accuray : 0.9258559126233984  loss : 0.2954171241535097\n",
      "iterations 6152 accuray : 0.9258559126233984  loss : 0.29540617959504845\n",
      "iterations 6153 accuray : 0.9258559126233984  loss : 0.2953953852545835\n",
      "iterations 6154 accuray : 0.9258559126233984  loss : 0.2953846266289593\n",
      "iterations 6155 accuray : 0.9258559126233984  loss : 0.2953734729175418\n",
      "iterations 6156 accuray : 0.9258559126233984  loss : 0.29536278559488777\n",
      "iterations 6157 accuray : 0.9258559126233984  loss : 0.29535196296703586\n",
      "iterations 6158 accuray : 0.9258559126233984  loss : 0.29534106046195596\n",
      "iterations 6159 accuray : 0.9258559126233984  loss : 0.2953298583079396\n",
      "iterations 6160 accuray : 0.9258559126233984  loss : 0.29531941605921813\n",
      "iterations 6161 accuray : 0.9258559126233984  loss : 0.29530935476202336\n",
      "iterations 6162 accuray : 0.9258559126233984  loss : 0.2952982951793797\n",
      "iterations 6163 accuray : 0.9258559126233984  loss : 0.2952874193873845\n",
      "iterations 6164 accuray : 0.9258559126233984  loss : 0.2952763528658888\n",
      "iterations 6165 accuray : 0.9258559126233984  loss : 0.29526578006334325\n",
      "iterations 6166 accuray : 0.9258559126233984  loss : 0.2952548827846466\n",
      "iterations 6167 accuray : 0.9258559126233984  loss : 0.29524418635608923\n",
      "iterations 6168 accuray : 0.9258559126233984  loss : 0.29523323989538075\n",
      "iterations 6169 accuray : 0.9258559126233984  loss : 0.29522275806316034\n",
      "iterations 6170 accuray : 0.9258559126233984  loss : 0.29521138569896305\n",
      "iterations 6171 accuray : 0.9258559126233984  loss : 0.2952005481800374\n",
      "iterations 6172 accuray : 0.9258559126233984  loss : 0.2951898730654784\n",
      "iterations 6173 accuray : 0.9258559126233984  loss : 0.29517942753605797\n",
      "iterations 6174 accuray : 0.9258559126233984  loss : 0.295168726072989\n",
      "iterations 6175 accuray : 0.9258559126233984  loss : 0.295157388895234\n",
      "iterations 6176 accuray : 0.9258559126233984  loss : 0.2951464918288253\n",
      "iterations 6177 accuray : 0.9258559126233984  loss : 0.29513552824044204\n",
      "iterations 6178 accuray : 0.9258559126233984  loss : 0.295124467377784\n",
      "iterations 6179 accuray : 0.9258559126233984  loss : 0.2951136273920609\n",
      "iterations 6180 accuray : 0.9258559126233984  loss : 0.2951033278739172\n",
      "iterations 6181 accuray : 0.9258559126233984  loss : 0.29509238812893485\n",
      "iterations 6182 accuray : 0.9258559126233984  loss : 0.2950820411265197\n",
      "iterations 6183 accuray : 0.9258559126233984  loss : 0.29507124587029493\n",
      "iterations 6184 accuray : 0.9258559126233984  loss : 0.29506040343148576\n",
      "iterations 6185 accuray : 0.9258559126233984  loss : 0.29504960525978474\n",
      "iterations 6186 accuray : 0.9258559126233984  loss : 0.29503859349873796\n",
      "iterations 6187 accuray : 0.9258559126233984  loss : 0.2950280136313546\n",
      "iterations 6188 accuray : 0.9258559126233984  loss : 0.2950175424542614\n",
      "iterations 6189 accuray : 0.9258559126233984  loss : 0.2950067283575067\n",
      "iterations 6190 accuray : 0.9258559126233984  loss : 0.2949959866036868\n",
      "iterations 6191 accuray : 0.9258559126233984  loss : 0.2949854132404312\n",
      "iterations 6192 accuray : 0.9258559126233984  loss : 0.2949748911174654\n",
      "iterations 6193 accuray : 0.9258559126233984  loss : 0.29496384923191266\n",
      "iterations 6194 accuray : 0.9258559126233984  loss : 0.2949528453706065\n",
      "iterations 6195 accuray : 0.9258559126233984  loss : 0.2949418632562023\n",
      "iterations 6196 accuray : 0.9258559126233984  loss : 0.29493073163101197\n",
      "iterations 6197 accuray : 0.9258559126233984  loss : 0.2949203016142844\n",
      "iterations 6198 accuray : 0.9258559126233984  loss : 0.29490932093858097\n",
      "iterations 6199 accuray : 0.9258559126233984  loss : 0.29489880148898107\n",
      "iterations 6200 accuray : 0.9258559126233984  loss : 0.2948880727420425\n",
      "iterations 6201 accuray : 0.9258559126233984  loss : 0.29487780795955115\n",
      "iterations 6202 accuray : 0.9258559126233984  loss : 0.29486739852320526\n",
      "iterations 6203 accuray : 0.9258559126233984  loss : 0.294856774108445\n",
      "iterations 6204 accuray : 0.9258559126233984  loss : 0.29484581632977164\n",
      "iterations 6205 accuray : 0.9258559126233984  loss : 0.294835102580311\n",
      "iterations 6206 accuray : 0.9258559126233984  loss : 0.2948241897061302\n",
      "iterations 6207 accuray : 0.9258559126233984  loss : 0.29481342003558964\n",
      "iterations 6208 accuray : 0.9258559126233984  loss : 0.2948030292463367\n",
      "iterations 6209 accuray : 0.9258559126233984  loss : 0.29479187233406745\n",
      "iterations 6210 accuray : 0.9258559126233984  loss : 0.29478117891995226\n",
      "iterations 6211 accuray : 0.9258559126233984  loss : 0.29477088671172536\n",
      "iterations 6212 accuray : 0.9258559126233984  loss : 0.2947601742964339\n",
      "iterations 6213 accuray : 0.9258559126233984  loss : 0.294749547879798\n",
      "iterations 6214 accuray : 0.9258559126233984  loss : 0.2947385321170841\n",
      "iterations 6215 accuray : 0.9258559126233984  loss : 0.2947278559044341\n",
      "iterations 6216 accuray : 0.9258559126233984  loss : 0.294717072482905\n",
      "iterations 6217 accuray : 0.9258559126233984  loss : 0.2947066201487527\n",
      "iterations 6218 accuray : 0.9258559126233984  loss : 0.2946963277343603\n",
      "iterations 6219 accuray : 0.9258559126233984  loss : 0.29468544514563744\n",
      "iterations 6220 accuray : 0.9258559126233984  loss : 0.29467421351766043\n",
      "iterations 6221 accuray : 0.9258559126233984  loss : 0.2946637464689941\n",
      "iterations 6222 accuray : 0.9258559126233984  loss : 0.2946528096855671\n",
      "iterations 6223 accuray : 0.9258559126233984  loss : 0.29464232353289566\n",
      "iterations 6224 accuray : 0.9258559126233984  loss : 0.29463141959559563\n",
      "iterations 6225 accuray : 0.9258559126233984  loss : 0.2946210603705213\n",
      "iterations 6226 accuray : 0.9258559126233984  loss : 0.2946109643362131\n",
      "iterations 6227 accuray : 0.9258559126233984  loss : 0.2946009791556192\n",
      "iterations 6228 accuray : 0.9258559126233984  loss : 0.2945902411124482\n",
      "iterations 6229 accuray : 0.9258559126233984  loss : 0.29457998500327104\n",
      "iterations 6230 accuray : 0.9258559126233984  loss : 0.2945694231100652\n",
      "iterations 6231 accuray : 0.9258559126233984  loss : 0.29455913268512174\n",
      "iterations 6232 accuray : 0.9258559126233984  loss : 0.29454858864071426\n",
      "iterations 6233 accuray : 0.9258559126233984  loss : 0.2945379339361647\n",
      "iterations 6234 accuray : 0.9258559126233984  loss : 0.2945273716121476\n",
      "iterations 6235 accuray : 0.9258559126233984  loss : 0.2945170549589374\n",
      "iterations 6236 accuray : 0.9258559126233984  loss : 0.29450621111319636\n",
      "iterations 6237 accuray : 0.9258559126233984  loss : 0.2944952485190915\n",
      "iterations 6238 accuray : 0.9258559126233984  loss : 0.29448453697440863\n",
      "iterations 6239 accuray : 0.9258559126233984  loss : 0.2944737653023477\n",
      "iterations 6240 accuray : 0.9258559126233984  loss : 0.29446314060120976\n",
      "iterations 6241 accuray : 0.9258559126233984  loss : 0.2944527072538133\n",
      "iterations 6242 accuray : 0.9258559126233984  loss : 0.2944421531882621\n",
      "iterations 6243 accuray : 0.9258559126233984  loss : 0.2944311569580938\n",
      "iterations 6244 accuray : 0.9258559126233984  loss : 0.2944205125051563\n",
      "iterations 6245 accuray : 0.9258559126233984  loss : 0.2944096260240844\n",
      "iterations 6246 accuray : 0.9258559126233984  loss : 0.29439870244112865\n",
      "iterations 6247 accuray : 0.9258559126233984  loss : 0.2943873106724862\n",
      "iterations 6248 accuray : 0.9258559126233984  loss : 0.29437656304228144\n",
      "iterations 6249 accuray : 0.9258559126233984  loss : 0.29436612466542156\n",
      "iterations 6250 accuray : 0.9258559126233984  loss : 0.2943554230599699\n",
      "iterations 6251 accuray : 0.9258559126233984  loss : 0.29434464871571137\n",
      "iterations 6252 accuray : 0.9258559126233984  loss : 0.29433397072829703\n",
      "iterations 6253 accuray : 0.9258559126233984  loss : 0.29432383611126034\n",
      "iterations 6254 accuray : 0.9258559126233984  loss : 0.29431300446206343\n",
      "iterations 6255 accuray : 0.9258559126233984  loss : 0.2943023110188491\n",
      "iterations 6256 accuray : 0.9258559126233984  loss : 0.29429152813657034\n",
      "iterations 6257 accuray : 0.9258559126233984  loss : 0.2942808530875215\n",
      "iterations 6258 accuray : 0.9258559126233984  loss : 0.29426972114598293\n",
      "iterations 6259 accuray : 0.9258559126233984  loss : 0.29425874431216203\n",
      "iterations 6260 accuray : 0.9258559126233984  loss : 0.29424809473760993\n",
      "iterations 6261 accuray : 0.9258559126233984  loss : 0.2942376155414727\n",
      "iterations 6262 accuray : 0.9258559126233984  loss : 0.2942266097106388\n",
      "iterations 6263 accuray : 0.9258559126233984  loss : 0.29421603920364275\n",
      "iterations 6264 accuray : 0.9258559126233984  loss : 0.2942052685866031\n",
      "iterations 6265 accuray : 0.9258559126233984  loss : 0.2941945993491462\n",
      "iterations 6266 accuray : 0.9258559126233984  loss : 0.29418447509595874\n",
      "iterations 6267 accuray : 0.9258559126233984  loss : 0.29417373834159205\n",
      "iterations 6268 accuray : 0.9258559126233984  loss : 0.2941636375894014\n",
      "iterations 6269 accuray : 0.9258559126233984  loss : 0.2941530117827849\n",
      "iterations 6270 accuray : 0.9258559126233984  loss : 0.2941421697844355\n",
      "iterations 6271 accuray : 0.9258559126233984  loss : 0.2941317520876276\n",
      "iterations 6272 accuray : 0.9258559126233984  loss : 0.29412093155127766\n",
      "iterations 6273 accuray : 0.9258559126233984  loss : 0.2941105040458982\n",
      "iterations 6274 accuray : 0.9258559126233984  loss : 0.29410061944660704\n",
      "iterations 6275 accuray : 0.9258559126233984  loss : 0.29408985097800133\n",
      "iterations 6276 accuray : 0.9258559126233984  loss : 0.2940796217632439\n",
      "iterations 6277 accuray : 0.9258559126233984  loss : 0.2940690570460751\n",
      "iterations 6278 accuray : 0.9258559126233984  loss : 0.29405810190237724\n",
      "iterations 6279 accuray : 0.9258559126233984  loss : 0.2940470678199247\n",
      "iterations 6280 accuray : 0.9258559126233984  loss : 0.2940358688195833\n",
      "iterations 6281 accuray : 0.9258559126233984  loss : 0.294025043355619\n",
      "iterations 6282 accuray : 0.9258559126233984  loss : 0.294014810821786\n",
      "iterations 6283 accuray : 0.9258559126233984  loss : 0.294004877399014\n",
      "iterations 6284 accuray : 0.9258559126233984  loss : 0.2939944964898308\n",
      "iterations 6285 accuray : 0.9258559126233984  loss : 0.2939843027408844\n",
      "iterations 6286 accuray : 0.9258559126233984  loss : 0.29397373702180524\n",
      "iterations 6287 accuray : 0.9258559126233984  loss : 0.29396301122360047\n",
      "iterations 6288 accuray : 0.9258559126233984  loss : 0.2939525703359195\n",
      "iterations 6289 accuray : 0.9258559126233984  loss : 0.2939422182994885\n",
      "iterations 6290 accuray : 0.9258559126233984  loss : 0.29393155160224704\n",
      "iterations 6291 accuray : 0.9258559126233984  loss : 0.2939207471609029\n",
      "iterations 6292 accuray : 0.9258559126233984  loss : 0.29391059121580276\n",
      "iterations 6293 accuray : 0.9258559126233984  loss : 0.293900043145123\n",
      "iterations 6294 accuray : 0.9258559126233984  loss : 0.29388931802993257\n",
      "iterations 6295 accuray : 0.9258559126233984  loss : 0.29387895265388514\n",
      "iterations 6296 accuray : 0.9258559126233984  loss : 0.2938686514602606\n",
      "iterations 6297 accuray : 0.9258559126233984  loss : 0.2938577243983954\n",
      "iterations 6298 accuray : 0.9258559126233984  loss : 0.2938466685765868\n",
      "iterations 6299 accuray : 0.9258559126233984  loss : 0.29383622900375067\n",
      "iterations 6300 accuray : 0.9258559126233984  loss : 0.29382546336878823\n",
      "iterations 6301 accuray : 0.9258559126233984  loss : 0.29381478799318556\n",
      "iterations 6302 accuray : 0.9258559126233984  loss : 0.2938039321493958\n",
      "iterations 6303 accuray : 0.9258559126233984  loss : 0.29379358357430685\n",
      "iterations 6304 accuray : 0.9258559126233984  loss : 0.29378329404413267\n",
      "iterations 6305 accuray : 0.9258559126233984  loss : 0.29377255124913865\n",
      "iterations 6306 accuray : 0.9258559126233984  loss : 0.2937620347758389\n",
      "iterations 6307 accuray : 0.9258559126233984  loss : 0.29375184991219694\n",
      "iterations 6308 accuray : 0.9258559126233984  loss : 0.2937416283483775\n",
      "iterations 6309 accuray : 0.9258559126233984  loss : 0.2937312139480577\n",
      "iterations 6310 accuray : 0.9258559126233984  loss : 0.29372032779850743\n",
      "iterations 6311 accuray : 0.9258559126233984  loss : 0.29370975453686615\n",
      "iterations 6312 accuray : 0.9258559126233984  loss : 0.2936991537934188\n",
      "iterations 6313 accuray : 0.9258559126233984  loss : 0.29368865991589277\n",
      "iterations 6314 accuray : 0.9258559126233984  loss : 0.29367845515275004\n",
      "iterations 6315 accuray : 0.9258559126233984  loss : 0.2936679619669675\n",
      "iterations 6316 accuray : 0.9258559126233984  loss : 0.29365722971730673\n",
      "iterations 6317 accuray : 0.9258559126233984  loss : 0.2936469881523143\n",
      "iterations 6318 accuray : 0.9258559126233984  loss : 0.29363639173445016\n",
      "iterations 6319 accuray : 0.9258559126233984  loss : 0.29362569311118525\n",
      "iterations 6320 accuray : 0.9258559126233984  loss : 0.2936149228978742\n",
      "iterations 6321 accuray : 0.9258559126233984  loss : 0.29360413168246796\n",
      "iterations 6322 accuray : 0.9258559126233984  loss : 0.2935941203624868\n",
      "iterations 6323 accuray : 0.9258559126233984  loss : 0.29358370437726095\n",
      "iterations 6324 accuray : 0.9258559126233984  loss : 0.29357323189759965\n",
      "iterations 6325 accuray : 0.9258559126233984  loss : 0.2935632458264456\n",
      "iterations 6326 accuray : 0.9258559126233984  loss : 0.2935522403142352\n",
      "iterations 6327 accuray : 0.9258559126233984  loss : 0.293541952046352\n",
      "iterations 6328 accuray : 0.9258559126233984  loss : 0.29353127334829365\n",
      "iterations 6329 accuray : 0.9258559126233984  loss : 0.29352053949231244\n",
      "iterations 6330 accuray : 0.925645872715816  loss : 0.29351031364200003\n",
      "iterations 6331 accuray : 0.9258559126233984  loss : 0.29350033411506316\n",
      "iterations 6332 accuray : 0.9258559126233984  loss : 0.29348992007740604\n",
      "iterations 6333 accuray : 0.9258559126233984  loss : 0.29347949452043853\n",
      "iterations 6334 accuray : 0.9258559126233984  loss : 0.29346896239083525\n",
      "iterations 6335 accuray : 0.9258559126233984  loss : 0.29345858107955286\n",
      "iterations 6336 accuray : 0.9258559126233984  loss : 0.2934484090356179\n",
      "iterations 6337 accuray : 0.9258559126233984  loss : 0.2934380556142498\n",
      "iterations 6338 accuray : 0.9258559126233984  loss : 0.29342751085048696\n",
      "iterations 6339 accuray : 0.925645872715816  loss : 0.2934166440131474\n",
      "iterations 6340 accuray : 0.9258559126233984  loss : 0.29340668119870494\n",
      "iterations 6341 accuray : 0.9258559126233984  loss : 0.2933964601079702\n",
      "iterations 6342 accuray : 0.9258559126233984  loss : 0.29338622206555887\n",
      "iterations 6343 accuray : 0.9258559126233984  loss : 0.2933765574249795\n",
      "iterations 6344 accuray : 0.9258559126233984  loss : 0.29336546332579616\n",
      "iterations 6345 accuray : 0.9258559126233984  loss : 0.29335506986546017\n",
      "iterations 6346 accuray : 0.9258559126233984  loss : 0.29334488073192033\n",
      "iterations 6347 accuray : 0.9258559126233984  loss : 0.2933343600925232\n",
      "iterations 6348 accuray : 0.9258559126233984  loss : 0.2933241287066922\n",
      "iterations 6349 accuray : 0.9258559126233984  loss : 0.29331272588736795\n",
      "iterations 6350 accuray : 0.9258559126233984  loss : 0.2933021430297595\n",
      "iterations 6351 accuray : 0.9258559126233984  loss : 0.2932916624935214\n",
      "iterations 6352 accuray : 0.9258559126233984  loss : 0.29328148914375757\n",
      "iterations 6353 accuray : 0.9258559126233984  loss : 0.29327091327269383\n",
      "iterations 6354 accuray : 0.9258559126233984  loss : 0.2932603486164709\n",
      "iterations 6355 accuray : 0.925645872715816  loss : 0.29325024439506325\n",
      "iterations 6356 accuray : 0.9258559126233984  loss : 0.2932394313997175\n",
      "iterations 6357 accuray : 0.9258559126233984  loss : 0.2932289993432194\n",
      "iterations 6358 accuray : 0.9258559126233984  loss : 0.2932184034040435\n",
      "iterations 6359 accuray : 0.9258559126233984  loss : 0.2932079949781209\n",
      "iterations 6360 accuray : 0.9258559126233984  loss : 0.29319794705726415\n",
      "iterations 6361 accuray : 0.9258559126233984  loss : 0.2931875852869354\n",
      "iterations 6362 accuray : 0.9258559126233984  loss : 0.2931772535136305\n",
      "iterations 6363 accuray : 0.9258559126233984  loss : 0.2931669820307952\n",
      "iterations 6364 accuray : 0.9258559126233984  loss : 0.2931565473973286\n",
      "iterations 6365 accuray : 0.9258559126233984  loss : 0.2931460930846154\n",
      "iterations 6366 accuray : 0.925645872715816  loss : 0.2931357483117767\n",
      "iterations 6367 accuray : 0.925645872715816  loss : 0.2931251908923778\n",
      "iterations 6368 accuray : 0.925645872715816  loss : 0.2931148651660295\n",
      "iterations 6369 accuray : 0.925645872715816  loss : 0.29310462830915074\n",
      "iterations 6370 accuray : 0.925645872715816  loss : 0.2930944042154977\n",
      "iterations 6371 accuray : 0.925645872715816  loss : 0.29308401779148574\n",
      "iterations 6372 accuray : 0.925645872715816  loss : 0.2930737490521354\n",
      "iterations 6373 accuray : 0.925645872715816  loss : 0.29306369633762397\n",
      "iterations 6374 accuray : 0.925645872715816  loss : 0.29305349538942493\n",
      "iterations 6375 accuray : 0.925645872715816  loss : 0.29304318682184705\n",
      "iterations 6376 accuray : 0.925645872715816  loss : 0.2930329035321228\n",
      "iterations 6377 accuray : 0.925645872715816  loss : 0.29302252518055477\n",
      "iterations 6378 accuray : 0.925645872715816  loss : 0.2930121315582133\n",
      "iterations 6379 accuray : 0.925645872715816  loss : 0.29300168106448343\n",
      "iterations 6380 accuray : 0.925645872715816  loss : 0.29299096542151076\n",
      "iterations 6381 accuray : 0.925645872715816  loss : 0.29298085049341177\n",
      "iterations 6382 accuray : 0.925645872715816  loss : 0.29297096348156215\n",
      "iterations 6383 accuray : 0.9254358328082336  loss : 0.29296064189107135\n",
      "iterations 6384 accuray : 0.9254358328082336  loss : 0.2929507242582398\n",
      "iterations 6385 accuray : 0.9254358328082336  loss : 0.29294031053038627\n",
      "iterations 6386 accuray : 0.925645872715816  loss : 0.29293056941785534\n",
      "iterations 6387 accuray : 0.9254358328082336  loss : 0.29292015270793503\n",
      "iterations 6388 accuray : 0.9252257929006511  loss : 0.2929094077465573\n",
      "iterations 6389 accuray : 0.9254358328082336  loss : 0.2928990622708303\n",
      "iterations 6390 accuray : 0.925645872715816  loss : 0.29288856940153973\n",
      "iterations 6391 accuray : 0.9252257929006511  loss : 0.2928780232304868\n",
      "iterations 6392 accuray : 0.9252257929006511  loss : 0.2928674444943547\n",
      "iterations 6393 accuray : 0.925645872715816  loss : 0.29285733323505014\n",
      "iterations 6394 accuray : 0.925645872715816  loss : 0.2928475767779628\n",
      "iterations 6395 accuray : 0.9252257929006511  loss : 0.2928372540824273\n",
      "iterations 6396 accuray : 0.9252257929006511  loss : 0.2928272878350216\n",
      "iterations 6397 accuray : 0.9252257929006511  loss : 0.29281671482278576\n",
      "iterations 6398 accuray : 0.9252257929006511  loss : 0.29280668728976644\n",
      "iterations 6399 accuray : 0.9252257929006511  loss : 0.2927958986958223\n",
      "iterations 6400 accuray : 0.9252257929006511  loss : 0.29278572053252977\n",
      "iterations 6401 accuray : 0.9252257929006511  loss : 0.29277579042053553\n",
      "iterations 6402 accuray : 0.925645872715816  loss : 0.2927657604118401\n",
      "iterations 6403 accuray : 0.925645872715816  loss : 0.29275600086415937\n",
      "iterations 6404 accuray : 0.9254358328082336  loss : 0.29274565362519106\n",
      "iterations 6405 accuray : 0.925645872715816  loss : 0.2927358078560392\n",
      "iterations 6406 accuray : 0.9252257929006511  loss : 0.29272581315711194\n",
      "iterations 6407 accuray : 0.9252257929006511  loss : 0.2927153145420518\n",
      "iterations 6408 accuray : 0.9252257929006511  loss : 0.29270530307544196\n",
      "iterations 6409 accuray : 0.9252257929006511  loss : 0.2926950250128368\n",
      "iterations 6410 accuray : 0.9252257929006511  loss : 0.29268484811561474\n",
      "iterations 6411 accuray : 0.9252257929006511  loss : 0.2926743786124522\n",
      "iterations 6412 accuray : 0.9252257929006511  loss : 0.2926641754757474\n",
      "iterations 6413 accuray : 0.9252257929006511  loss : 0.2926537802156824\n",
      "iterations 6414 accuray : 0.9252257929006511  loss : 0.29264362939949046\n",
      "iterations 6415 accuray : 0.9252257929006511  loss : 0.29263373211799626\n",
      "iterations 6416 accuray : 0.9252257929006511  loss : 0.29262376147886937\n",
      "iterations 6417 accuray : 0.9252257929006511  loss : 0.29261308395827873\n",
      "iterations 6418 accuray : 0.9252257929006511  loss : 0.29260326874155146\n",
      "iterations 6419 accuray : 0.9252257929006511  loss : 0.2925928480406681\n",
      "iterations 6420 accuray : 0.9252257929006511  loss : 0.29258246409973016\n",
      "iterations 6421 accuray : 0.9252257929006511  loss : 0.29257212081666095\n",
      "iterations 6422 accuray : 0.9252257929006511  loss : 0.2925619627076893\n",
      "iterations 6423 accuray : 0.9252257929006511  loss : 0.29255160539121816\n",
      "iterations 6424 accuray : 0.9252257929006511  loss : 0.29254113560963035\n",
      "iterations 6425 accuray : 0.9252257929006511  loss : 0.29253062438217287\n",
      "iterations 6426 accuray : 0.9252257929006511  loss : 0.2925201506286301\n",
      "iterations 6427 accuray : 0.9252257929006511  loss : 0.2925102160175959\n",
      "iterations 6428 accuray : 0.9252257929006511  loss : 0.29250015608534036\n",
      "iterations 6429 accuray : 0.9252257929006511  loss : 0.29248959560828713\n",
      "iterations 6430 accuray : 0.9254358328082336  loss : 0.2924797415812887\n",
      "iterations 6431 accuray : 0.9252257929006511  loss : 0.2924695311191429\n",
      "iterations 6432 accuray : 0.9252257929006511  loss : 0.29245964387650814\n",
      "iterations 6433 accuray : 0.9254358328082336  loss : 0.2924499519658246\n",
      "iterations 6434 accuray : 0.9252257929006511  loss : 0.2924396305428581\n",
      "iterations 6435 accuray : 0.9254358328082336  loss : 0.29242979191966134\n",
      "iterations 6436 accuray : 0.9254358328082336  loss : 0.292419995887167\n",
      "iterations 6437 accuray : 0.9254358328082336  loss : 0.29241036194970155\n",
      "iterations 6438 accuray : 0.9252257929006511  loss : 0.29240007663526624\n",
      "iterations 6439 accuray : 0.9254358328082336  loss : 0.29239030751534145\n",
      "iterations 6440 accuray : 0.9254358328082336  loss : 0.2923803041048931\n",
      "iterations 6441 accuray : 0.9254358328082336  loss : 0.2923705074518787\n",
      "iterations 6442 accuray : 0.925645872715816  loss : 0.29236045875592437\n",
      "iterations 6443 accuray : 0.9254358328082336  loss : 0.29235000166045644\n",
      "iterations 6444 accuray : 0.9254358328082336  loss : 0.2923400742261639\n",
      "iterations 6445 accuray : 0.9254358328082336  loss : 0.29232999705469187\n",
      "iterations 6446 accuray : 0.9252257929006511  loss : 0.29231967838029466\n",
      "iterations 6447 accuray : 0.9252257929006511  loss : 0.29231000785693073\n",
      "iterations 6448 accuray : 0.9252257929006511  loss : 0.2922999337830905\n",
      "iterations 6449 accuray : 0.9252257929006511  loss : 0.29228974750900355\n",
      "iterations 6450 accuray : 0.9252257929006511  loss : 0.29227941233177873\n",
      "iterations 6451 accuray : 0.9252257929006511  loss : 0.29226943605001526\n",
      "iterations 6452 accuray : 0.9252257929006511  loss : 0.2922594344643621\n",
      "iterations 6453 accuray : 0.9252257929006511  loss : 0.29224943602434333\n",
      "iterations 6454 accuray : 0.9252257929006511  loss : 0.29223925959604113\n",
      "iterations 6455 accuray : 0.9252257929006511  loss : 0.29222887236907324\n",
      "iterations 6456 accuray : 0.9252257929006511  loss : 0.2922183076668607\n",
      "iterations 6457 accuray : 0.9252257929006511  loss : 0.292208196855485\n",
      "iterations 6458 accuray : 0.9252257929006511  loss : 0.29219827454746\n",
      "iterations 6459 accuray : 0.9252257929006511  loss : 0.29218790191715577\n",
      "iterations 6460 accuray : 0.9252257929006511  loss : 0.29217806013815595\n",
      "iterations 6461 accuray : 0.9252257929006511  loss : 0.2921681050689989\n",
      "iterations 6462 accuray : 0.9252257929006511  loss : 0.29215792377393385\n",
      "iterations 6463 accuray : 0.9252257929006511  loss : 0.29214774390761056\n",
      "iterations 6464 accuray : 0.9252257929006511  loss : 0.2921372975162624\n",
      "iterations 6465 accuray : 0.9250157529930687  loss : 0.292127106097971\n",
      "iterations 6466 accuray : 0.9252257929006511  loss : 0.2921172470567042\n",
      "iterations 6467 accuray : 0.9252257929006511  loss : 0.29210702918386783\n",
      "iterations 6468 accuray : 0.9252257929006511  loss : 0.2920972580465523\n",
      "iterations 6469 accuray : 0.9252257929006511  loss : 0.29208766348732296\n",
      "iterations 6470 accuray : 0.9252257929006511  loss : 0.2920772028336752\n",
      "iterations 6471 accuray : 0.9252257929006511  loss : 0.2920674253456561\n",
      "iterations 6472 accuray : 0.9252257929006511  loss : 0.2920573958492753\n",
      "iterations 6473 accuray : 0.9252257929006511  loss : 0.29204755281190653\n",
      "iterations 6474 accuray : 0.9252257929006511  loss : 0.2920374827167907\n",
      "iterations 6475 accuray : 0.9252257929006511  loss : 0.29202754486435434\n",
      "iterations 6476 accuray : 0.9252257929006511  loss : 0.29201722356130444\n",
      "iterations 6477 accuray : 0.9252257929006511  loss : 0.2920069503526141\n",
      "iterations 6478 accuray : 0.9252257929006511  loss : 0.2919969121529143\n",
      "iterations 6479 accuray : 0.9250157529930687  loss : 0.2919865875534533\n",
      "iterations 6480 accuray : 0.9252257929006511  loss : 0.2919768791732474\n",
      "iterations 6481 accuray : 0.9252257929006511  loss : 0.2919667550737084\n",
      "iterations 6482 accuray : 0.9252257929006511  loss : 0.29195678216530924\n",
      "iterations 6483 accuray : 0.9250157529930687  loss : 0.29194687723916063\n",
      "iterations 6484 accuray : 0.9250157529930687  loss : 0.2919365936884575\n",
      "iterations 6485 accuray : 0.9250157529930687  loss : 0.2919260345675272\n",
      "iterations 6486 accuray : 0.9250157529930687  loss : 0.29191622363703595\n",
      "iterations 6487 accuray : 0.9250157529930687  loss : 0.29190660686403525\n",
      "iterations 6488 accuray : 0.9250157529930687  loss : 0.2918965992994819\n",
      "iterations 6489 accuray : 0.9250157529930687  loss : 0.2918865046460711\n",
      "iterations 6490 accuray : 0.9252257929006511  loss : 0.29187696939379515\n",
      "iterations 6491 accuray : 0.9252257929006511  loss : 0.29186722917040997\n",
      "iterations 6492 accuray : 0.9252257929006511  loss : 0.29185719506336266\n",
      "iterations 6493 accuray : 0.9252257929006511  loss : 0.2918474412819229\n",
      "iterations 6494 accuray : 0.9252257929006511  loss : 0.291837320953783\n",
      "iterations 6495 accuray : 0.9252257929006511  loss : 0.29182764913535975\n",
      "iterations 6496 accuray : 0.9252257929006511  loss : 0.2918177275189041\n",
      "iterations 6497 accuray : 0.9252257929006511  loss : 0.291807455277868\n",
      "iterations 6498 accuray : 0.9252257929006511  loss : 0.29179757226098524\n",
      "iterations 6499 accuray : 0.9252257929006511  loss : 0.29178763980418093\n",
      "iterations 6500 accuray : 0.9250157529930687  loss : 0.29177751384737705\n",
      "iterations 6501 accuray : 0.9252257929006511  loss : 0.2917681089933302\n",
      "iterations 6502 accuray : 0.9252257929006511  loss : 0.29175811051356076\n",
      "iterations 6503 accuray : 0.9252257929006511  loss : 0.2917479311429609\n",
      "iterations 6504 accuray : 0.9252257929006511  loss : 0.2917385699021519\n",
      "iterations 6505 accuray : 0.9252257929006511  loss : 0.2917285742694539\n",
      "iterations 6506 accuray : 0.9252257929006511  loss : 0.29171875987804513\n",
      "iterations 6507 accuray : 0.9252257929006511  loss : 0.2917089108206515\n",
      "iterations 6508 accuray : 0.9252257929006511  loss : 0.29169964655664204\n",
      "iterations 6509 accuray : 0.9252257929006511  loss : 0.29168966847687067\n",
      "iterations 6510 accuray : 0.9252257929006511  loss : 0.2916798786086186\n",
      "iterations 6511 accuray : 0.9252257929006511  loss : 0.29166921051734734\n",
      "iterations 6512 accuray : 0.9252257929006511  loss : 0.29165916602314684\n",
      "iterations 6513 accuray : 0.9252257929006511  loss : 0.2916492441996989\n",
      "iterations 6514 accuray : 0.9252257929006511  loss : 0.29163945243617306\n",
      "iterations 6515 accuray : 0.9252257929006511  loss : 0.29163001618615114\n",
      "iterations 6516 accuray : 0.9252257929006511  loss : 0.29161980574328256\n",
      "iterations 6517 accuray : 0.9252257929006511  loss : 0.2916097358024577\n",
      "iterations 6518 accuray : 0.9252257929006511  loss : 0.2915998750362362\n",
      "iterations 6519 accuray : 0.9252257929006511  loss : 0.2915893094255228\n",
      "iterations 6520 accuray : 0.9252257929006511  loss : 0.2915791261369994\n",
      "iterations 6521 accuray : 0.9252257929006511  loss : 0.29156923708433274\n",
      "iterations 6522 accuray : 0.9252257929006511  loss : 0.291559200165133\n",
      "iterations 6523 accuray : 0.9252257929006511  loss : 0.2915491534416157\n",
      "iterations 6524 accuray : 0.9250157529930687  loss : 0.2915387789434044\n",
      "iterations 6525 accuray : 0.9250157529930687  loss : 0.2915286071489468\n",
      "iterations 6526 accuray : 0.9250157529930687  loss : 0.291518530154707\n",
      "iterations 6527 accuray : 0.9250157529930687  loss : 0.2915084693855618\n",
      "iterations 6528 accuray : 0.9250157529930687  loss : 0.2914986169489882\n",
      "iterations 6529 accuray : 0.9250157529930687  loss : 0.2914887570811029\n",
      "iterations 6530 accuray : 0.9250157529930687  loss : 0.2914786800991557\n",
      "iterations 6531 accuray : 0.9250157529930687  loss : 0.29146900592272296\n",
      "iterations 6532 accuray : 0.9250157529930687  loss : 0.29145903207046325\n",
      "iterations 6533 accuray : 0.9250157529930687  loss : 0.2914491035198648\n",
      "iterations 6534 accuray : 0.9250157529930687  loss : 0.2914391464708014\n",
      "iterations 6535 accuray : 0.9252257929006511  loss : 0.29142919480288604\n",
      "iterations 6536 accuray : 0.9252257929006511  loss : 0.29141928009650425\n",
      "iterations 6537 accuray : 0.9252257929006511  loss : 0.29140925107222726\n",
      "iterations 6538 accuray : 0.9252257929006511  loss : 0.29139941974594963\n",
      "iterations 6539 accuray : 0.9252257929006511  loss : 0.29138965292178354\n",
      "iterations 6540 accuray : 0.9252257929006511  loss : 0.29137970559940635\n",
      "iterations 6541 accuray : 0.9252257929006511  loss : 0.2913694739305095\n",
      "iterations 6542 accuray : 0.9250157529930687  loss : 0.29135942223984734\n",
      "iterations 6543 accuray : 0.9250157529930687  loss : 0.2913495163484874\n",
      "iterations 6544 accuray : 0.9250157529930687  loss : 0.29133905427899137\n",
      "iterations 6545 accuray : 0.9252257929006511  loss : 0.29132981961767046\n",
      "iterations 6546 accuray : 0.9252257929006511  loss : 0.29132021600183877\n",
      "iterations 6547 accuray : 0.9252257929006511  loss : 0.29131048848277125\n",
      "iterations 6548 accuray : 0.9252257929006511  loss : 0.29130107036109953\n",
      "iterations 6549 accuray : 0.9252257929006511  loss : 0.29129123639951804\n",
      "iterations 6550 accuray : 0.9252257929006511  loss : 0.29128178221152295\n",
      "iterations 6551 accuray : 0.9252257929006511  loss : 0.2912724047501954\n",
      "iterations 6552 accuray : 0.9252257929006511  loss : 0.29126238865568377\n",
      "iterations 6553 accuray : 0.9252257929006511  loss : 0.2912524835641413\n",
      "iterations 6554 accuray : 0.9252257929006511  loss : 0.2912429250008877\n",
      "iterations 6555 accuray : 0.9252257929006511  loss : 0.2912331742854437\n",
      "iterations 6556 accuray : 0.9252257929006511  loss : 0.29122349324202007\n",
      "iterations 6557 accuray : 0.9252257929006511  loss : 0.2912137593091057\n",
      "iterations 6558 accuray : 0.9252257929006511  loss : 0.2912037604508049\n",
      "iterations 6559 accuray : 0.9252257929006511  loss : 0.29119437770615386\n",
      "iterations 6560 accuray : 0.9252257929006511  loss : 0.29118435710456325\n",
      "iterations 6561 accuray : 0.9252257929006511  loss : 0.2911746927389563\n",
      "iterations 6562 accuray : 0.9252257929006511  loss : 0.29116534746942585\n",
      "iterations 6563 accuray : 0.9252257929006511  loss : 0.29115527935709534\n",
      "iterations 6564 accuray : 0.9252257929006511  loss : 0.291145006858253\n",
      "iterations 6565 accuray : 0.9250157529930687  loss : 0.29113480343383247\n",
      "iterations 6566 accuray : 0.9250157529930687  loss : 0.29112515235581365\n",
      "iterations 6567 accuray : 0.9250157529930687  loss : 0.2911154471950595\n",
      "iterations 6568 accuray : 0.9252257929006511  loss : 0.29110602789631645\n",
      "iterations 6569 accuray : 0.9252257929006511  loss : 0.29109655655681904\n",
      "iterations 6570 accuray : 0.9250157529930687  loss : 0.29108634406190953\n",
      "iterations 6571 accuray : 0.9250157529930687  loss : 0.29107629778763516\n",
      "iterations 6572 accuray : 0.9250157529930687  loss : 0.2910669720998046\n",
      "iterations 6573 accuray : 0.9250157529930687  loss : 0.29105723874127004\n",
      "iterations 6574 accuray : 0.9252257929006511  loss : 0.2910476192728679\n",
      "iterations 6575 accuray : 0.9250157529930687  loss : 0.2910371390050412\n",
      "iterations 6576 accuray : 0.9250157529930687  loss : 0.2910272031094504\n",
      "iterations 6577 accuray : 0.9250157529930687  loss : 0.2910178157534843\n",
      "iterations 6578 accuray : 0.9250157529930687  loss : 0.2910076871317508\n",
      "iterations 6579 accuray : 0.9250157529930687  loss : 0.29099786181272724\n",
      "iterations 6580 accuray : 0.9250157529930687  loss : 0.2909875309988451\n",
      "iterations 6581 accuray : 0.9250157529930687  loss : 0.2909775819057136\n",
      "iterations 6582 accuray : 0.9250157529930687  loss : 0.2909678514671695\n",
      "iterations 6583 accuray : 0.9250157529930687  loss : 0.29095824360237205\n",
      "iterations 6584 accuray : 0.9250157529930687  loss : 0.290948713452488\n",
      "iterations 6585 accuray : 0.9250157529930687  loss : 0.29093904481178173\n",
      "iterations 6586 accuray : 0.9250157529930687  loss : 0.2909291963779216\n",
      "iterations 6587 accuray : 0.9250157529930687  loss : 0.2909195592529988\n",
      "iterations 6588 accuray : 0.9250157529930687  loss : 0.29091032563770364\n",
      "iterations 6589 accuray : 0.9250157529930687  loss : 0.29090057249510004\n",
      "iterations 6590 accuray : 0.9250157529930687  loss : 0.29089068970602866\n",
      "iterations 6591 accuray : 0.9250157529930687  loss : 0.2908807739872257\n",
      "iterations 6592 accuray : 0.9250157529930687  loss : 0.29087129394413125\n",
      "iterations 6593 accuray : 0.9250157529930687  loss : 0.2908612542751263\n",
      "iterations 6594 accuray : 0.9250157529930687  loss : 0.29085153207671016\n",
      "iterations 6595 accuray : 0.9250157529930687  loss : 0.29084176124471384\n",
      "iterations 6596 accuray : 0.9252257929006511  loss : 0.2908318694009837\n",
      "iterations 6597 accuray : 0.9252257929006511  loss : 0.2908214681396166\n",
      "iterations 6598 accuray : 0.9252257929006511  loss : 0.290811518929639\n",
      "iterations 6599 accuray : 0.9252257929006511  loss : 0.2908018103886295\n",
      "iterations 6600 accuray : 0.9252257929006511  loss : 0.2907915791555096\n",
      "iterations 6601 accuray : 0.9252257929006511  loss : 0.29078162085824244\n",
      "iterations 6602 accuray : 0.9252257929006511  loss : 0.29077203181496497\n",
      "iterations 6603 accuray : 0.9252257929006511  loss : 0.29076225773340836\n",
      "iterations 6604 accuray : 0.9252257929006511  loss : 0.290752409065122\n",
      "iterations 6605 accuray : 0.9252257929006511  loss : 0.2907425584664189\n",
      "iterations 6606 accuray : 0.9252257929006511  loss : 0.2907327257655875\n",
      "iterations 6607 accuray : 0.9252257929006511  loss : 0.2907230265231539\n",
      "iterations 6608 accuray : 0.9250157529930687  loss : 0.2907131407837593\n",
      "iterations 6609 accuray : 0.9250157529930687  loss : 0.2907032811288048\n",
      "iterations 6610 accuray : 0.9250157529930687  loss : 0.29069353888387506\n",
      "iterations 6611 accuray : 0.9250157529930687  loss : 0.2906838767139082\n",
      "iterations 6612 accuray : 0.9250157529930687  loss : 0.29067421997096005\n",
      "iterations 6613 accuray : 0.9250157529930687  loss : 0.29066395653142163\n",
      "iterations 6614 accuray : 0.9250157529930687  loss : 0.2906543360276135\n",
      "iterations 6615 accuray : 0.9250157529930687  loss : 0.29064475676571666\n",
      "iterations 6616 accuray : 0.9252257929006511  loss : 0.2906349360727319\n",
      "iterations 6617 accuray : 0.9252257929006511  loss : 0.2906251104749192\n",
      "iterations 6618 accuray : 0.9252257929006511  loss : 0.29061528869683717\n",
      "iterations 6619 accuray : 0.9252257929006511  loss : 0.2906058970735249\n",
      "iterations 6620 accuray : 0.9252257929006511  loss : 0.29059654279801944\n",
      "iterations 6621 accuray : 0.9252257929006511  loss : 0.2905866347717803\n",
      "iterations 6622 accuray : 0.9252257929006511  loss : 0.29057672090119985\n",
      "iterations 6623 accuray : 0.9252257929006511  loss : 0.29056709098481764\n",
      "iterations 6624 accuray : 0.9252257929006511  loss : 0.29055750857664997\n",
      "iterations 6625 accuray : 0.9252257929006511  loss : 0.29054785192764593\n",
      "iterations 6626 accuray : 0.9250157529930687  loss : 0.2905373957290974\n",
      "iterations 6627 accuray : 0.9252257929006511  loss : 0.2905277445652963\n",
      "iterations 6628 accuray : 0.9250157529930687  loss : 0.29051775008421094\n",
      "iterations 6629 accuray : 0.9250157529930687  loss : 0.29050840327025207\n",
      "iterations 6630 accuray : 0.9250157529930687  loss : 0.2904982765980757\n",
      "iterations 6631 accuray : 0.9250157529930687  loss : 0.29048887360507464\n",
      "iterations 6632 accuray : 0.9250157529930687  loss : 0.2904791817770966\n",
      "iterations 6633 accuray : 0.9250157529930687  loss : 0.2904693310045417\n",
      "iterations 6634 accuray : 0.9250157529930687  loss : 0.29045957494686464\n",
      "iterations 6635 accuray : 0.9250157529930687  loss : 0.29044945377832554\n",
      "iterations 6636 accuray : 0.9250157529930687  loss : 0.2904399673959617\n",
      "iterations 6637 accuray : 0.9250157529930687  loss : 0.2904307117860567\n",
      "iterations 6638 accuray : 0.9250157529930687  loss : 0.29042059227651673\n",
      "iterations 6639 accuray : 0.9250157529930687  loss : 0.2904106454777256\n",
      "iterations 6640 accuray : 0.9250157529930687  loss : 0.29040071437141557\n",
      "iterations 6641 accuray : 0.9250157529930687  loss : 0.29039074108004226\n",
      "iterations 6642 accuray : 0.9250157529930687  loss : 0.2903814209433287\n",
      "iterations 6643 accuray : 0.9250157529930687  loss : 0.29037212334632356\n",
      "iterations 6644 accuray : 0.9250157529930687  loss : 0.2903624087378963\n",
      "iterations 6645 accuray : 0.9250157529930687  loss : 0.29035275670833105\n",
      "iterations 6646 accuray : 0.9250157529930687  loss : 0.29034282306655945\n",
      "iterations 6647 accuray : 0.9250157529930687  loss : 0.2903329703263\n",
      "iterations 6648 accuray : 0.9250157529930687  loss : 0.29032355012461913\n",
      "iterations 6649 accuray : 0.9250157529930687  loss : 0.2903139684522681\n",
      "iterations 6650 accuray : 0.9250157529930687  loss : 0.29030482296856347\n",
      "iterations 6651 accuray : 0.9250157529930687  loss : 0.29029486851980923\n",
      "iterations 6652 accuray : 0.9250157529930687  loss : 0.2902850810988648\n",
      "iterations 6653 accuray : 0.9250157529930687  loss : 0.29027536095062156\n",
      "iterations 6654 accuray : 0.9250157529930687  loss : 0.2902652859296441\n",
      "iterations 6655 accuray : 0.9250157529930687  loss : 0.2902556014168641\n",
      "iterations 6656 accuray : 0.9250157529930687  loss : 0.29024538968708863\n",
      "iterations 6657 accuray : 0.9250157529930687  loss : 0.2902353937478214\n",
      "iterations 6658 accuray : 0.9250157529930687  loss : 0.2902259410447521\n",
      "iterations 6659 accuray : 0.9250157529930687  loss : 0.29021652587743396\n",
      "iterations 6660 accuray : 0.9250157529930687  loss : 0.2902073005807302\n",
      "iterations 6661 accuray : 0.9250157529930687  loss : 0.2901976604790972\n",
      "iterations 6662 accuray : 0.9250157529930687  loss : 0.29018791653512815\n",
      "iterations 6663 accuray : 0.9250157529930687  loss : 0.29017839631304093\n",
      "iterations 6664 accuray : 0.9250157529930687  loss : 0.29016893519990483\n",
      "iterations 6665 accuray : 0.9250157529930687  loss : 0.29015928616738806\n",
      "iterations 6666 accuray : 0.9250157529930687  loss : 0.29014956469571085\n",
      "iterations 6667 accuray : 0.9250157529930687  loss : 0.2901404177199302\n",
      "iterations 6668 accuray : 0.9250157529930687  loss : 0.290130089816802\n",
      "iterations 6669 accuray : 0.9250157529930687  loss : 0.290120416098008\n",
      "iterations 6670 accuray : 0.9250157529930687  loss : 0.29011127907594164\n",
      "iterations 6671 accuray : 0.9250157529930687  loss : 0.29010126904190287\n",
      "iterations 6672 accuray : 0.9250157529930687  loss : 0.29009194105638675\n",
      "iterations 6673 accuray : 0.9250157529930687  loss : 0.290082324338157\n",
      "iterations 6674 accuray : 0.9250157529930687  loss : 0.29007329787234104\n",
      "iterations 6675 accuray : 0.9250157529930687  loss : 0.2900635718998862\n",
      "iterations 6676 accuray : 0.9250157529930687  loss : 0.2900536665353952\n",
      "iterations 6677 accuray : 0.9250157529930687  loss : 0.29004440870220266\n",
      "iterations 6678 accuray : 0.9250157529930687  loss : 0.2900346162696979\n",
      "iterations 6679 accuray : 0.9250157529930687  loss : 0.2900253688071251\n",
      "iterations 6680 accuray : 0.9250157529930687  loss : 0.2900158732583167\n",
      "iterations 6681 accuray : 0.9250157529930687  loss : 0.29000619780726555\n",
      "iterations 6682 accuray : 0.9250157529930687  loss : 0.28999658539235484\n",
      "iterations 6683 accuray : 0.9250157529930687  loss : 0.28998690468587646\n",
      "iterations 6684 accuray : 0.9250157529930687  loss : 0.289977221979785\n",
      "iterations 6685 accuray : 0.9250157529930687  loss : 0.2899677218821002\n",
      "iterations 6686 accuray : 0.9250157529930687  loss : 0.28995807828023457\n",
      "iterations 6687 accuray : 0.9250157529930687  loss : 0.2899484709724005\n",
      "iterations 6688 accuray : 0.9250157529930687  loss : 0.28993867420243946\n",
      "iterations 6689 accuray : 0.9250157529930687  loss : 0.2899284752316822\n",
      "iterations 6690 accuray : 0.9250157529930687  loss : 0.28991878830590534\n",
      "iterations 6691 accuray : 0.9250157529930687  loss : 0.28990915833921854\n",
      "iterations 6692 accuray : 0.9250157529930687  loss : 0.28989929075307186\n",
      "iterations 6693 accuray : 0.9250157529930687  loss : 0.28988919003536523\n",
      "iterations 6694 accuray : 0.9250157529930687  loss : 0.2898793367262568\n",
      "iterations 6695 accuray : 0.9250157529930687  loss : 0.28986999020775933\n",
      "iterations 6696 accuray : 0.9250157529930687  loss : 0.28986069322388386\n",
      "iterations 6697 accuray : 0.9250157529930687  loss : 0.28985094613932133\n",
      "iterations 6698 accuray : 0.9250157529930687  loss : 0.2898418391537645\n",
      "iterations 6699 accuray : 0.9250157529930687  loss : 0.2898319566046898\n",
      "iterations 6700 accuray : 0.9250157529930687  loss : 0.28982247452915455\n",
      "iterations 6701 accuray : 0.9250157529930687  loss : 0.28981280038064255\n",
      "iterations 6702 accuray : 0.9250157529930687  loss : 0.28980305892247793\n",
      "iterations 6703 accuray : 0.9250157529930687  loss : 0.28979324723091127\n",
      "iterations 6704 accuray : 0.9250157529930687  loss : 0.28978345270873307\n",
      "iterations 6705 accuray : 0.9250157529930687  loss : 0.28977389969185036\n",
      "iterations 6706 accuray : 0.9250157529930687  loss : 0.2897645115681207\n",
      "iterations 6707 accuray : 0.9250157529930687  loss : 0.2897546897869989\n",
      "iterations 6708 accuray : 0.9250157529930687  loss : 0.28974527192395394\n",
      "iterations 6709 accuray : 0.9250157529930687  loss : 0.28973529097883444\n",
      "iterations 6710 accuray : 0.9250157529930687  loss : 0.2897258309775176\n",
      "iterations 6711 accuray : 0.9250157529930687  loss : 0.2897165853650886\n",
      "iterations 6712 accuray : 0.9250157529930687  loss : 0.28970696251518296\n",
      "iterations 6713 accuray : 0.9250157529930687  loss : 0.2896973497392597\n",
      "iterations 6714 accuray : 0.9250157529930687  loss : 0.2896875494089564\n",
      "iterations 6715 accuray : 0.9250157529930687  loss : 0.28967836194044655\n",
      "iterations 6716 accuray : 0.9250157529930687  loss : 0.28966882670181426\n",
      "iterations 6717 accuray : 0.9250157529930687  loss : 0.28965895520108675\n",
      "iterations 6718 accuray : 0.9250157529930687  loss : 0.2896495119663152\n",
      "iterations 6719 accuray : 0.9250157529930687  loss : 0.28963979333561674\n",
      "iterations 6720 accuray : 0.9250157529930687  loss : 0.28963042607828826\n",
      "iterations 6721 accuray : 0.9250157529930687  loss : 0.28962104133787253\n",
      "iterations 6722 accuray : 0.9250157529930687  loss : 0.28961173848419863\n",
      "iterations 6723 accuray : 0.9250157529930687  loss : 0.28960241980972584\n",
      "iterations 6724 accuray : 0.9250157529930687  loss : 0.28959286659331296\n",
      "iterations 6725 accuray : 0.9250157529930687  loss : 0.2895834017553554\n",
      "iterations 6726 accuray : 0.9250157529930687  loss : 0.2895737391468282\n",
      "iterations 6727 accuray : 0.9250157529930687  loss : 0.2895638959356276\n",
      "iterations 6728 accuray : 0.9250157529930687  loss : 0.2895546508738326\n",
      "iterations 6729 accuray : 0.9250157529930687  loss : 0.2895447059366367\n",
      "iterations 6730 accuray : 0.9250157529930687  loss : 0.2895348035255231\n",
      "iterations 6731 accuray : 0.9250157529930687  loss : 0.28952550529862375\n",
      "iterations 6732 accuray : 0.9250157529930687  loss : 0.28951591226925716\n",
      "iterations 6733 accuray : 0.9250157529930687  loss : 0.28950653004178106\n",
      "iterations 6734 accuray : 0.9250157529930687  loss : 0.28949711831401437\n",
      "iterations 6735 accuray : 0.9250157529930687  loss : 0.28948788259711133\n",
      "iterations 6736 accuray : 0.9250157529930687  loss : 0.2894781755318845\n",
      "iterations 6737 accuray : 0.9250157529930687  loss : 0.28946894457346695\n",
      "iterations 6738 accuray : 0.9250157529930687  loss : 0.28945923591325096\n",
      "iterations 6739 accuray : 0.9250157529930687  loss : 0.28944939900310673\n",
      "iterations 6740 accuray : 0.9250157529930687  loss : 0.2894399460258879\n",
      "iterations 6741 accuray : 0.9250157529930687  loss : 0.289429898414393\n",
      "iterations 6742 accuray : 0.9250157529930687  loss : 0.28942088848414\n",
      "iterations 6743 accuray : 0.9250157529930687  loss : 0.28941147988862564\n",
      "iterations 6744 accuray : 0.9248057130854862  loss : 0.2894014954065563\n",
      "iterations 6745 accuray : 0.9248057130854862  loss : 0.2893916988302921\n",
      "iterations 6746 accuray : 0.9245956731779038  loss : 0.2893820815668993\n",
      "iterations 6747 accuray : 0.9245956731779038  loss : 0.2893718957362221\n",
      "iterations 6748 accuray : 0.9245956731779038  loss : 0.28936303897191823\n",
      "iterations 6749 accuray : 0.9248057130854862  loss : 0.289353710732169\n",
      "iterations 6750 accuray : 0.9248057130854862  loss : 0.289344172842585\n",
      "iterations 6751 accuray : 0.9248057130854862  loss : 0.2893348494946306\n",
      "iterations 6752 accuray : 0.9248057130854862  loss : 0.28932499672082723\n",
      "iterations 6753 accuray : 0.9248057130854862  loss : 0.2893150390185072\n",
      "iterations 6754 accuray : 0.9248057130854862  loss : 0.28930587017563786\n",
      "iterations 6755 accuray : 0.9245956731779038  loss : 0.28929606109589606\n",
      "iterations 6756 accuray : 0.9245956731779038  loss : 0.2892863157727509\n",
      "iterations 6757 accuray : 0.9245956731779038  loss : 0.28927659070722184\n",
      "iterations 6758 accuray : 0.9245956731779038  loss : 0.28926715505321277\n",
      "iterations 6759 accuray : 0.9245956731779038  loss : 0.2892578162221756\n",
      "iterations 6760 accuray : 0.9245956731779038  loss : 0.28924803957969436\n",
      "iterations 6761 accuray : 0.9245956731779038  loss : 0.2892393090295053\n",
      "iterations 6762 accuray : 0.9245956731779038  loss : 0.2892298202396196\n",
      "iterations 6763 accuray : 0.9245956731779038  loss : 0.28922088864619844\n",
      "iterations 6764 accuray : 0.9245956731779038  loss : 0.28921176637915863\n",
      "iterations 6765 accuray : 0.9245956731779038  loss : 0.2892021020190204\n",
      "iterations 6766 accuray : 0.9245956731779038  loss : 0.28919298076519884\n",
      "iterations 6767 accuray : 0.9245956731779038  loss : 0.28918346753578605\n",
      "iterations 6768 accuray : 0.9245956731779038  loss : 0.28917314265959526\n",
      "iterations 6769 accuray : 0.9245956731779038  loss : 0.2891638130880393\n",
      "iterations 6770 accuray : 0.9245956731779038  loss : 0.2891547536556666\n",
      "iterations 6771 accuray : 0.9245956731779038  loss : 0.28914482234662997\n",
      "iterations 6772 accuray : 0.9245956731779038  loss : 0.2891350985494733\n",
      "iterations 6773 accuray : 0.9245956731779038  loss : 0.2891253769781166\n",
      "iterations 6774 accuray : 0.9245956731779038  loss : 0.2891159514507212\n",
      "iterations 6775 accuray : 0.9245956731779038  loss : 0.2891064564966054\n",
      "iterations 6776 accuray : 0.9245956731779038  loss : 0.28909698564644537\n",
      "iterations 6777 accuray : 0.9245956731779038  loss : 0.28908794364355883\n",
      "iterations 6778 accuray : 0.9245956731779038  loss : 0.2890785705464732\n",
      "iterations 6779 accuray : 0.9245956731779038  loss : 0.2890692473893749\n",
      "iterations 6780 accuray : 0.9245956731779038  loss : 0.2890596528640562\n",
      "iterations 6781 accuray : 0.9245956731779038  loss : 0.289050532259257\n",
      "iterations 6782 accuray : 0.9245956731779038  loss : 0.28904036607608236\n",
      "iterations 6783 accuray : 0.9245956731779038  loss : 0.28903104267892926\n",
      "iterations 6784 accuray : 0.9245956731779038  loss : 0.2890219616848531\n",
      "iterations 6785 accuray : 0.9245956731779038  loss : 0.2890128407053425\n",
      "iterations 6786 accuray : 0.9245956731779038  loss : 0.2890037441089411\n",
      "iterations 6787 accuray : 0.9245956731779038  loss : 0.28899434023794207\n",
      "iterations 6788 accuray : 0.9245956731779038  loss : 0.288984689135439\n",
      "iterations 6789 accuray : 0.9245956731779038  loss : 0.2889748007617118\n",
      "iterations 6790 accuray : 0.9245956731779038  loss : 0.2889657070619814\n",
      "iterations 6791 accuray : 0.9245956731779038  loss : 0.28895559270164506\n",
      "iterations 6792 accuray : 0.9245956731779038  loss : 0.2889466929605548\n",
      "iterations 6793 accuray : 0.9245956731779038  loss : 0.288937287373558\n",
      "iterations 6794 accuray : 0.9245956731779038  loss : 0.2889276725510199\n",
      "iterations 6795 accuray : 0.9245956731779038  loss : 0.28891850243937417\n",
      "iterations 6796 accuray : 0.9245956731779038  loss : 0.2889092573179577\n",
      "iterations 6797 accuray : 0.9245956731779038  loss : 0.28890005712934347\n",
      "iterations 6798 accuray : 0.9245956731779038  loss : 0.2888902156550216\n",
      "iterations 6799 accuray : 0.9245956731779038  loss : 0.28888071573889956\n",
      "iterations 6800 accuray : 0.9245956731779038  loss : 0.2888713683813732\n",
      "iterations 6801 accuray : 0.9245956731779038  loss : 0.28886183354817657\n",
      "iterations 6802 accuray : 0.9245956731779038  loss : 0.2888524520783539\n",
      "iterations 6803 accuray : 0.9245956731779038  loss : 0.2888433908272344\n",
      "iterations 6804 accuray : 0.9245956731779038  loss : 0.28883436655395767\n",
      "iterations 6805 accuray : 0.9245956731779038  loss : 0.28882528342510766\n",
      "iterations 6806 accuray : 0.9245956731779038  loss : 0.2888155016322652\n",
      "iterations 6807 accuray : 0.9245956731779038  loss : 0.2888062073822545\n",
      "iterations 6808 accuray : 0.9245956731779038  loss : 0.2887970959195829\n",
      "iterations 6809 accuray : 0.9245956731779038  loss : 0.2887881094673687\n",
      "iterations 6810 accuray : 0.9245956731779038  loss : 0.28877878481646463\n",
      "iterations 6811 accuray : 0.9245956731779038  loss : 0.288768956335\n",
      "iterations 6812 accuray : 0.9245956731779038  loss : 0.28875953747107375\n",
      "iterations 6813 accuray : 0.9245956731779038  loss : 0.2887499460604715\n",
      "iterations 6814 accuray : 0.9245956731779038  loss : 0.2887411024331072\n",
      "iterations 6815 accuray : 0.9245956731779038  loss : 0.2887318151287429\n",
      "iterations 6816 accuray : 0.9245956731779038  loss : 0.28872216978235005\n",
      "iterations 6817 accuray : 0.9245956731779038  loss : 0.2887128276569163\n",
      "iterations 6818 accuray : 0.9245956731779038  loss : 0.2887036675101198\n",
      "iterations 6819 accuray : 0.9245956731779038  loss : 0.28869444867435584\n",
      "iterations 6820 accuray : 0.9245956731779038  loss : 0.2886849259917297\n",
      "iterations 6821 accuray : 0.9245956731779038  loss : 0.28867536549801587\n",
      "iterations 6822 accuray : 0.9245956731779038  loss : 0.28866591252385565\n",
      "iterations 6823 accuray : 0.9245956731779038  loss : 0.28865678768490055\n",
      "iterations 6824 accuray : 0.9245956731779038  loss : 0.28864738235604087\n",
      "iterations 6825 accuray : 0.9245956731779038  loss : 0.2886375542649322\n",
      "iterations 6826 accuray : 0.9245956731779038  loss : 0.2886282291763456\n",
      "iterations 6827 accuray : 0.9245956731779038  loss : 0.288618341053957\n",
      "iterations 6828 accuray : 0.9245956731779038  loss : 0.2886093051572802\n",
      "iterations 6829 accuray : 0.9245956731779038  loss : 0.2885999590107588\n",
      "iterations 6830 accuray : 0.9245956731779038  loss : 0.2885902201848101\n",
      "iterations 6831 accuray : 0.9245956731779038  loss : 0.28858096093979374\n",
      "iterations 6832 accuray : 0.9245956731779038  loss : 0.28857187516484384\n",
      "iterations 6833 accuray : 0.9245956731779038  loss : 0.2885624849522854\n",
      "iterations 6834 accuray : 0.9245956731779038  loss : 0.28855289294378494\n",
      "iterations 6835 accuray : 0.9245956731779038  loss : 0.2885433511199894\n",
      "iterations 6836 accuray : 0.9245956731779038  loss : 0.288534299887502\n",
      "iterations 6837 accuray : 0.9245956731779038  loss : 0.28852521467262016\n",
      "iterations 6838 accuray : 0.9245956731779038  loss : 0.2885161448079223\n",
      "iterations 6839 accuray : 0.9245956731779038  loss : 0.2885071105106293\n",
      "iterations 6840 accuray : 0.9245956731779038  loss : 0.28849772307520066\n",
      "iterations 6841 accuray : 0.9245956731779038  loss : 0.2884883908859261\n",
      "iterations 6842 accuray : 0.9245956731779038  loss : 0.288478926506658\n",
      "iterations 6843 accuray : 0.9245956731779038  loss : 0.2884694656185704\n",
      "iterations 6844 accuray : 0.9245956731779038  loss : 0.28846034811470866\n",
      "iterations 6845 accuray : 0.9245956731779038  loss : 0.288450886538879\n",
      "iterations 6846 accuray : 0.9245956731779038  loss : 0.2884415568372829\n",
      "iterations 6847 accuray : 0.9245956731779038  loss : 0.28843230114725815\n",
      "iterations 6848 accuray : 0.9245956731779038  loss : 0.28842322994974057\n",
      "iterations 6849 accuray : 0.9245956731779038  loss : 0.28841449126529206\n",
      "iterations 6850 accuray : 0.9245956731779038  loss : 0.28840543624273873\n",
      "iterations 6851 accuray : 0.9245956731779038  loss : 0.2883960769505275\n",
      "iterations 6852 accuray : 0.9245956731779038  loss : 0.28838657371233145\n",
      "iterations 6853 accuray : 0.9245956731779038  loss : 0.28837750688095576\n",
      "iterations 6854 accuray : 0.9245956731779038  loss : 0.2883684584246871\n",
      "iterations 6855 accuray : 0.9245956731779038  loss : 0.28835917984364323\n",
      "iterations 6856 accuray : 0.9245956731779038  loss : 0.28835012091095624\n",
      "iterations 6857 accuray : 0.9245956731779038  loss : 0.28834124628727503\n",
      "iterations 6858 accuray : 0.9245956731779038  loss : 0.2883320952260516\n",
      "iterations 6859 accuray : 0.9245956731779038  loss : 0.2883231799499765\n",
      "iterations 6860 accuray : 0.9245956731779038  loss : 0.2883136970595497\n",
      "iterations 6861 accuray : 0.9245956731779038  loss : 0.28830379623914426\n",
      "iterations 6862 accuray : 0.9245956731779038  loss : 0.2882946947216027\n",
      "iterations 6863 accuray : 0.9245956731779038  loss : 0.28828576925132116\n",
      "iterations 6864 accuray : 0.9245956731779038  loss : 0.2882771098484148\n",
      "iterations 6865 accuray : 0.9245956731779038  loss : 0.2882679585087429\n",
      "iterations 6866 accuray : 0.9245956731779038  loss : 0.2882588089431674\n",
      "iterations 6867 accuray : 0.9245956731779038  loss : 0.28824957083815955\n",
      "iterations 6868 accuray : 0.9245956731779038  loss : 0.2882405212686259\n",
      "iterations 6869 accuray : 0.9245956731779038  loss : 0.2882312689891143\n",
      "iterations 6870 accuray : 0.9245956731779038  loss : 0.28822194558375724\n",
      "iterations 6871 accuray : 0.9245956731779038  loss : 0.28821255590914724\n",
      "iterations 6872 accuray : 0.9245956731779038  loss : 0.2882030791215607\n",
      "iterations 6873 accuray : 0.9245956731779038  loss : 0.2881935396304844\n",
      "iterations 6874 accuray : 0.9245956731779038  loss : 0.2881846251436855\n",
      "iterations 6875 accuray : 0.9245956731779038  loss : 0.28817519462482105\n",
      "iterations 6876 accuray : 0.9245956731779038  loss : 0.2881658861268735\n",
      "iterations 6877 accuray : 0.9245956731779038  loss : 0.2881562825214364\n",
      "iterations 6878 accuray : 0.9245956731779038  loss : 0.28814710462419735\n",
      "iterations 6879 accuray : 0.9245956731779038  loss : 0.2881376016141646\n",
      "iterations 6880 accuray : 0.9245956731779038  loss : 0.2881279144218965\n",
      "iterations 6881 accuray : 0.9245956731779038  loss : 0.28811863011247485\n",
      "iterations 6882 accuray : 0.9245956731779038  loss : 0.28810954124373567\n",
      "iterations 6883 accuray : 0.9245956731779038  loss : 0.2881001811379616\n",
      "iterations 6884 accuray : 0.9245956731779038  loss : 0.288090511724873\n",
      "iterations 6885 accuray : 0.9245956731779038  loss : 0.28808130520384023\n",
      "iterations 6886 accuray : 0.9245956731779038  loss : 0.2880722052290326\n",
      "iterations 6887 accuray : 0.9245956731779038  loss : 0.28806304944587297\n",
      "iterations 6888 accuray : 0.9245956731779038  loss : 0.28805372508129334\n",
      "iterations 6889 accuray : 0.9245956731779038  loss : 0.2880445563514315\n",
      "iterations 6890 accuray : 0.9245956731779038  loss : 0.28803550730874367\n",
      "iterations 6891 accuray : 0.9245956731779038  loss : 0.28802639637752453\n",
      "iterations 6892 accuray : 0.9245956731779038  loss : 0.28801664652516934\n",
      "iterations 6893 accuray : 0.9245956731779038  loss : 0.28800728302907624\n",
      "iterations 6894 accuray : 0.9245956731779038  loss : 0.28799777944483596\n",
      "iterations 6895 accuray : 0.9245956731779038  loss : 0.2879885180052527\n",
      "iterations 6896 accuray : 0.9245956731779038  loss : 0.2879793183342573\n",
      "iterations 6897 accuray : 0.9245956731779038  loss : 0.2879702421549548\n",
      "iterations 6898 accuray : 0.9245956731779038  loss : 0.2879610841815985\n",
      "iterations 6899 accuray : 0.9243856332703214  loss : 0.2879518797111776\n",
      "iterations 6900 accuray : 0.9243856332703214  loss : 0.28794264287071714\n",
      "iterations 6901 accuray : 0.9245956731779038  loss : 0.2879332935971612\n",
      "iterations 6902 accuray : 0.9245956731779038  loss : 0.28792390305558807\n",
      "iterations 6903 accuray : 0.9245956731779038  loss : 0.28791455074517225\n",
      "iterations 6904 accuray : 0.9245956731779038  loss : 0.2879053609854378\n",
      "iterations 6905 accuray : 0.9245956731779038  loss : 0.28789615247002837\n",
      "iterations 6906 accuray : 0.9245956731779038  loss : 0.28788691583598286\n",
      "iterations 6907 accuray : 0.9245956731779038  loss : 0.28787754663976733\n",
      "iterations 6908 accuray : 0.9245956731779038  loss : 0.2878683307436853\n",
      "iterations 6909 accuray : 0.9245956731779038  loss : 0.2878596297055776\n",
      "iterations 6910 accuray : 0.9245956731779038  loss : 0.2878505332617486\n",
      "iterations 6911 accuray : 0.9243856332703214  loss : 0.2878410674934292\n",
      "iterations 6912 accuray : 0.9245956731779038  loss : 0.28783225618199926\n",
      "iterations 6913 accuray : 0.9243856332703214  loss : 0.28782280713406594\n",
      "iterations 6914 accuray : 0.9245956731779038  loss : 0.28781341384077186\n",
      "iterations 6915 accuray : 0.9245956731779038  loss : 0.28780438359843696\n",
      "iterations 6916 accuray : 0.9245956731779038  loss : 0.28779505927017013\n",
      "iterations 6917 accuray : 0.9245956731779038  loss : 0.28778593110883494\n",
      "iterations 6918 accuray : 0.9245956731779038  loss : 0.2877768441623989\n",
      "iterations 6919 accuray : 0.9243856332703214  loss : 0.28776782991613753\n",
      "iterations 6920 accuray : 0.9245956731779038  loss : 0.2877584889671961\n",
      "iterations 6921 accuray : 0.9245956731779038  loss : 0.28774967176903193\n",
      "iterations 6922 accuray : 0.9245956731779038  loss : 0.28774034465774406\n",
      "iterations 6923 accuray : 0.9245956731779038  loss : 0.2877314335845747\n",
      "iterations 6924 accuray : 0.9245956731779038  loss : 0.28772234195907614\n",
      "iterations 6925 accuray : 0.9245956731779038  loss : 0.2877133094615311\n",
      "iterations 6926 accuray : 0.9245956731779038  loss : 0.2877039361137585\n",
      "iterations 6927 accuray : 0.9245956731779038  loss : 0.28769482398672436\n",
      "iterations 6928 accuray : 0.9245956731779038  loss : 0.28768584839850464\n",
      "iterations 6929 accuray : 0.9245956731779038  loss : 0.28767682182515836\n",
      "iterations 6930 accuray : 0.9245956731779038  loss : 0.2876673674452064\n",
      "iterations 6931 accuray : 0.9245956731779038  loss : 0.28765831999892616\n",
      "iterations 6932 accuray : 0.9245956731779038  loss : 0.28764922648008684\n",
      "iterations 6933 accuray : 0.9245956731779038  loss : 0.2876401310446971\n",
      "iterations 6934 accuray : 0.9245956731779038  loss : 0.2876314350501017\n",
      "iterations 6935 accuray : 0.9245956731779038  loss : 0.28762232405186755\n",
      "iterations 6936 accuray : 0.9245956731779038  loss : 0.28761285376264106\n",
      "iterations 6937 accuray : 0.9245956731779038  loss : 0.2876044235563498\n",
      "iterations 6938 accuray : 0.9245956731779038  loss : 0.28759559854771505\n",
      "iterations 6939 accuray : 0.9245956731779038  loss : 0.2875858453048977\n",
      "iterations 6940 accuray : 0.9245956731779038  loss : 0.2875766299745242\n",
      "iterations 6941 accuray : 0.9245956731779038  loss : 0.2875674610458902\n",
      "iterations 6942 accuray : 0.9245956731779038  loss : 0.28755828656828886\n",
      "iterations 6943 accuray : 0.9245956731779038  loss : 0.2875496610798279\n",
      "iterations 6944 accuray : 0.9245956731779038  loss : 0.2875404571416445\n",
      "iterations 6945 accuray : 0.9245956731779038  loss : 0.2875314950086145\n",
      "iterations 6946 accuray : 0.9245956731779038  loss : 0.28752239101327315\n",
      "iterations 6947 accuray : 0.9245956731779038  loss : 0.28751329303281886\n",
      "iterations 6948 accuray : 0.9245956731779038  loss : 0.2875038443222322\n",
      "iterations 6949 accuray : 0.9245956731779038  loss : 0.2874950905597105\n",
      "iterations 6950 accuray : 0.9245956731779038  loss : 0.2874859639102079\n",
      "iterations 6951 accuray : 0.9245956731779038  loss : 0.28747683901651155\n",
      "iterations 6952 accuray : 0.9243856332703214  loss : 0.2874671150837788\n",
      "iterations 6953 accuray : 0.9245956731779038  loss : 0.2874581138471139\n",
      "iterations 6954 accuray : 0.9245956731779038  loss : 0.28744925597714227\n",
      "iterations 6955 accuray : 0.9245956731779038  loss : 0.28744024396596907\n",
      "iterations 6956 accuray : 0.9245956731779038  loss : 0.28743090323775133\n",
      "iterations 6957 accuray : 0.9245956731779038  loss : 0.28742195245248153\n",
      "iterations 6958 accuray : 0.9245956731779038  loss : 0.2874134941789723\n",
      "iterations 6959 accuray : 0.9245956731779038  loss : 0.2874042139114954\n",
      "iterations 6960 accuray : 0.9245956731779038  loss : 0.2873952424761508\n",
      "iterations 6961 accuray : 0.9245956731779038  loss : 0.2873865901672335\n",
      "iterations 6962 accuray : 0.9245956731779038  loss : 0.2873772730277159\n",
      "iterations 6963 accuray : 0.9245956731779038  loss : 0.2873676407645977\n",
      "iterations 6964 accuray : 0.9245956731779038  loss : 0.2873584514852237\n",
      "iterations 6965 accuray : 0.9245956731779038  loss : 0.2873494668021848\n",
      "iterations 6966 accuray : 0.9245956731779038  loss : 0.2873404339887688\n",
      "iterations 6967 accuray : 0.9245956731779038  loss : 0.28733099575824733\n",
      "iterations 6968 accuray : 0.9245956731779038  loss : 0.2873221699550722\n",
      "iterations 6969 accuray : 0.9245956731779038  loss : 0.28731322526788816\n",
      "iterations 6970 accuray : 0.9245956731779038  loss : 0.2873040504175559\n",
      "iterations 6971 accuray : 0.9245956731779038  loss : 0.28729487208704785\n",
      "iterations 6972 accuray : 0.9245956731779038  loss : 0.2872859916836621\n",
      "iterations 6973 accuray : 0.9245956731779038  loss : 0.28727714507677155\n",
      "iterations 6974 accuray : 0.9245956731779038  loss : 0.28726818808584004\n",
      "iterations 6975 accuray : 0.9245956731779038  loss : 0.28725920998149135\n",
      "iterations 6976 accuray : 0.9243856332703214  loss : 0.28725023411433526\n",
      "iterations 6977 accuray : 0.9245956731779038  loss : 0.287241286134072\n",
      "iterations 6978 accuray : 0.9245956731779038  loss : 0.28723230837313984\n",
      "iterations 6979 accuray : 0.9245956731779038  loss : 0.287223223739288\n",
      "iterations 6980 accuray : 0.9245956731779038  loss : 0.28721430910295204\n",
      "iterations 6981 accuray : 0.9245956731779038  loss : 0.2872055099984586\n",
      "iterations 6982 accuray : 0.9245956731779038  loss : 0.2871967633348858\n",
      "iterations 6983 accuray : 0.9245956731779038  loss : 0.28718765627101767\n",
      "iterations 6984 accuray : 0.9245956731779038  loss : 0.28717858573081034\n",
      "iterations 6985 accuray : 0.9245956731779038  loss : 0.28716928240847023\n",
      "iterations 6986 accuray : 0.9245956731779038  loss : 0.28716024299868625\n",
      "iterations 6987 accuray : 0.9245956731779038  loss : 0.28715102688888183\n",
      "iterations 6988 accuray : 0.9245956731779038  loss : 0.287142267440218\n",
      "iterations 6989 accuray : 0.9245956731779038  loss : 0.28713314260073347\n",
      "iterations 6990 accuray : 0.9245956731779038  loss : 0.2871242929916299\n",
      "iterations 6991 accuray : 0.9245956731779038  loss : 0.2871155742968453\n",
      "iterations 6992 accuray : 0.9245956731779038  loss : 0.28710647586774596\n",
      "iterations 6993 accuray : 0.9245956731779038  loss : 0.28709795398450016\n",
      "iterations 6994 accuray : 0.9245956731779038  loss : 0.2870887746657697\n",
      "iterations 6995 accuray : 0.9245956731779038  loss : 0.28707959930146637\n",
      "iterations 6996 accuray : 0.9245956731779038  loss : 0.2870713075633808\n",
      "iterations 6997 accuray : 0.9245956731779038  loss : 0.2870628410566671\n",
      "iterations 6998 accuray : 0.9245956731779038  loss : 0.2870533755796438\n",
      "iterations 6999 accuray : 0.9243856332703214  loss : 0.28704433651079\n",
      "iterations 7000 accuray : 0.9245956731779038  loss : 0.28703567286088494\n",
      "iterations 7001 accuray : 0.9245956731779038  loss : 0.28702704988243183\n",
      "iterations 7002 accuray : 0.9243856332703214  loss : 0.28701765452942546\n",
      "iterations 7003 accuray : 0.9243856332703214  loss : 0.2870088404262072\n",
      "iterations 7004 accuray : 0.9243856332703214  loss : 0.2869998534938805\n",
      "iterations 7005 accuray : 0.9243856332703214  loss : 0.2869915696518963\n",
      "iterations 7006 accuray : 0.9243856332703214  loss : 0.28698268651625347\n",
      "iterations 7007 accuray : 0.9245956731779038  loss : 0.2869740508556113\n",
      "iterations 7008 accuray : 0.9245956731779038  loss : 0.28696531411293613\n",
      "iterations 7009 accuray : 0.9245956731779038  loss : 0.28695669804226315\n",
      "iterations 7010 accuray : 0.9245956731779038  loss : 0.2869477374608678\n",
      "iterations 7011 accuray : 0.9245956731779038  loss : 0.28693890156855867\n",
      "iterations 7012 accuray : 0.9245956731779038  loss : 0.28692962012986073\n",
      "iterations 7013 accuray : 0.9245956731779038  loss : 0.2869204347818787\n",
      "iterations 7014 accuray : 0.9243856332703214  loss : 0.2869113704476852\n",
      "iterations 7015 accuray : 0.9243856332703214  loss : 0.2869022496176211\n",
      "iterations 7016 accuray : 0.9243856332703214  loss : 0.2868932634294573\n",
      "iterations 7017 accuray : 0.9243856332703214  loss : 0.28688389024520167\n",
      "iterations 7018 accuray : 0.9243856332703214  loss : 0.28687481281447674\n",
      "iterations 7019 accuray : 0.9243856332703214  loss : 0.28686581681952483\n",
      "iterations 7020 accuray : 0.9243856332703214  loss : 0.2868566558691775\n",
      "iterations 7021 accuray : 0.9243856332703214  loss : 0.2868481146924468\n",
      "iterations 7022 accuray : 0.9243856332703214  loss : 0.28683892678446793\n",
      "iterations 7023 accuray : 0.9243856332703214  loss : 0.28682969306863604\n",
      "iterations 7024 accuray : 0.9243856332703214  loss : 0.2868208911707318\n",
      "iterations 7025 accuray : 0.9243856332703214  loss : 0.2868115934948561\n",
      "iterations 7026 accuray : 0.9243856332703214  loss : 0.28680234355134565\n",
      "iterations 7027 accuray : 0.9243856332703214  loss : 0.2867930918662636\n",
      "iterations 7028 accuray : 0.9243856332703214  loss : 0.28678361032708666\n",
      "iterations 7029 accuray : 0.9243856332703214  loss : 0.28677462761504735\n",
      "iterations 7030 accuray : 0.9243856332703214  loss : 0.28676567493535066\n",
      "iterations 7031 accuray : 0.9243856332703214  loss : 0.2867567239109633\n",
      "iterations 7032 accuray : 0.9243856332703214  loss : 0.2867474453332584\n",
      "iterations 7033 accuray : 0.9243856332703214  loss : 0.2867389246750975\n",
      "iterations 7034 accuray : 0.9241755933627389  loss : 0.2867299319942376\n",
      "iterations 7035 accuray : 0.9241755933627389  loss : 0.2867210774740007\n",
      "iterations 7036 accuray : 0.9241755933627389  loss : 0.28671238089786055\n",
      "iterations 7037 accuray : 0.9241755933627389  loss : 0.2867036728602964\n",
      "iterations 7038 accuray : 0.9241755933627389  loss : 0.28669510843343265\n",
      "iterations 7039 accuray : 0.9241755933627389  loss : 0.2866866063737287\n",
      "iterations 7040 accuray : 0.9241755933627389  loss : 0.2866775890782864\n",
      "iterations 7041 accuray : 0.9241755933627389  loss : 0.28666895418461613\n",
      "iterations 7042 accuray : 0.9241755933627389  loss : 0.28666002612572034\n",
      "iterations 7043 accuray : 0.9239655534551565  loss : 0.28665075622590264\n",
      "iterations 7044 accuray : 0.9241755933627389  loss : 0.2866416541265923\n",
      "iterations 7045 accuray : 0.9241755933627389  loss : 0.28663300492530497\n",
      "iterations 7046 accuray : 0.9241755933627389  loss : 0.2866238302308023\n",
      "iterations 7047 accuray : 0.9241755933627389  loss : 0.2866146401092422\n",
      "iterations 7048 accuray : 0.9241755933627389  loss : 0.28660552886113705\n",
      "iterations 7049 accuray : 0.9241755933627389  loss : 0.28659680415124833\n",
      "iterations 7050 accuray : 0.9241755933627389  loss : 0.2865876793265911\n",
      "iterations 7051 accuray : 0.9241755933627389  loss : 0.28657843176216025\n",
      "iterations 7052 accuray : 0.9241755933627389  loss : 0.2865699471574494\n",
      "iterations 7053 accuray : 0.9241755933627389  loss : 0.28656113776482867\n",
      "iterations 7054 accuray : 0.9241755933627389  loss : 0.28655212407184893\n",
      "iterations 7055 accuray : 0.9241755933627389  loss : 0.2865434111772471\n",
      "iterations 7056 accuray : 0.9241755933627389  loss : 0.28653479446646885\n",
      "iterations 7057 accuray : 0.9241755933627389  loss : 0.28652598845108646\n",
      "iterations 7058 accuray : 0.9241755933627389  loss : 0.2865171522383903\n",
      "iterations 7059 accuray : 0.9241755933627389  loss : 0.2865082091206579\n",
      "iterations 7060 accuray : 0.9241755933627389  loss : 0.28649946340017446\n",
      "iterations 7061 accuray : 0.9241755933627389  loss : 0.2864906173417929\n",
      "iterations 7062 accuray : 0.9241755933627389  loss : 0.2864819808633604\n",
      "iterations 7063 accuray : 0.9241755933627389  loss : 0.2864729790654859\n",
      "iterations 7064 accuray : 0.9241755933627389  loss : 0.28646432867374266\n",
      "iterations 7065 accuray : 0.9241755933627389  loss : 0.2864553555470774\n",
      "iterations 7066 accuray : 0.9241755933627389  loss : 0.28644642881300747\n",
      "iterations 7067 accuray : 0.9241755933627389  loss : 0.28643784341946615\n",
      "iterations 7068 accuray : 0.9241755933627389  loss : 0.28642906250171585\n",
      "iterations 7069 accuray : 0.9241755933627389  loss : 0.28642019638762306\n",
      "iterations 7070 accuray : 0.9241755933627389  loss : 0.28641135300534637\n",
      "iterations 7071 accuray : 0.9241755933627389  loss : 0.28640331093440036\n",
      "iterations 7072 accuray : 0.9241755933627389  loss : 0.2863946205408377\n",
      "iterations 7073 accuray : 0.9241755933627389  loss : 0.28638554596673754\n",
      "iterations 7074 accuray : 0.9241755933627389  loss : 0.28637660364181067\n",
      "iterations 7075 accuray : 0.9241755933627389  loss : 0.2863677647387996\n",
      "iterations 7076 accuray : 0.9241755933627389  loss : 0.2863589281550083\n",
      "iterations 7077 accuray : 0.9241755933627389  loss : 0.2863497776172034\n",
      "iterations 7078 accuray : 0.9241755933627389  loss : 0.28634071748215234\n",
      "iterations 7079 accuray : 0.9241755933627389  loss : 0.28633204598278394\n",
      "iterations 7080 accuray : 0.9241755933627389  loss : 0.2863236969936406\n",
      "iterations 7081 accuray : 0.9241755933627389  loss : 0.286314719846375\n",
      "iterations 7082 accuray : 0.9241755933627389  loss : 0.28630564600474795\n",
      "iterations 7083 accuray : 0.9241755933627389  loss : 0.2862971895649049\n",
      "iterations 7084 accuray : 0.9241755933627389  loss : 0.2862884002710552\n",
      "iterations 7085 accuray : 0.9241755933627389  loss : 0.2862798352701715\n",
      "iterations 7086 accuray : 0.9241755933627389  loss : 0.28627133039341596\n",
      "iterations 7087 accuray : 0.9241755933627389  loss : 0.28626265176876625\n",
      "iterations 7088 accuray : 0.9241755933627389  loss : 0.2862537887832422\n",
      "iterations 7089 accuray : 0.9241755933627389  loss : 0.28624527410994444\n",
      "iterations 7090 accuray : 0.9241755933627389  loss : 0.2862363486689642\n",
      "iterations 7091 accuray : 0.9241755933627389  loss : 0.2862273552305564\n",
      "iterations 7092 accuray : 0.9241755933627389  loss : 0.2862187515789896\n",
      "iterations 7093 accuray : 0.9241755933627389  loss : 0.2862097039167496\n",
      "iterations 7094 accuray : 0.9243856332703214  loss : 0.28620069981312285\n",
      "iterations 7095 accuray : 0.9241755933627389  loss : 0.2861918976853406\n",
      "iterations 7096 accuray : 0.9241755933627389  loss : 0.2861831802147729\n",
      "iterations 7097 accuray : 0.9241755933627389  loss : 0.28617466448388096\n",
      "iterations 7098 accuray : 0.9241755933627389  loss : 0.28616571961764997\n",
      "iterations 7099 accuray : 0.9241755933627389  loss : 0.28615720256064014\n",
      "iterations 7100 accuray : 0.9241755933627389  loss : 0.28614824315904924\n",
      "iterations 7101 accuray : 0.9241755933627389  loss : 0.2861395207028646\n",
      "iterations 7102 accuray : 0.9241755933627389  loss : 0.28613051186566535\n",
      "iterations 7103 accuray : 0.9241755933627389  loss : 0.28612196463589185\n",
      "iterations 7104 accuray : 0.9241755933627389  loss : 0.28611350402665875\n",
      "iterations 7105 accuray : 0.9241755933627389  loss : 0.28610413694614645\n",
      "iterations 7106 accuray : 0.9241755933627389  loss : 0.2860954331134064\n",
      "iterations 7107 accuray : 0.9241755933627389  loss : 0.2860867301558386\n",
      "iterations 7108 accuray : 0.9241755933627389  loss : 0.28607805025514005\n",
      "iterations 7109 accuray : 0.9241755933627389  loss : 0.2860692263722674\n",
      "iterations 7110 accuray : 0.9241755933627389  loss : 0.28606046532237484\n",
      "iterations 7111 accuray : 0.9241755933627389  loss : 0.28605133587840065\n",
      "iterations 7112 accuray : 0.9241755933627389  loss : 0.28604259706111745\n",
      "iterations 7113 accuray : 0.9241755933627389  loss : 0.28603393351157347\n",
      "iterations 7114 accuray : 0.9241755933627389  loss : 0.2860251073604942\n",
      "iterations 7115 accuray : 0.9241755933627389  loss : 0.28601673017038753\n",
      "iterations 7116 accuray : 0.9241755933627389  loss : 0.28600769709638113\n",
      "iterations 7117 accuray : 0.9241755933627389  loss : 0.2859986815654992\n",
      "iterations 7118 accuray : 0.9241755933627389  loss : 0.28599054029333915\n",
      "iterations 7119 accuray : 0.9241755933627389  loss : 0.28598198124758417\n",
      "iterations 7120 accuray : 0.9241755933627389  loss : 0.28597354559566357\n",
      "iterations 7121 accuray : 0.9241755933627389  loss : 0.2859647197805875\n",
      "iterations 7122 accuray : 0.9241755933627389  loss : 0.28595601828599865\n",
      "iterations 7123 accuray : 0.9241755933627389  loss : 0.28594758240667567\n",
      "iterations 7124 accuray : 0.9241755933627389  loss : 0.2859388186438325\n",
      "iterations 7125 accuray : 0.9241755933627389  loss : 0.2859303577393828\n",
      "iterations 7126 accuray : 0.9241755933627389  loss : 0.28592160284210233\n",
      "iterations 7127 accuray : 0.9241755933627389  loss : 0.28591241047591565\n",
      "iterations 7128 accuray : 0.9241755933627389  loss : 0.28590375921553157\n",
      "iterations 7129 accuray : 0.9241755933627389  loss : 0.2858946071019927\n",
      "iterations 7130 accuray : 0.9241755933627389  loss : 0.2858858636542502\n",
      "iterations 7131 accuray : 0.9241755933627389  loss : 0.2858774735734987\n",
      "iterations 7132 accuray : 0.9241755933627389  loss : 0.28586882411349507\n",
      "iterations 7133 accuray : 0.9241755933627389  loss : 0.28586036695520395\n",
      "iterations 7134 accuray : 0.9241755933627389  loss : 0.285851023150318\n",
      "iterations 7135 accuray : 0.9241755933627389  loss : 0.2858425002006954\n",
      "iterations 7136 accuray : 0.9241755933627389  loss : 0.28583440487008355\n",
      "iterations 7137 accuray : 0.9241755933627389  loss : 0.2858258802063272\n",
      "iterations 7138 accuray : 0.9241755933627389  loss : 0.28581732817053246\n",
      "iterations 7139 accuray : 0.9241755933627389  loss : 0.2858084144857703\n",
      "iterations 7140 accuray : 0.9243856332703214  loss : 0.2857992048031531\n",
      "iterations 7141 accuray : 0.9241755933627389  loss : 0.2857901431193503\n",
      "iterations 7142 accuray : 0.9241755933627389  loss : 0.2857812067813906\n",
      "iterations 7143 accuray : 0.9241755933627389  loss : 0.28577293348116123\n",
      "iterations 7144 accuray : 0.9241755933627389  loss : 0.2857639280353375\n",
      "iterations 7145 accuray : 0.9241755933627389  loss : 0.2857544522414311\n",
      "iterations 7146 accuray : 0.9241755933627389  loss : 0.2857459053248371\n",
      "iterations 7147 accuray : 0.9241755933627389  loss : 0.2857368498356057\n",
      "iterations 7148 accuray : 0.9241755933627389  loss : 0.2857284815252506\n",
      "iterations 7149 accuray : 0.9241755933627389  loss : 0.2857195196338069\n",
      "iterations 7150 accuray : 0.9241755933627389  loss : 0.28571105231045485\n",
      "iterations 7151 accuray : 0.9241755933627389  loss : 0.285702421548732\n",
      "iterations 7152 accuray : 0.9241755933627389  loss : 0.28569403083135203\n",
      "iterations 7153 accuray : 0.9241755933627389  loss : 0.2856849990259857\n",
      "iterations 7154 accuray : 0.9241755933627389  loss : 0.2856762299947535\n",
      "iterations 7155 accuray : 0.9241755933627389  loss : 0.2856675933936856\n",
      "iterations 7156 accuray : 0.9241755933627389  loss : 0.28565897632782195\n",
      "iterations 7157 accuray : 0.9241755933627389  loss : 0.28565029194773817\n",
      "iterations 7158 accuray : 0.9241755933627389  loss : 0.2856416040951699\n",
      "iterations 7159 accuray : 0.9241755933627389  loss : 0.2856329147230333\n",
      "iterations 7160 accuray : 0.9241755933627389  loss : 0.2856239395536932\n",
      "iterations 7161 accuray : 0.9241755933627389  loss : 0.28561474480986415\n",
      "iterations 7162 accuray : 0.9241755933627389  loss : 0.2856059419762934\n",
      "iterations 7163 accuray : 0.9241755933627389  loss : 0.2855975960635516\n",
      "iterations 7164 accuray : 0.9241755933627389  loss : 0.2855888138218055\n",
      "iterations 7165 accuray : 0.9241755933627389  loss : 0.2855800000436557\n",
      "iterations 7166 accuray : 0.9241755933627389  loss : 0.28557117163142187\n",
      "iterations 7167 accuray : 0.9241755933627389  loss : 0.28556227138695717\n",
      "iterations 7168 accuray : 0.9241755933627389  loss : 0.2855537818534191\n",
      "iterations 7169 accuray : 0.9241755933627389  loss : 0.2855449442146628\n",
      "iterations 7170 accuray : 0.9241755933627389  loss : 0.2855364969785174\n",
      "iterations 7171 accuray : 0.9241755933627389  loss : 0.2855276558147149\n",
      "iterations 7172 accuray : 0.9241755933627389  loss : 0.2855188547687367\n",
      "iterations 7173 accuray : 0.9241755933627389  loss : 0.2855101287333407\n",
      "iterations 7174 accuray : 0.9241755933627389  loss : 0.28550180995454383\n",
      "iterations 7175 accuray : 0.9241755933627389  loss : 0.28549323295607804\n",
      "iterations 7176 accuray : 0.9241755933627389  loss : 0.28548504073296865\n",
      "iterations 7177 accuray : 0.9241755933627389  loss : 0.2854764139543053\n",
      "iterations 7178 accuray : 0.9241755933627389  loss : 0.28546771882697414\n",
      "iterations 7179 accuray : 0.9241755933627389  loss : 0.28545930874447323\n",
      "iterations 7180 accuray : 0.9241755933627389  loss : 0.2854507259207543\n",
      "iterations 7181 accuray : 0.9241755933627389  loss : 0.2854421419659382\n",
      "iterations 7182 accuray : 0.9241755933627389  loss : 0.28543381622933384\n",
      "iterations 7183 accuray : 0.9241755933627389  loss : 0.2854248536731603\n",
      "iterations 7184 accuray : 0.9241755933627389  loss : 0.28541623118264275\n",
      "iterations 7185 accuray : 0.9241755933627389  loss : 0.28540768808379136\n",
      "iterations 7186 accuray : 0.9241755933627389  loss : 0.285399389813339\n",
      "iterations 7187 accuray : 0.9241755933627389  loss : 0.28539050278951217\n",
      "iterations 7188 accuray : 0.9241755933627389  loss : 0.28538204391286753\n",
      "iterations 7189 accuray : 0.9241755933627389  loss : 0.2853736264933777\n",
      "iterations 7190 accuray : 0.9241755933627389  loss : 0.28536565164235755\n",
      "iterations 7191 accuray : 0.9241755933627389  loss : 0.2853565250105666\n",
      "iterations 7192 accuray : 0.9241755933627389  loss : 0.2853477073171568\n",
      "iterations 7193 accuray : 0.9241755933627389  loss : 0.28533887528449764\n",
      "iterations 7194 accuray : 0.9241755933627389  loss : 0.2853302119662588\n",
      "iterations 7195 accuray : 0.9241755933627389  loss : 0.2853221138058275\n",
      "iterations 7196 accuray : 0.9241755933627389  loss : 0.2853134144790906\n",
      "iterations 7197 accuray : 0.9241755933627389  loss : 0.28530443592979965\n",
      "iterations 7198 accuray : 0.9243856332703214  loss : 0.2852956473484537\n",
      "iterations 7199 accuray : 0.9241755933627389  loss : 0.285287070360226\n",
      "iterations 7200 accuray : 0.9243856332703214  loss : 0.285278369834003\n",
      "iterations 7201 accuray : 0.9243856332703214  loss : 0.2852698150701037\n",
      "iterations 7202 accuray : 0.9241755933627389  loss : 0.2852617120629698\n",
      "iterations 7203 accuray : 0.9241755933627389  loss : 0.2852533609942853\n",
      "iterations 7204 accuray : 0.9241755933627389  loss : 0.2852447189542639\n",
      "iterations 7205 accuray : 0.9241755933627389  loss : 0.28523578764449675\n",
      "iterations 7206 accuray : 0.9241755933627389  loss : 0.2852272900635303\n",
      "iterations 7207 accuray : 0.9241755933627389  loss : 0.2852188382877238\n",
      "iterations 7208 accuray : 0.9241755933627389  loss : 0.28521023206328017\n",
      "iterations 7209 accuray : 0.9241755933627389  loss : 0.2852015337637837\n",
      "iterations 7210 accuray : 0.9241755933627389  loss : 0.2851932608667748\n",
      "iterations 7211 accuray : 0.9241755933627389  loss : 0.2851848012605359\n",
      "iterations 7212 accuray : 0.9241755933627389  loss : 0.28517597008820755\n",
      "iterations 7213 accuray : 0.9241755933627389  loss : 0.2851673042587196\n",
      "iterations 7214 accuray : 0.9241755933627389  loss : 0.2851588379405332\n",
      "iterations 7215 accuray : 0.9241755933627389  loss : 0.28515055647952436\n",
      "iterations 7216 accuray : 0.9241755933627389  loss : 0.28514251797871076\n",
      "iterations 7217 accuray : 0.9241755933627389  loss : 0.2851332630395794\n",
      "iterations 7218 accuray : 0.9241755933627389  loss : 0.28512459727273864\n",
      "iterations 7219 accuray : 0.9241755933627389  loss : 0.285115956978099\n",
      "iterations 7220 accuray : 0.9241755933627389  loss : 0.2851072158994363\n",
      "iterations 7221 accuray : 0.9241755933627389  loss : 0.2850988913568837\n",
      "iterations 7222 accuray : 0.9243856332703214  loss : 0.2850901534117634\n",
      "iterations 7223 accuray : 0.9241755933627389  loss : 0.28508188031630305\n",
      "iterations 7224 accuray : 0.9241755933627389  loss : 0.28507381377475965\n",
      "iterations 7225 accuray : 0.9241755933627389  loss : 0.2850651998521444\n",
      "iterations 7226 accuray : 0.9241755933627389  loss : 0.28505676894603976\n",
      "iterations 7227 accuray : 0.9241755933627389  loss : 0.28504850179739916\n",
      "iterations 7228 accuray : 0.9241755933627389  loss : 0.28504008673067266\n",
      "iterations 7229 accuray : 0.9241755933627389  loss : 0.2850309981233228\n",
      "iterations 7230 accuray : 0.9243856332703214  loss : 0.28502252612438495\n",
      "iterations 7231 accuray : 0.9243856332703214  loss : 0.2850139116926504\n",
      "iterations 7232 accuray : 0.9241755933627389  loss : 0.2850057143946952\n",
      "iterations 7233 accuray : 0.9243856332703214  loss : 0.28499721084628277\n",
      "iterations 7234 accuray : 0.9243856332703214  loss : 0.28498841007405873\n",
      "iterations 7235 accuray : 0.9243856332703214  loss : 0.2849801941604514\n",
      "iterations 7236 accuray : 0.9243856332703214  loss : 0.2849720182071524\n",
      "iterations 7237 accuray : 0.9243856332703214  loss : 0.2849634688542037\n",
      "iterations 7238 accuray : 0.9243856332703214  loss : 0.2849546877198056\n",
      "iterations 7239 accuray : 0.9243856332703214  loss : 0.28494637828458935\n",
      "iterations 7240 accuray : 0.9243856332703214  loss : 0.2849383578400277\n",
      "iterations 7241 accuray : 0.9243856332703214  loss : 0.28493009613503545\n",
      "iterations 7242 accuray : 0.9243856332703214  loss : 0.28492181180390336\n",
      "iterations 7243 accuray : 0.9243856332703214  loss : 0.2849133831386424\n",
      "iterations 7244 accuray : 0.9243856332703214  loss : 0.28490514692512203\n",
      "iterations 7245 accuray : 0.9243856332703214  loss : 0.28489667297682375\n",
      "iterations 7246 accuray : 0.9243856332703214  loss : 0.2848877186576295\n",
      "iterations 7247 accuray : 0.9243856332703214  loss : 0.2848798008373583\n",
      "iterations 7248 accuray : 0.9243856332703214  loss : 0.2848714771742906\n",
      "iterations 7249 accuray : 0.9243856332703214  loss : 0.284862845707132\n",
      "iterations 7250 accuray : 0.9243856332703214  loss : 0.284854769585502\n",
      "iterations 7251 accuray : 0.9243856332703214  loss : 0.2848463826810018\n",
      "iterations 7252 accuray : 0.9243856332703214  loss : 0.2848374460356194\n",
      "iterations 7253 accuray : 0.9243856332703214  loss : 0.2848289034011686\n",
      "iterations 7254 accuray : 0.9243856332703214  loss : 0.28482078969572366\n",
      "iterations 7255 accuray : 0.9241755933627389  loss : 0.284812286126503\n",
      "iterations 7256 accuray : 0.9241755933627389  loss : 0.28480337490994506\n",
      "iterations 7257 accuray : 0.9241755933627389  loss : 0.2847946834622468\n",
      "iterations 7258 accuray : 0.9243856332703214  loss : 0.2847859952317799\n",
      "iterations 7259 accuray : 0.9243856332703214  loss : 0.2847774173460317\n",
      "iterations 7260 accuray : 0.9243856332703214  loss : 0.2847691079741106\n",
      "iterations 7261 accuray : 0.9241755933627389  loss : 0.2847609988593169\n",
      "iterations 7262 accuray : 0.9241755933627389  loss : 0.2847525400118173\n",
      "iterations 7263 accuray : 0.9241755933627389  loss : 0.2847443742768307\n",
      "iterations 7264 accuray : 0.9241755933627389  loss : 0.2847361506001095\n",
      "iterations 7265 accuray : 0.9241755933627389  loss : 0.2847276744518722\n",
      "iterations 7266 accuray : 0.9241755933627389  loss : 0.28471912608787164\n",
      "iterations 7267 accuray : 0.9241755933627389  loss : 0.28471064545760183\n",
      "iterations 7268 accuray : 0.9243856332703214  loss : 0.28470153625088707\n",
      "iterations 7269 accuray : 0.9241755933627389  loss : 0.284693335725283\n",
      "iterations 7270 accuray : 0.9243856332703214  loss : 0.2846845730197203\n",
      "iterations 7271 accuray : 0.9241755933627389  loss : 0.2846761781381558\n",
      "iterations 7272 accuray : 0.9243856332703214  loss : 0.2846676598000995\n",
      "iterations 7273 accuray : 0.9243856332703214  loss : 0.284659590453329\n",
      "iterations 7274 accuray : 0.9243856332703214  loss : 0.2846509601466368\n",
      "iterations 7275 accuray : 0.9243856332703214  loss : 0.2846428808547403\n",
      "iterations 7276 accuray : 0.9243856332703214  loss : 0.284634587636277\n",
      "iterations 7277 accuray : 0.9243856332703214  loss : 0.28462609316474685\n",
      "iterations 7278 accuray : 0.9241755933627389  loss : 0.284617890993723\n",
      "iterations 7279 accuray : 0.9243856332703214  loss : 0.28460916738622577\n",
      "iterations 7280 accuray : 0.9243856332703214  loss : 0.2846006075517923\n",
      "iterations 7281 accuray : 0.9243856332703214  loss : 0.28459247228441453\n",
      "iterations 7282 accuray : 0.9243856332703214  loss : 0.2845838473123515\n",
      "iterations 7283 accuray : 0.9243856332703214  loss : 0.28457550321199954\n",
      "iterations 7284 accuray : 0.9243856332703214  loss : 0.28456694206248745\n",
      "iterations 7285 accuray : 0.9243856332703214  loss : 0.28455845595893026\n",
      "iterations 7286 accuray : 0.9243856332703214  loss : 0.2845500547483492\n",
      "iterations 7287 accuray : 0.9243856332703214  loss : 0.28454173977037794\n",
      "iterations 7288 accuray : 0.9243856332703214  loss : 0.2845331057231991\n",
      "iterations 7289 accuray : 0.9243856332703214  loss : 0.2845244760051315\n",
      "iterations 7290 accuray : 0.9243856332703214  loss : 0.28451604825258536\n",
      "iterations 7291 accuray : 0.9243856332703214  loss : 0.2845080759298234\n",
      "iterations 7292 accuray : 0.9243856332703214  loss : 0.2844993128984668\n",
      "iterations 7293 accuray : 0.9243856332703214  loss : 0.2844910311183246\n",
      "iterations 7294 accuray : 0.9243856332703214  loss : 0.28448255999543\n",
      "iterations 7295 accuray : 0.9243856332703214  loss : 0.2844736969859693\n",
      "iterations 7296 accuray : 0.9245956731779038  loss : 0.2844647438294087\n",
      "iterations 7297 accuray : 0.9245956731779038  loss : 0.28445593370300964\n",
      "iterations 7298 accuray : 0.9245956731779038  loss : 0.28444777026320356\n",
      "iterations 7299 accuray : 0.9245956731779038  loss : 0.28443958311644507\n",
      "iterations 7300 accuray : 0.9245956731779038  loss : 0.2844314112512781\n",
      "iterations 7301 accuray : 0.9245956731779038  loss : 0.2844232036168212\n",
      "iterations 7302 accuray : 0.9245956731779038  loss : 0.28441487478595256\n",
      "iterations 7303 accuray : 0.9245956731779038  loss : 0.28440637597937407\n",
      "iterations 7304 accuray : 0.9243856332703214  loss : 0.28439831735170856\n",
      "iterations 7305 accuray : 0.9243856332703214  loss : 0.28439007835714836\n",
      "iterations 7306 accuray : 0.9245956731779038  loss : 0.28438141050990673\n",
      "iterations 7307 accuray : 0.9245956731779038  loss : 0.28437258119520875\n",
      "iterations 7308 accuray : 0.9245956731779038  loss : 0.28436441711088845\n",
      "iterations 7309 accuray : 0.9245956731779038  loss : 0.2843563342875743\n",
      "iterations 7310 accuray : 0.9245956731779038  loss : 0.28434784442759087\n",
      "iterations 7311 accuray : 0.9245956731779038  loss : 0.2843396279720404\n",
      "iterations 7312 accuray : 0.9245956731779038  loss : 0.28433121020710356\n",
      "iterations 7313 accuray : 0.9245956731779038  loss : 0.2843229850865822\n",
      "iterations 7314 accuray : 0.9245956731779038  loss : 0.28431490523661507\n",
      "iterations 7315 accuray : 0.9245956731779038  loss : 0.2843061724561051\n",
      "iterations 7316 accuray : 0.9245956731779038  loss : 0.2842973917481203\n",
      "iterations 7317 accuray : 0.9245956731779038  loss : 0.28428865158612665\n",
      "iterations 7318 accuray : 0.9245956731779038  loss : 0.28427991089394\n",
      "iterations 7319 accuray : 0.9245956731779038  loss : 0.28427143366201485\n",
      "iterations 7320 accuray : 0.9245956731779038  loss : 0.28426319721570187\n",
      "iterations 7321 accuray : 0.9245956731779038  loss : 0.2842548380051016\n",
      "iterations 7322 accuray : 0.9245956731779038  loss : 0.2842463145850735\n",
      "iterations 7323 accuray : 0.9245956731779038  loss : 0.2842381992334998\n",
      "iterations 7324 accuray : 0.9245956731779038  loss : 0.28422996975154635\n",
      "iterations 7325 accuray : 0.9245956731779038  loss : 0.28422138010311765\n",
      "iterations 7326 accuray : 0.9245956731779038  loss : 0.28421286934952367\n",
      "iterations 7327 accuray : 0.9245956731779038  loss : 0.28420432113451544\n",
      "iterations 7328 accuray : 0.9245956731779038  loss : 0.28419589349915286\n",
      "iterations 7329 accuray : 0.9245956731779038  loss : 0.28418782855682195\n",
      "iterations 7330 accuray : 0.9245956731779038  loss : 0.2841795079775579\n",
      "iterations 7331 accuray : 0.9245956731779038  loss : 0.2841715701069218\n",
      "iterations 7332 accuray : 0.9245956731779038  loss : 0.2841632945763254\n",
      "iterations 7333 accuray : 0.9245956731779038  loss : 0.2841546897438673\n",
      "iterations 7334 accuray : 0.9245956731779038  loss : 0.2841463878804898\n",
      "iterations 7335 accuray : 0.9245956731779038  loss : 0.28413806512297146\n",
      "iterations 7336 accuray : 0.9245956731779038  loss : 0.2841292086006025\n",
      "iterations 7337 accuray : 0.9245956731779038  loss : 0.2841210145275048\n",
      "iterations 7338 accuray : 0.9245956731779038  loss : 0.28411297176711703\n",
      "iterations 7339 accuray : 0.9245956731779038  loss : 0.28410503620550626\n",
      "iterations 7340 accuray : 0.9245956731779038  loss : 0.2840970676858664\n",
      "iterations 7341 accuray : 0.9245956731779038  loss : 0.28408835537629556\n",
      "iterations 7342 accuray : 0.9245956731779038  loss : 0.2840801385881882\n",
      "iterations 7343 accuray : 0.9245956731779038  loss : 0.28407163117706175\n",
      "iterations 7344 accuray : 0.9245956731779038  loss : 0.28406312823339036\n",
      "iterations 7345 accuray : 0.9245956731779038  loss : 0.2840547743770291\n",
      "iterations 7346 accuray : 0.9245956731779038  loss : 0.28404641865791885\n",
      "iterations 7347 accuray : 0.9245956731779038  loss : 0.2840383478886731\n",
      "iterations 7348 accuray : 0.9245956731779038  loss : 0.28403034574355734\n",
      "iterations 7349 accuray : 0.9245956731779038  loss : 0.2840219688520845\n",
      "iterations 7350 accuray : 0.9245956731779038  loss : 0.2840137116953125\n",
      "iterations 7351 accuray : 0.9245956731779038  loss : 0.28400503312302383\n",
      "iterations 7352 accuray : 0.9245956731779038  loss : 0.2839971422642701\n",
      "iterations 7353 accuray : 0.9245956731779038  loss : 0.28398857814404843\n",
      "iterations 7354 accuray : 0.9245956731779038  loss : 0.2839798709701056\n",
      "iterations 7355 accuray : 0.9245956731779038  loss : 0.2839717821575618\n",
      "iterations 7356 accuray : 0.9245956731779038  loss : 0.28396309003590886\n",
      "iterations 7357 accuray : 0.9245956731779038  loss : 0.2839545057327744\n",
      "iterations 7358 accuray : 0.9245956731779038  loss : 0.2839461825705942\n",
      "iterations 7359 accuray : 0.9245956731779038  loss : 0.2839375645417355\n",
      "iterations 7360 accuray : 0.9245956731779038  loss : 0.28392894202550745\n",
      "iterations 7361 accuray : 0.9245956731779038  loss : 0.28392047299259227\n",
      "iterations 7362 accuray : 0.9245956731779038  loss : 0.28391211744517236\n",
      "iterations 7363 accuray : 0.9245956731779038  loss : 0.2839039819888243\n",
      "iterations 7364 accuray : 0.9245956731779038  loss : 0.2838954079619955\n",
      "iterations 7365 accuray : 0.9245956731779038  loss : 0.2838872642643243\n",
      "iterations 7366 accuray : 0.9245956731779038  loss : 0.28387913735986386\n",
      "iterations 7367 accuray : 0.9245956731779038  loss : 0.2838707711119004\n",
      "iterations 7368 accuray : 0.9245956731779038  loss : 0.28386239992981754\n",
      "iterations 7369 accuray : 0.9245956731779038  loss : 0.2838541050226415\n",
      "iterations 7370 accuray : 0.9245956731779038  loss : 0.28384605604767665\n",
      "iterations 7371 accuray : 0.9245956731779038  loss : 0.2838379372674578\n",
      "iterations 7372 accuray : 0.9245956731779038  loss : 0.2838295590467129\n",
      "iterations 7373 accuray : 0.9245956731779038  loss : 0.28382089481131406\n",
      "iterations 7374 accuray : 0.9245956731779038  loss : 0.28381268354502676\n",
      "iterations 7375 accuray : 0.9245956731779038  loss : 0.283804462535108\n",
      "iterations 7376 accuray : 0.9245956731779038  loss : 0.2837963127014174\n",
      "iterations 7377 accuray : 0.9245956731779038  loss : 0.2837882573384868\n",
      "iterations 7378 accuray : 0.9245956731779038  loss : 0.28378000325431474\n",
      "iterations 7379 accuray : 0.9245956731779038  loss : 0.28377174378540476\n",
      "iterations 7380 accuray : 0.9245956731779038  loss : 0.28376364012716543\n",
      "iterations 7381 accuray : 0.9245956731779038  loss : 0.2837556702979037\n",
      "iterations 7382 accuray : 0.9245956731779038  loss : 0.2837470840366655\n",
      "iterations 7383 accuray : 0.9245956731779038  loss : 0.2837391262149679\n",
      "iterations 7384 accuray : 0.9245956731779038  loss : 0.2837307142315244\n",
      "iterations 7385 accuray : 0.9245956731779038  loss : 0.2837221858202268\n",
      "iterations 7386 accuray : 0.9245956731779038  loss : 0.28371390981942224\n",
      "iterations 7387 accuray : 0.9243856332703214  loss : 0.2837058169496259\n",
      "iterations 7388 accuray : 0.9243856332703214  loss : 0.28369780886849794\n",
      "iterations 7389 accuray : 0.9245956731779038  loss : 0.2836900201688279\n",
      "iterations 7390 accuray : 0.9245956731779038  loss : 0.2836816286533986\n",
      "iterations 7391 accuray : 0.9245956731779038  loss : 0.2836735302594965\n",
      "iterations 7392 accuray : 0.9245956731779038  loss : 0.2836653400575161\n",
      "iterations 7393 accuray : 0.9245956731779038  loss : 0.2836569644992145\n",
      "iterations 7394 accuray : 0.9245956731779038  loss : 0.2836480855029783\n",
      "iterations 7395 accuray : 0.9245956731779038  loss : 0.2836400271907875\n",
      "iterations 7396 accuray : 0.9245956731779038  loss : 0.28363168956095625\n",
      "iterations 7397 accuray : 0.9245956731779038  loss : 0.2836232718320757\n",
      "iterations 7398 accuray : 0.9245956731779038  loss : 0.28361529450105766\n",
      "iterations 7399 accuray : 0.9245956731779038  loss : 0.2836070256734156\n",
      "iterations 7400 accuray : 0.9245956731779038  loss : 0.2835991525266003\n",
      "iterations 7401 accuray : 0.9245956731779038  loss : 0.2835905347308511\n",
      "iterations 7402 accuray : 0.9245956731779038  loss : 0.2835821041365628\n",
      "iterations 7403 accuray : 0.9245956731779038  loss : 0.2835739145777199\n",
      "iterations 7404 accuray : 0.9245956731779038  loss : 0.28356565109644866\n",
      "iterations 7405 accuray : 0.9245956731779038  loss : 0.2835574755986643\n",
      "iterations 7406 accuray : 0.9245956731779038  loss : 0.2835493603371812\n",
      "iterations 7407 accuray : 0.9245956731779038  loss : 0.28354080817701116\n",
      "iterations 7408 accuray : 0.9245956731779038  loss : 0.2835324984622429\n",
      "iterations 7409 accuray : 0.9245956731779038  loss : 0.283524986908566\n",
      "iterations 7410 accuray : 0.9245956731779038  loss : 0.2835164662604046\n",
      "iterations 7411 accuray : 0.9245956731779038  loss : 0.283508711131092\n",
      "iterations 7412 accuray : 0.9245956731779038  loss : 0.28350037485352214\n",
      "iterations 7413 accuray : 0.9245956731779038  loss : 0.2834920652497838\n",
      "iterations 7414 accuray : 0.9245956731779038  loss : 0.2834840174520371\n",
      "iterations 7415 accuray : 0.9245956731779038  loss : 0.28347582140837163\n",
      "iterations 7416 accuray : 0.9245956731779038  loss : 0.28346765424220444\n",
      "iterations 7417 accuray : 0.9245956731779038  loss : 0.28345918261690517\n",
      "iterations 7418 accuray : 0.9245956731779038  loss : 0.2834512336980227\n",
      "iterations 7419 accuray : 0.9245956731779038  loss : 0.28344295316736046\n",
      "iterations 7420 accuray : 0.9245956731779038  loss : 0.2834348172683259\n",
      "iterations 7421 accuray : 0.9245956731779038  loss : 0.28342626131226684\n",
      "iterations 7422 accuray : 0.9245956731779038  loss : 0.2834180061436984\n",
      "iterations 7423 accuray : 0.9245956731779038  loss : 0.2834100903157531\n",
      "iterations 7424 accuray : 0.9245956731779038  loss : 0.2834017971446255\n",
      "iterations 7425 accuray : 0.9245956731779038  loss : 0.28339379812691795\n",
      "iterations 7426 accuray : 0.9245956731779038  loss : 0.28338571131094914\n",
      "iterations 7427 accuray : 0.9245956731779038  loss : 0.2833778036732567\n",
      "iterations 7428 accuray : 0.9245956731779038  loss : 0.2833696239119711\n",
      "iterations 7429 accuray : 0.9245956731779038  loss : 0.2833614107117363\n",
      "iterations 7430 accuray : 0.9245956731779038  loss : 0.2833528893991603\n",
      "iterations 7431 accuray : 0.9245956731779038  loss : 0.283345104666402\n",
      "iterations 7432 accuray : 0.9245956731779038  loss : 0.2833375381632808\n",
      "iterations 7433 accuray : 0.9245956731779038  loss : 0.28332961705925036\n",
      "iterations 7434 accuray : 0.9245956731779038  loss : 0.283321460767087\n",
      "iterations 7435 accuray : 0.9245956731779038  loss : 0.28331338235234566\n",
      "iterations 7436 accuray : 0.9245956731779038  loss : 0.2833049653544434\n",
      "iterations 7437 accuray : 0.9245956731779038  loss : 0.2832969692267772\n",
      "iterations 7438 accuray : 0.9245956731779038  loss : 0.2832886957194127\n",
      "iterations 7439 accuray : 0.9245956731779038  loss : 0.2832805043329669\n",
      "iterations 7440 accuray : 0.9245956731779038  loss : 0.28327246272866774\n",
      "iterations 7441 accuray : 0.9245956731779038  loss : 0.2832644239571016\n",
      "iterations 7442 accuray : 0.9245956731779038  loss : 0.2832566503099975\n",
      "iterations 7443 accuray : 0.9245956731779038  loss : 0.28324869425111726\n",
      "iterations 7444 accuray : 0.9245956731779038  loss : 0.2832405979214238\n",
      "iterations 7445 accuray : 0.9245956731779038  loss : 0.2832323827838734\n",
      "iterations 7446 accuray : 0.9245956731779038  loss : 0.28322441318561525\n",
      "iterations 7447 accuray : 0.9245956731779038  loss : 0.2832165181549915\n",
      "iterations 7448 accuray : 0.9245956731779038  loss : 0.283208218627264\n",
      "iterations 7449 accuray : 0.9245956731779038  loss : 0.2831998960801997\n",
      "iterations 7450 accuray : 0.9245956731779038  loss : 0.2831919570048854\n",
      "iterations 7451 accuray : 0.9245956731779038  loss : 0.28318397455556094\n",
      "iterations 7452 accuray : 0.9245956731779038  loss : 0.2831762595690663\n",
      "iterations 7453 accuray : 0.9245956731779038  loss : 0.28316821347988463\n",
      "iterations 7454 accuray : 0.9245956731779038  loss : 0.2831596924970265\n",
      "iterations 7455 accuray : 0.9245956731779038  loss : 0.2831516490377723\n",
      "iterations 7456 accuray : 0.9245956731779038  loss : 0.28314374806902626\n",
      "iterations 7457 accuray : 0.9245956731779038  loss : 0.28313535430387465\n",
      "iterations 7458 accuray : 0.9245956731779038  loss : 0.2831268981631992\n",
      "iterations 7459 accuray : 0.9245956731779038  loss : 0.283118961345666\n",
      "iterations 7460 accuray : 0.9245956731779038  loss : 0.2831104776899923\n",
      "iterations 7461 accuray : 0.9245956731779038  loss : 0.2831026707640889\n",
      "iterations 7462 accuray : 0.9245956731779038  loss : 0.2830947866953061\n",
      "iterations 7463 accuray : 0.9245956731779038  loss : 0.2830871329827654\n",
      "iterations 7464 accuray : 0.9245956731779038  loss : 0.28307923296414317\n",
      "iterations 7465 accuray : 0.9245956731779038  loss : 0.28307104081170054\n",
      "iterations 7466 accuray : 0.9245956731779038  loss : 0.2830632699966188\n",
      "iterations 7467 accuray : 0.9245956731779038  loss : 0.2830554433189824\n",
      "iterations 7468 accuray : 0.9245956731779038  loss : 0.28304662272077974\n",
      "iterations 7469 accuray : 0.9245956731779038  loss : 0.2830384548956905\n",
      "iterations 7470 accuray : 0.9245956731779038  loss : 0.283030297124532\n",
      "iterations 7471 accuray : 0.9245956731779038  loss : 0.2830223935031678\n",
      "iterations 7472 accuray : 0.9245956731779038  loss : 0.28301390913736985\n",
      "iterations 7473 accuray : 0.9245956731779038  loss : 0.2830060784158221\n",
      "iterations 7474 accuray : 0.9245956731779038  loss : 0.2829981058303539\n",
      "iterations 7475 accuray : 0.9245956731779038  loss : 0.282989756647228\n",
      "iterations 7476 accuray : 0.9245956731779038  loss : 0.28298168743453944\n",
      "iterations 7477 accuray : 0.9245956731779038  loss : 0.2829733811625592\n",
      "iterations 7478 accuray : 0.9245956731779038  loss : 0.2829651725804849\n",
      "iterations 7479 accuray : 0.9245956731779038  loss : 0.2829571850942307\n",
      "iterations 7480 accuray : 0.9245956731779038  loss : 0.2829493012928655\n",
      "iterations 7481 accuray : 0.9245956731779038  loss : 0.28294159814484054\n",
      "iterations 7482 accuray : 0.9245956731779038  loss : 0.2829333629865134\n",
      "iterations 7483 accuray : 0.9245956731779038  loss : 0.28292543733529013\n",
      "iterations 7484 accuray : 0.9245956731779038  loss : 0.2829171435080611\n",
      "iterations 7485 accuray : 0.9245956731779038  loss : 0.28290937487796525\n",
      "iterations 7486 accuray : 0.9245956731779038  loss : 0.28290144556977015\n",
      "iterations 7487 accuray : 0.9245956731779038  loss : 0.2828931081733273\n",
      "iterations 7488 accuray : 0.9245956731779038  loss : 0.28288527539916936\n",
      "iterations 7489 accuray : 0.9245956731779038  loss : 0.2828768949872437\n",
      "iterations 7490 accuray : 0.9245956731779038  loss : 0.2828691124998508\n",
      "iterations 7491 accuray : 0.9245956731779038  loss : 0.2828604413879022\n",
      "iterations 7492 accuray : 0.9245956731779038  loss : 0.2828523398118409\n",
      "iterations 7493 accuray : 0.9245956731779038  loss : 0.2828440136164561\n",
      "iterations 7494 accuray : 0.9245956731779038  loss : 0.28283639051113696\n",
      "iterations 7495 accuray : 0.9245956731779038  loss : 0.28282844856705647\n",
      "iterations 7496 accuray : 0.9245956731779038  loss : 0.28282058702307994\n",
      "iterations 7497 accuray : 0.9245956731779038  loss : 0.2828128833925436\n",
      "iterations 7498 accuray : 0.9245956731779038  loss : 0.2828046831169653\n",
      "iterations 7499 accuray : 0.9245956731779038  loss : 0.2827962360484611\n",
      "iterations 7500 accuray : 0.9245956731779038  loss : 0.2827885135113081\n",
      "iterations 7501 accuray : 0.9245956731779038  loss : 0.2827803607230151\n",
      "iterations 7502 accuray : 0.9245956731779038  loss : 0.28277197375781393\n",
      "iterations 7503 accuray : 0.9245956731779038  loss : 0.28276386475188414\n",
      "iterations 7504 accuray : 0.9243856332703214  loss : 0.28275557570192694\n",
      "iterations 7505 accuray : 0.9243856332703214  loss : 0.2827480942201209\n",
      "iterations 7506 accuray : 0.9243856332703214  loss : 0.2827397718505129\n",
      "iterations 7507 accuray : 0.9243856332703214  loss : 0.28273173697332743\n",
      "iterations 7508 accuray : 0.9245956731779038  loss : 0.2827240210666251\n",
      "iterations 7509 accuray : 0.9245956731779038  loss : 0.2827158814296389\n",
      "iterations 7510 accuray : 0.9243856332703214  loss : 0.2827073548462024\n",
      "iterations 7511 accuray : 0.9243856332703214  loss : 0.28269910786075697\n",
      "iterations 7512 accuray : 0.9243856332703214  loss : 0.2826912978896563\n",
      "iterations 7513 accuray : 0.9241755933627389  loss : 0.2826829024924974\n",
      "iterations 7514 accuray : 0.9241755933627389  loss : 0.28267440308337605\n",
      "iterations 7515 accuray : 0.9241755933627389  loss : 0.28266617011699935\n",
      "iterations 7516 accuray : 0.9241755933627389  loss : 0.28265799896627036\n",
      "iterations 7517 accuray : 0.9243856332703214  loss : 0.2826502167204664\n",
      "iterations 7518 accuray : 0.9241755933627389  loss : 0.282641577853653\n",
      "iterations 7519 accuray : 0.9241755933627389  loss : 0.2826333179093775\n",
      "iterations 7520 accuray : 0.9241755933627389  loss : 0.2826253566012617\n",
      "iterations 7521 accuray : 0.9241755933627389  loss : 0.2826177404244846\n",
      "iterations 7522 accuray : 0.9241755933627389  loss : 0.28260952319643345\n",
      "iterations 7523 accuray : 0.9241755933627389  loss : 0.2826015176337224\n",
      "iterations 7524 accuray : 0.9243856332703214  loss : 0.2825937344726988\n",
      "iterations 7525 accuray : 0.9241755933627389  loss : 0.28258565622050336\n",
      "iterations 7526 accuray : 0.9243856332703214  loss : 0.2825779491906831\n",
      "iterations 7527 accuray : 0.9241755933627389  loss : 0.28256983332343916\n",
      "iterations 7528 accuray : 0.9243856332703214  loss : 0.2825617945956783\n",
      "iterations 7529 accuray : 0.9241755933627389  loss : 0.28255342800050953\n",
      "iterations 7530 accuray : 0.9241755933627389  loss : 0.2825451693920488\n",
      "iterations 7531 accuray : 0.9241755933627389  loss : 0.2825374350999961\n",
      "iterations 7532 accuray : 0.9243856332703214  loss : 0.282529766348271\n",
      "iterations 7533 accuray : 0.9241755933627389  loss : 0.28252180103910884\n",
      "iterations 7534 accuray : 0.9243856332703214  loss : 0.2825139959129458\n",
      "iterations 7535 accuray : 0.9241755933627389  loss : 0.28250581201041586\n",
      "iterations 7536 accuray : 0.9241755933627389  loss : 0.28249763875327083\n",
      "iterations 7537 accuray : 0.9241755933627389  loss : 0.2824901262144294\n",
      "iterations 7538 accuray : 0.9241755933627389  loss : 0.2824822982691337\n",
      "iterations 7539 accuray : 0.9241755933627389  loss : 0.2824744253634305\n",
      "iterations 7540 accuray : 0.9241755933627389  loss : 0.28246678794078134\n",
      "iterations 7541 accuray : 0.9241755933627389  loss : 0.2824587647499033\n",
      "iterations 7542 accuray : 0.9241755933627389  loss : 0.28245063759198674\n",
      "iterations 7543 accuray : 0.9241755933627389  loss : 0.28244258141416495\n",
      "iterations 7544 accuray : 0.9241755933627389  loss : 0.2824343862276312\n",
      "iterations 7545 accuray : 0.9241755933627389  loss : 0.2824261007897447\n",
      "iterations 7546 accuray : 0.9241755933627389  loss : 0.2824183163111388\n",
      "iterations 7547 accuray : 0.9241755933627389  loss : 0.28241094916422516\n",
      "iterations 7548 accuray : 0.9241755933627389  loss : 0.2824030775861257\n",
      "iterations 7549 accuray : 0.9241755933627389  loss : 0.2823957217039491\n",
      "iterations 7550 accuray : 0.9241755933627389  loss : 0.2823877435897334\n",
      "iterations 7551 accuray : 0.9243856332703214  loss : 0.28238012218454944\n",
      "iterations 7552 accuray : 0.9245956731779038  loss : 0.28237299782806474\n",
      "iterations 7553 accuray : 0.9245956731779038  loss : 0.28236506599837063\n",
      "iterations 7554 accuray : 0.9245956731779038  loss : 0.2823572308282931\n",
      "iterations 7555 accuray : 0.9243856332703214  loss : 0.2823490908057903\n",
      "iterations 7556 accuray : 0.9243856332703214  loss : 0.28234095066208076\n",
      "iterations 7557 accuray : 0.9243856332703214  loss : 0.2823330239232955\n",
      "iterations 7558 accuray : 0.9245956731779038  loss : 0.2823257149983085\n",
      "iterations 7559 accuray : 0.9245956731779038  loss : 0.28231774375005264\n",
      "iterations 7560 accuray : 0.9245956731779038  loss : 0.2823100008730796\n",
      "iterations 7561 accuray : 0.9245956731779038  loss : 0.2823022188286321\n",
      "iterations 7562 accuray : 0.9245956731779038  loss : 0.28229441559809415\n",
      "iterations 7563 accuray : 0.9245956731779038  loss : 0.28228654175992834\n",
      "iterations 7564 accuray : 0.9245956731779038  loss : 0.28227875362489085\n",
      "iterations 7565 accuray : 0.9245956731779038  loss : 0.2822708835781224\n",
      "iterations 7566 accuray : 0.9245956731779038  loss : 0.2822629526029499\n",
      "iterations 7567 accuray : 0.9245956731779038  loss : 0.282255320232443\n",
      "iterations 7568 accuray : 0.9245956731779038  loss : 0.2822468852794819\n",
      "iterations 7569 accuray : 0.9245956731779038  loss : 0.2822391471088818\n",
      "iterations 7570 accuray : 0.9245956731779038  loss : 0.28223098402414926\n",
      "iterations 7571 accuray : 0.9245956731779038  loss : 0.2822227306840739\n",
      "iterations 7572 accuray : 0.9243856332703214  loss : 0.28221487842923426\n",
      "iterations 7573 accuray : 0.9243856332703214  loss : 0.28220686118095656\n",
      "iterations 7574 accuray : 0.9241755933627389  loss : 0.28219865370701275\n",
      "iterations 7575 accuray : 0.9241755933627389  loss : 0.2821905945841158\n",
      "iterations 7576 accuray : 0.9241755933627389  loss : 0.2821824851851632\n",
      "iterations 7577 accuray : 0.9241755933627389  loss : 0.2821744490479354\n",
      "iterations 7578 accuray : 0.9241755933627389  loss : 0.28216642001635134\n",
      "iterations 7579 accuray : 0.9243856332703214  loss : 0.2821587514876996\n",
      "iterations 7580 accuray : 0.9241755933627389  loss : 0.282150944534531\n",
      "iterations 7581 accuray : 0.9243856332703214  loss : 0.2821428977398106\n",
      "iterations 7582 accuray : 0.9245956731779038  loss : 0.2821351296263616\n",
      "iterations 7583 accuray : 0.9245956731779038  loss : 0.28212720961340365\n",
      "iterations 7584 accuray : 0.9245956731779038  loss : 0.28211973699950454\n",
      "iterations 7585 accuray : 0.9245956731779038  loss : 0.2821120921436568\n",
      "iterations 7586 accuray : 0.9245956731779038  loss : 0.2821039334775518\n",
      "iterations 7587 accuray : 0.9245956731779038  loss : 0.2820957227104879\n",
      "iterations 7588 accuray : 0.9245956731779038  loss : 0.2820879709040874\n",
      "iterations 7589 accuray : 0.9243856332703214  loss : 0.28207970729621634\n",
      "iterations 7590 accuray : 0.9243856332703214  loss : 0.2820718325968831\n",
      "iterations 7591 accuray : 0.9245956731779038  loss : 0.28206435571970706\n",
      "iterations 7592 accuray : 0.9245956731779038  loss : 0.2820566840590688\n",
      "iterations 7593 accuray : 0.9245956731779038  loss : 0.28204890999817744\n",
      "iterations 7594 accuray : 0.9245956731779038  loss : 0.28204051561999394\n",
      "iterations 7595 accuray : 0.9245956731779038  loss : 0.2820326990110782\n",
      "iterations 7596 accuray : 0.9243856332703214  loss : 0.2820241821185828\n",
      "iterations 7597 accuray : 0.9243856332703214  loss : 0.2820164068846629\n",
      "iterations 7598 accuray : 0.9243856332703214  loss : 0.2820086501613127\n",
      "iterations 7599 accuray : 0.9241755933627389  loss : 0.28200013645208816\n",
      "iterations 7600 accuray : 0.9243856332703214  loss : 0.2819923110015831\n",
      "iterations 7601 accuray : 0.9243856332703214  loss : 0.281984690878396\n",
      "iterations 7602 accuray : 0.9245956731779038  loss : 0.2819771893379926\n",
      "iterations 7603 accuray : 0.9245956731779038  loss : 0.28196979857491156\n",
      "iterations 7604 accuray : 0.9243856332703214  loss : 0.2819616879355529\n",
      "iterations 7605 accuray : 0.9243856332703214  loss : 0.2819534505316403\n",
      "iterations 7606 accuray : 0.9241755933627389  loss : 0.281945591885984\n",
      "iterations 7607 accuray : 0.9241755933627389  loss : 0.28193768202747044\n",
      "iterations 7608 accuray : 0.9241755933627389  loss : 0.2819293161989173\n",
      "iterations 7609 accuray : 0.9241755933627389  loss : 0.2819219227041258\n",
      "iterations 7610 accuray : 0.9241755933627389  loss : 0.2819142166687779\n",
      "iterations 7611 accuray : 0.9245956731779038  loss : 0.2819070085276239\n",
      "iterations 7612 accuray : 0.9241755933627389  loss : 0.2818986994827907\n",
      "iterations 7613 accuray : 0.9241755933627389  loss : 0.2818903078114759\n",
      "iterations 7614 accuray : 0.9241755933627389  loss : 0.28188244160637443\n",
      "iterations 7615 accuray : 0.9241755933627389  loss : 0.2818747061947954\n",
      "iterations 7616 accuray : 0.9241755933627389  loss : 0.28186652124736583\n",
      "iterations 7617 accuray : 0.9241755933627389  loss : 0.28185881618916414\n",
      "iterations 7618 accuray : 0.9241755933627389  loss : 0.2818512179990487\n",
      "iterations 7619 accuray : 0.9241755933627389  loss : 0.2818434350138413\n",
      "iterations 7620 accuray : 0.9241755933627389  loss : 0.281834944072614\n",
      "iterations 7621 accuray : 0.9241755933627389  loss : 0.2818267962931945\n",
      "iterations 7622 accuray : 0.9241755933627389  loss : 0.28181883953789383\n",
      "iterations 7623 accuray : 0.9241755933627389  loss : 0.28181125452204664\n",
      "iterations 7624 accuray : 0.9241755933627389  loss : 0.28180360882111544\n",
      "iterations 7625 accuray : 0.9241755933627389  loss : 0.28179564411935154\n",
      "iterations 7626 accuray : 0.9241755933627389  loss : 0.28178800894431677\n",
      "iterations 7627 accuray : 0.9241755933627389  loss : 0.2817799971287911\n",
      "iterations 7628 accuray : 0.9241755933627389  loss : 0.28177212518179545\n",
      "iterations 7629 accuray : 0.9241755933627389  loss : 0.281764017383995\n",
      "iterations 7630 accuray : 0.9241755933627389  loss : 0.2817559888929698\n",
      "iterations 7631 accuray : 0.9241755933627389  loss : 0.2817479856209066\n",
      "iterations 7632 accuray : 0.9241755933627389  loss : 0.2817400165703836\n",
      "iterations 7633 accuray : 0.9241755933627389  loss : 0.2817320292653422\n",
      "iterations 7634 accuray : 0.9241755933627389  loss : 0.2817238158041785\n",
      "iterations 7635 accuray : 0.9241755933627389  loss : 0.28171588091475447\n",
      "iterations 7636 accuray : 0.9241755933627389  loss : 0.2817084819112167\n",
      "iterations 7637 accuray : 0.9241755933627389  loss : 0.2817005783766766\n",
      "iterations 7638 accuray : 0.9241755933627389  loss : 0.2816927399326137\n",
      "iterations 7639 accuray : 0.9241755933627389  loss : 0.2816852619101213\n",
      "iterations 7640 accuray : 0.9241755933627389  loss : 0.28167735812864025\n",
      "iterations 7641 accuray : 0.9241755933627389  loss : 0.28166937905315287\n",
      "iterations 7642 accuray : 0.9241755933627389  loss : 0.28166152720561566\n",
      "iterations 7643 accuray : 0.9241755933627389  loss : 0.2816535102492369\n",
      "iterations 7644 accuray : 0.9241755933627389  loss : 0.28164546069476976\n",
      "iterations 7645 accuray : 0.9241755933627389  loss : 0.2816375872426253\n",
      "iterations 7646 accuray : 0.9241755933627389  loss : 0.2816293907904155\n",
      "iterations 7647 accuray : 0.9241755933627389  loss : 0.281621538301187\n",
      "iterations 7648 accuray : 0.9241755933627389  loss : 0.2816138505635826\n",
      "iterations 7649 accuray : 0.9241755933627389  loss : 0.28160576553327005\n",
      "iterations 7650 accuray : 0.9241755933627389  loss : 0.28159776652499485\n",
      "iterations 7651 accuray : 0.9241755933627389  loss : 0.2815896052384721\n",
      "iterations 7652 accuray : 0.9241755933627389  loss : 0.28158151158053507\n",
      "iterations 7653 accuray : 0.9241755933627389  loss : 0.28157347611674066\n",
      "iterations 7654 accuray : 0.9241755933627389  loss : 0.2815648557090371\n",
      "iterations 7655 accuray : 0.9241755933627389  loss : 0.2815571489273146\n",
      "iterations 7656 accuray : 0.9241755933627389  loss : 0.2815489290318657\n",
      "iterations 7657 accuray : 0.9241755933627389  loss : 0.2815412871865035\n",
      "iterations 7658 accuray : 0.9241755933627389  loss : 0.28153345788391876\n",
      "iterations 7659 accuray : 0.9241755933627389  loss : 0.2815256704615273\n",
      "iterations 7660 accuray : 0.9241755933627389  loss : 0.2815176474938914\n",
      "iterations 7661 accuray : 0.9241755933627389  loss : 0.2815099346563042\n",
      "iterations 7662 accuray : 0.9241755933627389  loss : 0.28150229902333324\n",
      "iterations 7663 accuray : 0.9241755933627389  loss : 0.28149412287580944\n",
      "iterations 7664 accuray : 0.9241755933627389  loss : 0.2814865097122648\n",
      "iterations 7665 accuray : 0.9241755933627389  loss : 0.28147861477552616\n",
      "iterations 7666 accuray : 0.9241755933627389  loss : 0.28147026417621357\n",
      "iterations 7667 accuray : 0.9241755933627389  loss : 0.28146261602768696\n",
      "iterations 7668 accuray : 0.9241755933627389  loss : 0.2814548119640619\n",
      "iterations 7669 accuray : 0.9241755933627389  loss : 0.28144721365013425\n",
      "iterations 7670 accuray : 0.9241755933627389  loss : 0.2814393724966762\n",
      "iterations 7671 accuray : 0.9241755933627389  loss : 0.28143174226040246\n",
      "iterations 7672 accuray : 0.9241755933627389  loss : 0.281424422079482\n",
      "iterations 7673 accuray : 0.9241755933627389  loss : 0.2814169060572643\n",
      "iterations 7674 accuray : 0.9241755933627389  loss : 0.2814094716136536\n",
      "iterations 7675 accuray : 0.9241755933627389  loss : 0.28140181688476684\n",
      "iterations 7676 accuray : 0.9241755933627389  loss : 0.2813939491359833\n",
      "iterations 7677 accuray : 0.9241755933627389  loss : 0.2813862495718718\n",
      "iterations 7678 accuray : 0.9241755933627389  loss : 0.281378410250995\n",
      "iterations 7679 accuray : 0.9241755933627389  loss : 0.2813704858030036\n",
      "iterations 7680 accuray : 0.9241755933627389  loss : 0.2813628186646859\n",
      "iterations 7681 accuray : 0.9241755933627389  loss : 0.2813550247778659\n",
      "iterations 7682 accuray : 0.9241755933627389  loss : 0.28134726494386014\n",
      "iterations 7683 accuray : 0.9241755933627389  loss : 0.2813396758832002\n",
      "iterations 7684 accuray : 0.9241755933627389  loss : 0.2813316039641198\n",
      "iterations 7685 accuray : 0.9241755933627389  loss : 0.28132375338089893\n",
      "iterations 7686 accuray : 0.9241755933627389  loss : 0.28131537589874006\n",
      "iterations 7687 accuray : 0.9241755933627389  loss : 0.28130762510919277\n",
      "iterations 7688 accuray : 0.9241755933627389  loss : 0.28129988540259837\n",
      "iterations 7689 accuray : 0.9241755933627389  loss : 0.2812920035297074\n",
      "iterations 7690 accuray : 0.9241755933627389  loss : 0.2812844432699434\n",
      "iterations 7691 accuray : 0.9241755933627389  loss : 0.2812770584979198\n",
      "iterations 7692 accuray : 0.9241755933627389  loss : 0.2812692684096501\n",
      "iterations 7693 accuray : 0.9241755933627389  loss : 0.281261810609031\n",
      "iterations 7694 accuray : 0.9241755933627389  loss : 0.2812537740935374\n",
      "iterations 7695 accuray : 0.9241755933627389  loss : 0.28124586457065054\n",
      "iterations 7696 accuray : 0.9241755933627389  loss : 0.28123806329875617\n",
      "iterations 7697 accuray : 0.9241755933627389  loss : 0.28123048060657146\n",
      "iterations 7698 accuray : 0.9241755933627389  loss : 0.28122297055574563\n",
      "iterations 7699 accuray : 0.9241755933627389  loss : 0.2812149857454511\n",
      "iterations 7700 accuray : 0.9241755933627389  loss : 0.2812076448423134\n",
      "iterations 7701 accuray : 0.9241755933627389  loss : 0.2812000562631892\n",
      "iterations 7702 accuray : 0.9239655534551565  loss : 0.2811919411547843\n",
      "iterations 7703 accuray : 0.9239655534551565  loss : 0.28118424205575643\n",
      "iterations 7704 accuray : 0.9241755933627389  loss : 0.281176548857589\n",
      "iterations 7705 accuray : 0.9241755933627389  loss : 0.28116891975927294\n",
      "iterations 7706 accuray : 0.9241755933627389  loss : 0.28116135267786874\n",
      "iterations 7707 accuray : 0.9241755933627389  loss : 0.28115330196038907\n",
      "iterations 7708 accuray : 0.9241755933627389  loss : 0.2811454905986682\n",
      "iterations 7709 accuray : 0.9241755933627389  loss : 0.2811377041883775\n",
      "iterations 7710 accuray : 0.9241755933627389  loss : 0.28112950458919994\n",
      "iterations 7711 accuray : 0.9239655534551565  loss : 0.28112175009402535\n",
      "iterations 7712 accuray : 0.9239655534551565  loss : 0.28111377053507813\n",
      "iterations 7713 accuray : 0.9239655534551565  loss : 0.2811064285678513\n",
      "iterations 7714 accuray : 0.9239655534551565  loss : 0.28109896438319043\n",
      "iterations 7715 accuray : 0.9241755933627389  loss : 0.2810914910520941\n",
      "iterations 7716 accuray : 0.9241755933627389  loss : 0.2810839682244187\n",
      "iterations 7717 accuray : 0.9239655534551565  loss : 0.28107629316208566\n",
      "iterations 7718 accuray : 0.9239655534551565  loss : 0.28106861094291646\n",
      "iterations 7719 accuray : 0.9239655534551565  loss : 0.2810605884664054\n",
      "iterations 7720 accuray : 0.9239655534551565  loss : 0.2810530239286981\n",
      "iterations 7721 accuray : 0.9239655534551565  loss : 0.2810450039068766\n",
      "iterations 7722 accuray : 0.9239655534551565  loss : 0.28103715421391146\n",
      "iterations 7723 accuray : 0.9239655534551565  loss : 0.28102947037629805\n",
      "iterations 7724 accuray : 0.9239655534551565  loss : 0.2810218561118416\n",
      "iterations 7725 accuray : 0.9239655534551565  loss : 0.281013820577999\n",
      "iterations 7726 accuray : 0.9239655534551565  loss : 0.28100597152466755\n",
      "iterations 7727 accuray : 0.9241755933627389  loss : 0.280998133820181\n",
      "iterations 7728 accuray : 0.9239655534551565  loss : 0.28099039295985934\n",
      "iterations 7729 accuray : 0.9239655534551565  loss : 0.2809823365772227\n",
      "iterations 7730 accuray : 0.9241755933627389  loss : 0.2809739602068855\n",
      "iterations 7731 accuray : 0.9241755933627389  loss : 0.28096636627186417\n",
      "iterations 7732 accuray : 0.9241755933627389  loss : 0.28095872493041996\n",
      "iterations 7733 accuray : 0.9241755933627389  loss : 0.2809508424931186\n",
      "iterations 7734 accuray : 0.9241755933627389  loss : 0.2809431594513348\n",
      "iterations 7735 accuray : 0.9241755933627389  loss : 0.2809358770080639\n",
      "iterations 7736 accuray : 0.9241755933627389  loss : 0.28092833825737645\n",
      "iterations 7737 accuray : 0.9241755933627389  loss : 0.28092071669516755\n",
      "iterations 7738 accuray : 0.9241755933627389  loss : 0.2809130579005682\n",
      "iterations 7739 accuray : 0.9241755933627389  loss : 0.280905376694375\n",
      "iterations 7740 accuray : 0.9241755933627389  loss : 0.2808976342705904\n",
      "iterations 7741 accuray : 0.9241755933627389  loss : 0.28089043895334626\n",
      "iterations 7742 accuray : 0.9241755933627389  loss : 0.280882696539912\n",
      "iterations 7743 accuray : 0.9241755933627389  loss : 0.280875179321093\n",
      "iterations 7744 accuray : 0.9241755933627389  loss : 0.2808674400991269\n",
      "iterations 7745 accuray : 0.9241755933627389  loss : 0.2808599616315771\n",
      "iterations 7746 accuray : 0.9241755933627389  loss : 0.2808523528715768\n",
      "iterations 7747 accuray : 0.9241755933627389  loss : 0.2808449042528373\n",
      "iterations 7748 accuray : 0.9241755933627389  loss : 0.28083704856756503\n",
      "iterations 7749 accuray : 0.9241755933627389  loss : 0.2808296214020261\n",
      "iterations 7750 accuray : 0.9241755933627389  loss : 0.2808218378930132\n",
      "iterations 7751 accuray : 0.9241755933627389  loss : 0.28081415294691026\n",
      "iterations 7752 accuray : 0.9241755933627389  loss : 0.2808066356625551\n",
      "iterations 7753 accuray : 0.9241755933627389  loss : 0.28079901567224796\n",
      "iterations 7754 accuray : 0.9241755933627389  loss : 0.2807914050265683\n",
      "iterations 7755 accuray : 0.9241755933627389  loss : 0.28078326789423985\n",
      "iterations 7756 accuray : 0.9241755933627389  loss : 0.2807751797030586\n",
      "iterations 7757 accuray : 0.9241755933627389  loss : 0.28076746778230327\n",
      "iterations 7758 accuray : 0.9241755933627389  loss : 0.2807596993265122\n",
      "iterations 7759 accuray : 0.9241755933627389  loss : 0.28075160734525506\n",
      "iterations 7760 accuray : 0.9241755933627389  loss : 0.2807439489014201\n",
      "iterations 7761 accuray : 0.9241755933627389  loss : 0.28073651475653705\n",
      "iterations 7762 accuray : 0.9241755933627389  loss : 0.2807284556435028\n",
      "iterations 7763 accuray : 0.9241755933627389  loss : 0.2807205006008148\n",
      "iterations 7764 accuray : 0.9241755933627389  loss : 0.28071319122198457\n",
      "iterations 7765 accuray : 0.9241755933627389  loss : 0.28070586147047244\n",
      "iterations 7766 accuray : 0.9241755933627389  loss : 0.28069882168924626\n",
      "iterations 7767 accuray : 0.9241755933627389  loss : 0.28069098371943113\n",
      "iterations 7768 accuray : 0.9241755933627389  loss : 0.2806834133606259\n",
      "iterations 7769 accuray : 0.9241755933627389  loss : 0.28067590064114445\n",
      "iterations 7770 accuray : 0.9241755933627389  loss : 0.28066822446615675\n",
      "iterations 7771 accuray : 0.9241755933627389  loss : 0.28066046487685326\n",
      "iterations 7772 accuray : 0.9241755933627389  loss : 0.28065309584745984\n",
      "iterations 7773 accuray : 0.9241755933627389  loss : 0.2806455213771786\n",
      "iterations 7774 accuray : 0.9241755933627389  loss : 0.2806380080044451\n",
      "iterations 7775 accuray : 0.9241755933627389  loss : 0.2806298695895094\n",
      "iterations 7776 accuray : 0.9241755933627389  loss : 0.2806221648754499\n",
      "iterations 7777 accuray : 0.9241755933627389  loss : 0.2806146697889749\n",
      "iterations 7778 accuray : 0.9241755933627389  loss : 0.2806070805766633\n",
      "iterations 7779 accuray : 0.9241755933627389  loss : 0.2805998414218893\n",
      "iterations 7780 accuray : 0.9241755933627389  loss : 0.2805924048213683\n",
      "iterations 7781 accuray : 0.9241755933627389  loss : 0.28058408797579815\n",
      "iterations 7782 accuray : 0.9241755933627389  loss : 0.28057635247972734\n",
      "iterations 7783 accuray : 0.9241755933627389  loss : 0.2805692340354892\n",
      "iterations 7784 accuray : 0.9241755933627389  loss : 0.28056123543907235\n",
      "iterations 7785 accuray : 0.9241755933627389  loss : 0.2805535744530632\n",
      "iterations 7786 accuray : 0.9241755933627389  loss : 0.2805459139651565\n",
      "iterations 7787 accuray : 0.9241755933627389  loss : 0.2805379956243768\n",
      "iterations 7788 accuray : 0.9241755933627389  loss : 0.28053035200143456\n",
      "iterations 7789 accuray : 0.9241755933627389  loss : 0.28052266914424556\n",
      "iterations 7790 accuray : 0.9241755933627389  loss : 0.28051522593777267\n",
      "iterations 7791 accuray : 0.9241755933627389  loss : 0.280507603191442\n",
      "iterations 7792 accuray : 0.9241755933627389  loss : 0.2805002983230648\n",
      "iterations 7793 accuray : 0.9241755933627389  loss : 0.2804927231986783\n",
      "iterations 7794 accuray : 0.9241755933627389  loss : 0.28048526602121904\n",
      "iterations 7795 accuray : 0.9241755933627389  loss : 0.28047796640449746\n",
      "iterations 7796 accuray : 0.9241755933627389  loss : 0.280470879151706\n",
      "iterations 7797 accuray : 0.9241755933627389  loss : 0.28046310889950204\n",
      "iterations 7798 accuray : 0.9241755933627389  loss : 0.28045594778160515\n",
      "iterations 7799 accuray : 0.9241755933627389  loss : 0.28044838420542134\n",
      "iterations 7800 accuray : 0.9241755933627389  loss : 0.2804405293458063\n",
      "iterations 7801 accuray : 0.9241755933627389  loss : 0.28043264687541036\n",
      "iterations 7802 accuray : 0.9241755933627389  loss : 0.2804253127359712\n",
      "iterations 7803 accuray : 0.9241755933627389  loss : 0.28041741238884943\n",
      "iterations 7804 accuray : 0.9241755933627389  loss : 0.2804100213143855\n",
      "iterations 7805 accuray : 0.9241755933627389  loss : 0.2804024245671849\n",
      "iterations 7806 accuray : 0.9241755933627389  loss : 0.28039482170230373\n",
      "iterations 7807 accuray : 0.9241755933627389  loss : 0.2803874731070665\n",
      "iterations 7808 accuray : 0.9241755933627389  loss : 0.28037966425787214\n",
      "iterations 7809 accuray : 0.9241755933627389  loss : 0.28037204162680884\n",
      "iterations 7810 accuray : 0.9241755933627389  loss : 0.28036442592018535\n",
      "iterations 7811 accuray : 0.9241755933627389  loss : 0.28035680403549046\n",
      "iterations 7812 accuray : 0.9241755933627389  loss : 0.2803493260544583\n",
      "iterations 7813 accuray : 0.9241755933627389  loss : 0.28034245278780134\n",
      "iterations 7814 accuray : 0.9241755933627389  loss : 0.28033484737466924\n",
      "iterations 7815 accuray : 0.9241755933627389  loss : 0.2803275484953669\n",
      "iterations 7816 accuray : 0.9241755933627389  loss : 0.28032030529515456\n",
      "iterations 7817 accuray : 0.9241755933627389  loss : 0.2803129305447079\n",
      "iterations 7818 accuray : 0.9241755933627389  loss : 0.2803053078075196\n",
      "iterations 7819 accuray : 0.9241755933627389  loss : 0.2802977671656957\n",
      "iterations 7820 accuray : 0.9241755933627389  loss : 0.2802898046172288\n",
      "iterations 7821 accuray : 0.9241755933627389  loss : 0.2802825109508995\n",
      "iterations 7822 accuray : 0.9241755933627389  loss : 0.2802748777028545\n",
      "iterations 7823 accuray : 0.9241755933627389  loss : 0.2802672325845245\n",
      "iterations 7824 accuray : 0.9241755933627389  loss : 0.2802601394092433\n",
      "iterations 7825 accuray : 0.9241755933627389  loss : 0.28025203508808766\n",
      "iterations 7826 accuray : 0.9241755933627389  loss : 0.2802445026907221\n",
      "iterations 7827 accuray : 0.9241755933627389  loss : 0.2802364102615488\n",
      "iterations 7828 accuray : 0.9241755933627389  loss : 0.2802287116016641\n",
      "iterations 7829 accuray : 0.9241755933627389  loss : 0.2802211636091769\n",
      "iterations 7830 accuray : 0.9241755933627389  loss : 0.28021320953271567\n",
      "iterations 7831 accuray : 0.9241755933627389  loss : 0.2802055928806819\n",
      "iterations 7832 accuray : 0.9241755933627389  loss : 0.2801980125069949\n",
      "iterations 7833 accuray : 0.9241755933627389  loss : 0.28019054145272704\n",
      "iterations 7834 accuray : 0.9241755933627389  loss : 0.2801832773872334\n",
      "iterations 7835 accuray : 0.9241755933627389  loss : 0.2801755555018671\n",
      "iterations 7836 accuray : 0.9241755933627389  loss : 0.2801677237324287\n",
      "iterations 7837 accuray : 0.9241755933627389  loss : 0.280159817805901\n",
      "iterations 7838 accuray : 0.9241755933627389  loss : 0.28015222200296497\n",
      "iterations 7839 accuray : 0.9241755933627389  loss : 0.2801447180890777\n",
      "iterations 7840 accuray : 0.9241755933627389  loss : 0.2801369812853477\n",
      "iterations 7841 accuray : 0.9241755933627389  loss : 0.28012925073616485\n",
      "iterations 7842 accuray : 0.9241755933627389  loss : 0.2801215191176219\n",
      "iterations 7843 accuray : 0.9241755933627389  loss : 0.28011401628723726\n",
      "iterations 7844 accuray : 0.9241755933627389  loss : 0.2801070241044406\n",
      "iterations 7845 accuray : 0.9241755933627389  loss : 0.2800996538296616\n",
      "iterations 7846 accuray : 0.9241755933627389  loss : 0.2800924579478575\n",
      "iterations 7847 accuray : 0.9241755933627389  loss : 0.2800851154393368\n",
      "iterations 7848 accuray : 0.9241755933627389  loss : 0.28007769996328435\n",
      "iterations 7849 accuray : 0.9241755933627389  loss : 0.28007013279341153\n",
      "iterations 7850 accuray : 0.9241755933627389  loss : 0.28006273089946326\n",
      "iterations 7851 accuray : 0.9241755933627389  loss : 0.2800554748348438\n",
      "iterations 7852 accuray : 0.9241755933627389  loss : 0.2800477405427756\n",
      "iterations 7853 accuray : 0.9241755933627389  loss : 0.2800404362594806\n",
      "iterations 7854 accuray : 0.9241755933627389  loss : 0.2800326950869995\n",
      "iterations 7855 accuray : 0.9241755933627389  loss : 0.280025137944507\n",
      "iterations 7856 accuray : 0.9241755933627389  loss : 0.2800172160722149\n",
      "iterations 7857 accuray : 0.9241755933627389  loss : 0.2800098839930296\n",
      "iterations 7858 accuray : 0.9241755933627389  loss : 0.2800024328053169\n",
      "iterations 7859 accuray : 0.9241755933627389  loss : 0.2799951549597373\n",
      "iterations 7860 accuray : 0.9241755933627389  loss : 0.2799875955777512\n",
      "iterations 7861 accuray : 0.9241755933627389  loss : 0.2799792787032411\n",
      "iterations 7862 accuray : 0.9241755933627389  loss : 0.2799716327666923\n",
      "iterations 7863 accuray : 0.9241755933627389  loss : 0.27996439971718\n",
      "iterations 7864 accuray : 0.9241755933627389  loss : 0.27995715384114367\n",
      "iterations 7865 accuray : 0.9241755933627389  loss : 0.27994958628679006\n",
      "iterations 7866 accuray : 0.9241755933627389  loss : 0.27994173963491165\n",
      "iterations 7867 accuray : 0.9241755933627389  loss : 0.2799345510825442\n",
      "iterations 7868 accuray : 0.9241755933627389  loss : 0.2799270772011823\n",
      "iterations 7869 accuray : 0.9241755933627389  loss : 0.27991960983371383\n",
      "iterations 7870 accuray : 0.9241755933627389  loss : 0.279912311780272\n",
      "iterations 7871 accuray : 0.9241755933627389  loss : 0.2799048257713475\n",
      "iterations 7872 accuray : 0.9241755933627389  loss : 0.27989745017287965\n",
      "iterations 7873 accuray : 0.9241755933627389  loss : 0.2798905705359466\n",
      "iterations 7874 accuray : 0.9241755933627389  loss : 0.2798830562620078\n",
      "iterations 7875 accuray : 0.9241755933627389  loss : 0.27987592592956045\n",
      "iterations 7876 accuray : 0.9241755933627389  loss : 0.2798684068172958\n",
      "iterations 7877 accuray : 0.9241755933627389  loss : 0.27986100679561904\n",
      "iterations 7878 accuray : 0.9241755933627389  loss : 0.2798533772736283\n",
      "iterations 7879 accuray : 0.9241755933627389  loss : 0.27984606028013786\n",
      "iterations 7880 accuray : 0.9241755933627389  loss : 0.2798384613907075\n",
      "iterations 7881 accuray : 0.9241755933627389  loss : 0.2798306228924245\n",
      "iterations 7882 accuray : 0.9241755933627389  loss : 0.27982312767579154\n",
      "iterations 7883 accuray : 0.9241755933627389  loss : 0.27981554229330924\n",
      "iterations 7884 accuray : 0.9241755933627389  loss : 0.27980780718631315\n",
      "iterations 7885 accuray : 0.9241755933627389  loss : 0.2798002931223839\n",
      "iterations 7886 accuray : 0.9241755933627389  loss : 0.27979331069133045\n",
      "iterations 7887 accuray : 0.9241755933627389  loss : 0.27978570588871987\n",
      "iterations 7888 accuray : 0.9241755933627389  loss : 0.27977791511778727\n",
      "iterations 7889 accuray : 0.9241755933627389  loss : 0.27977015916687265\n",
      "iterations 7890 accuray : 0.9241755933627389  loss : 0.27976273705927335\n",
      "iterations 7891 accuray : 0.9241755933627389  loss : 0.27975502356293064\n",
      "iterations 7892 accuray : 0.9241755933627389  loss : 0.27974732499558086\n",
      "iterations 7893 accuray : 0.9241755933627389  loss : 0.2797393590736245\n",
      "iterations 7894 accuray : 0.9241755933627389  loss : 0.27973166986090997\n",
      "iterations 7895 accuray : 0.9241755933627389  loss : 0.2797241857804299\n",
      "iterations 7896 accuray : 0.9241755933627389  loss : 0.27971682753509025\n",
      "iterations 7897 accuray : 0.9241755933627389  loss : 0.27970942911073354\n",
      "iterations 7898 accuray : 0.9241755933627389  loss : 0.27970198541015934\n",
      "iterations 7899 accuray : 0.9241755933627389  loss : 0.2796948443054952\n",
      "iterations 7900 accuray : 0.9241755933627389  loss : 0.27968724320324584\n",
      "iterations 7901 accuray : 0.9241755933627389  loss : 0.27967988041702\n",
      "iterations 7902 accuray : 0.9241755933627389  loss : 0.2796724637185683\n",
      "iterations 7903 accuray : 0.9241755933627389  loss : 0.27966485237165284\n",
      "iterations 7904 accuray : 0.9241755933627389  loss : 0.2796571402719938\n",
      "iterations 7905 accuray : 0.9241755933627389  loss : 0.2796497621923857\n",
      "iterations 7906 accuray : 0.9241755933627389  loss : 0.27964187264542417\n",
      "iterations 7907 accuray : 0.9241755933627389  loss : 0.2796344492557109\n",
      "iterations 7908 accuray : 0.9241755933627389  loss : 0.2796267801568018\n",
      "iterations 7909 accuray : 0.9241755933627389  loss : 0.2796192021169053\n",
      "iterations 7910 accuray : 0.9241755933627389  loss : 0.2796117504547698\n",
      "iterations 7911 accuray : 0.9241755933627389  loss : 0.27960417136257293\n",
      "iterations 7912 accuray : 0.9241755933627389  loss : 0.2795966966804523\n",
      "iterations 7913 accuray : 0.9241755933627389  loss : 0.27958908398501464\n",
      "iterations 7914 accuray : 0.9241755933627389  loss : 0.2795818896342092\n",
      "iterations 7915 accuray : 0.9241755933627389  loss : 0.2795744690947854\n",
      "iterations 7916 accuray : 0.9241755933627389  loss : 0.27956702001482936\n",
      "iterations 7917 accuray : 0.9241755933627389  loss : 0.2795592546398611\n",
      "iterations 7918 accuray : 0.9241755933627389  loss : 0.2795517060959091\n",
      "iterations 7919 accuray : 0.9241755933627389  loss : 0.2795441798631588\n",
      "iterations 7920 accuray : 0.9241755933627389  loss : 0.27953682153944287\n",
      "iterations 7921 accuray : 0.9241755933627389  loss : 0.27952940722429\n",
      "iterations 7922 accuray : 0.9241755933627389  loss : 0.27952229629491926\n",
      "iterations 7923 accuray : 0.9241755933627389  loss : 0.27951542149112885\n",
      "iterations 7924 accuray : 0.9241755933627389  loss : 0.27950849084872753\n",
      "iterations 7925 accuray : 0.9241755933627389  loss : 0.2795007767289816\n",
      "iterations 7926 accuray : 0.9241755933627389  loss : 0.2794929692007942\n",
      "iterations 7927 accuray : 0.9241755933627389  loss : 0.2794857732465032\n",
      "iterations 7928 accuray : 0.9241755933627389  loss : 0.2794779839051216\n",
      "iterations 7929 accuray : 0.9241755933627389  loss : 0.279470452055966\n",
      "iterations 7930 accuray : 0.9241755933627389  loss : 0.2794627784572954\n",
      "iterations 7931 accuray : 0.9241755933627389  loss : 0.27945567233100554\n",
      "iterations 7932 accuray : 0.9241755933627389  loss : 0.27944829636203533\n",
      "iterations 7933 accuray : 0.9241755933627389  loss : 0.2794408765911653\n",
      "iterations 7934 accuray : 0.9241755933627389  loss : 0.2794338774190288\n",
      "iterations 7935 accuray : 0.9241755933627389  loss : 0.27942633433967734\n",
      "iterations 7936 accuray : 0.9241755933627389  loss : 0.2794184782011028\n",
      "iterations 7937 accuray : 0.9241755933627389  loss : 0.2794111257906569\n",
      "iterations 7938 accuray : 0.9241755933627389  loss : 0.27940357556242257\n",
      "iterations 7939 accuray : 0.9241755933627389  loss : 0.2793964396259244\n",
      "iterations 7940 accuray : 0.9241755933627389  loss : 0.27938906331881735\n",
      "iterations 7941 accuray : 0.9241755933627389  loss : 0.2793818683272617\n",
      "iterations 7942 accuray : 0.9241755933627389  loss : 0.27937447321497977\n",
      "iterations 7943 accuray : 0.9241755933627389  loss : 0.27936707962105156\n",
      "iterations 7944 accuray : 0.9241755933627389  loss : 0.2793595169248767\n",
      "iterations 7945 accuray : 0.9241755933627389  loss : 0.2793520628373864\n",
      "iterations 7946 accuray : 0.9241755933627389  loss : 0.27934445297476423\n",
      "iterations 7947 accuray : 0.9241755933627389  loss : 0.27933723641700825\n",
      "iterations 7948 accuray : 0.9241755933627389  loss : 0.27932956376202644\n",
      "iterations 7949 accuray : 0.9241755933627389  loss : 0.279322331966036\n",
      "iterations 7950 accuray : 0.9241755933627389  loss : 0.27931462522239947\n",
      "iterations 7951 accuray : 0.9241755933627389  loss : 0.27930748113774545\n",
      "iterations 7952 accuray : 0.9241755933627389  loss : 0.2792996969311798\n",
      "iterations 7953 accuray : 0.9241755933627389  loss : 0.27929195667424617\n",
      "iterations 7954 accuray : 0.9241755933627389  loss : 0.2792847860773678\n",
      "iterations 7955 accuray : 0.9241755933627389  loss : 0.2792774036048605\n",
      "iterations 7956 accuray : 0.9241755933627389  loss : 0.2792704070878526\n",
      "iterations 7957 accuray : 0.9241755933627389  loss : 0.2792631461717592\n",
      "iterations 7958 accuray : 0.9241755933627389  loss : 0.27925589583532995\n",
      "iterations 7959 accuray : 0.9241755933627389  loss : 0.27924827066450747\n",
      "iterations 7960 accuray : 0.9241755933627389  loss : 0.2792407204905412\n",
      "iterations 7961 accuray : 0.9241755933627389  loss : 0.279233344723286\n",
      "iterations 7962 accuray : 0.9241755933627389  loss : 0.27922612313076844\n",
      "iterations 7963 accuray : 0.9241755933627389  loss : 0.2792185950680515\n",
      "iterations 7964 accuray : 0.9241755933627389  loss : 0.2792108534654275\n",
      "iterations 7965 accuray : 0.9241755933627389  loss : 0.27920321971601353\n",
      "iterations 7966 accuray : 0.9241755933627389  loss : 0.2791958847807739\n",
      "iterations 7967 accuray : 0.9241755933627389  loss : 0.27918855072601395\n",
      "iterations 7968 accuray : 0.9241755933627389  loss : 0.2791813886668643\n",
      "iterations 7969 accuray : 0.9241755933627389  loss : 0.27917424823356146\n",
      "iterations 7970 accuray : 0.9241755933627389  loss : 0.2791665294979128\n",
      "iterations 7971 accuray : 0.9241755933627389  loss : 0.2791592230677823\n",
      "iterations 7972 accuray : 0.9241755933627389  loss : 0.2791517394106555\n",
      "iterations 7973 accuray : 0.9241755933627389  loss : 0.27914462690390357\n",
      "iterations 7974 accuray : 0.9241755933627389  loss : 0.2791377453867164\n",
      "iterations 7975 accuray : 0.9241755933627389  loss : 0.27913046624190296\n",
      "iterations 7976 accuray : 0.9241755933627389  loss : 0.27912283711786406\n",
      "iterations 7977 accuray : 0.9241755933627389  loss : 0.2791158369730735\n",
      "iterations 7978 accuray : 0.9241755933627389  loss : 0.2791086393015781\n",
      "iterations 7979 accuray : 0.9241755933627389  loss : 0.27910106808930907\n",
      "iterations 7980 accuray : 0.9241755933627389  loss : 0.2790941316015633\n",
      "iterations 7981 accuray : 0.9241755933627389  loss : 0.2790866186774125\n",
      "iterations 7982 accuray : 0.9241755933627389  loss : 0.27907934746012214\n",
      "iterations 7983 accuray : 0.9241755933627389  loss : 0.2790716023974958\n",
      "iterations 7984 accuray : 0.9241755933627389  loss : 0.27906414929536333\n",
      "iterations 7985 accuray : 0.9241755933627389  loss : 0.2790570483621685\n",
      "iterations 7986 accuray : 0.9241755933627389  loss : 0.27904955292985156\n",
      "iterations 7987 accuray : 0.9241755933627389  loss : 0.2790426063129932\n",
      "iterations 7988 accuray : 0.9241755933627389  loss : 0.2790351747216579\n",
      "iterations 7989 accuray : 0.9241755933627389  loss : 0.27902770155524614\n",
      "iterations 7990 accuray : 0.9241755933627389  loss : 0.2790204832028813\n",
      "iterations 7991 accuray : 0.9241755933627389  loss : 0.2790127649098251\n",
      "iterations 7992 accuray : 0.9241755933627389  loss : 0.2790056538266349\n",
      "iterations 7993 accuray : 0.9241755933627389  loss : 0.27899814539191536\n",
      "iterations 7994 accuray : 0.9241755933627389  loss : 0.2789912065893049\n",
      "iterations 7995 accuray : 0.9241755933627389  loss : 0.2789844754537047\n",
      "iterations 7996 accuray : 0.9241755933627389  loss : 0.27897682078549163\n",
      "iterations 7997 accuray : 0.9241755933627389  loss : 0.2789693478988795\n",
      "iterations 7998 accuray : 0.9241755933627389  loss : 0.27896241063659777\n",
      "iterations 7999 accuray : 0.9241755933627389  loss : 0.2789557580652469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegressionAssignment at 0x20755e362b0>"
      ]
     },
     "execution_count": 1564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegressionAssignment(iteration=8000, learning_rete=0.01, c=0.001, penalty='l2')\n",
    "clf2.fit(x_train, y_train, batch_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9241755933627389, 0.929471032745592)"
      ]
     },
     "execution_count": 1565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(x_train, y_train), clf2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(clf2.loss)), clf2.loss)\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = clf2.predict(x_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envtf",
   "language": "python",
   "name": "envtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
